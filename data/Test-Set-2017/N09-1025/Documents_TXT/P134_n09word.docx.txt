Edinburgh's Machine Translation Systems for European Language Pairs


Nadir Durrani, Barry Haddow, Kenneth Heafield, and Philipp Koehn
School of Informatics 
University of Edinburgh 
Scotland, United Kingdom
{dnadir,bhaddow,kheafiel,pkoehn}@inf.ed.ac.uk





Abstract

We validated various novel and recently 
proposed methods for statistical machine 
translation  on  10  language  pairs,  using 
large  data  resources.      We  saw  gains 
from optimizing parameters, training with 
sparse features, the operation sequence 
model, and domain adaptation techniques. 
We also report on utilizing a huge lan­ 
guage model trained on 126 billion tokens.

  The annual machine translation evaluation cam­ 
paign for European languages  organized around 
the ACL Workshop on Statistical Machine Trans­ 
lation offers the opportunity to test recent advance­ 
ments in machine translation in large data condi­ 
tion across several diverse language pairs.
  Building on our own developments and external 
contributions to the Moses open source toolkit, we 
carried out extensive experiments that, by early in­ 
dications, led to a strong showing in the evaluation 
campaign.
We would like to stress especially two contri­
butions: the use of the new operation sequence 
model (Section 3) within Moses, and-in a sepa­ 
rate unconstraint track submission -the use of a 
huge language model trained on 126 billion tokens 
with a new training tool (Section 4).

1 Initial System Development

We start with systems (Haddow and Koehn, 2012) 
that we developed for the 2012 Workshop on 
Statistical  Machine  Translation  (Callison-Burch 
et al., 2012). The notable features of these systems 
are:
• Moses phrase-based models with mostly de­
fault settings
• training on all available parallel data, includ­ 
ing the large UN parallel data, the French­ 
English 109  parallel data and the LDC Giga­ 
worddata


• very large tuning set consisting of the test sets 
from 2008-2010, with a total of 7,567 sen­ 
tences per language
• German-English     with      syntactic     pre­ 
reordering (Collins et al., 2005), compound 
splitting (Koehn and Knight, 2003) and use 
of factored representation for a POS target 
sequence model (Koehn and Hoang, 2007)
• English-German with morphological  target 
sequence model
  Note  that  while  our  final  2012  systems  in­ 
cluded subsarnpling of training data with modified 
Moore-Lewis filtering (Axelrod et al., 2011), we 
did not use such filtering at the slatting  point of 
our development. We will report on such filtering 
in Section 2.
  Moreover,   our  system  development  initially 
used the WMT 2012 data condition, since it took 
place throughout 2012, and we switched to WMT
2013 traitting data at a later stage.   In this sec­
tion, we report cased BLEU scores (Papineni et al.,
2001) on newstest20ll.

1.1   Factored Backoff (German-English)
We have consistently used factored models in past 
WMT systems for the German-English language 
pairs to include POS and morphological target se­ 
quence models.  But we did not use the factored 
decomposition  of translation  options into  multi­ 
ple mapping steps, since this usually lead to much 
slower systems with usually worse results.
A good place, however, for factored decompo­
sition is the handling of rare and unknown source 
words which have more frequent morphological 
variants (Koehn and Haddow, 2012a).  Here, we 
used ouly factored backoff for unknown words, 
giving gains in BLEU of +.12 for German-English.

1.2   Tuning with k-best MIRA
In preparation for training with sparse features, we 
moved away from MERT which is known to fall




114
Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 114-121,
Sofia, Bulgaria, August 8-9, 2013 @2013 Association for Computational  Unguistics


apart with many more than a couple of dozen fea­ 
tures. Instead, we used k-best MIRA (Cherry and 
Foster, 2012). For the different language pairs, we 
saw improvements in BLEU of -.05 to +.39, with an 
average of +.09. There was only a minimal change
in the length ratio (Table 1)


The lexical features  were restricted  to the 50 
most frequent  words.   All these features  
together  only gave minor improvements (Table 
3).




Table 1:Thning with k-best MIRA instead of MERT
(cased BLEU scores with length ratio)



1.3   Translation Table Smoothing with
Kneser-Ney Discounting

Previously,  we smoothed counts for the phrasal 
conditional probability distributions in the trans­ 
lation model with Good Turing discounting.  We 
explored  the use of Kneser-Ney  discounting, but 
resnlts  are  mixed  (no difference on  average,  see 
Table 2), so we did not pursue this further.


Table 3: Sparse 
features


  We also explored  domain  features  in the 
sparse feature framework, in three different  
variations. Assume that we have three 
domains, and a phrase pair occurs  in domain  
A 15 times, in domain  B 5 times, and in 
domain C never.
We compute three types of domain features:

• binary indicator, if phrase-pairs occurs in 
do­
main (example: indA = 1, indB = 1, indo 
= 0)
• ratio how frequent  the phrase pairs occurs in
domain (example: ratioA   = 1i!s = .75, ratioB  =
15   5  = .25, ratioc = 0)
• subset  of domains in which  phrase  pair  
oc­
curs  (example: subsetAB = 1, other subsets 0)

  We  tested  all  three  feature   types,  and  
found the biggest gain with the domain  
indicator feature (+.11, Table 4). Note that we 
define as domain the different  corpora  
(Europarl, etc.).  The number  of
domains ranges from 2 to 9 (see column #d).1




Table 2: Translation model smoothing with Kneser-Ney




1.4   Sparse Features

A significant  extension of the Moses  system  over 
the last couple of years was the support for large 
numbers  of sparse  features. This  year, we tested 
this capability on our big WMT systems.  First, we 
used features  proposed  by Chiang et al. (2009):

• phrase  pair count  bin features  (bins  1, 2, 3,
4-5, 6-9, 10+)
• target word insertion  features
• source word deletion  features
• word translation features
• phrase length feature  (source, target, both)








Table 4:Sparse domain features


  When combining the domain features and 
the other   sparse   features,   we  see  roughly   
additive gains (Table 5). We use the domain  
indicator fea­ ture and the other sparse features 
in subsequent ex­ periments.

  1In the final experiments on the 2013 data condition, 
one domain (commoncrawl) was added for all language 
pairs.




bas
elin
e
in
di
ca
to
r
r
a
t
i
o
s
u
b
s
e
t
de
-
en
fr
-
e
n
es
-
en 
cs
-
en 
en
-
de 
en
-fr 
en
-
es 
en
-
cs
22
.1
0
30
.1
1
30
.6
3
25
.4
9
1
6.
1
2
29
.6
5
31
.9
5
1
7.
4
2
22.
18 
+.0
8
30.
41 
+.3
0
30.
75 
+.1
2
25.
56 
+.0
7
15.
95
-
.17
29.
96 
+.3
1
32.
12 
+.1
7
17.
38
-
.04
22.
10 
±.0
0
30.
49 
+.3
8
30.
56
-
.07
25.
63 
+.1
4
15
.9
6-
.1
6
29.
88 
+.2
3
32.
16 
+.2
1
17
.3
5-
.0
7
22.
16
+.0
6
30.
36
+.2
5
30.
85 
+.2
2
25.
43-
.06
16.
05
-
.07
29.
92
+.2
7
32.
08 
+.2
3
17.
40
-
.02
avg
.

+
.
1
1
+
.
0
9
+
.
1
1



Table 5: Combining domain and other sparse features



1.5   Thning Settings

Given the opportunity to explore the parameter 
tuning of models with sparse features across many 
language pairs, we investigated a number of set­ 
tings. We expect tuning to work better with more 
iterations, longer n-best lists and bigger cube prun­ 
ing pop limits. Our baseline settings are 10 itera­ 
tions with 100-best lists (accumulating) and a pop 
limit ofI000 for tuning and 5000 for testing.


Table 7: Maximum phrase length, reduced from baseline


1.7    Unpruned Language Models
Previously, we trained 5-gram language models 
using the default settings of the SRILM toolkit in 
terms of singleton pruning. Thus, training throws 
out all singletons n-grams of order 3 and higher. 
We explored whether unpruned language models 
could give better performance, even if we are ouly 
able to train 4-gram models due to memory con­ 
straints. At the time, we were not able to build un­ 
pruned 4-gram language models for English, but 
for the other language pairs we did see improve­ 
ments of -.07 to +.13 (Table 8). We adopted such 
models for these language pairs.




5g
pru
ne
d
4gu
npr
une
d

en-
fr
en
-
es 
en
-
cs
2
9
.
8
9
3
2
.
2
7
1
7
.
4
1
2
9
.
8
3
3
2
.
3
4
1
7
.
5
4
.0
7
+.0
7
+.1
3

Table 8: Language models without singleton pruning



Table 6: Tuning settings (number of iterations, size of n-best
list, and cube pruning pup limit)


  Results support running tuning for 25 iterations 
but we see no gains for 5000 pops.  There is ev­ 
idence that ann-best list size of 1000 is better in 
tuning but we did not adopt this since these large 
lists take up a lot of disk space and slow down the 
MIRA optimization step (Table 6).


1.6   Smaller Phrases

Given the very large corpus sizes (up to a billion 
words  of  parallel data  for  French-Englisb),  the 
size of translation model and lexicalized reorder­ 
ing model becomes a challenge.  Hence, we want 
to examine if restriction to smaller phrases is fea­ 
sible without loss in translation quality.  Results 
in Table 7 suggest that a maximum phrase length 
of 5 gives almost identical results, and ouly with 
a phrase length limit of 4 significant losses occur. 
We adopted the limit of 5.



1.8   Translations per Input Phrase
Finally, we explored one more parameter: the limit 
on how many translation options are considered 
per input phrase. The default for this setting is 20. 
However, our experiments (Table 9) sbow that we 
can get better results with a translation table limit 
of I00, so we adopted this.


ttl
20
ttl
30
ttl 
50
ttll
OO
de
-
en
fr-
en 
es
-
en 
cs
-
en 
en
-
de 
en
-fr 
en
-
es
e
n-
cs
21.
05
30.
39
30.
86
25.
53
15.
97
29.
83
32.
34
17.
54
+.0
6
-
.0
2
±.0
0
+.2
4
+.0
3
+.1
4
+.0
8
-
.0
5
+.0
9
+.0
5
-
.0
3
+.1
3
+.0
7
+.1
9
+.1
0
-
.0
2
+.
01
+.
07
-
.0
7
+.
20
+.
11
+.
13
+.
07
+.
01
avg

+.0
6
+.0
7
+.
07

Table 9: Maximal number translations per input phrase


1.9   Other Experiments
We explored a number of other settings and fea­
tures, but did not observe any gains.



• Using  HMM   alignment   instead   of   IBM 
Model4 leads to losses of -.01 to -.27.
• An earlier check of modified Moore-Lewis 
filtering (see also below in Section 3) gave 
very inconsistent results.
• Filtering  the  phrase table  with significance 
filtering (Johnson eta!., 2007) leads to losses 
of -.19 to -.63.
• Throwing out phrase pairs with direct transla­
tion probability cf>( elf) of less than w-5 has
almost no effect.
• Double-checking   the   contribution   of   the 
sparse lexical features in the final setup, we 
observe an average losses of -.07 when drop­ 
ping these features.
• For the German-English language pairs we 
saw some benefits to using sparse lexical fea­ 
tures over POS tags instead of words, so we 
used this in the final system.

1.10   Summary
We adopted a number of changes that improved 
our baseline system by an average of +.30, see Ta­ 
ble 10 for a breakdown.

avg.	method
+.01 	factored backoff
+.09 	kbest MIRA
+.11 	sparse features and domain indicator
+.03 	tuning with 25 iterations
-.03	maximum phrase length 5
+.02 	unpruned4-gramLM
+.07     translation table limit 100
+.30 	total

Table 10: Summary of impact of clumges


  Minor improvements that we did not adopt was 
avoiding reducing maximum phrase length to 5 
(average +.03) and turting with 1000-best lists 
(+.02).
  The improvements differed significantly by lan­ 
guage  pair,  as  detailed  in  Table  11,  with  the 
biggest gains for English-French (+.70), no gain 
for English-German and no gain for English­ 
German.

1.11   New Data
The final experiment of the initial system devel­ 
opment phase was to train the systems on the new 
data, adding newstest2011 to the turting set (now
10,068 sentences).  Table 12 reports the gains on
newstest2012 due to added data, indicating very 
clearly that valuable new data resources became 
available this year.




bas
elin
e
imp
rov
ed
L
J
.
de-
en
fr-
en 
es
-
en 
cs
-
en 
en
-
de 
en
-fr 
en
-
es 
en
-
cs
2
1.
9
9
3
0.
0
0
3
0.
4
2
2
5.
5
4
1
6.
0
8
2
9.
2
6
3
1.
9
2
1
7.
3
8
2
2.
0
9
3
0
.
4
6
3
0
.
7
9
2
5.
7
3
1
6
.
0
8
2
9.
9
6
3
2
.
4
1
1
7
.
5
5
+.1
0
+.4
6
+.3
7
+.1
9
±.0
0
+.7
0
+.4
9
+.1
7

Table 11: Overall improvements  per language pair


W
M
T2
01
2
W
M
T2
01
3
L
J
.
de-
en
fr-
en
es
-
en 
cs-
en 
ru-
en 
en
-
de 
en
-fr 
en
-es 
en
-cs 
en
-ru
2
3
.
1
1
2
9
.
2
5
3
2
.
8
0
2
2
.
5
3

1
6
.
7
8
2
7
.
9
2
3
3
.
4
1
1
5
.
5
1
2
4
.
0
1
3
0
.
7
7
3
3
.
9
9
2
2
.
8
6
3
1
.
6
7
1
7
.
9
5
2
8
.
7
6
3
4
.
0
0
1
5
.
7
8
2
3
.
7
8
+0.
90
+1.
52
+1.
19
+0.
33

+1.
17
+0.
84
+0.
59
+0.
27
Table 12: Training with new data (newstest2012  scores)


2   Domain Adaptation Techniques

We explored two additional domain adaptation 
techniques: phrase table interpolation and modi­ 
fied Moore-Lewis filtering.

2.1   Phrase Table Interpolation
We experimented  with phrase-table interpolation 
using perplexity minimisation (Foster eta!.,  2010; 
Sennrich, 2012).   1n particular,  we used the im­ 
plementation released with Sennrich (2012) and 
available in Moses, comparing both the naive and 
modified  interpolation  methods from that paper. 
For each language pair, we took the alignments 
created from all the data concatenated, built sepa­ 
rate phrase tables from each of the individual cor­ 
para, and interpolated using each method. The re­ 
sults are shown in Table 13


bas
elin
e
n
a
i
v
e
m
od
ifi
ed
f
r
-
e
n
es
-
en
• 
cs
-
en
"' 
ru
-
en
e
n
-
f
r 
e
n
-
e
s 
e
n
-
c
s 
e
n
-
r
u
3
0.
7
7
3
3.
9
8
2
3.
1
9
3
1.
6
7
28
.7
6
3
4.
0
0
1
5.
7
8
23
.7
8
30.
63   
.14
33.
83
-
.15
22.
77-
.42
31.
42
-
.25
28.
88
+.1
2
34.
07 
+.0
7
15.
88
+.1
0
23.
84
+.0
6

34.
03 
+.0
5
23.
03-
.17
31.
59-
.08

34.
31 
+.3
1
15.
87 
+.0
9
23.
68-
.10

Table 13:   Comparison  of phrase-table interpolation (two 
methods) with baseline (on newstest2012). The baselines are 
as Table 12 except  for  the starred  rows  where  tuning  with 
PRO was found to be better. The modified interpolation was 
not possible in fr++en as it uses to much RAM.


  The results from the phrase-table interpolation 
are quite mixed, and we ouly used the technique



for the final system in en-es.   An interpolation 
based on PRO has recently been shown (Haddow,
2013)  to improve  on perplexity  minimisation  is
some cases, but the current implementation of this 
method is limited to 2 phrase-tables, so we did not 
use it in this evaluation.

2.2    Modified  Moore-Lewis Filtering

In last  year's  evaluation  (Koehn  and  Haddow,
2012b)   we   had   some  success   with  modified 
Moore-Lewis filtering (Moore and Lewis, 2010; 
Axelrod et  al., 2011) of the training  data.   This 
year we conducted experiments in most of the lan­ 
guage pairs using MML filtering, and also exper­ 
imented using instance weighting (Mansour and 
Ney, 2012)  using the (exponential of) the MML 
weights. The results are show in Table 14


ba
se
lin
e
M
M
L
2
0
%
Tn
st. 
W
t
Tn
st. 
W
t
(s
c
al
e
)
f
r
-
e
n
es
-
en
*
cs
-
en
*
r
u
-
e
n 
e
n
-
f
r 
e
n
-
e
s 
e
n
-
c
s 
e
n
-
r
u
30.
77
33.
98
23.
19
31.
67
28.
67
34.
00
15.
78
23.
78
-
34.
26 
+.2
8
22
.6
2-
.5
7
31
.5
8-
.0
9
28.
74 
+.0
7
34.
07 
+.0
7
15
.3
7-
.4
1
22
.9
0-
.8
8

33.
85-
.13
23.
17-
.02
31.
57-
.10
28.
81 
+.1
7
34.
27 
+.2
7
15.
87 
+.0
9
23.
82 
+.0
5

33.
98 
±.0
0
23.
13-
.06
31.
62-
.05
28.
63-
.04
34.
03 
+.0
3
15.
89 
+.I
I
23.
72-
.06

Table 14: Comparison of MML filtering and weighting with 
baseline.  The MML uses monolingual news as in-domain, 
and selects from all training data after alignment.The weight­ 
ing uses the MML weights, optionally downscaled by 10, 
then exponentiated. Baselines are as Table 13.


  As with phrase-table interpolation, MML filter­ 
ing and weighting shows a very mixed picture, and 
not the consistent improvements these techniques 
offer on IWSLT data. In the final systems, we used 
MML filtering only for es-en.

3   Operation Sequence Model (OSM)

We enhanced  the phrase segmentation  and re­ 
ordering mechanism by integrating OSM: an op­ 
eration sequence N-gram-based translation and re­ 
ordering  model  (Durrani  et  al.,  2011)  into  the 
Moses phrase-based decoder. The model is based 
on minimal translation units (MTUs) and Markov 
chains over sequences of operations.   An opera­ 
tion can be (a) to jointly generate a bi-language 
MTU, composed from sou rce and target words, or 
(b) to perform reordering by inserting gaps and do­ 
ing jumps.

Model:    Given   a   bilingual   sentence   pair   <
F, E  > and its alignment  A, we transform it to


If h g aycht z/Jn 
hars

I    do o tfthhotse

Figure 1: Bilingual Sentence with 
Alignments

sequence of operations (01, 02 , . . . , OJ)  and 
learn a Markov model over this sequence as:

J
Posm(F, E,A) = p(o{) = IJ  p(ojlOj-n+l, ...,Oj-
1)
j 
=
l

  By coupling reordering with lexical 
generation, each  (translation  or  reordering)  
decision  condi­ tions on n - 1 previous 
(translation and reorder­ ing) decisions spann ing 
across phrasal boundaries thus overcoming the 
problematic phrasal indepen­ dence assumption 
in the phrase-based model.  In the OSM model, 
the reordering decisions influ­ ence lexical 
selection and vice versa. Lexical gen­ eration is 
strongly coupled with reordering thus improving 
the overall reordering mechanism.
  We  used  the  modified  version  of  the  
OSM model  (Durrani   et   al.,  2013b)   that  
addition­ ally handles discontinuous and 
unaligned target MTUs3. We borrow 4 count-
based supportive fea­ tures, the Gap, Open 
Gap, Gap-width and Dele­ tion penalties from 
Durrani eta!. (2011).

Training:   During training, each bilingual sen­ 
tence  pair  is  deterministically   converted  to  
a unique sequence of operations.   Please refer 
to Durrani et al. (2011) for a list of operations 
and the conversion algorithm and see Figure 1 
and Ta­ ble 15 for a sample  bilingual sentence 
pair and its step-wise conversion into a 
sequence of oper­ ation.  A 9-gram  Kneser-Ney 
smoothed operation sequence model is trained 
with SRILM.

Search:   Although the OSM model is based 
on minimal uni ts, phrase-based search on top of 
OSM model was found to be superior to the 
MTU-based decoding in Durrani et al. (2013a). 
Following this framework allows us to use OSM 
model in tandem with phrase-based models. We 
integrated the gen­ erative story of the OSM 
model into the hypothe­ sis extension of the 
phrase-based Moses decoder. Please refer to 
(Durrani et al., 2013b) for details.

Results:   Table 16 shows  case-sensitive 
BLEU
scores on newstest2012 and newstest2013 for 
fi-

  3 In the original OSM model these are removed from 
the alignments through a post-processing heuristic which 
hurt.s in some language pairs. See Durrani et al. (2013b) 
for deta1led experiments.



393m 	3,775m 	17,629m 	39,919m 	59,794m
Table 17: Counts of unique n-grams (m for millions) for the
5 orders in the unconstrained language model















Table 15: Step-Wise Generation ofFtgore I
  

The large  language model  was 1hen 
quantized to 10 bits and compressed to 643 
GB wi1h KenLM (Heafield,  2011),  loaded  
onto  a machine wi1h 1
TB RAM,  and used as an additional feature  
in unconstrained French-English, 
Spanish-English, and Czech-English 
submissions. This  additional language 
model is 1he ouly difference between  our 
final constrained and  unconstrained 
submissions; no additional parallel  data  
was used.  Results  are shown  in Table 18.  
Improvement from  large lan­ guage  models  
is not  a new  result  (Brants  et al.,
2007); 1he primary  contribution is 
estimating on a
single 
machine.




Co
nst
rai
ned
Un
con
stra
ine
d
f
)
.
fr
-
e
n
es
-
en 
cs
-
en 
ru
-
eo
3
1
.
4
6
3
0
.
5
9
2
7
.
3
8
2
4
.
3
3
3
2
.
2
4
3
1
.
3
7
2
8
.
1
6
2
5
.
1
4
+.7
8
+.7
8
+.7
8
+.8
1





Table 16: Results using the OSM Feature


nal systems from Section 1 and 1hese systems aug­ 
mented  wi1h 1he operation sequence model.   The 
model  gives  gains  for  all  language pairs  (BLEU
+.09 to +.90, average +.37, on newstest2013).

4   Huge Language Models

To overcome 1he memory  limitations of SRILM, 
we  implemented  modified   Kneser-Ney   (Kneser 
and Ney, 1995; Chen and Goodman, 1998) 
smoothlng from  scratch  using disk-based stream­ 
ing  algori1hms.     This  open-source4  tool  is  de­ 
scribed  fully by Heafield et al. (2013).  We used it
to estimate  an unpruned  5-gram language model 
on web pages from ClueWeb09.5 The corpus was 
preprocessed by removing spam  (Cormack et al.,
2011), selecting English  documents, splitting  sen­ 
tences,  deduplicating, tokenizing, and truecasing. 
Estimation on 1he remaining 126  billion  tokens 
took  2.8 days  on  a single  machine  wi1h 140  GB 
RAM (of which 123GB was used at peak) and sbr. 
hard drives in  a RAIDS  configuration. Statistics 
about 1he resulting  model are shown in Table 17.

4http://kheafield.com/code/
5http://lemurproject.org/clueweb&9/


Table 18: Gain on newstest2013 from the unconstrained lan­ 
guage model.   Our time on shared machines with 1 TB is 
limited so Russian-English  was run after the deadline and 
German-English was not ready in time.



5   Summary

Table 19 breaks down 1he gains over 1he final sys­ 
tem from  Section  1 from  using 1he operation se­ 
quence models (OSM), modified Moore-Lewis fil­ 
tering  (MML),  fixing  a bug  wi1h 1he sparse  lex­ 
ical features  (Sparse-Lex Bugfix), and instance 
weighting (Instance  Wt.), translation model com­ 
bination  (TM-Combine), and use of 1he huge lan­ 
guage model (ClueWeb09 LM).

Acknowledgments

Thanks to Miles Osborne for preprocessing the ClueWeb09 
corpus.     The  research  leading  to  these  results  has re­ 
ceived   funding  from  the  European Union   Seventh 
Framework  Programme  (FP7n007-2013) under graot 
agreement   287658   (EU  BRIDGE)   aod  grant   agreement
288487(MosesCore).This work  made use  of  the  resources 
pruvided  by  the  Edioburgh  Compure  aod  Data  Facility'. 
The  ECDF  is  partilllly  supported   by  the  eDIKT  initia­ 
tive7.    This work also used the Extreme Science  and 
Engineering Discovery  Environment (XSEDE),  which  is
supported by  National Science  Foundation grant number 
OCI-1053575.   Specifically, Stampede was used under 
allocation TG-CCR110017.

6http://www.ecdf.ed.ac.uk/
7http://www.edikt.org.uk/








System 	1     2012 	2013
Spanish-English







Bnglish-Spamsh








Czech-English


References
Axelrod, A., He, X., and Gao, J. (2011).  Dmuain 
adaptation
via pseudo in-domain data selection. In Proceedings 
of the
2011 Conference on Empirical Methods in Natural 
Lan­
guage Processing,  pages 355-362, Edinburgh,  
Scotland,
UK. Association for Computational 
Linguistics.
Brants, T., Popat, A. C., Xu, P., Och, F. J., and 
Dean, J. (2007).   Large language models in 
machine translation. In Proceedings of the 2007 
Joint Conference on Empir­ ical Methods in 
Natural Language Processing and Com­ putational 
Natural Language Learning (EMNLP-CoNU), pages 
858--867.
Callison-Burch, C., Koehn, P., Monz, C., PosM., 
Soticu R., and Specia,  L. (2012).    Findings  of 
the 2012  work­ shop on statistical machine 
translation. In Proceedings of the Seventh Workshop 
on Statistical Machine Translation. pages 10-48, 
Montreal, Canada. Association for Compu­ tational 
Linguistics.
Chen,  S. and Goodman,  J. (1998).    An empirical 
study of smoothing  techniques  for langusge 
modeling.  Technical Report TR-10-98, Harvard 
University.
Cherry, C. and Foster, G. (2012).  Batch tuning strategies 
for
statistical machine translation. In Proceedings of the 
2012
Conference of the North American Chapter of the 
Asso­ ciation for Computational Linguistics: 
Human Language Technologies, pages 427-436, 
Montreal, Canada Associ­
ation for Computational 
Linguistics.
Cltiang, D., Knight, K., and Wang, W. (2009).    11,001 
new features for statistical machine translation. In 
Proceedings of Human Language Technologies: The 
2009 Amwal Con­


1.	Baseline
2. 	1+()SM

1.	Baseline
2. 	1+()SM


18.35
18.62+.27

31.09
31.46 +.37


ference of the 
North 
American 
Chapter of 
the 
Association 
for 
Computationa
l  
linguistics, 
pages 218-
226, 
Boulder, 
Colorado. 
Association 
for 
Computation
al 
Linguistics.
Collins,  M.,  
Koeho, P., and  
Kucerova,  I. 
(2005).     Clause
restructuring 
for statistical 
machine 
translation. 
In Pro­


   3.     2+ClueWeb09 LM 	32.24 +1.15 	 
English-French




German-English
I.   Baseliue	123.85	26.54
2. 	!+()SM 	24.11 +.26 	26.83 +.29
Bnglish-Gemum
I.  B-	117.95 	20.06
2. 	l+()SM 	18.02 +.07 	20.26 +.20
Russian-English
I 31.87 	24.00




Th.ble 19: Summary of methods with BLEU scores on news­ 
test2012 and newstest2013. Bold systems were submitted, 
with the ClueWeb09 LM systems submitted in the uncon­ 
straint  track.    The  German-English and  English-German 
OSM systems did not complete in time for the official sub­ 
mission.


ceedings  of the 43rd Annual Meeting  of the Association
for Computational  Linguistics  (ACL'05), pages 531-540,
Ann Arbor, Michigan. Association for Computational Lin­
guistics.
Cormack,  G. V., Smucker, M.D., and Clarke, C. L. (2011).
Efficient and effective spam. filtering and re-ranking for
lmge web datasets. lnfonnation retrieval, 14(5):441-465.
Durrani, N., Fraser, A., and Schmid, H. (2013a). Model With 
Minimal Translation  Units, But Decode With Phrases.  In 
The 2013 Conference  of the North American  Chapter  of the 
Association for Computational Linguistics: Human
Language Technologies, Atlanta, Georgia, USA. Associ­
ation for Computational Linguistics.
Durrani, N., Fraser, A., Schmid, H., Hoang, H., and Koehn.
P. (2013b).  Can Markov Models  Over Minimal Transla­ tion  
Units Help  Phrase-Based  SMT1  In Proceedings  of the 51st 
Annual Meeting of the Association for Computa­ tional 
Linguistics, Sofia, Bulgaria. Association for Com­
putational Linguistics.
Durrani, N., Sehmid,  H., and Fraser, A. (2011).  A Joint Se­ 
quence Translation Model with Integrated Reordering.  In 
Proceedings of the 49th Annual Meeting of the Association for 
Computational Linguistics: Human Language Tech­ 
nologies, pages 1045-1054, Portland, Oregon, USA.
Foster, G., Goutte, C., and Kulm, R. (2010).  Discriminative 
instance weighting for domain adaptation in statistical ma­ 
chine translation. In Proceedings of the 2010 Conference on 
Empirical Methods in Natural Language Processing, pages 
451-459, Cambridge, MA. Association for Compu­ tational 
Linguistics.


Haddow, B. (2013).  Applying pairwise ranked optimisation 
to improve  the interpolation of translation models. In Pro­ 
ceedings of the 2013  Coriference of the North American 
Chapter of the Association for Computational Linguistics: 
HU11UU1 Language Technologies, pages 342-347, Atlanta, 
Georgia. Association for Computational Linguistics.
Haddow, B. and Koehn, P. (2012).    Analysing  the effect  of 
out-of-domain data on smt systems.  In Proceedings of 
the Seventh Workshop on Statistical Machine Translation, 
pages 175-185, Montreal, Canada. Association for Com­ 
putational Linguistics.
Healield,  K. (2011).    KenLM: Faster  and smaller langoage 
model queries.   In Proceedings of the Sixth Workshop 
on Statistical Machine  Translation, pages 187-197, Edin­ 
burgh, Scotland.  Association  for Computational Unguis­ 
tics.
Healield,  K., Pouzyrevsky, I., Clark,  J. H.,  and Koehn,  P. 
(2013).   Scalable modified Kneser-Ney language model 
estimation. In Proceedings of the 51st Annual Meeting of 
the Association for Computational Linguistics, Sofia, Bul­ 
garia.
Johnson,  H.,  Martio,  J.,  Foster,  G.,  and  Knhn,  R. (2007).
Improving translation quality by discarding most of the 
phrasetable. In Proceedings of the 2007 Joint Confer­ 
ence  on Empirical  Methods  in Natural  Language Pro­ 
cessing and Computational Natural  Language   Learning 
(EMNLP-CoNIL}, pages %7-975.
Kneser, R. and  Ney, H. (1995).    hnproved backing-off  for 
m-gram language modeling. In Proceedings of the IEEE 
International Conference on Acoustics, Speech and Signal 
Processing, pages 181-184.
Koelm, P. and Haddow, B. (2012a).  Interpolated  backoff for 
factored translation  models. In Proceedings of the Tenth 
Coriference of the Association for Machine  Translation in 
the Americas (AMTA).
Koehn, P. and Haddow, B. (2012b). Towards Effective Use of 
Training Data in Statistical Machine Translation. In Pro­ 
ceedings of the Seventh Workshop  on Statistical Machine 
Translation,  pages 317-321, Montreal,  Canada.  Associa­ 
tion for Computational Linguistics.
Koelm, P. and  Hoang,   H.  (2007).      Factored  Translation 
Models.	In  Proceedings  of  the  2007   Joint   Confer­ 
ence  on  Empirical  Methods   in  Natural   Language   Pro­
cessing and Computational Natural  Language   Learning 
(EMNLP-CoNIL), pages 868--ll76, Pragoe, Czech Repob­ 
lic. Association for Computational Linguistics.
Koelm, P. and Knigbt, K. (2003). Empirical methods for coro­ 
pound splitting. In Proceedings of Meeting  of the Euro­ 
pean  Chapter of  the  Association of Computational  Lin­ 
guistics (EACL).
Mansour,  S.  and  Ney,  H. (2012).      A  Simple  and  Effec­ 
tive Weighted Phrase Extraction for Machine Translation 
Adaptatioo. In Proceedings of IWSLT.
Moore, R. C. and Lewis, W. (2010).  Intelligeot  selection of 
langoage modellrllining data. In Proceedings of the ACL
2010 Conference Short Papers, pages 220-224, Uppsala,
Sweden. Association for Computational Linguistics.
Papineni,  K., Roukos, S., Ward, T., and Zhu, W.-J. (2001).
BLEU: a method for automatic evaluation of machine
translation.      Technical  Report  RC22176(W0109-022), 
WM Research Report.
Sennrich. R. (2012). Perplexity minimization for translation 
model domain adaptation in statistical machine transla­ 
tion.  In Proceedings of the 13th  Conference of the Eu­ 
ropean  Chapter of the Association for Computational Lin-


guistics, pages 539-549, Avignon, France. Association for
Computational Linguistics.

