<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">We introduce an approach to optimize a machine translation (MT) system on multiple metrics simultaneously.</S>
		<S sid ="2" ssid = "2">Different metrics (e.g. BLEU, TER) focus on different aspects of translation quality; our multi-objective approach leverages these diverse aspects to improve overall quality.</S>
		<S sid ="3" ssid = "3">Our approach is based on the theory of Pareto Optimality.</S>
		<S sid ="4" ssid = "4">It is simple to implement on top of existing single-objective optimization methods (e.g. MERT, PRO) and outperforms ad hoc alternatives based on linear-combination of metrics.</S>
		<S sid ="5" ssid = "5">We also discuss the issue of metric tunability and show that our Pareto approach is more effective in incorporating new metrics from MT evaluation for MT optimization.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="6" ssid = "6">Weight optimization is an important step in building machine translation (MT) systems.</S>
			<S sid ="7" ssid = "7">Discrimi- native optimization methods such as MERT (Och, 2003), MIRA (Crammer et al., 2006), PRO (Hopkins and May, 2011), and Downhill-Simplex (Nelder and Mead, 1965) have been influential in improving MT systems in recent years.</S>
			<S sid ="8" ssid = "8">These methods are effective because they tune the system to maximize an automatic evaluation metric such as BLEU, which serve as surrogate objective for translation quality.</S>
			<S sid ="9" ssid = "9">However, we know that a single metric such as BLEU is not enough.</S>
			<S sid ="10" ssid = "10">Ideally, we want to tune towards an automatic metric that has perfect correlation with human judgments of translation quality.</S>
			<S sid ="11" ssid = "11">∗*Now at Nara Institute of Science &amp; Technology (NAIST) While many alternatives have been proposed, such a perfect evaluation metric remains elusive.</S>
			<S sid ="12" ssid = "12">As a result, many MT evaluation campaigns now report multiple evaluation metrics (CallisonBurch et al., 2011; Paul, 2010).</S>
			<S sid ="13" ssid = "13">Different evaluation metrics focus on different aspects of translation quality.</S>
			<S sid ="14" ssid = "14">For example, while BLEU (Papineni et al., 2002) focuses on word-based n-gram precision, METEOR (Lavie and Agarwal, 2007) allows for stem/synonym matching and incorporates recall.</S>
			<S sid ="15" ssid = "15">TER (Snover et al., 2006) allows arbitrary chunk movements, while permutation metrics like RIBES (Isozaki et al., 2010; Birch et al., 2010) measure deviation in word order.</S>
			<S sid ="16" ssid = "16">Syntax (Owczarzak et al., 2007) and semantics (Pado et al., 2009) also help.</S>
			<S sid ="17" ssid = "17">Arguably, all these metrics correspond to our intuitions on what is a good translation.</S>
			<S sid ="18" ssid = "18">The current approach of optimizing MT towards a single metric runs the risk of sacrificing other metrics.</S>
			<S sid ="19" ssid = "19">Can we really claim that a system is good if it has high BLEU, but very low METEOR?</S>
			<S sid ="20" ssid = "20">Similarly, is a high-METEOR low-BLEU system desirable?</S>
			<S sid ="21" ssid = "21">Our goal is to propose a multi-objective optimization method that avoids “overfitting to a single metric”.</S>
			<S sid ="22" ssid = "22">We want to build a MT system that does well with respect to many aspects of translation quality.</S>
			<S sid ="23" ssid = "23">In general, we cannot expect to improve multiple metrics jointly if there are some inherent trade- offs.</S>
			<S sid ="24" ssid = "24">We therefore need to define the notion of Pareto Optimality (Pareto, 1906), which characterizes this tradeoff in a rigorous way and distinguishes the set of equally good solutions.</S>
			<S sid ="25" ssid = "25">We will describe Pareto Optimality in detail later, but roughly speaking, a 1 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 1–10, Jeju, Republic of Korea, 814 July 2012.</S>
			<S sid ="26" ssid = "26">Qc 2012 Association for Computational Linguistics hypothesis is pareto-optimal if there exist no other hypothesis better in all metrics.</S>
			<S sid ="27" ssid = "27">The contribution of this paper is twofold: • We introduce PMO (Pareto-based Multi- objective Optimization), a general approach for learning with multiple metrics.</S>
			<S sid ="28" ssid = "28">Existing single- objective methods can be easily extended to multi-objective using PMO.</S>
			<S sid ="29" ssid = "29">• We show that PMO outperforms the alternative (single-objective optimization of linearly- combined metrics) in multi-objective space, 1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 metric1 and especially obtains stronger results for metrics that may be difficult to tune individually.</S>
			<S sid ="30" ssid = "30">In the following, we first explain the theory of Pareto Optimality (Section 2), and then use it to build up our proposed PMO approach (Section 3).</S>
			<S sid ="31" ssid = "31">Experiments on NIST ChineseEnglish and PubMed EnglishJapanese translation using BLEU, TER, and RIBES are presented in Section 4.</S>
			<S sid ="32" ssid = "32">We conclude by discussing related work (Section 5) and opportunities/limitations (Section 6).</S>
	</SECTION>
	<SECTION title="Theory of Pareto Optimality. " number = "2">
			<S sid ="33" ssid = "1">2.1 Definitions and Concepts.</S>
			<S sid ="34" ssid = "2">The idea of Pareto optimality comes originally from economics (Pareto, 1906), where the goal is to characterize situations when a change in allocation of goods does not make anybody worse off.</S>
			<S sid ="35" ssid = "3">Here, we will explain it in terms of MT: Let h ∈ L be a hypothesis from an N-best list L. We have a total of K different metrics Mk (h) for evaluating the quality of h. Without loss of gen erality, we assume metric scores are bounded between 0 and 1, with 1 being perfect.</S>
			<S sid ="36" ssid = "4">Each hypothesis h can be mapped to a K -dimensional vector M (h) = [M1(h); M2(h); ...; MK (h)].</S>
			<S sid ="37" ssid = "5">For example, suppose K = 2, M1(h) computes the BLEU score, and M2(h) gives the METEOR score of h. Figure 1 illustrates the set of vectors {M (h)} in a 10-best list.</S>
			<S sid ="38" ssid = "6">For two hypotheses h1, h2, we write M (h1) &gt; M (h2) if h1 is better than h2 in all metrics, and M (h1) ≥ M (h2) if h1 is better than or equal to h2 in all metrics.</S>
			<S sid ="39" ssid = "7">When M (h1) ≥ M (h2) and Mk (h1) &gt; Mk (h2) for at least one metric k, we say that h1 dominates h2 and write M (h1) � M (h2).</S>
			<S sid ="40" ssid = "8">Figure 1: Illustration of Pareto Frontier.</S>
			<S sid ="41" ssid = "9">Ten hypotheses are plotted by their scores in two metrics.</S>
			<S sid ="42" ssid = "10">Hypotheses indicated by a circle (o) are pareto-optimal, while those indicated by a plus (+) are not.</S>
			<S sid ="43" ssid = "11">The line shows the convex hull, which attains only a subset of pareto-optimal points.</S>
			<S sid ="44" ssid = "12">The triangle (�) is a point that is weakly pareto-optimal but not pareto-optimal.</S>
			<S sid ="45" ssid = "13">Definition 1.</S>
			<S sid ="46" ssid = "14">Pareto Optimal: A hypothesis h∗ ∈ L is pareto-optimal iff there does not exist another hypothesis h ∈ L such that M (h) � M (h∗).</S>
			<S sid ="47" ssid = "15">In Figure 1, the hypotheses indicated by circle (o) are pareto-optimal, while those with plus (+) are not.</S>
			<S sid ="48" ssid = "16">To visualize this, take for instance the pareto- optimal point (0.4,0.7).</S>
			<S sid ="49" ssid = "17">There is no other point witheither (metric1 &gt; 0.4 and metric2 ≥ 0.7), or (met ric1 ≥ 0.4 and metric2 &gt; 0.7).</S>
			<S sid ="50" ssid = "18">On the other hand, the non-pareto point (0.6,0.4) is “dominated” by another point (0.7,0.6), because for metric1: 0.7 &gt; 0.6 and for metric2: 0.6 &gt; 0.4.</S>
			<S sid ="51" ssid = "19">There is another definition of optimality, which disregards ties and may be easier to visualize: Definition 2.</S>
			<S sid ="52" ssid = "20">Weakly Pareto Optimal: A hypothesis h∗ ∈ L is weakly pareto-optimal iff there is no other hypothesis h ∈ L such that M (h) &gt; M (h∗).</S>
			<S sid ="53" ssid = "21">Weakly pareto-optimal points are a superset of pareto-optimal points.</S>
			<S sid ="54" ssid = "22">A hypothesis is weakly pareto-optimal if there is no other hypothesis that improves all the metrics; a hypothesis is pareto- optimal if there is no other hypothesis that improves at least one metric without detriment to other metrics.</S>
			<S sid ="55" ssid = "23">In Figure 1, point (0.1,0.8) is weakly pareto- optimal but not pareto-optimal, because of the competing point (0.3,0.8).</S>
			<S sid ="56" ssid = "24">Here we focus on paretooptimality, but note our algorithms can be easily modified for weakly paretooptimality.</S>
			<S sid ="57" ssid = "25">Finally, we can introduce the key concept used in our proposed PMO approach: Definition 3.</S>
			<S sid ="58" ssid = "26">Pareto Frontier: Given an N-best list L, the set of all pareto-optimal hypotheses h ∈ L is called the Pareto Frontier.</S>
			<S sid ="59" ssid = "27">The Pareto Frontier has two desirable properties from the multi-objective optimization perspective: 1.</S>
			<S sid ="60" ssid = "28">Hypotheses on the Frontier are equivalently.</S>
			<S sid ="61" ssid = "29">good in the Pareto sense.</S>
			<S sid ="62" ssid = "30">2.</S>
			<S sid ="63" ssid = "31">For each hypothesis not on the Frontier, there.</S>
			<S sid ="64" ssid = "32">is always a better (pareto-optimal) hypothesis.</S>
			<S sid ="65" ssid = "33">This provides a principled approach to optimization: i.e. optimizing towards points on the Frontier and away from those that are not, and giving no preference to different pareto-optimal hypotheses.</S>
			<S sid ="66" ssid = "34">2.2 Reduction to Linear Combination.</S>
			<S sid ="67" ssid = "35">Multi-objective problems can be formulated as: arg max [M1(h); M2(h); . . .</S>
			<S sid ="68" ssid = "36">; Mk (h)] (1) w where h = Decode(w, f ) Here, the MT system’s Decode function, parameterized by weight vector w, takes in a foreign sentence f and returns a translated hypothesis h. The argmax operates in vector space and our goal is to find w leading to hypotheses on the Pareto Frontier.</S>
			<S sid ="69" ssid = "37">In the study of Pareto Optimality, one central question is: To what extent can multi-objective problems be solved by single-objective methods?</S>
			<S sid ="70" ssid = "38">Equation 1 can be reduced to a single-objective problem by scalarizing the vector [M1(h); . . .</S>
			<S sid ="71" ssid = "39">; Mk (h)] with a linear combination: K Theorem 1.</S>
			<S sid ="72" ssid = "40">Sufficient Condition: If w∗ is solution to Eq. 2, then it is weakly pareto-optimal.</S>
			<S sid ="73" ssid = "41">Further, if w∗ is unique, then it is pareto-optimal.</S>
			<S sid ="74" ssid = "42">Theorem 2.</S>
			<S sid ="75" ssid = "43">No Necessary Condition: There may exist solutions to Eq. 1 that cannot be achieved by Eq. 2, irregardless of any setting of {pk }.</S>
			<S sid ="76" ssid = "44">Theorem 1 is a positive result asserting that linear combination can give pareto-optimal solutions.</S>
			<S sid ="77" ssid = "45">However, Theorem 2 states the limits: in particular, Eq. 2 attains only pareto-optimal points that are on the convex hull.</S>
			<S sid ="78" ssid = "46">This is illustrated in Figure 1: imagine sweeping all values of p1 = [0, 1] and p2 = 1 − p1 and recording the set of hypotheses that maximizes Lk pk Mk (h).</S>
			<S sid ="79" ssid = "47">For 0.6 &lt; p1 ≤ 1 we get h = (0.9, 0.1), for p1 = 0.6 we get (0.7, 0.6), and for 0 &lt; p1 &lt; 0.6 we get (0.4, 0.8).</S>
			<S sid ="80" ssid = "48">At no setting of p1 do we attain h = (0.4, 0.7) which is also pareto-optimal but not on the convex hull.1 This may have ramifications for issues like metric tunability and local optima.</S>
			<S sid ="81" ssid = "49">To summarize, linear- combination is reasonable but has limitations.</S>
			<S sid ="82" ssid = "50">Our proposed approach will instead directly solve Eq. 1.</S>
			<S sid ="83" ssid = "51">Pareto Optimality and multi-objective optimization is a deep field with active inquiry in engineering, operations research, economics, etc. For the interested reader, we recommend the survey by Mar- ler and Arora (2004) and books by (Sawaragi et al., 1985; Miettinen, 1998).</S>
	</SECTION>
	<SECTION title="Multi-objective Algorithms. " number = "3">
			<S sid ="84" ssid = "1">3.1 Computing the Pareto Frontier.</S>
			<S sid ="85" ssid = "2">Our PMO approach will need to compute the Pareto Frontier for potentially large sets of points, so we first describe how this can be done efficiently.</S>
			<S sid ="86" ssid = "3">Given a set of N vectors {M (h)} from an N-best list L, our goal is extract the subset that are pareto-optimal.</S>
			<S sid ="87" ssid = "4">Here we present an algorithm based on iterative arg max w pk Mk (h) (2) k=1 filtering, in our opinion the simplest algorithm to understand and implement.</S>
			<S sid ="88" ssid = "5">The strategy is to loop where h = Decode(w, f ) Here, pk are positive real numbers indicating the relative importance of each metric (without loss of gen erality, assume Lk pk = 1).</S>
			<S sid ="89" ssid = "6">Are the solutions to through the list L, keeping track of any dominant points.</S>
			<S sid ="90" ssid = "7">Given a dominant point, it is easy to filter out many points that are dominated by it.</S>
			<S sid ="91" ssid = "8">After successive rounds, any remaining points that are not fil 1 We note that scalarization by exponentiated-combination.</S>
			<S sid ="92" ssid = "9">L p M (h)q , for a suitable q &gt; 0, does satisfy necessary Eq. 2 also solutions to Eq. 1 (i.e. pareto-optimal) and vice-versa?</S>
			<S sid ="93" ssid = "10">The theory says: k k k conditions for pareto optimality.</S>
			<S sid ="94" ssid = "11">However the proper tuning of q is not known a priori.</S>
			<S sid ="95" ssid = "12">See (Miettinen, 1998) for theorem proofs.</S>
			<S sid ="96" ssid = "13">Algorithm 1 FindParetoFrontier Input: {M (h)}, h ∈ L Output: All pareto-optimal points of {M (h)} 1: F = ∅ 2: while L is not empty do 3: h∗ = shift(L) 4: for each h in L do 5: if (M (h∗) � M (h)): remove h from L 6: else if (M (h) � M (h∗)): remove h from L; set h∗ = h 7: end for 8: Add h∗ to Frontier Set F 9: for each h in L do 10: if (M (h∗) � M (h)): remove h from L 11: end for 12: end while 13: Return F tered are necessarily pareto-optimal.</S>
			<S sid ="97" ssid = "14">Algorithm 1 shows the pseudocode.</S>
			<S sid ="98" ssid = "15">In line 3, we take a point h∗ and check if it is dominating or dominated in the for- loop (lines 48).</S>
			<S sid ="99" ssid = "16">At least one pareto-optimal point will be found by line 8.</S>
			<S sid ="100" ssid = "17">The second loop (lines 911) further filters the list for points that are dominated by h∗ but iterated before h∗ in the first for-loop.</S>
			<S sid ="101" ssid = "18">The outer while-loop stops exactly after P iterations, where P is the actual number of pareto- optimal points in L. Each inner loop costs O(K N ) so the total complexity is O(P K N ).</S>
			<S sid ="102" ssid = "19">Since P ≤ N with the actual value depending on the probability distribution of {M (h)}, the worst-case run-time is O(K N 2).</S>
			<S sid ="103" ssid = "20">For a survey of various Pareto algorithms, refer to (Godfrey et al., 2007).</S>
			<S sid ="104" ssid = "21">The algorithm we described here is borrowed from the database literature ilar to many MT optimization methods.</S>
			<S sid ="105" ssid = "22">The main difference is that rather than trying to maximize a single metric, we maximize the number of pareto points, in order to expand the Pareto Frontier We will explain PMO-PRO in terms of the pseudo-code shown in Algorithm 2.</S>
			<S sid ="106" ssid = "23">For each sentence pair (f, e) in the devset, we first generate an N-best list L ≡ {h} using the current weight vector w (line 5).</S>
			<S sid ="107" ssid = "24">In line 6, we evaluate each hypothesis h with respect to the K metrics, giving a set of K - dimensional vectors {M (h)}.</S>
			<S sid ="108" ssid = "25">Lines 78 is the critical part: it gives a “label” to each hypothesis, based on whether it is in the Pareto Frontier.</S>
			<S sid ="109" ssid = "26">In particular, first we call FindParetoFrontier (Algorithm 1), which returns a set of pareto hypotheses; pareto-optimal hypotheses will get label 1 while non-optimal hypotheses will get label 0.</S>
			<S sid ="110" ssid = "27">This information is added to the training set T (line 8), which is then optimized by any conventional subroutine in line 10.</S>
			<S sid ="111" ssid = "28">We will follow PRO in using a pairwise classifier in line 10, which finds w∗ that separates hypotheses with labels 1 vs. 0.</S>
			<S sid ="112" ssid = "29">In essence, this is the trick we employ to directly optimize on the Pareto Frontier.</S>
			<S sid ="113" ssid = "30">If we had used BLEU scores rather than the {0, 1} labels in line 8, the entire PMO-PRO algorithm would revert to single-objective PRO.</S>
			<S sid ="114" ssid = "31">By definition, there is no single “best” result for multi-objective optimization, so we collect all weights and return the Pareto-optimal set.</S>
			<S sid ="115" ssid = "32">In line 13 we evaluate each weight w on K metrics across the entire corpus and call FindParetoFrontier in line 14.3 This choice highlights an interesting in what is known as skyline operators.2 change of philosophy: While setting {pk} in linear 3.2 PMO-PRO Algorithm.</S>
			<S sid ="116" ssid = "33">We are now ready to present an algorithm for multi- objective optimization.</S>
			<S sid ="117" ssid = "34">As we will see, it can be seen as a generalization of the pairwise ranking optimization (PRO) of (Hopkins and May, 2011), so we call it PMO-PRO.</S>
			<S sid ="118" ssid = "35">PMO-PRO approach works by iteratively decoding-and-optimizing on the devset, sim 2 The inquisitive reader may wonder how is Pareto related to databases.</S>
			<S sid ="119" ssid = "36">The motivation is to incorporate preferences into relational queries(Bo¨ rzso¨ nyi et al., 2001).</S>
			<S sid ="120" ssid = "37">For K = 2 metrics, combination forces the designer to make an a priori preference among metrics prior to optimization, the PMO strategy is to optimize first agnostically and a posteriori let the designer choose among a set of weights.</S>
			<S sid ="121" ssid = "38">Arguably it is easier to choose among solutions based on their evaluation scores rather than devising exact values for {pk }.</S>
			<S sid ="122" ssid = "39">3.3 Discussion.</S>
			<S sid ="123" ssid = "40">Variants: In practice we find that a slight modification of line 8 in Algorithm 2 leads to more sta they also present an alternative faster O(N logN) algorithm by first topologically sorting along the 2 dimensions.</S>
			<S sid ="124" ssid = "41">All dominated points can be filtered by one-pass by comparing with the most-recent dominating point.</S>
			<S sid ="125" ssid = "42">3 Note this is the same FindParetoFrontier algorithm as used.</S>
			<S sid ="126" ssid = "43">in line 7.</S>
			<S sid ="127" ssid = "44">Both operate on sets of points in K -dimensional space, induced from either weights {w} or hypotheses {h}.</S>
			<S sid ="128" ssid = "45">Algorithm 2 Proposed PMO-PRO algorithm Input: Devset, max number of iterations I Output: A set of (pareto-optimal) weight vectors 1: Initialize w. Let W = ∅.</S>
			<S sid ="129" ssid = "46">2: for i = 1 to I do 3: Let T = ∅.</S>
			<S sid ="130" ssid = "47">4: for each (f, e) in devset do 5: {h} =DecodeNbest(w,f ) 6: {M (h)}=EvalMetricsOnSentence({h}, e) 7: {f } =FindParetoFrontier({M (h)}) 8: foreach h ∈ {h}: abstracts.</S>
			<S sid ="131" ssid = "48">As metrics we use BLEU and RIBES (which demonstrated good human correlation in this language pair (Goto et al., 2011)).</S>
			<S sid ="132" ssid = "49">(2) The NIST task is Chinese-to English translation with OpenMT08 training data and MT06 as devset.</S>
			<S sid ="133" ssid = "50">As metrics we use BLEU and NTER.</S>
			<S sid ="134" ssid = "51">• BLEU = BP × (Πprecn)1/4.</S>
			<S sid ="135" ssid = "52">BP is brevity penality.</S>
			<S sid ="136" ssid = "53">precn is precision of n gram matches.</S>
			<S sid ="137" ssid = "54">RIBES = (τ + 1)/2 × prec1/4, with Kendall’s if h ∈ {f }, set l=1, else l=0; Add (l, h) to T 9: end for 10: w∗=OptimizationSubroutine(T , w) 11: Add w∗ to W ; Set w = w∗.</S>
			<S sid ="138" ssid = "55">12: end for • 1 τ computed by measuring permutation between matching words in reference and hypothesis5.</S>
			<S sid ="139" ssid = "56">• NTER=max(1−TER, 0), which normalizes 6 13: M (w) =EvalMetricsOnCorpus(w,devset) ∀w ∈ W Translation Edit Rate so that NTER=1 is best.</S>
			<S sid ="140" ssid = "57">14: Return FindParetoFrontier({M (w)})ble results for PMO-PRO: for non-pareto hypothe We compare two multi-objective approaches: 1.</S>
			<S sid ="141" ssid = "58">Linear-Combination of metrics (Eq. 2),.</S>
			<S sid ="142" ssid = "59">optimized with PRO.</S>
			<S sid ="143" ssid = "60">We search a range ses h ∈/ {f }, we set label l = Lk Mk (h)/K in of com bination settings: (p1, p2) =stead of l = 0, so the method not only learns to dis criminate pareto vs. non-pareto but also also learns to discriminate among competing non-pareto points.</S>
			<S sid ="144" ssid = "61">Also, like other MT works, in line 5 the N-best list is concatenated to N-best lists from previous iterations, so {h} is a set with i · N elements.</S>
			<S sid ="145" ssid = "62">General PMO Approach: The strategy we outlined in Section 3.2 can be easily applied to other MT optimization techniques.</S>
			<S sid ="146" ssid = "63">For example, by replacing the optimization subroutine (line 10, Algorithm 2) with a Powell search (Och, 2003), one can get PMOMERT4.</S>
			<S sid ="147" ssid = "64">Alternatively, by using the large- margin optimizer in (Chiang et al., 2009) and moving it into the for-each loop (lines 49), one can get an online algorithm such PMOMIRA.</S>
			<S sid ="148" ssid = "65">Virtually all MT optimization algorithms have a place where metric scores feedback into the optimization procedure; the idea of PMO is to replace these raw scores with labels derived from Pareto optimality.</S>
	</SECTION>
	<SECTION title="Experiments. " number = "4">
			<S sid ="149" ssid = "1">4.1 Evaluation Methodology.</S>
			<S sid ="150" ssid = "2">We experiment with two datasets: (1) The PubMed task is English-to-Japanese translation of scientific 4 A difference with traditional MERT is the necessity of sentence-BLEU (Liang et al., 2006) in line 6.</S>
			<S sid ="151" ssid = "3">We use sentence- BLEU for optimization but corpus-BLEU for evaluation here.</S>
			<S sid ="152" ssid = "4">{(0, 1), (0.3, 0.7), (0.5, 0.5), (0.7, 0.3), (1, 0)}.</S>
			<S sid ="153" ssid = "5">Note (1, 0) reduces to standard single-metric optimization of e.g. BLEU.</S>
			<S sid ="154" ssid = "6">2.</S>
			<S sid ="155" ssid = "7">Proposed Pareto approach (PMO-PRO)..</S>
			<S sid ="156" ssid = "8">Evaluation of multi-objective problems can be tricky because there is no single figure-of-merit.</S>
			<S sid ="157" ssid = "9">We thus adopted the following methodology: We run both methods 5 times (i.e. using the 5 different (p1, p2) setting each time) and I = 20 iterations each.</S>
			<S sid ="158" ssid = "10">For each method, this generates 5x20=100 results, and we plot the Pareto Frontier of these points in a 2-dimensional metric space (e.g. see Figure 2).</S>
			<S sid ="159" ssid = "11">A method is deemed better if its final Pareto Frontier curve is strictly dominating the other.</S>
			<S sid ="160" ssid = "12">We report devset results here; testset trends are similar but not included due to space constraints.7 5 from www.kecl.ntt.co.jp/icl/lirg/ribes 6 from www.umd.edu/˜snover/tercom 7 An aside: For comparing optimization methods, we believe.</S>
			<S sid ="161" ssid = "13">devset comparison is preferable to testset since data mismatch may confound results.</S>
			<S sid ="162" ssid = "14">If one worries about generalization, we advocate to re-decode the devset with final weights and evaluate its 1-best output (which is done here).</S>
			<S sid ="163" ssid = "15">This is preferable to simply reporting the achieved scores on devset N-best (as done in some open-source scripts) since the learned weight may pick out good hypotheses in the N-best but perform poorly when re-decoding the same devset.</S>
			<S sid ="164" ssid = "16">The re-decode devset approach avoids being overly optimistic while accurately measuring optimization performance.</S>
			<S sid ="165" ssid = "17">0.695 Linear Combination Pareto (PMO−PRO) Table 1: Task characteristics: #sentences in Train/Dev, # of features, and metrics used.</S>
			<S sid ="166" ssid = "18">Our MT models are trained with standard phrase-based Moses software (Koehn and others, 2007), with IBM M4 alignments, 4gram SRILM, lexical ordering for PubMed and distance ordering for the NIST system.</S>
			<S sid ="167" ssid = "19">The decoder generates 50-best lists each iteration.</S>
			<S sid ="168" ssid = "20">We use SVMRank (Joachims, 2006) as optimization subroutine for PRO, which efficiently handle all pairwise samples without the need for sampling.</S>
			<S sid ="169" ssid = "21">4.2 Results.</S>
			<S sid ="170" ssid = "22">Figures 2 and 3 show the results for PubMed and NIST, respectively.</S>
			<S sid ="171" ssid = "23">A method is better if its Pareto Frontier lies more towards the upper-right hand cor 0.69 0.685 0.68 0.675 0.67 0.665 0.2 0.21 0.22 0.23 0.24 0.25 0.26 0.27 bleu Figure 2: PubMed Results.</S>
			<S sid ="172" ssid = "24">The curve represents the Pareto Frontier of all results collected after multiple runs.</S>
			<S sid ="173" ssid = "25">0.704 Linear Combination ner of the graph.</S>
			<S sid ="174" ssid = "26">Our observations are: 1.</S>
			<S sid ="175" ssid = "27">PMO-PRO generally outperforms Linear-.</S>
			<S sid ="176" ssid = "28">Combination with any setting of (p1, p2).</S>
			<S sid ="177" ssid = "29">The Pareto Frontier of PMO-PRO dominates that of Linear-Combination.</S>
			<S sid ="178" ssid = "30">This implies PMO is effective in optimizing towards Pareto hypotheses.</S>
			<S sid ="179" ssid = "31">2.</S>
			<S sid ="180" ssid = "32">For both methods, trading-off between met-.</S>
			<S sid ="181" ssid = "33">0.703 0.702 0.701 0.7 0.699 0.698 0.697 0.696 0.695 0.694 Pareto (PMO−PRO) rics is necessary.</S>
			<S sid ="182" ssid = "34">For example in PubMed, the designer would need to make a choice between picking the best weight according to BLEU (BLEU=.265,RIBES=.665) vs. another weight with higher RIBES but poorer BLEU, e.g.</S>
			<S sid ="183" ssid = "35">(.255,.675).</S>
			<S sid ="184" ssid = "36">Nevertheless, both the PMO and Linear-Combination with various (p1, p2) samples this joint-objective space broadly.</S>
			<S sid ="185" ssid = "37">3.</S>
			<S sid ="186" ssid = "38">Interestingly, a multi-objective approach can.</S>
			<S sid ="187" ssid = "39">sometimes outperform a single-objective optimizer in its own metric.</S>
			<S sid ="188" ssid = "40">In Figure 2, single- objective PRO focusing on optimizing RIBES only achieves 0.68, but PMO-PRO using both BLEU and RIBES outperforms with 0.685.</S>
			<S sid ="189" ssid = "41">The third observation relates to the issue of metric tunability (Liu et al., 2011).</S>
			<S sid ="190" ssid = "42">We found that RIBES can be difficult to tune directly.</S>
			<S sid ="191" ssid = "43">It is an extremely non-smooth objective with many local optima–slight changes in word ordering causes large changes in RIBES.</S>
			<S sid ="192" ssid = "44">So the best way to improve RIBES is to 0.146 0.148 0.15 0.152 0.154 0.156 0.158 0.16 0.162 0.164 bleu Figure 3: NIST Results not to optimize it directly, but jointly with a more tunable metric BLEU.</S>
			<S sid ="193" ssid = "45">The learning curve in Figure 4 show that single-objective optimization of RIBES quickly falls into local optimum (at iteration 3) whereas PMO can zigzag and sacrifice RIBES in intermediate iterations (e.g. iteration 2, 15) leading to a stronger result ultimately.</S>
			<S sid ="194" ssid = "46">The reason is the diversity of solutions provided by the Pareto Frontier.</S>
			<S sid ="195" ssid = "47">This finding suggests that multi-objective approaches may be preferred, especially when dealing with new metrics that may be difficult to tune.</S>
			<S sid ="196" ssid = "48">4.3 Additional Analysis and Discussions.</S>
			<S sid ="197" ssid = "49">What is the training time?</S>
			<S sid ="198" ssid = "50">The Pareto approach does not add much overhead to PMO-PRO.</S>
			<S sid ="199" ssid = "51">While FindParetoFrontier scales quadratically by size of N-best list, Figure 5 shows that the runtime is triv 0.69 0.68 35 N I S T P u b M e d 30 0.67 25 0.66 20 0.65 15 0.64 Single− Objective RIBES 10 Pareto (PMO− PRO) 0.63 0 2 4 6 8 10 12 14 16 18 20 i t e r a t i o n 5 0 2 4 6 8 10 12 14 16 18 I t e r a t i o n s Figure 4: Learning Curve on RIBES: comparing single- objective optimization and PMO.</S>
			<S sid ="200" ssid = "52">Figure 6: Average number of Pareto points 0.35 0.3 0.25 0.2 0.15 0.1 0.05 0 A l g o r i t h m 1 T o p o l o g i c a l S o r t ( f o o t n o t e 2 ) 0 100 200 300 400 500 600 700 800 900 1000 S e t s i z e | L | hypoth eses gives a rough indicati on of the diversi ty of hypoth eses that can be exploit ed by PMO.</S>
			<S sid ="201" ssid = "53">Figure 6 shows that this numbe r increas es gradua lly per iteratio n. This perhap s gives PMO PRO more directions for optimi zing aroun d potenti al local optim al. Nevert heless, we note that tens of Pareto points is far few compa red to the large size of N-best lists used at later iteratio ns of PMO PRO.</S>
			<S sid ="202" ssid = "54">This may explai n why the differe nces betwe en metho ds in Figure 3 are not more subst antial.</S>
			<S sid ="203" ssid = "55">Theor eticall y, the number will eventu ally level off as it gets increa singly harder to genera te new Pareto points in a crowd ed Figure 5: Avg.</S>
			<S sid ="204" ssid = "56">runtime per sentence of FindPareto ial (0.3 seconds for 1000-best).</S>
			<S sid ="205" ssid = "57">Table 2 shows the time usage breakdown in different iterations for PubMed.</S>
			<S sid ="206" ssid = "58">We see it is mostly dominated by decoding time (constant per iteration at 40 minutes on single 3.33GHz processor).</S>
			<S sid ="207" ssid = "59">At later iterations, Opt takes more time due to larger file I/O in SVMRank.</S>
			<S sid ="208" ssid = "60">Note Decode and Pareto can be “embarrasingly par- allelized.” Iter Ti me De co de (lin e 5) Par eto (lin e 7) Op t (lin e 10) Mis c.</S>
			<S sid ="209" ssid = "61">(lin e 6,8 ) 1 10 20 47 m 62 m 91 m 85 % 67 % 47 % 1% 6% 15 % 1% 8% 22 % 13 % 19 % 16 % Table 2: Training time usage in PMO-PRO (Algo 2).</S>
			<S sid ="210" ssid = "62">How many Pareto points?</S>
			<S sid ="211" ssid = "63">The number of pareto space (Bentley et al., 1978).</S>
			<S sid ="212" ssid = "64">Practical recommendation: We present the Pareto approach as a way to agnostically optimize multiple metrics jointly.</S>
			<S sid ="213" ssid = "65">However, in practice, one may have intuitions about metric tradeoffs even if one cannot specify {pk }.</S>
			<S sid ="214" ssid = "66">For example, we mightbelieve that approximately 1-point BLEU degra dation is acceptable only if RIBES improves by at least 3-points.</S>
			<S sid ="215" ssid = "67">In this case, we recommend the following trick: Set up a multi-objective problem where one metric is BLEU and the other is3/4BLEU+1/4RIBES.</S>
			<S sid ="216" ssid = "68">This encourages PMO to ex plore the joint metric space but avoid solutions that sacrifice too much BLEU, and should also outperform Linear Combination that searches only on the (3/4,1/4) direction.</S>
	</SECTION>
	<SECTION title="Related Work. " number = "5">
			<S sid ="217" ssid = "1">Multi-objective optimization for MT is a relatively new area.</S>
			<S sid ="218" ssid = "2">Linear-combination of BLEU/TER is the most common technique (Zaidan, 2009), sometimes achieving good results in evaluation campaigns (Dyer et al., 2009).</S>
			<S sid ="219" ssid = "3">As far as we known, the only work that directly proposes a multi-objective technique is (He and Way, 2009), which modifies MERT to optimize a single metric subject to the constraint that it does not degrade others.</S>
			<S sid ="220" ssid = "4">These approaches all require some setting of constraint strength or combination weights {pk }.</S>
			<S sid ="221" ssid = "5">Recent work in MT evaluation has examined combining metrics using machine learning for better correlation with human judgments (Liu and Gildea, 2007; Albrecht and Hwa, 2007; Gimnez and Ma`rquez, 2008) and may give insights for setting {pk }.</S>
			<S sid ="222" ssid = "6">We view our Pareto-based approach as orthogonal to these efforts.</S>
			<S sid ="223" ssid = "7">The tunability of metrics is a problem that is gaining recognition (Liu et al., 2011).</S>
			<S sid ="224" ssid = "8">If a good evaluation metric could not be used for tuning, it would be a pity.</S>
			<S sid ="225" ssid = "9">The Tunable Metrics task at WMT2011 concluded that BLEU is still the easiest to tune (CallisonBurch et al., 2011).</S>
			<S sid ="226" ssid = "10">(Mauser et al., 2008; Cer et al., 2010) report similar observations, in addition citing WER being difficult and BLEUTER being amenable.</S>
			<S sid ="227" ssid = "11">One unsolved question is whether metric tunability is a problem inherent to the metric only, or depends also on the underlying optimization algorithm.</S>
			<S sid ="228" ssid = "12">Our positive results with PMO suggest that the choice of optimization algorithm can help.</S>
			<S sid ="229" ssid = "13">Multi-objective ideas are being explored in other NLP areas.</S>
			<S sid ="230" ssid = "14">(Spitkovsky et al., 2011) describe a technique that alternates between hard and soft EM objectives in order to achieve better local optimum in grammar induction.</S>
			<S sid ="231" ssid = "15">(Hall et al., 2011) investigates joint optimization of a supervised parsing objective and some extrinsic objectives based on downstream applications.</S>
			<S sid ="232" ssid = "16">(Agarwal et al., 2011) considers using multiple signals (of varying quality) from online users to train recommendation models.</S>
			<S sid ="233" ssid = "17">(Eisner and Daume´ III, 2011) trades off speed and accuracy of a parser with reinforcement learning.</S>
			<S sid ="234" ssid = "18">None of the techniques in NLP use Pareto concepts, however.</S>
	</SECTION>
	<SECTION title="Opportunities and Limitations. " number = "6">
			<S sid ="235" ssid = "1">We introduce a new approach (PMO) for training MT systems on multiple metrics.</S>
			<S sid ="236" ssid = "2">Leveraging the diverse perspectives of different evaluation metrics has the potential to improve overall quality.</S>
			<S sid ="237" ssid = "3">Based on Pareto Optimality, PMO is easy to implement and achieves better solutions compared to linear- combination baselines, for any setting of combination weights.</S>
			<S sid ="238" ssid = "4">Further we observe that multi- objective approaches can be helpful for optimizing difficult-to-tune metrics; this is beneficial for quickly introducing new metrics developed in MT evaluation into MT optimization, especially whengood {pk } are not yet known.</S>
			<S sid ="239" ssid = "5">We conclude by draw ing attention to some limitations and opportunities raised by this work: Limitations: (1) The performance of PMO is limited by the size of the Pareto set.</S>
			<S sid ="240" ssid = "6">Small N-best lists lead to sparsely-sampled Pareto Frontiers, and a much better approach would be to enlarge the hypothesis space using lattices (Macherey et al., 2008).</S>
			<S sid ="241" ssid = "7">How to compute Pareto points directly from lattices is an interesting open research question.</S>
			<S sid ="242" ssid = "8">(2) The binary distinction between pareto vs. non-pareto points ignores the fact that 2nd-place non-pareto points may also lead to good practical solutions.</S>
			<S sid ="243" ssid = "9">A better approach may be to adopt a graded definition of Pareto optimality as done in some multi-objective works (Deb et al., 2002).</S>
			<S sid ="244" ssid = "10">(3) A robust evaluation methodology that enables significance testing for multi-objective problems is sorely needed.</S>
			<S sid ="245" ssid = "11">This will make it possible to compare multi-objective methods on more than 2 metrics.</S>
			<S sid ="246" ssid = "12">We also need to follow up with human evaluation.</S>
			<S sid ="247" ssid = "13">Opportunities: (1) There is still much we do not understand about metric tunability; we can learn much by looking at joint metric-spaces and examining how new metrics correlate with established ones.</S>
			<S sid ="248" ssid = "14">(2) Pareto is just one approach among many in multi-objective optimization.</S>
			<S sid ="249" ssid = "15">A wealth of methods are available (Marler and Arora, 2004) and more experimentation in this space will definitely lead to new insights.</S>
			<S sid ="250" ssid = "16">(3) Finally, it would be interesting to explore other creative uses of multiple-objectives in MT beyond multiple metrics.</S>
			<S sid ="251" ssid = "17">For example: Can we learn to translate faster while sacrificing little on accuracy?</S>
			<S sid ="252" ssid = "18">Can we learn to jointly optimize cascaded systems, such as as speech translation or pivot translation?</S>
			<S sid ="253" ssid = "19">Life is full of multiple competing objectives.</S>
	</SECTION>
	<SECTION title="Acknowledgments">
			<S sid ="254" ssid = "20">We thank the reviewers for insightful feedback.</S>
	</SECTION>
</PAPER>
