Finding Paraphrase Facts
Based on  Coordinate Relationships


Meng Zhao(B) , Hiroaki Ohshima, and Katsumi  Tanaka

Graduate School of Informatics, Kyoto  University, 
Yoshida Honmachi,  Kyoto  606–8501, Japan
{zhao,ohshima,tanaka}@dl.kuis.kyoto-u.ac.jp



Abstract

We propose  a method  to acquire paraphrases from the Web 
in accordance with a given sentence. For example, consider  an input  sen- 
tence  “Lemon is a high vitamin c fruit”. Its paraphrases are expressions 
or sentences that  convey the  same  meaning  but  are  diﬀerent  syntacti- 
cally,  such as “Lemons are rich in vitamin c”, or “Lemons contain  a lot of 
vitamin c”.  We aim at ﬁnding sentence-level paraphrases from the noisy 
Web, instead of domain-speciﬁc corpora. By  observing search  results of 
paraphrases, users  are  able  to  estimate the  likelihood  of the  sentence 
as  a  fact.  We evaluate the  proposed  method  on ﬁve  distinct semantic 
relations. Experiments show  our  average precision  is 60.5 %,  compared 
to TE/ASE  method  with  average precision  of 44.15 %.  Besides,  we can 
acquire 3 paraphrases more than  TE/ASE  method  per input.


Keywords: Paraphrase acquisition · Coordinate relationship · Web 
mining  · Mutual  reinforcement


1    Introduction

Nowadays,  it is intuitive to utilize the Web as a huge encyclopedia and trust 
information  on the  Web. However,  those  information  is not  always correct  or 
true. For example, it has been reported that information on the Wikipedia, which 
is regarded  as the biggest online encyclopedia, is not so credible [9]. Therefore, it 
is necessary to understand risks  of Web information  and distinguish  facts  from 
it. We assume  information,  which is often mentioned  by people on the Web, is 
more likely to be correct  or true.  Consequently, such information  is regarded  as 
“fact” with a high possibility. On the contrary, we assume  information,  which is 
rarely  mentioned by people on the Web, is more likely to be incorrect  or untrue, 
consequently unlikely  to be “fact”. Based  on the  assumption, a naive  way  to 
estimate   the  likelihood  of a  sentence  as  a  fact  is to  observe  its  hit  count  on 
the Web. However, it always fails since the expression  of a user-input  sentence 
may  be rarely  used on the Web. Suppose  a user wants  to know whether  lemon 
is a high vitamin  c fruit  or not. He thinks  of a sentence  like “Lemon  is a high 
vitamin  c fruit”  and use it as a query to search on the Web. Neither Google1  nor
1  http://www.google.com.
Oc   Springer International  Publishing Switzerland 2015
A.  Liu  et al. (Eds.): DASFAA 2015  Workshops, LNCS 9052, pp. 135–151, 2015.
DOI: 10.1007/978-3-319-22324-7 12



Bing2  return  any matches  for this query  (at  the time of writing the document). 
However, if it is rewritten  as “Lemons are rich in vitamin  c”, or “Lemons contain 
a lot of vitamin  c”, adequate number of Web pages can be obtained.  Hence, the 
user  can  infer  that  lemon  is a high vitamin  c fruit.  In this  paper,  we aim  at 
ﬁnding sentence-level  paraphrases from the noisy Web, instead of domain-speciﬁc 
corpora.  By  observing  search  results  of paraphrases, especially frequently-used 
ones, users  are able to estimate  the likelihood of an input sentence  as a fact.
   Paraphrases are  linguistic  expressions that  restate  the same  meaning  using 
diﬀerent  variations. In the most extreme  case,  they  may  not be even similar  in 
wording.  It has  been shown that  paraphrases are  useful  in many  applications. 
For example,  paraphrases can help detect fragments  of text that convey the same 
meaning across documents  and this can improve the precision of multi-document 
summarization [6, 17]. In the  ﬁeld of machine  translation, [8, 15, 16]  show that 
augmenting  the training  data  with paraphrases generated  by  pivoting  through 
other languages  can alleviate the vocabulary coverage  problem.  In information 
extraction, [7, 10, 26]  present  approaches incorporating paraphrases  to  extract 
semantic  relations  among  entities.  In information  retrieval, paraphrases have 
been used  for query  expansion  [2, 20, 25]. A large  proportion  of previous  work 
extract and generate  paraphrases based  on parallel  corpora  [3, 5] or comparable 
corpora  [4, 21, 23]. However,  there  are  limitations   in using  those  corpora.  For 
example,  the quality of obtained  paraphrases strongly  depends on the quality of 
the corpus, a high-quality  corpus can cost a great deal of manpower  and time to 
construct. Moreover,  it may  be hard  to cover  all possible  genres.  For example, 
[23] uses  a corpus  consisted  of newswire  articles  written  by  six  diﬀerent  news 
agencies.
   Entity  tuples  that describe  or are members of the same relationships may be 
deﬁned  as “coordinate tuples” to each  other.  For example,  (guavas,vitamin c) 
and (tomatoes,potassium) are coordinate  tuples since there is a highConcen- 
tration relation  between  guavas  and  vitamin   c, so is  between  tomatoes   and 
potassium.  We think  it is not easy  to ﬁnd all variations of paraphrases by just 
one entity  tuple,  and such variations exist  in expressions of its coordinate  ones. 
For example,  given the sentence “Guavas are rich in vitamin  c”, it might be diﬃ- 
cult to ﬁnd part of its paraphrases, such as “Guavas are considered a high vitamin 
c fruit”, since it is seldom used by the entity  tuple (guavas,vitamin c). However, 
such paraphrases can be acquired  from the expressions of its coordinate  entity 
tuples,  i.e. the former paraphrase can be easily  found via (tomatoes,potassium). 
Thus, we can capture  more paraphrases by mining the expressions of coordinate 
entity  tuples.
   The distributional hypothesis, attributed to Harris [12], has been the basis 
for Statistical Semantics.  It states  that  words  that  occur  in the same  contexts 
tend  to have  similar  meanings.  Moreover,  its extension  that  if two phrases,  or 
two  text  units,  occur  in  similar  contexts then  they  may  be  interchangeable 
has  been  extensively tested.  Our idea  is based  on the  extended  hypothesis: if 
two templates share  more common coordinate  entity  tuples,  then they  may  be

2  http://www.bing.com.



paraphrase templates; if two entity  tuples  share more common paraphrase tem- 
plates,  then they  may  be coordinate  entity  tuples.  Thus, paraphrase templates 
and coordinate  tuples  are in a mutually reinforcing  relationship, and this rela- 
tionship  can be used to ﬁnd more paraphrase templates or coordinate  tuples.
   We assume  a sentence  is mapped  to a template  and an entity  tuple.  Thus, 
given a sentence  query,  it can be separated into a template and a corresponding 
entity  tuple.  The proposed  method  ﬁrst  extracts templates that  connect  that 
entity  tuple and entity  tuples mentioned by that template. Several  ﬁlters and 
limitations  are  added  to  eliminate  partial inappropriate templates and  entity 
tuples.  A mutually reinforcing  approach  is proposed  to simultaneously identify 
diﬀerent  templates that  convey  the same meaning with the given template, and 
entity tuples which hold the same relation with the given entity tuple. Finally, 
paraphrase queries  can be generated  by substituting the given entity  tuple  into 
discovered  paraphrase templates.
   Our contributions can be summarized  as follows. First, we propose a method 
for detecting  sentence-level  paraphrases and our method does not require  deep 
natural language  processing  such  as  dependency  parsing.  Second,  paraphrases 
are not limited to word-level, or phrase-level.  Given a sentence query, our method 
outputs  its paraphrases at the sentence level. Third, instead of using high-quality 
input data  restricted to a particular genre, our method can employe the Web as 
its data  source.
   The remainder  of the paper is organized as follows. In Sect. 2, we discuss some 
related  work. Section 3 shows some preliminaries and Sect. 4 describes  our basic 
idea. In Sect. 5, we illustrate the method to acquire  paraphrases from the Web 
by  a given  sentence.  We evaluate the proposed  paraphrase acquisition  method 
using ﬁve semantic  relations  in Sect. 6. Finally,  Sect. 7 concludes  the paper  and 
gives an outline of our future  work.


2    Related Work

2.1     Semantic Relation Extraction

Snowball [1], KnowItAll [11], TextRunner [26] are famous information extraction 
systems.  All of them extract valuable information  from plain-text documents  by 
using lexical-syntactic patterns. Snowball  and TextRunner require  a handful  of 
training  examples  from users,  while KnowItAll emphasizes  its distinctive ability 
to extract information  without  any  hand-labeled  training  examples.
   In Snowball,  given a handful of example  tuples,  such as organization-location 
tuple  <o,l>, Snowball  ﬁnds segments  of text  in the document  collection  where 
o and  l occur  close  to  each  other,  and  analyzes the  text  that  “connects” o 
and  l to  generate  patterns. It  extracts diﬀerent  relationships from  the  Web 
by  the  bootstrap method.  Besides,  Snowball’s patterns include  named-entity 
tags.  An example  is <ORGANIZATION>’s headquarters  in  <LOCATION>.
<ORGANIZATION> will only match a string identiﬁed  by a POS tagger  as an 
entity  of type  ORGANIZATION. So does <LOCATION>.



   In KnowItAll,  its input  is a set of predicates that  represent  classes  or rela- 
tionships  of interest.  A generic representation of rule templates for binary  pred- 
icates is relation(Class1,Class2). For example,  the predicate CeoOf(PERSON, 
COMPANY) corresponds  to the pattern <PERSON> is the CEO  of <COMP- 
ANY>. It learns  eﬀective  patterns to extract relevant entity  names.
   In TextRunner, extractions take the form of a tuple t = (ei , ri,j , ej ), where ei 
and ej  are strings meant to denote entities,  and ri,j is a string meant to denote a 
relationship between them. A deep linguistic  parser  is deployed to obtain depen- 
dency  graph  representations by parsing  thousand  of sentences.  For each pair of 
noun phrases (ei , ej ), TextRunner traverses the dependency  graph, especially the 
part  connecting  ei  and ej , to ﬁnd a sequence of words that composes a potential 
relation  ri,j in the tuple  t.


2.2     Paraphrase Acquisition

Paraphrase acquisition  is a task  of acquiring  paraphrases of a given  text  frag- 
ment. Some approaches have  been proposed  for acquiring  paraphrases at word, 
or phrasal  level. However, these techniques  are designed only suitable for speciﬁc 
types  of resources.  Both [22] and [24] acquire  paraphrases from news article.  In 
[22], Shinyama  et al.  considered  that  news articles  reported  the same  event  of 
the same day by diﬀerent news agents  can contain  paraphrases. Thus, they pro- 
posed an automatic paraphrase acquisition  approach  based  on the assumption 
that  named entities  are preserved across  paraphrases. Pairs  of similar  sentences 
whose similarity is above  a certain  threshold  are chosen. For any pair, if the two 
sentences  share the same number of comparable named entities,  then patterns in 
the two sentences  are linked as paraphrases. In [24], news article  headlines,which 
are already grouped by news aggregators such as Google News, are taken for fur- 
ther processing. k-means clustering  and pairwise  similarity are applied to ﬁnd 
paraphrases, respectively. These work has explicit  access  to, and relies strongly 
on clues such as the news articles  that  describe  the same event.
   To acquire  paraphrases, some works  proposed  methods  based  on deep nat- 
ural  language  processing,  i.e.  dependency  parsing.  Lin and  Pantel  introduced 
an unsupervised method to discover  inference  rules  from text  in [14]. Inference 
rules include not only exact  paraphrases, but also related  and potentially useful 
expressions. Their core idea is also based  on an extension  to the distributional 
hypothesis: if two paths  in dependency  trees  tend to occur  in similar  contexts, 
the meanings  of the paths  tend to be similar.  The words that  ﬁll the slots  of a 
path  is regarded  as a context  for the path.  Idan et al. [13] took a verb  lexicon 
as  the  input  and  for each  verb  searches  the  Web for related  syntactic entail- 
ment  templates. Although  they  did not use  the  term  “coordinate”, they  used 
a  similar  concept  called  “anchors” referred  to  lexical  elements  describing  the 
context  of a sentence.  Diﬀerent from our method,  they  ﬁrst  extract promising 
anchor  sets for the verb  lexicon,  then extract templates (dependency parse-tree 
fragments) for which an entailment relation holds with the verb lexicon from 
sentences  containing  the promising anchor sets.



   Pa¸sca and Dienes proposed a method diﬀered from previous ones in [19]. They 
use inherently  noisy, unreliable Web documents  rather  than clean, formatted 
documents  so that  the  paraphrases are  not  limited  to  a  speciﬁc  domain  or a 
narrow  class.  Their  proposed  method  is based  on the  assumption that  if two 
sentence  fragments  have  common word sequences  at both extremities, then the 
variable word sequences  in the middle are potential  paraphrases of each other. 
So actually, their  acquired  paraphrases are  almost  word-, or phrase-level  ones, 
while our work aims to get sentential paraphrases.
   In [25], Yamamoto and Tanaka  also concentrated on improving  search results 
responded  by sentence  queries.  Unlike we focus on paraphrases, they  generally 
collected  several  types  of sentence  substitutions, including  paraphrases, gener- 
alized  sentences,  detailed  sentences  and  comparative sentences.  Based  on the 
criteria  that  sentence  substitutions which appears  frequently on the  Web and 
whose context  is similar  to that  of the input  sentence  query  should  be ranked 
higher, a ranking  algorithm  is also stated.


3    Preliminaries

We assume  a sentence  consists  of a template  and an entity  tuple.  Thus, given a 
sentence,  it can be separated into a template and a corresponding  entity  tuple. 
For example,  “Google has purchased Nest Labs”  consists  of the template X has 
purchased  Y and the entity  tuple  (Google,Nest  Labs).  For further  illustration, 
we borrow  the idea about  the deﬁnition  of a relation  in [7]. They  advocated a 
relation  can be expressed extensionally by enumerating all the instances  of that 
relation. Take the acquisition relation3 for example. An extensional deﬁnition of 
acquisition is a set of all pairs of two companies in which one company  acquired 
another,  i.e.  (Google,Nest  Labs),  (Adobe  Systems,Macromedia). In this  paper, 
entity tuples hold the same relation are deﬁned to be “coordinated” to each other. 
For simplicity, relations  are  all  binary  relations.  Thus,  in the former  example, 
(Adobe  Systems,Macromedia) is a coordinate  entity  tuple of (Google,Nest  Labs). 
Bollegala  et al. [7] also introduced  an intensional  deﬁnition of a relation by listing 
all the paraphrases of that relation.  Therefore, ﬁnding paraphrases of a template 
can also be regarded  as a way  to survey a certain  relation.  Terminologies  used 
in this paper  are listed  Table 1.
   Let T be the set of all possible  templates in the world,  E be the set of all 
possible  entity  tuples  in the world. Three predicates are deﬁned as follows:
fact(e,t). It returns  true when the statement of sentence  mapped  by  e and  t
is actually the case  or has  really  occurred,  where  e ∈ E, t ∈ T . If f act holds
for a certain  pair  of an entity  tuple  and  a template, we call  the entity  pair  is
“suitable” for the template  and vice-versa.



3  The  acquisition  relation exists   between   two  companies such  that  one  company 
acquired another.



Table 1. Terminologies

Sen
ten
ce
Go
ogle 
has 
pur
cha
sed 
Nes
t 
Lab
s
Ent
ity 
tup
le
(Go
ogl
e,N
est 
Lab
s)
Sub
stit
uti
on
X=
Goo
gle, 
Y=
Nes
t 
Lab
s
Te
mpl
ate
X  
has 
pur
cha
sed 
Y.
Par
aph
rase 
tem
plat
es
X  
buy
s  
Y,  
X  
has 
acq
uire
d 
Y,  
X  
ﬁna
lizes  
acq
uisi
tio
n of 
Y
Par
aph
rase
s
Go
ogle 
buy
s  
Nes
t 
Lab
s

Go
ogle 
has 
acq
uire
d 
Nes
t 
Lab
s

Go
ogle 
ﬁna
lizes  
acq
uisi
tio
n of 
Nes
t 
Lab
s
Co
ordi
nat
e 
enti
ty 
tup
les
(Mi
cro
soft
,No
kia)
,(Y
aho
o,T
um
blr)
,(A
ma
zon
,Go
odr
ead
s)



para (t i , t j ). It returns  true when template ti and template  tj  both convey  the 
same meaning (“paraphrases”), where ti , tj  ∈ T .

coord (e k , e g ). It returns  true when entity  tuple ek and entity  tuple eg  hold the 
coordinate  relation,  where ek , eg  ∈ E.


4    Basic  Idea

In this paper, in order to ﬁnd the paraphrases of a sentence query, we aim to ﬁnd 
pairs  of templates ti and tj  and coordinates ek  and eg  that  make the predicate 
para(ti , tj ) and coord(ek , eg ) are true.
   In the ideal world, two templates are paraphrases if every  entity  tuple  that 
is suitable for one templates is also  suitable  for the  other  template. Formally,
let ti , tj  ∈ T , and Eti   = {e|f act(e, ti )}, Etj   = {e|f act(e, tj )}. If Eti   = Etj , then
para(ti , tj ) = true.
   Similarly, two entity  tuples  are coordinates if every  template that  is suitable 
for one tuple  is also  suitable  for the other  tuple.  Formally, let ek , eg  ∈ E, and 
Tek    =  {t|f act(ek , t)},  Teg    =  {t|f act(eg , t)}.  If  Tek    =  Teg ,  then  coord(ek , eg ) =  
true.
However, even in the ideal world, we can easily  ﬁnd a counterexample to the
above  discussion  of para.  Suppose  ti is X and  Y , and tj  is X or  Y . This is
an  extreme  case  where  both  ti and  tj   are  very  general  templates suitable  for
almost  all  entity  tuples.  Consequently, Eti    might  be  equal  to  Etj    so that  X
and  Y and X or Y are misjudged  as paraphrases. One may add the following 
condition  to exclude  such noisy entity  tuples:  if Eti   = Etj   and ∀(ek , eg ) ∈ Eti  ×
Eti , coord(ek , eg ), then para(ti , tj ) is true. Soon we ﬁnd another  problem  that 
the newly added condition is too strict  and will likely miss many paraphrases. A 
single template may represent  several  relations.  For example, X direct Y may be



























Fig. 1.  An  example for  grouped  entity tuples. Entity  tuples  in big  frame  are  those 
suitable for the template X direct Y , whereas  entity tuples  in small  frame  are  those 
held the same  relation.


interpreted as the directorOf relation4 , the leaderOf relation5 , or the ceoOf 
relation6 . As a result,  the entity  tuples  suitable for X direct  Y are  naturally 
grouped  in accordance with the relation  held by each tuple,  shown in Fig. 1.
Hence, we moderate  the conditions  for para  as follows:
– If ∃Et  ⊂ Eti   ∩ Etj    and  |Et| > α,  ∀(ek , eg )  ∈ Et × Et, coord(ek , eg ),  then
para(ti , tj ) is true.
Here α is a threshold.
Let  us  look  at  a  single  entity  tuple.  It  is  easy  to  ﬁnd  diﬀerent  relation-
ships between  the entities  of the tuple.  Take (Mark  Zuckerberg,Facebook)  as an
example.  There exists  the founderOf  relation7  between  Mark Zuckerberg  and
Facebook. There  also  exists  the  ceoOf   relation  between  Mark  Zuckerberg  and
Facebook. Based on our discussion  that  a relation  can be expressed by listing all
4  The directorOf  relation exists  between  a director and his works,  i.e. (Steven Spiel- 
berg,Saving Private Ryan), (James Cameron,Titanic).
5  The leaderOf relation exists  between  a country and its current leader,  i.e. (Barack
Obama,U.S.), (Giorgio  Napolitano,Italy).
6  The ceoOf relation exists  between  a company and the chief executive oﬃcer of that
company, i.e. (Tim  Cook,Apple), (Mark Zuckerberg,Facebook).
7  The  founderOf  relation exists   between   a  person  and  his  founded  company, i.e.
(Larry  Page,Google).



the paraphrases of that relation,  we can see the similar phenomenon occurs that 
the  templates suitable   for (Mark  Zuckerberg,Facebook)   are  naturally grouped 
in accordance with diﬀerent  relations.  Following this, we modify conditions  for 
coord  as:
– If  ∃T t  ⊂ Tek   ∩ Teg    and  |T t|  > β,  ∀(ti , tj )  ∈  T t × T t, para(ti , tj ),  then
coord(ek , eg ) is true.
Here β is a threshold.
However, in the real  world,  it is diﬃcult  to ﬁnd all paraphrases by a single
entity  tuple  perhaps  because  of idiomatic  expressions and personal  preferences.
For example,  consider  the sentence  “Guavas are  rich in vitamin  c”,  where  the
entity  tuple  is (guavas,vitamin c),  the template is X are rich in  Y . It might
be diﬃcult  to ﬁnd some of its paraphrases, such as X are considered  a high Y
fruit,  or X pop a powerful  Y punch, since people seldom use those expressions
to describe the relation  between guavas and vitamin  c. Similarly, it is diﬃcult to
ﬁnd all coordinate  entity tuples by a single template, since the template  might be
specially used with a subset  of entity  tuples.  Hence, we cannot  ﬁnd the exactly
equal  sets  of entity  tuples  when considering  the  value  of para(ti , tj ),  and  the
exactly equal sets of templates when considering  the value  of coord(ek , eg ).
In Fig. 2(a),  there are two templates t1  and t2 . Under each template, there
is a set of all suitable entity  tuples  shown in a big oval.  Besides,  the tuples  are
further  grouped  according  to  the  relations  they  hold,  shown  in a  small  oval.
If e3   is  coordinated   to  e4 ,  then  we  think  they  are  interchangeable, meaning
{e1 , e2 , e4 } = {e1 , e2 , e3 }. In addition,  since e7  is coordinated  to e5 , e6  under the
same  relation,  we think  people  always use  the  expression  of t2  to describe  e7
but seldom use the expression  of t1 . Therefore, although  the sizes of two subsets 
are  diﬀerent,  {e5 , e6 } is regarded  as equal  to {e5 , e6 , e7 }. Finally,  if all pairs  of
subsets  are  “equal”, t1  and  t2  are  paraphrases, meaning  para(t1 , t2 ) = true. 
Similarly, in Fig. 2(b),  there are two entity  tuples  e1  and e2 . Under each tuple, 
there list all suitable templates in big oval.  Besides,  they are grouped according 
to diﬀerent  relations,  shown  in small  oval.  If t3  is paraphrased to t4 , then  we
think  they  are  interchangeable, meaning  {t1 , t2 , t4 } = {t1 , t2 , t3 }. In addition,
since t7 is paraphrased to t5 , t6 under the same relation,  we think people always
use the expression  of t7 to describe e2 but seldom use it to describe e1 . Therefore, 
although  the sizes of two subsets  are  diﬀerent,  {t5 , t6 } is regarded  as equal  to
{t5 , t6 , t7 }. Finally,  if all pairs  of subsets  are “equal”, e1  and e2  are coordinate
entity  tuples,  meaning coord(e1 , e2 ) = true.

5    Our  Method

In this paper,  the problem  to be solved  is as follows: given a sentence,  its para- 
phrases  are automatically acquired  from the Web, and they are ranked in accor- 
dance  with  paraphrase degree.  We have  stated  our  basic  idea  in Sect. 4 that 
paraphrase relationship and  coordinate  relationship interdepend  and  mutually



 

 

Fig. 2.  A real-world  situation


reinforce each other. Hence, at the very  beginning, it is necessary to gather  tem- 
plates  and  entity  tuples.  Brief introductions of template  extraction and  entity 
tuple extraction are given in Sects. 5.1 and 5.2, respectively. Then details  of our 
method are addressed in Sect. 5.3.

5.1     Template Extraction

As we mentioned  in Sect. 1, we use the Web as  our data  source,  so we search 
the  Web and  extract templates from it.  Suppose  a  given  sentence  is s which 
consists  of a template  t and an entity  tuple  e. t is actually made  by  replacing 
two entities  in e respectively with two variables X and Y in the sentence  s. An 
example  is shown in Table 1. The entity  tuple is (Google,Nest  Labs). We replace 
Goolge with variable X and Nest Labs with variable Y and get the template  X 
has purchased  Y . An AND query  generated  from e is issued  to the Web, i.e. 
“Google AND Nest Labs”.  We gather  templates from the top N search  results 
of the query8  that  satisfy  the following conditions.

(1)  A template  must contain exactly one occurrence of each X and Y (i.e. exactly 
one X and one Y must exist  in a template).
(2)  The maximum  length of a template  is Lmax times of that  of s.
(3)  The minimum length of a template  is Lmin times of that  of s.
(4)  Information  such as date,  money, quantity, are removed  if s doesn’t  contain
such information.
(5)  Templates  must  be consistent  of s (if s is a question,  gathered  templates
must  limit  to questions;  if s is a declarative sentence,  gathered  templates
must also be declarative ones).

The values  of parameters N , Lmax and Lmin are set experimentally, as explained 
later  in Sect. 6. The proposed template extraction algorithm  takes  all the words
8  Replace entities in e with variables.



in a sentence  into  account,  and  is not  limited  to extract templates only  from 
the portion of a sentence  that  appears  between two entities.  Besides,  we assume 
an  overlong  template   is  more  likely  to  contain  additional information,  while 
a too-short  template is more likely  to miss some information.  Both  the situa- 
tions lead to non-paraphrases. Therefore, we consider two length limitations  to 
exclude some inappropriate templates in advance and reduce the number of tem- 
plates  gathered  from the Web. The consideration of (4), (5) is because  of similar 
reasons.

5.2     Entity Tuple Extraction

As we mentioned  in Sect. 1, we use the Web as  our data  source,  so we search 
the Web and extract entity  tuples  from it. Suppose  a given sentence  is s which 
consists  of a template  t and an entity  tuple e. Still use the example  presented  in 
Table 1. We ﬁrst search  coordinate  terms of two entities  in e, respectively, using 
the bi-directional  lexico-syntactic pattern-based algorithm  [18]. For example,  we 
get Yahoo, Microsoft,  Apple  and etc.  as coordinate  terms  of Google ; Samsung, 
Dropcam  and  etc.  as  coordinate  terms  of Nest  Labs.  Next,  we issue  wildcard 
queries  generated  by  t and  either  of the  two  entities  in e or their  coordinate 
terms  to the Web and extract the other ones from the top M search  results.  To 
detect  entities  in sentences,  we run a POS tagger9  and only annotate sentences 
exactly contained  the queries  with POS tags.  Then nouns or noun phrases  are 
selected  out. For example,  queries, such as “Google has purchased *”, or “Yahoo 
has purchased *”, are formed to extract corresponding  companions.  As a result, 
entity  tuples  like (Google,YouTube), or (Google,Titan Aerospace)  are extracted 
by  the  former  query,  entity  tuples  like  (Yahoo,Tumblr), or (Yahoo,Blink) are 
extracted by the latter  query.
   We use  coordinate  terms  for the  following  two  reasons.  First,  there  is too 
massive  information  on the Web. If we only search  by  t (i.e.  “* has purchased
*”) and  extract entity  tuples  from corresponding  portions  of sentences,  many 
irrelevant tuples  are gathered,  such as (God,freedom). Hence, coordinate  terms 
are used to reduce  the number  of irrelevant tuples.  Second, there might be few 
entity  tuples  extracted from the  Web if the  binary  relation  in e is one-to-one 
type. For example,  in sentence “The capital  of Japan is Tokyo”,  relation  between 
Japan  and Tokyo  belongs  to one-to-one type,  since we can  only  ﬁnd Tokyo  as 
the answer  for which city  the capital  of Japan  is, and  vise  versa,  we can  only 
ﬁnd Japan  as  the  answer  for Tokyo  is the  capital  of which  country. Thus,  it 
is diﬃcult  to get other  entity  tuples  from wildcard  query  “The  capital  of * is 
Tokyo”  or “The  capital  of Japan is *”. In this case,  coordinate  terms  are used 
to increase  the number  of entity  tuples  extracted from the Web.

5.3     The  Mutual Reinforcement Algorithm

Assuming that the set of all extracted templates is T , and the set of all extracted 
entity  tuples  is E. Suppose there are m templates in T and n entity  tuples  in E.
9  http://nlp.stanford.edu/software/tagger.shtml.






 



Fig. 3.   An   example  of  the   mutual  reinforcement  between    P r(para(ti , tj ))   and
P r(coord(ek , eg )).

Let W TE  ∈ Rm×n denote  the transition matrix  from T to E, whose entry  wte


is the proportion  of ej


i ’s top search  results.  
Let W ET


∈ Rn×m


denote the transition matrix  from E to T , whose entry  wet  is the proportion  of
tj ’s occurrence  in ei ’s top search  results.
Since  we  want  to  know  the  quality of a  paraphrase rather  than  treat  all
paraphrases equally,  we introduce  paraphrase degree  between  two templates ti
and tj  as P r(para(ti , tj )), which returns  a value  between  0 and 1. A high value
will be returned  when ti and tj  are more likely to be paraphrased to each other.
Similarly, we introduce  coordinate  degree between two entity  tuples ei  and ej  as
P r(coord(ei , ej )), which returns  a value  between  0 and 1. A high value  will be
returned  when ei  and ej  are more likely  to be coordinated  to each other.
As we mentioned  in Sect. 4, if two templates are paraphrased to each other,
they are interchangeable; if two coordinate  entity  tuples  are coordinated  to each
other, they are interchangeable. In Fig. 3(a), it shows two diﬀerent situations to
consider the paraphrase degree between  ti and tj . One is exactly equivalence of
ti ’s suitable entity  tuples and tj ’s suitable entity  tuples, such as ek . If we can ﬁnd
many such entity tuples, the paraphrase degree between ti and tj  is high. Another
is interchangeability of ti ’s suitable entity  tuples  and tj ’s suitable entity  tuples,
i.e.  ek  and  eg   are  interchangeable with  the  degree  of P r(coord(ek , eg )).  As a
result,  the value  of P r(coord(ek , eg )) is propagated to P r(para(ti , tj )) according
to the  transition probability. Similarly, additional values  are  propagated from
other paris of coordinate  entity  tuples in E to P r(para(ti , tj )), then the value  of
P r(para(ti , tj )) is updated.  In Fig. 3(b),  it shows the new value  is propagated
to P r(coord(ek , eg )).



Formally, the mutually reinforcing  calculations are written  as:


1    	)



te    et


P r(para(ti , tj )) = 2 (



ek ,eg ∈E


wik wgj P r(coord(ek , eg )) +


) wte    et



ek ,eg ∈E


jg wki P r(coord(ek , eg )))





1    	)



et    te


P r(coord(ek , eg )) = 2 (



ti ,tj ∈T


wki wjg P r(para(ti , tj )) +


) wet    te



ti ,tj ∈T


gj wik P r(para(ti , tj )))



where  i, j ∈ [1, m], k, g ∈ [1, n]. Especially, when i = j,  P r(para(ti , tj ))  = 1, 
which indicates the exactly equal case. Similarly, when k = g, P r(coord(ek , eg )) =
1. After values  for all pairs  of templates are updated,  a normalization is taken
place.  The same  for all  pairs  of entity  tuples.  Besides,  update  continues  until
diﬀerence  between  each new value  and old value  is smaller  than  a threshold  θ.
As a result,  the paraphrase degree  of two templates will be high if they  share
many common entity tuples, or have many interchangeable tuples; the coordinate
degree of two entity  tuples will be high if they share many common templates, or
have  many  interchangeable templates. Finally,  we get paraphrases of the given
sentence  by substituting its entity  tuples  into discovered  paraphrase templates.

6 	Evaluation

6.1 	Experimental Setting

In this  section,  we  introduce  experiments to  validate the  main  claims  of the 
paper.
   Given a sentence, it is costly to ﬁnd all templates and all entity tuples through 
the whole Web. For our experiments, we set N as 1000, viz. we limit data  to the 
top 1000 search  results  obtained  from Bing Search  API10   for each AND query 
formed by an entity tuple. Besides, to exclude overlong or too-short templates 
extracted from  the  Web,  we  set  Lmax = 2, Lmin = 0.5. We set  M  as  250, 
viz.  we extract entity  tuples  by  a wildcard  query  in its top 250 search  results. 
Moreover,  since  the  calculation of WTE   requires  many  accesses  to  the  Web, 
we only consider 40 most frequently occurring templates. We ﬁx the value  of 
threshold  θ to 0.0001 and ﬁnd values  of P r(para(ti , tj )) and P r(coord(ek , eg ))
to converge  after  20 ∼ 25 updates.
One claim of this paper  is that  paraphrase relationship and coordinate  rela-
tionship  mutually reinforce each other, so paraphrase templates can be selected
out. To verify  this, we evaluate the performance  on the following ﬁve semantic
relations:
10  http://datamarket.azure.com/dataset/bing/search.



1.  highConcentration: We  define this as a food contains  a high amount  of a 
certain  nutrient.
2.  acquisition: We define this as the activity  between two companies  such that 
one company  acquired another.
3.  founderOf: We define this as the relation between a person and his founded 
company.
4.  headquarter: We  define  this  as the  relation  between  a company  and  the 
location of its headquarter.
5.  field:  We  define this as the relation  between a person and his field of exper- 
tise.



Table 2. Input  sentences.

Rela
tion
Sen
ten
ce
En
tity 
tup
le
high
Con
cent
ratio
n
Le
mo
ns 
are  
rich 
in 
vit
am
in 
c
(le
mo
ns,
vita
min 
c)
acqu
isiti
on
Go
ogl
e 
has 
pur
cha
sed 
Nes
t 
La
bs
(Go
ogl
e,N
est 
Lab
s)
foun
der
Of
Lar
ry  
Pag
e  
fou
nde
d  
Go
ogl
e
(La
rry  
Pa
ge,
Go
ogl
e)
hea
dqu
arter
Yah
oo  
is 
hea
dq
uar
ter
ed 
in 
Su
nn
yva
le
(Ya
hoo
,Su
nny
val
e)
ﬁeld
Alb
ert  
Ein
stei
n  
rev
olu
tio
niz
ed 
ph
ysi
cs
(Al
ber
t 
Ein
stei
n,p
hys
ics)



   In Table 2, we list ﬁve input  sentences  of the above  semantic  relations,  and 
the entity  tuple  extracted from each sentence,  respectively. Thus, templates are 
easily  obtained  by substituting entity  tuples  with variables. For example,  in the 
ﬁrst sentence,  let X=lemons, Y=vitamin c, we have template  X are rich in Y .
   We ﬁnd paraphrase templates and coordinate  entity  tuples  for each of these 
inputs  by  the  co-acquisition  method  described  in Sect. 5. Our evaluation  will 
consider  only paraphrasing, i.e. given a sentence  s, we will assess  the quality of 
its paraphrases we acquire from the Web, whether they convey the same meaning 
with the given sentence.  We do not assess  whether  it is really  a fact.


Table 3. Performance of our method  for paraphrase acquisition.

relat
ion
hig
hC
onc
ent
rati
on
acq
uisi
tio
n
fou
nde
rOf
hea
dq
uar
ter
ﬁel
d
# 
Obt
aine
d
1
6
2
6
1
1
10
5
# 
Para
phra
ses
9
2
1
5
4
4
Prec
ision
56.
3 %
80.
8 %
45.
5 %
40 
%
80 
%
Aver
age 
Prec
ision
60.5 %
Ave
rage 
# 
per 
inpu
t
8.6



Table 4. An example of some discovered paraphrases.

Sen
ten
ce
Go
ogle 
has 
pur
cha
sed 
Nes
t 
Lab
s
Cor
rect
Go
ogle 
has 
acq
uire
d 
Nes
t 
Lab
s

Go
ogle 
is 
buyi
ng  
Nes
t 
Lab
s

Go
ogle 
own
ed 
Nes
t 
Lab
s

Go
ogle 
is 
buy
s  
Nes
t 
Lab
s

Go
ogle 
has 
ann
oun
ced 
thei
r  
acq
uisi
tion 
of 
Nes
t 
Lab
s

Go
ogle 
ﬁna
lizes  
acq
uisi
tio
n of 
Nes
t 
Lab
s
Inc
orre
ct
Go
ogle 
has 
ann
oun
ced 
plan
s  to 
buy  
the
rm
ost
at 
ma
ker 
Nes
t 
Lab
s

Go
ogle 
has 
acq
uir
ed 
sm
art
-
ga
dge
t  
co
mp
any 
Nes
t 
Lab
s

Table 5. Another  example of some discovered paraphrases.

Sen
ten
ce
Yah
oo  
is 
hea
dqu
arte
red 
in 
Sun
nyv
ale
Cor
rect
Yah
oo  
is 
loc
ate
d in 
Sun
nyv
ale

Su
nny
vale 
is 
ho
me 
to 
not
able 
co
mp
ani
es 
suc
h  
as 
Yah
oo

Yah
oo  
hea
dqu
arte
rs 
in 
the 
Su
nny
vale 
are
a

Yah
oo  
hea
dqu
arte
rs 
in 
Sun
nyv
ale.
Inc
orre
ct
Vie
w 
all 
Yah
oo  
jobs  
in 
Sun
nyv
ale

Rev
iew
s 
on 
Yah
oo  
in 
Sun
nyv
ale


6.2     Results

In this section, we show the results  of the experiments and analyze  them. Table 3 
shows the performance  of our proposed method for each of the ﬁve semantic  rela- 
tions  and  their  average. We calculate the precision  as how many  “true” para- 
phrases are in the paraphrases obtained by our method. From Table 3, we can see 
the sentence  query  for the acquisition relation  achieved  the best  performance 
with the precision of 80.8 %, while the sentence query for the headquarter  rela- 
tion preforms  the worst with the precision  of 40 %. As there isn’t  much work in 
acquiring  sentential-level paraphrases  from the Web, it is hard  to construct a 
baseline  to compare  against. However, we can analyze  them in consideration of 
numbers  reported  previously for acquiring  paraphrases from the Web. TE/ASE 
method [13] reports  obtained  precision of 44.15 %, compared  to our average pre- 
cision  of 60.5 %.  It  is  diﬃcult  to  estimate  the  recall  since  we  do not  have  a 
complete  set  of paraphrases for a given  sentence.  Instead  of evaluating recall, 
we calculate the average number of correct  paraphrases per input sentence.  The 
average number  of paraphrases per input  is 5.5 of TE/ASE method,  compared 
to our 8.6.
   In order to ﬁnd the reasons why our method succeeds or fails to acquire para- 
phrases,  let  us do in-depth  analysis especially on the  best  performance  query 
and the worst  performance  query,  respectively. Table 4 shows some correct  and



incorrect  paraphrases obtained  by  our  method  for the  query  from the  acqui- 
sition relation.  As we mentioned  before,  this  query  achieves  the  best  perfor- 
mance.  Actually, we extract more than  280 templates from the top 1000 search 
results  of the AND query “Google AND Nest Labs”.  The most frequently occur- 
ring  templates themselves are  good candidates. Therefore,  we get  more  para- 
phrases  with a single input.  On the other  hand,  take  the incorrect  paraphrase 
“Google  has announced  plans  to buy  thermostat maker  Nest Labs.”  for exam- 
ple. Compared  with the given  sentence  “Google  has purchased Nest Labs.”,  it 
also  contains  a further  explanation of Nest  Labs  that  Nest  Labs  is a thermo- 
stat  maker,  and we think such additional information  leads to non-paraphrases. 
Although  its template X h as announced  plans  to buy  thermostat maker  Y is 
suitable for few extracted entity  tuples,  it received  the propagated value  from 
the strong coordinate degree between other tuples and (Google,Nest Labs). We 
surveyed the result  of coordinate  entity  tuples  and found that entity  tuples  such 
as  (Microsoft,Nokia), (Yahoo,Tumblr)  get higher coordinate  values  than  those 
of other queries.  This leads  a misjudgment of paraphrases. Table 5 shows some 
correct  and  incorrect  paraphrases obtained  by  our method  for the query  from 
the  headquarter relation.  As we mentioned  before,  this  query  performs  the 
worst. Actually, we extract even less than 40 templates from the top 1000 search 
results  of the query  “Yahoo  AND Sunnyvale”. The reasons  we considered  are 
that ﬁrstly,  there are not so many search results  contained  both Yahoo and Sun- 
nyvale  in a single sentence;  secondly,  even  they  are  in the same  sentence,  that 
sentence  may  be too short,  or too long. Besides,  advertisements also  have  an 
inﬂuence.  Take  the  incorrect  paraphrase “View  all  Yahoo  jobs  in Sunnyvale.” 
for example.  Such  advertisements are  suitable   for almost  all  extracted entity 
tuples,  so they get higher paraphrase values.  From the above  discussion,  we can 
point  out  that  if the number  of extracted templates could  increase  (i.e.  using 
high-valued coordinate  entity tuples to gather more templates), our method’s 
performance  would improve  to some extent.  And we should give a penalty  to a 
too-general template to restrict the value  propagation, since it is likely to be an 
advertisement, or an automatically generated  sequence  by a website  to increase 
its click rate.


7    Conclusion

Given a sentence,  our proposed  method  aims  to ﬁnd its paraphrases from the 
noisy Web. Here we incorporate coordinate  relationship and take a mutually 
reinforcing  way  to calculate paraphrase degree  and  coordinate  degree.  Experi- 
ments show our average precision is 60.5 %, compared  to TE/ASE method with 
average precision of 44.15 %. Besides, the average number of correct paraphrases 
is 8.6 of our method, compared  to TE/ASE method of 5.5.
   As we stated  in Sect. 6.2, for some queries,  we cannot  get enough templates. 
One way  to solve this problem  is to use high-valued  coordinate  entity  tuples  to 
gather more templates, and even execute  our method in a iterative way. However, 
it  causes  too  many  accesses  to  the  Web, and  sometimes,  we still  cannot  ﬁnd



enough templates. Another way to solve this problem is to do syntactic analysis 
to eliminate some additional information,  i.e. “thermostat maker”. Furthermore, 
we will give a penalty  to a too-general template to restrict the value propagation.


Acknowledgment. This work was supported in part by the following projects: Grants- 
in-Aid for Scientiﬁc  Research (Nos. 24240013, 24680008) from MEXT of Japan.

References

1.  Agichtein,   E.,  Gravano, L.:  Snowball: extracting  relations from  large  plain-text 
collections. In: Proceedings of the Fifth ACM Conference  on Digital  Libraries, DL
2000, pp. 85–94 (2000)
2.  Anick, P.G., Tipirneni, S.: The paraphrase search  assistant: terminological feedback
for iterative information seeking.  In: Proceedings of the 22Nd Annual  International
ACM SIGIR Conference  on Research and  Development in Information Retrieval,
pp. 153–159 (1999)
3.  Bannard, C., Callison-Burch, C.: Paraphrasing with bilingual parallel corpora. In:
Proceedings of the  43rd  Annual  Meeting  on Association for Computational Lin-
guistics, pp. 597–604 (2005)
4.  Barzilay, R., Elhadad, N.: Sentence  alignment for monolingual comparable corpora.
In: Proceedings of the 2003 Conference on Empirical Methods in Natural Language
Processing, pp. 25–32 (2003)
5.  Barzilay, R., McKeown,  K.R.:  Extracting paraphrases from  a parallel corpus.  In:
Proceedings of the  39th  Annual  Meeting  on Association for Computational Lin-
guistics, pp. 50–57 (2001)
6.  Barzilay, R.,  McKeown,  K.R.,  Elhadad, M.: Information fusion  in the  context  of
multi-document summarization.  In:  Proceedings of the  37th  Annual  Meeting  of
the Association for Computational Linguistics on Computational Linguistics, pp.
550–557 (1999)
7.  Bollegala, D.T., Matsuo,  Y., Ishizuka, M.: Relational duality: unsupervised extrac-
tion of semantic relations between  entities on the web. In: Proceedings of the 19th
International Conference  on World Wide Web, pp. 151–160 (2010)
8.  Callison-Burch, C., Koehn,  P.,  Osborne,  M.: Improved statistical machine  trans-
lation  using paraphrases. In: Proceedings of the Main Conference  on Human Lan-
guage  Technology Conference  of the  North  American Chapter  of the  Association
of Computational Linguistics, pp. 17–24 (2006)
9.  Denning,  P.,  Horning,  J., Parnas, D., Weinstein,   L.: Wikipedia  risks.  Commun.
ACM 48(12), 152–152 (2005)
10.  Etzioni,  O., Banko,  M., Soderland, S., Weld,  D.S.: Open information extraction
from the web.  Commun.  ACM 51(12), 68–74 (2008)
11.  Etzioni,  O., Cafarella, M., Downey,  D., Popescu, A.M., Shaked,  T., Soderland, S.,
Weld,  D.S.,  Yates, A.:  Unsupervised named-entity extraction  from  the  web:  an
experimental study. Artif.  Intell.  165,  91–134 (2005)
12.  Harris,  Z.S.: Distributional structure. Word 10,  146–162 (1954)
13.  Idan,  I.S., Tanev, H., Dagan,  I.: Scaling  web-based acquisition of entailment rela-
tions.  In: Proceedings of EMNLP, pp. 41–48 (2004)
14.  Lin, D., Pantel, P.:  Dirt  - discovery of inference  rules  from  text. In: Proceedings
of the ACM SIGKDD Conference  on Knowledge Discovery and  Data  Mining, pp.
323–328 (2001)



15.  Madnani,  N., Ayan,  N.F., Resnik,  P., Dorr, B.J.: Using paraphrases for parameter 
tuning  in statistical machine  translation. In: Proceedings of the ACL Workshop  on 
Statistical Machine  Translation (2007)
16.  Marton,  Y.,  Callison-Burch, C., Resnik,  P.: Improved statistical machine  transla- 
tion using monolingually-derived paraphrases. In: Proceedings of the 2009 Confer- 
ence on Empirical Methods  in Natural Language  Processing, pp. 381–390 (2009)
17.  McKeown,   K.R.,   Barzilay,  R.,  Evans,   D.,  Hatzivassiloglou,  V.,  Klavans,  J.L., 
Nenkova,  A.,  Sable,  C., Schiﬀman,  B.,  Sigelman,  S.,  Summarization, M.: Track- 
ing and  summarizing news  on a daily  basis  with  columbia’s newsblaster. In: Pro- 
ceedings  of the Second  International Conference  on Human Language Technology 
Research, pp. 280–285 (2002)
18.  Ohshima, H., Oyama,  S., Tanaka, K.: Searching coordinate terms with their context 
from  the  web.  In: Aberer,  K.,  Peng,  Z., Rundensteiner, E.A.,  Zhang,  Y.,  Li, X., 
Unland,  R. (eds.)  WISE 2006. LNCS, vol.  4255, pp.  40–47. Springer,  Heidelberg 
(2006)
19.  Pa¸sca, M., Dienes, P.: Aligning needles in a haystack: paraphrase acquisition across 
the web. In: Dale, R., Wong, K.-F., Su, J., Kwong, O.Y., Unland,  R. (eds.)  IJCNLP
2005. LNCS (LNAI), vol. 3651, pp. 119–130. Springer,  Heidelberg  (2005)
20.  Salton,  G., McGill, M.J.:  Introduction to Modern Information Retrieval. McGraw-
Hill Inc., New York  (1986)
21.  Shinyama, Y.,  Sekine,  S.:  Paraphrase acquisition for  information extraction.  In:
Proceedings of the  Second  International Workshop  on Paraphrasing, vol.  16, 65–
71 (2003)
22.  Shinyama, Y.,  Sekine,  S., Sudo,  K.:  Automatic paraphrase acquisition from news
articles. In: Proceedings of the  Second  International Conference  on Human  Lan-
guage  Technology Research, HLT 2002, pp. 313–318 (2002)
23.  Wang,  R., Callison-Burch, C.: Paraphrase fragment extraction from monolingual
comparable corpora. In: Proceedings of the 4th Workshop  on Building  and  Using
Comparable Corpora:  Comparable Corpora  and the Web, pp. 52–60 (2011)
24.  Wubben,  S., van  den  Bosch,  A., Krahmer, E., Marsi,  E.: Clustering and  match-
ing  headlines for  automatic paraphrase acquisition. In:  Proceedings of the  12th
European Workshop  on Natural Language Generation, ENLG 2009, pp.  122–125
(2009)
25.  Yamamoto, Y.,  Tanaka, K.:  Towards web  search  by  sentence queries:  asking  the
web for query  substitutions. In: Yu,  J.X., Kim, M.H., Unland,  R. (eds.)  DASFAA
2011, Part  II. LNCS, vol. 6588, pp. 83–92. Springer,  Heidelberg  (2011)
26.  Yates, A., Cafarella, M., Banko,  M., Etzioni,  O., Broadhead, M., Soderland, S.:
Textrunner: Open information extraction on the  web.  In: Proceedings of Human
Language Technologies: The Annual  Conference  of the North American Chapter  of
the Association for Computational Linguistics: Demonstrations, pp. 25–26 (2007)




