<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">A method is presented for segmenting documents into conceptually related areas.</S>
		<S sid ="2" ssid = "2">Determining the equivalence of text is often based on the number of word repetitions.</S>
		<S sid ="3" ssid = "3">This approach is unsuitable for detecting short segments because terms tend not to be repeated across just a few sentences.</S>
		<S sid ="4" ssid = "4">In this paper we investigate the contribution of two other lexical features to find related words: collocation and relation weights (which identify semantic relations).</S>
		<S sid ="5" ssid = "5">An experiment was conducted on a set of test data with known topic changes; performances of the three features were independently compared.</S>
		<S sid ="6" ssid = "6">A combination of all features was the most reliable indicator of a topic change.</S>
		<S sid ="7" ssid = "7">In another experiment, CNN news summaries were segmented into their individual news stories.</S>
		<S sid ="8" ssid = "8">Precision and recall rates of around 90% are reported for news story boundary detection.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="9" ssid = "9">In this paper we investigate the conceptual segmentation of a document.</S>
			<S sid ="10" ssid = "10">This method is useful for a number of applications such as text summarisation and information retrieval.</S>
			<S sid ="11" ssid = "11">A document can be segmented, each segment independently summarised, then all summaries combined to produce an abstract.</S>
			<S sid ="12" ssid = "12">To retrieve just the relevant areas of a document, text segmentation can decompose a document into related sections and then query terms can be compared to each section.</S>
			<S sid ="13" ssid = "13">Typically, segmentation algorithms identify related text segments by matching on repeated words [1, 2].</S>
			<S sid ="14" ssid = "14">This method is unreliable for segmenting between short excerpts such as a few sentences [3, 4].</S>
			<S sid ="15" ssid = "15">Ponte and Croft [4] segmented a database of brief news broadcasts.</S>
			<S sid ="16" ssid = "16">To increase the number of terms for matching, existing terms were expanded with collocations.</S>
			<S sid ="17" ssid = "17">(A collocation is a sequence of words, usually pairs, that frequently co-occur.)</S>
			<S sid ="18" ssid = "18">Another segmenter actually matched on collocating words [5].</S>
			<S sid ="19" ssid = "19">Semantic relations derived from WordNet have been used for text segmentation [6, 7] and for document matching [8].</S>
			<S sid ="20" ssid = "20">Many of these approaches failed to improve on the performance of algorithms that rely on word repetition.</S>
			<S sid ="21" ssid = "21">It was proposed that the reliability of segments found could be improved, particularly for short segments, by looking for multiple features.</S>
			<S sid ="22" ssid = "22">Lexical cohesion [9] describes the semantic relations that exist between words in a text.</S>
			<S sid ="23" ssid = "23">Sections of text that are strongly cohesive (have many relations) are likely to be related in meaning.</S>
			<S sid ="24" ssid = "24">This behaviour is useful for text segmentation.</S>
			<S sid ="25" ssid = "25">Lexical cohesion is generally represented in segmentation algorithms by just word repetition.</S>
			<S sid ="26" ssid = "26">Word repetition does comprise a significant proportion of lexical cohesion—nearly three- quarters of all ties [9]—but it is not the only contributing factor.</S>
			<S sid ="27" ssid = "27">Collocation accounts for about 17% of lexical cohesion ties, and a further 10% are synonym or superordinate relations.</S>
			<S sid ="28" ssid = "28">Morris and Hirst’s [10] segmenter looked for word repetition and semantic relations derived from a thesaurus.</S>
			<S sid ="29" ssid = "29">However, it did not include collocation, and was not automated.</S>
			<S sid ="30" ssid = "30">This paper presents a text segmentation algorithm that employs multiple lexical features, so short segments can be detected.</S>
	</SECTION>
	<SECTION title="Proposed algorithm. " number = "2">
			<S sid ="31" ssid = "1">In earlier work [11] a text segmentation algorithm was described that captured all types of lexical cohesion ties.</S>
			<S sid ="32" ssid = "2">To automatically find ties between pairwise words three features were developed: word repetition, collocation and relation weights.</S>
			<S sid ="33" ssid = "3">This paper describes the use of a modified segmenter and its application to short segments.</S>
			<S sid ="34" ssid = "4">Modifications include the automatic detection of sentences; the normalisation of all scores, so each feature contributes equally; and the summation of association ratios for collocations, rather than cumulating the number of occurrences.</S>
			<S sid ="35" ssid = "5">These enhancements have improved the segmenter’s performance.</S>
			<S sid ="36" ssid = "6">The proposed algorithm for text segmentation is shown in Figure 1.</S>
			<S sid ="37" ssid = "7">The algorithm uses ‘blocking.’ Lexical similarity is calculated for adjacent blocks of sentences, and segment boundaries are placed between blocks with low similarity.</S>
			<S sid ="38" ssid = "8">Currently, block size is variable which is useful for dealing with different length segments.</S>
			<S sid ="39" ssid = "9">1.</S>
			<S sid ="40" ssid = "10">Locate sentence boundaries..</S>
			<S sid ="41" ssid = "11">2.</S>
			<S sid ="42" ssid = "12">Compare pairwise words across adjacent blocks:.</S>
			<S sid ="43" ssid = "13">2.1 Ignore function words..</S>
			<S sid ="44" ssid = "14">2.2.</S>
			<S sid ="45" ssid = "15">Find related words (ties) using lexical features:.</S>
			<S sid ="46" ssid = "16">Word repetition; Collocation; Relation weights.</S>
			<S sid ="47" ssid = "17">2.3.</S>
			<S sid ="48" ssid = "18">Calculate a feature score for each matching pair..</S>
	</SECTION>
	<SECTION title="Calculate similarity scores:. " number = "3">
			<S sid ="49" ssid = "1">3.1.</S>
			<S sid ="50" ssid = "2">Cumulate feature scores for each lexical feature.</S>
			<S sid ="51" ssid = "3">across adjacent blocks.</S>
			<S sid ="52" ssid = "4">3.2.</S>
			<S sid ="53" ssid = "5">Normalise feature scores across all blocks..</S>
			<S sid ="54" ssid = "6">3.3.</S>
			<S sid ="55" ssid = "7">If multiple features are used, combine feature.</S>
			<S sid ="56" ssid = "8">scores across adjacent blocks then re-normalise.</S>
	</SECTION>
	<SECTION title="Insert segment boundaries at troughs in the similarity. " number = "4">
			<S sid ="57" ssid = "1">scores.</S>
			<S sid ="58" ssid = "2">Figure 1.</S>
			<S sid ="59" ssid = "3">Segmentation algorithm.</S>
			<S sid ="60" ssid = "4">Word repetition ties are identified by identical word pairs and pairs with the same root such as dark and darker.</S>
			<S sid ="61" ssid = "5">Morphological analysis is done by consulting a lexicon of root and inflected pairs (e.g. dark darker).</S>
			<S sid ="62" ssid = "6">A word pair is identified as a collocation by locating it in a lexicon pair.</S>
			<S sid ="63" ssid = "7">A trough in a sequence of similarity scores across a text signals a potential change of topic (a shift in the subject area discussed).</S>
			<S sid ="64" ssid = "8">The current algorithm considers all troughs to be an indication of a topic change.</S>
			<S sid ="65" ssid = "9">In future work a threshold or filter could be applied to differentiate between troughs.</S>
			<S sid ="66" ssid = "10">Hearst [1] selected troughs according to their relative depths.</S>
			<S sid ="67" ssid = "11">3.</S>
			<S sid ="68" ssid = "12">Experimental results.</S>
			<S sid ="69" ssid = "13">Two experiments are reported here which investigate the performance of the segmentation algorithm.</S>
			<S sid ="70" ssid = "14">In the first experiment a set of test data was generated to represent the base case.</S>
			<S sid ="71" ssid = "15">Pairwise articles from different topics were concatenated, so each concatenated text had at least one (known) topic change.</S>
			<S sid ="72" ssid = "16">The assumption was made that the location of these engineered changes was the easiest case.</S>
			<S sid ="73" ssid = "17">In the second experiment, CNN news summaries were segmented; this data is a real example of compounded text.</S>
			<S sid ="74" ssid = "18">3.1.</S>
			<S sid ="75" ssid = "19">Locating known topic changes.</S>
			<S sid ="76" ssid = "20">Ten topical articles, each covering a distinct subject, were collected from the Web.</S>
			<S sid ="77" ssid = "21">Concatenating pairs of these articles generated a total of 90 texts for test data.</S>
			<S sid ="78" ssid = "22">The transition from the first article to the second article represented a known topic change.</S>
			<S sid ="79" ssid = "23">The segmentation algorithm was applied using the three features both individually and in combination, and with a block size of six sentences following Hearst [1].</S>
			<S sid ="80" ssid = "24">Table 1 gives the results for the comparison of troughs placed by the segmentation algorithm to the known topic changes in the texts.</S>
			<S sid ="81" ssid = "25">comprising collocations and their association ratios [12] such as I(dark,ages) = 7.47.</S>
			<S sid ="82" ssid = "26">Relation weights [13] identify feature set mean number no error margin one sentence error margin and weight (0 to 100) semantically related pairs.</S>
			<S sid ="83" ssid = "27">They are based on the lexical organisation of Roget’s Thesaurus used troughs per text changes found prob.</S>
			<S sid ="84" ssid = "28">changes found prob.</S>
			<S sid ="85" ssid = "29">where both superordinate and synonym relationships are represented.</S>
			<S sid ="86" ssid = "30">About 20% of all word pairs (x,y) compared attain a significant weight where RW(x,y) &gt; 0.</S>
			<S sid ="87" ssid = "31">However, only strongly related pairs attain weights where RW(x,y) approaches 100, for example, RW(church,priest) = 81.25.</S>
			<S sid ="88" ssid = "32">A feature score is calculated for each matching word pair, f(x,y).</S>
			<S sid ="89" ssid = "33">Word repetition scores are quantitative; the number of repetitions observed are cumulated.</S>
			<S sid ="90" ssid = "34">Collocation and relation weight scores are qualitative; both features measure the strength of association between words.</S>
			<S sid ="91" ssid = "35">Feature scores are cumulated for each lexical feature across -1- f x y coll, rep, RW 4.0 86 .18 90 .53 rep, RW 3.6 84 .16 90 .47 coll, rep 4.0 83 .17 89 .52 rep 3.5 82 .15 90 .45 coll, RW 4.5 71 .20 85 .59 RW 5.1 65 .22 78 .67 coll 4.3 58 .19 81 .56 adjacent blocks by N where N is the total number of Table 1.</S>
			<S sid ="92" ssid = "36">Known topic changes found in 90 words compared.</S>
			<S sid ="93" ssid = "37">A similarity score is calculated for each pair of adjacent blocks based on the feature scores for that generated texts using a block size of six.</S>
			<S sid ="94" ssid = "38">The table shows the mean number of troughs found per text; the number of troughs that coincide with a known topic change; and the probability of a trough and a known change coinciding.</S>
			<S sid ="95" ssid = "39">Probability was calculated by dividing the number of troughs placed in a text by the total number of troughs that could occur.</S>
			<S sid ="96" ssid = "40">The majority of known topic changes coincided with a trough (96%) when all features were looked for across a text.</S>
			<S sid ="97" ssid = "41">This result is impressive because no error margin was used, and it reduces by approximately 50% the error rate of the best single feature—word repetition.</S>
			<S sid ="98" ssid = "42">Only four known topic changes went undetected.</S>
			<S sid ="99" ssid = "43">For each of these error cases a trough was placed within one sentence of the topic block size 1 2 3 4 P(trough at boundary) .32 .29 .28 .27 troughs per text 35.1 31.0 29.1 28.0 boundaries found 21.2 21.8 20.3 19.0 insertion errors 6.0 2.7 2.9 3.0 deletion errors 3.5 4.4 6.5 7.7 move errors 7.9 6.4 5.9 5.9 change.</S>
			<S sid ="100" ssid = "44">Hence, with a one sentence error margin, all 90 precision (excluding 60.4% 70.4% 69.5% 68.2% known topic changes were located.</S>
			<S sid ="101" ssid = "45">However, the probability of finding a change increases significantly recall move errors) 64.9% 66.8% 61.9% 58.2% when allowing an error margin.</S>
			<S sid ="102" ssid = "46">precision (including 83.1% 91.3% 90.4% 89.6% Looking for multiple features outperforms the use of these features individually.</S>
			<S sid ="103" ssid = "47">Word repetition was the most recall move errors) 89.1% 86.5% 80.1% 76.4% successful feature when applied alone (91%).</S>
			<S sid ="104" ssid = "48">This result is not surprising.</S>
			<S sid ="105" ssid = "49">Much previous work has used word repetition, so evidently it is a significant indicator of related text.</S>
			<S sid ="106" ssid = "50">This experiment demonstrates that word repetition in conjunction with additional lexical features gives a better boundary detection rate.</S>
			<S sid ="107" ssid = "51">3.2.</S>
			<S sid ="108" ssid = "52">Segmenting CNN news summaries.</S>
			<S sid ="109" ssid = "53">The objective of the current investigation was to determine if all troughs in a text coincide with topic changes, and to test the algorithm with real-world data.</S>
			<S sid ="110" ssid = "54">Sixty CNN news summaries were collected at random from the Web (http://cnn.com/QUICKNEWS/print.html) for test data.</S>
			<S sid ="111" ssid = "55">The data consisted of 2,019 news stories (segments) giving 1,959 segment boundaries for detection.</S>
			<S sid ="112" ssid = "56">These boundaries were considered the ground truth—the only Table 2.</S>
			<S sid ="113" ssid = "57">CNN news summaries segmented using different block sizes.</S>
			<S sid ="114" ssid = "58">With a block size of two, 66.8% of the boundaries were detected.</S>
			<S sid ="115" ssid = "59">On average, 6.4 boundaries per summary were within one sentence of a trough.</S>
			<S sid ="116" ssid = "60">Including these move errors reduces the error rate by nearly 60% giving a 86.5% boundary detection rate.</S>
			<S sid ="117" ssid = "61">In Figure 2, which shows the segmentation results for one of the CNN news summaries used for test data, there are four move errors.</S>
			<S sid ="118" ssid = "62">All other troughs (27) in this summary coincided exactly with a boundary.</S>
			<S sid ="119" ssid = "63">1.0 algorithm topic changes in the test data.</S>
			<S sid ="120" ssid = "64">In the previous experiment, a block size of six sentences was used.</S>
			<S sid ="121" ssid = "65">For the current test data, with an average segment size of 3.3 sentences, this block size is too large.</S>
			<S sid ="122" ssid = "66">So, the algorithm was tested with block sizes ranging from one to four sentences.</S>
			<S sid ="123" ssid = "67">The combination of all features produced the best correct rate in the first experiment; therefore, the same configuration was adopted in this experiment.</S>
			<S sid ="124" ssid = "68">The troughs placed by the algorithm were compared to the news story boundaries.</S>
			<S sid ="125" ssid = "69">Table 2 shows the statistical mean results for the segmentation of the summaries.</S>
			<S sid ="126" ssid = "70">Precision and recall are given for both the exclusion of deletion error move error 0 boundary insertion error news story boundary move errors (not allowing an error margin) and the inclusion of move errors when an error margin of one sentence was considered.</S>
			<S sid ="127" ssid = "71">Figure 2.</S>
			<S sid ="128" ssid = "72">Position of news story boundaries in a CNN news summary in relation to troughs found by the algorithm.</S>
			<S sid ="129" ssid = "73">Four summaries had 100% precision where all troughs corresponded to a news story boundary.</S>
			<S sid ="130" ssid = "74">However, none of the summaries attained perfect recall where all boundaries were found.</S>
			<S sid ="131" ssid = "75">Some news stories were only two sentences long.</S>
			<S sid ="132" ssid = "76">With a block size of the same length or longer, these stories were always compared alongside sentences from adjacent, unrelated stories.</S>
			<S sid ="133" ssid = "77">Consequently, the segment boundaries were more difficult to distinguish.</S>
			<S sid ="134" ssid = "78">Also, news stories are grouped together by their relevance to a particular category such as world news and politics.</S>
			<S sid ="135" ssid = "79">In some cases boundaries went undetected because consecutive news stories had similar subject matter.</S>
			<S sid ="136" ssid = "80">A block size of one has the most insertion errors (6.0).</S>
			<S sid ="137" ssid = "81">An example of this error type is given in Figure 2.</S>
			<S sid ="138" ssid = "82">The trough at sentence 72 does not coincide with a boundary.</S>
			<S sid ="139" ssid = "83">This trough, however, is weak (has a shallow valley) and could be eliminated by thresholding.</S>
			<S sid ="140" ssid = "84">The larger block sizes (three and four) tend to under-segment, so more deletion errors occur.</S>
			<S sid ="141" ssid = "85">Boundaries were missed at the start of a summary because block size was too coarse.</S>
			<S sid ="142" ssid = "86">In Figure 2, the initial boundary at sentence three went undetected because it was in the first block comparison (i.e. sentences one and two compared to sentences three and four).</S>
			<S sid ="143" ssid = "87">The current algorithm, which incorporates semantic information, improves on systems that look for just word repetition or just collocation (e.g. [1, 5]).</S>
			<S sid ="144" ssid = "88">Ponte and Croft [4] used collocations to expand terms.</S>
			<S sid ="145" ssid = "89">This approach worked well, achieving precision and recall rates of 95.0% and 84.4% (with no error margin), increasing to 95.9% and 85.2% with a two sentence margin.</S>
			<S sid ="146" ssid = "90">They reported that term expansion processes 200 KB of text per hour.</S>
			<S sid ="147" ssid = "91">The current segmenter has a faster processing speed (over 700 KB per hour), so it is more suitable for systems where response time is relevant.</S>
			<S sid ="148" ssid = "92">4.</S>
			<S sid ="149" ssid = "93">Conclusions and future work.</S>
			<S sid ="150" ssid = "94">The first experiment demonstrated that word matching using semantic relations, in addition to word repetition, improves segmentation.</S>
			<S sid ="151" ssid = "95">A total of 96% of the known topic changes in 90 texts were located.</S>
			<S sid ="152" ssid = "96">Four topic changes were not found, but in each case a trough was placed within one sentence of the change.</S>
			<S sid ="153" ssid = "97">In the second experiment, short segments were successfully detected in CNN news summaries.</S>
			<S sid ="154" ssid = "98">Nearly 70% of the boundaries between news stories were detected.</S>
			<S sid ="155" ssid = "99">Including move errors (boundaries within one sentence of a trough) improved boundary detection to 86.5%.</S>
			<S sid ="156" ssid = "100">The segmentation algorithm worked well for different segment lengths.</S>
			<S sid ="157" ssid = "101">In the first experiment segments averaged 17 sentences, and in the second experiment they were 3.3 sentences.</S>
			<S sid ="158" ssid = "102">The only parameter changed between the two experiments was block size.</S>
			<S sid ="159" ssid = "103">Currently, block size has been chosen by examining the data.</S>
			<S sid ="160" ssid = "104">In future work, an automatic process could be run where several block sizes are tested and a characteristic of the result could be analysed to determine the most suitable block size to proceed.</S>
			<S sid ="161" ssid = "105">An issue not addressed in this research is the consideration of document formatting features.</S>
			<S sid ="162" ssid = "106">Web-based CNN news summaries, for instance, include the section headers “World News” and “U.S. News.” These headers indicate the start of a new section and hence the beginning of a news story; they could be used to cue segment boundaries.</S>
			<S sid ="163" ssid = "107">However, such cues are likely to be document specific.</S>
			<S sid ="164" ssid = "108">A set of boundary cues would have to be identified for every document type processed by the segmenter.</S>
	</SECTION>
			<S sid ="165" ssid = "109">1.</S>
			<S sid ="166" ssid = "110">M.A. Hearst (1994) Multi-paragraph segmentation of expository texts, Report No.</S>
			<S sid ="167" ssid = "111">UCB/CSD 94/790, University of California, Berkeley 2.</S>
			<S sid ="168" ssid = "112">Y. Yaari (1997) Segmentation of expository texts by hierarchical agglomerative clustering, RANLP’97, Bulgaria 3.</S>
			<S sid ="169" ssid = "113">G. Salton and C. Buckley (1991) Global text matching for information retrieval, Science, 253, pp.</S>
			<S sid ="170" ssid = "114">10121015 4.</S>
			<S sid ="171" ssid = "115">J.M. Ponte and W.B. Croft (1997) Text segmentation by topic, Proceedings of the 1st European Conference on Research and Advanced Technology for Digital Libraries, pp.</S>
			<S sid ="172" ssid = "116">113125</S>
	</SECTION>
	<SECTION title="D. Beeferman, A. Berger and J. Lafferty (1997) Text " number = "5">
			<S sid ="173" ssid = "1">segmentation using exponential models, Proceedings of the 2nd Conference on Empirical Methods in Natural Language Processing</S>
	</SECTION>
	<SECTION title="M.A. Hearst (1993) TextTiling: A quantitative approach to " number = "6">
			<S sid ="174" ssid = "1">discourse segmentation, Technical Report 93/24, Sequoia 2000, University of California, Berkeley</S>
	</SECTION>
	<SECTION title="M.A. Stairmand (1997) Textual context analysis for " number = "7">
			<S sid ="175" ssid = "1">information retrieval, Proceedings of the ACM SIGIR Conference on Research and Development in Information Retrieval, Philadelphia, pp.</S>
			<S sid ="176" ssid = "2">140147</S>
	</SECTION>
	<SECTION title="S.J. Green (1998) Automated link generation: Can we do " number = "8">
			<S sid ="177" ssid = "1">better than term repetition?, Proceedings of the Seventh International World Wide Web Conference, Brisbane, Australia, pp.</S>
			<S sid ="178" ssid = "2">7584</S>
	</SECTION>
	<SECTION title="M.A.K. Halliday and R. Hasan (1976) Cohesion in English, " number = "9">
			<S sid ="179" ssid = "1">Longman Group</S>
	</SECTION>
	<SECTION title="J. Morris and G. Hirst (1991) Lexical cohesion computed by " number = "10">
			<S sid ="180" ssid = "1">thesaural relations as an indicator of the structure of text, Computational Linguistics, 17(1), pp.</S>
			<S sid ="181" ssid = "2">2148</S>
	</SECTION>
	<SECTION title="A.C. Jobbins and L.J. Evett (1998) Text segmentation using " number = "11">
			<S sid ="182" ssid = "1">reiteration and collocation, 17th International Conference on Computational Linguistics, Montreal, Canada</S>
	</SECTION>
	<SECTION title="K.W. Church and P. Hanks (1990) Word association norms, " number = "12">
			<S sid ="183" ssid = "1">mutual information and lexicography, Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics, pp.</S>
			<S sid ="184" ssid = "2">7683</S>
	</SECTION>
	<SECTION title="A.C. Jobbins and L.J. Evett (1995) Automatic identification " number = "13">
</PAPER>
