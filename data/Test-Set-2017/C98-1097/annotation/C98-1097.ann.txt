Citance Number: 1 | Reference Article: C98-1097 | Citing Article: C02-1033 | Citation Marker Offset: '15' | Citation Marker: Jobbins and Evett, 1998 | Citation Offset: '15' | Citation Text: <S sid ="15" ssid = "15">Hybrid systems that combine the approaches we have presented were also developed and illustrated the interest of such a combination: (Jobbins and Evett, 1998) combined word recurrence, collocations and a thesaurus; (Beeferman et al., 1999) relied on both collocations and linguistic cues.</S> | 
Citance Number: 2 | Reference Article: C98-1097 | Citing Article: C02-1033 | Citation Marker Offset: '136' | Citation Marker: Jobbins and Evett, 1998 | Citation Offset: '136' | Citation Text: <S sid ="136" ssid = "91">Thus, Table 1 confirms the fact reported in (Jobbins and Evett, 1998) that using collocations together with word recurrence is an interesting approach for text segmentation.</S> | 
Citance Number: 3 | Reference Article: C98-1097 | Citing Article: ICDAR99 | Citation Marker Offset: '31' | Citation Marker: 11 | Citation Offset: '31','32' | Citation Text: <S sid ="31" ssid = "1">In earlier work [11] a text segmentation algorithm was described that captured all types of lexical cohesion ties.</S><S sid ="32" ssid = "2">To automatically find ties between pairwise words three features were developed: word repetition, collocation and relation weights.</S> | 
Citance Number: 4 | Reference Article: C98-1097 | Citing Article: P07-1061 | Citation Marker Offset: '17' | Citation Marker: Job- bins and Evett, 1998 | Citation Offset: '17' | Citation Text: <S sid ="17" ssid = "17">Hybrid systems that combine the approaches we have presented were also developed and illustrated the interest of such a combination: (Job- bins and Evett, 1998) combined word recurrence, co-occurrences and a thesaurus; (Beeferman et al., 1999) relied on both lexical modeling and discourse cues; (Galley et al., 2003) made use of word reiteration through lexical chains and discourse cues.</S> | 
Citance Number: 5 | Reference Article: C98-1097 | Citing Article: P07-1061 | Citation Marker Offset: '30' | Citation Marker: Jobbins and Evett, 1998 | Citation Offset: '30','31','32' | Citation Text: <S sid ="30" ssid = "9">When no external knowledge is used, this similarity is only based on the strict reiteration of words.</S><S sid ="31" ssid = "10">But it can be enhanced by taking into account semantic relations between words.</S><S sid ="32" ssid = "11">This was done for instance in (Jobbins and Evett, 1998) by taking semantic relations from Roget's Thesaurus.</S> | 
Citance Number: 6 | Reference Article: C98-1097 | Citing Article: P07-1061 | Citation Marker Offset: '90' | Citation Marker: Jobbins and Evett, 1998 | Citation Offset: '89','90' | Citation Text: <S sid ="89" ssid = "5">The cohesion in the part of text delimited by this window is evaluated by measuring the word reiteration between its two sides.</S><S sid ="90" ssid = "6">This is done in our case by applying the Dice coefficient between the two sides of the focus window, following (Jobbins and Evett, 1998).</S> | 
Citance Number: 7 | Reference Article: C98-1097 | Citing Article: P07-1061 | Citation Marker Offset: '98' | Citation Marker: Jobbins and Evett, 1998 | Citation Offset: '97','98' | Citation Text: <S sid ="97" ssid = "13">This evaluation is also a weak point as card(Wl  Wr ) only relies on word reiteration.</S><S sid ="98" ssid = "14">As a consequence, two different words that respectively belongs to Wl and Wr but also belong to the same text topic cannot contribute l r to the identification of a possible topical similarity This measure was adopted instead of the Cosine measure used in TextTiling because its definition in terms of sets makes it easier to extend for taking into account other types of relations, as in (Jobbins and Evett, 1998).</S> | 
Citance Number: 8 | Reference Article: C98-1097 | Citing Article: P07-1061 | Citation Marker Offset: '203' | Citation Marker: Jobbins and Evett, 1998 | Citation Offset: '203','204' | Citation Text: <S sid ="203" ssid = "21">In fact, the way we use relations between words is closer to (Jobbins and Evett, 1998), even if the relations in this work come from a network of co-occurrences or a thesaurus rather than from text topics.</S><S sid ="204" ssid = "22">In both cases the similarity of two text units is determined by the proportion of their words that are part of a relation across the two units.</S> | 
Citance Number: 9 | Reference Article: C98-1097 | Citing Article: P07-1061 | Citation Marker Offset: '216' | Citation Marker: Job- bins and Evett, 1998 | Citation Offset: '216' | Citation Text: <S sid ="216" ssid = "8">This network could also be used more directly for topic segmentation as in (Job- bins and Evett, 1998).</S> | 
Citance Number: 10 | Reference Article: C98-1097 | Citing Article: P04470 | Citation Marker Offset: '27' | Citation Marker: 5 | Citation Offset: '27' | Citation Text: <S sid ="27" ssid = "4">In other words, meaning of UW can be found generally through co- occurrence words [5].</S> | 
Citance Number: 11 | Reference Article: C98-1097 | Citing Article: P06128 | Citation Marker Offset: '10' | Citation Marker: 1 | Citation Offset: '10' | Citation Text: <S sid ="10" ssid = "10">In information retrieval, to segment a long document into distinct topics is useful because only the topical segments relevant to the users needs are retrieved [1].</S> | 
Citance Number: 12 | Reference Article: C98-1097 | Citing Article: S0885 | Citation Marker Offset: '110' | Citation Marker: 1998 | Citation Offset: '109','110' | Citation Text: <S sid ="109" ssid = "27">Indeed, the primary goal of semantic relations is obviously to ensure that two semantically related words, e.g., car and drive, contribute to the lexical cohesion, thus avoiding erroneous topic boundaries between two such words.</S><S sid ="110" ssid = "28">These different methods can use semantic relations that are manually defined by experts, as in Morris and Hirst (1991), or extracted automatically from corpora (Ferret, 2006; Jobbins and Evett, 1998).</S> | 
