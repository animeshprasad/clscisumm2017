<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">We investigate the extraction of ontologies from biological text using a semantic representation derived from a robust parser.</S>
		<S sid ="2" ssid = "2">The use of a semantic representation avoids the problems that traditional pattern-based approaches have with complex syntactic constructions and long-distance dependencies.</S>
		<S sid ="3" ssid = "3">The discovery of taxonomic relationships is explored in a corpus consisting of 12,200 animal-related articles from the online encyclopaedia Wikipedia.</S>
		<S sid ="4" ssid = "4">The semantic representation used is Robust Minimal Recursion Semantics (RMRS).</S>
		<S sid ="5" ssid = "5">Initial experiments show good results in systematising extraction across a variety of hyponymic constructions.</S>
		<S sid ="6" ssid = "6">Key words: ontologies, ontology extraction, Wikipedia, semantics</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="7" ssid = "7">Ontology extraction has traditionally relied on pattern matching algorithms.</S>
			<S sid ="8" ssid = "8">Hearst [5] introduced hyponymic extraction using lexico-syntactic patterns.</S>
			<S sid ="9" ssid = "9">In the Hearst algorithm, the system looks for instances of certain expressions in the text, for example ‘X is a Y’ or ‘X such as Y and Z’, and infers the relations ‘X is-a Y’ and ‘X is-a Z’.</S>
			<S sid ="10" ssid = "10">Such systems are usually based on regular expressions over text or POS-tagged text, and sentences containing apposition, bracketing, long-distance dependencies or uncommon structures have to be coded explicitly.</S>
			<S sid ="11" ssid = "11">An example of such a sentence, extracted from the Wikipedia encyclopaedia, is: The Firemouth Cichlid is one of the ‘typical’ and most commonly seen (in pet stores) of the Cichlasoma-type South American cichlids.</S>
			<S sid ="12" ssid = "12">Here obtaining the relationship ‘Firemouth cichlid is-a cichlid’ involves the identification of the hyponym and hypernym as the first and last noun phrases of a lengthy sentence.</S>
			<S sid ="13" ssid = "13">This suggests that traditional methods might be improved by using deeper syntactic and semantic analysis.</S>
			<S sid ="14" ssid = "14">The work presented here investigates the use of a semantic model to address some of these issues.</S>
			<S sid ="15" ssid = "15">Robust Minimal Recursion Semantics (RMRS, [4]) provides argument-based representation of sentences.</S>
			<S sid ="16" ssid = "16">The theoretical idea is that, in the problematic sentence above, an RMRS output would contain the predicate associated with the identity copula be with a first argument corresponding to the term Firemouth cichlid and a second argument corresponding to cichlids, regardless of the word order, modification and so on.</S>
			<S sid ="17" ssid = "17">Thus, having obtained the RMRS representation of a given corpus, it would be possible to extract ontological relationships from a semantic structure that abstracts over those morphological and syntactic details that do not affect the ontological relationship.</S>
			<S sid ="18" ssid = "18">As pointed out by Pennacchiotti and Pantel [6], most ontology extraction systems so far have focused on generalised is-a or part-of relationships.</S>
			<S sid ="19" ssid = "19">Our work involves extracting general hyponymic relations with RMRS and applying a filter to the results to obtain biological, taxonomic relationships.</S>
			<S sid ="20" ssid = "20">The corpus was gathered by extracting 12,200 animal articles from the Wikipedia online encyclopaedia (http://www.wikipedia.org/), providing a semi-edited setting where the added robustness of semantics might prove its usefulness.</S>
			<S sid ="21" ssid = "21">The next section of this paper gives an overview of relevant prior work.</S>
			<S sid ="22" ssid = "22">It is followed by the description of an extraction system based on RMRS, using hard- wired rules.</S>
			<S sid ="23" ssid = "23">Results are discussed in the light of four different evaluation methods covering both manual and automatic recall and precision.</S>
			<S sid ="24" ssid = "24">A brief overview is then given of a further system, still under development, the aim of which is to automate the pattern extraction process.</S>
			<S sid ="25" ssid = "25">The conclusion presents different avenues for future work.</S>
	</SECTION>
	<SECTION title="Previous Work. " number = "2">
			<S sid ="26" ssid = "1">The most widely used framework for automatic ontology extraction was originally proposed by Marti Hearst [5], who introduced the use of lexico-syntactic patterns for the extraction of hyponymic relationships.</S>
			<S sid ="27" ssid = "2">Hearst’s method has since then been followed by the most successful systems, such as the Espresso system proposed by Pennacchiotti and Pantel [6], based on bootstrapping.</S>
			<S sid ="28" ssid = "3">Aside from this pattern-based approach, new clustering methods have also been investigated.</S>
			<S sid ="29" ssid = "4">The main idea is to group terms that appear in the same kind of context and label the resulting clusters.</S>
			<S sid ="30" ssid = "5">The process yields natural hyponymic relations between the members of the cluster and its label.</S>
			<S sid ="31" ssid = "6">The clustering approach was pioneered by Caraballo [2] who used conjunction and apposition to form new clusters.</S>
			<S sid ="32" ssid = "7">Other methods attempt to do away with prior text processing on the basis that, as the size of the corpus increases, syntactic processing is not sustainable.</S>
			<S sid ="33" ssid = "8">Ravichandran and Hovy[7] propose a pattern matching algorithm for question answering systems, which relies on the direct use of the surface form of the corpus.</S>
			<S sid ="34" ssid = "9">Our work takes an approach similar to those investigated by Hearst and Pantel: patterns containing a binary relation of interest are applied to the corpus to extract instances.</S>
			<S sid ="35" ssid = "10">However, the method uses prior syntactic and semantic processing at a deeper level than the techniques described above.1 1 We are grateful to a reviewer for pointing out Suchanek et al’s paper [8] (which appeared just after our work was completed).</S>
			<S sid ="36" ssid = "11">They show excellent results using a</S>
	</SECTION>
	<SECTION title="Using RMRS for Ontology Extraction. " number = "3">
			<S sid ="37" ssid = "1">3.1 An Introduction to RMRS.</S>
			<S sid ="38" ssid = "2">RMRS[4] is a development of Minimal Recursion Semantics [3].</S>
			<S sid ="39" ssid = "3">One of its main features is its compatibility with both shallow and deep parsers, making it versatile enough for a wide range of applications: for the work reported here, we use RMRS structures derived from parses produced by RASP3 (Robust Accurate Statistical Parser [1]).</S>
			<S sid ="40" ssid = "4">RMRS allows for semantic underspecification and is robust in that a structure is produced even for partial parses.</S>
			<S sid ="41" ssid = "5">In the worst case, a (highly underspecified) RMRS can be constructed from POS-tagged data alone.</S>
			<S sid ="42" ssid = "6">Thus structurally deficient analyses can still yield correct ontological relationships as long as a connection can be found between the two elements of a pair.</S>
			<S sid ="43" ssid = "7">For this work, we use a compiled form of RMRS in which each sentence in the corpus corresponds to a series of minimal trees.</S>
			<S sid ="44" ssid = "8">Each tree has a root, which is one of the lemmas in the sentence, and one or more daughters, the first one of which is the index of the lemma (the other daughters being potential arguments).</S>
			<S sid ="45" ssid = "9">As well as the argument trees, ‘in-group’ relations, denoted here by the tag ‘INGS’, express conjunction.</S>
			<S sid ="46" ssid = "10">The elements of the trees and in-group relations can be co-indexed to reconstruct the whole sentence or, if the complete parse is not available, phrases in the sentence.</S>
			<S sid ="47" ssid = "11">An example is shown in Fig.</S>
			<S sid ="48" ssid = "12">1.</S>
			<S sid ="49" ssid = "13">Fig.</S>
			<S sid ="50" ssid = "14">1.</S>
			<S sid ="51" ssid = "15">RMRS representation for the sentence Xanthidae is a family of crabs.</S>
			<S sid ="52" ssid = "16">Indices are not shown.</S>
			<S sid ="53" ssid = "17">Three trees are identified by the rectangular frames.</S>
			<S sid ="54" ssid = "18">parser of roughly similar depth to the one we use, but they rely on syntactically- labelled relations.</S>
			<S sid ="55" ssid = "19">In principle, the RMRS approach has the advantage that it allows more abstraction from irrelevant details of syntax and also that it is possible to switch between parsers without modification to the extraction code, and indeed to use merged results from more than one parser.</S>
			<S sid ="56" ssid = "20">See [4] for further discussion.</S>
			<S sid ="57" ssid = "21">3.2 Corpus Preparation.</S>
			<S sid ="58" ssid = "22">The Wikipedia corpus is available as various database dumps in XML format.</S>
			<S sid ="59" ssid = "23">The dump used in this work was released on 22nd April 2006 and includes the most up-to-date versions of all pages, without edit history or pictures, at the date of the dump creation.</S>
			<S sid ="60" ssid = "24">12,200 animal articles were extracted from the dump and preprocessed so that only text information remained.</S>
			<S sid ="61" ssid = "25">The resulting pages were parsed using RASP3 [1] and the RASP-RMRS converter [4] was applied to the derivations to obtain the RMRS.</S>
			<S sid ="62" ssid = "26">The core of our system is a collection of classes that extracts and records RMRS trees, as described in §3.1, out of the original RMRS parse.</S>
			<S sid ="63" ssid = "27">The resulting representation forms the basis of ontology extraction.</S>
			<S sid ="64" ssid = "28">3.3 System Design.</S>
			<S sid ="65" ssid = "29">An initial, manual annotation of 100 articles in the corpus showed that 50% of pages started with the simplest hyponymic relation: A is-a B, where A is the first argument and B the second argument of the identity copula.</S>
			<S sid ="66" ssid = "30">In order to test the capabilities of RMRS extraction, our system was designed to systematically process such relationships and a number of common variations such as A is a species of B or A is a B species in the C family.</S>
			<S sid ="67" ssid = "31">The patterns covered by the system are: 1.</S>
			<S sid ="68" ssid = "32">A is a B 2.</S>
			<S sid ="69" ssid = "33">A is a B species (or other taxonomic vocabulary) 3.</S>
			<S sid ="70" ssid = "34">A is a species of B (or other taxonomic vocabulary) 4.</S>
			<S sid ="71" ssid = "35">any of the above but with a ‘one of ’ construct inserted prior to the hypernym (e.g., the gecko is one of several species of lizards.)</S>
			<S sid ="72" ssid = "36">An assumption was made as to the directionality of the hyponymic relationship: the cases where the hypernym is indicated by the subject of the identity copula (one of the most common species of felines is the cat) were considered infrequent enough to bypass their separate treatment at this stage.</S>
			<S sid ="73" ssid = "37">The patterns above required the identification of taxonomic vocabulary.</S>
			<S sid ="74" ssid = "38">Contributors to Wikipedia consistently follow the Linnaean scientific classification.</S>
			<S sid ="75" ssid = "39">There are seven levels in the Linnaean hierarchy (kingdom, phylum, class, order, family, genus and species); those levels were recorded in a vocabulary file for future use, together with a few variations and additional terms commonly seen in the articles’ introductions.</S>
			<S sid ="76" ssid = "40">The algorithm processes each corpus sentence in four steps and fully utilises the argument structure and relational blocks of the RMRS.</S>
			<S sid ="77" ssid = "41">For conciseness, the following gives the skeleton of the code only but provides at each step the list of RMRS features used.</S>
			<S sid ="78" ssid = "42">1.</S>
			<S sid ="79" ssid = "43">Identify RMRS trees headed by the identity copula..</S>
			<S sid ="80" ssid = "44">ARG1 = base for hyponym ARG2 = base for hypernym Store ARG1 and ARG2 terms in arrays h and H. 2.</S>
			<S sid ="81" ssid = "45">Resolve ‘one-of’ constructs:.</S>
			<S sid ="82" ssid = "46">with: one INGS of then: of ARG1 x (replace ‘one’ with x in H.)</S>
			<S sid ="83" ssid = "47">3.</S>
			<S sid ="84" ssid = "48">Resolve taxonomic terms T:.</S>
			<S sid ="85" ssid = "49">with: ‘of’ trees (of ARG1 T ARG2 resolution) or: adjective trees (resolution ARG1 T)</S>
	</SECTION>
	<SECTION title="Expand hyponym and hypernym:. " number = "4">
			<S sid ="86" ssid = "1">with: compound_rel, named_rel and adjective trees (JJ ARG1 NN).</S>
			<S sid ="87" ssid = "2">The results of this process are potential hyponymic relations, which may refer to any kind of entity, not only animal organisms.</S>
			<S sid ="88" ssid = "3">A simple Named Entity Recognition method implemented by lexicon lookup was applied to the results to filer them.</S>
			<S sid ="89" ssid = "4">The NER lexicon was automatically constructed by recording the titles of all articles in the corpus.</S>
			<S sid ="90" ssid = "5">Truncation was systematically applied to both terms of the relation in order to extract terms such as wild cat out of the phrase a small wild cat.</S>
			<S sid ="91" ssid = "6">4 Results and Evaluation.</S>
			<S sid ="92" ssid = "7">4.1 Evaluation Measures.</S>
			<S sid ="93" ssid = "8">Four evaluation measures were trialled, covering traditional calculations such as manual precision over a subset of the corpus as well as less common methods such as manual recall.</S>
			<S sid ="94" ssid = "9">The following describes all four heuristics.</S>
			<S sid ="95" ssid = "10">The Gold Standard used throughout the evaluation was the NCBI online taxonomy (http: //www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=Taxonomy).</S>
			<S sid ="96" ssid = "11">1.</S>
			<S sid ="97" ssid = "12">Manual recall.</S>
			<S sid ="98" ssid = "13">Recall was calculated over a subset of the corpus.</S>
			<S sid ="99" ssid = "14">100 arti-.</S>
			<S sid ="100" ssid = "15">cles were read by one annotator and each relevant hyponymy recorded, together with its originating sentence.</S>
			<S sid ="101" ssid = "16">194 relationships were found and covered the use of syntactic patterns such as constructs depending on the identity copula, apposition, punctuation and full inclusion verbs (include, comprise, etc).</S>
			<S sid ="102" ssid = "17">The manual recall score is thus the number of unique pairs extracted from the subset divided by 194.2 2.</S>
			<S sid ="103" ssid = "18">‘Rough’ recall.</S>
			<S sid ="104" ssid = "19">This recall figure reflects how many pairs were found in relation to the number of articles considered.</S>
			<S sid ="105" ssid = "20">Using the figures compiled for manual recall calculation, it was estimated that each article contained roughly two unique taxonomic relationships.</S>
			<S sid ="106" ssid = "21">The rough recall was simply the number of unique pairs divided by twice the number of articles.</S>
			<S sid ="107" ssid = "22">3.</S>
			<S sid ="108" ssid = "23">Manual precision evaluation.</S>
			<S sid ="109" ssid = "24">Manual precision was calculated over 100.</S>
			<S sid ="110" ssid = "25">pairs randomly extracted from the results.</S>
			<S sid ="111" ssid = "26">The aim was to check the actual truth of the extracted relations rather than just their correspondence to the originating sentences.</S>
			<S sid ="112" ssid = "27">The scoring scheme was therefore designed to take into account the reliability of the sources used in checking: 2 Due to time constraints, evaluation was performed by one annotator only: we hope to remedy this in future work.</S>
			<S sid ="113" ssid = "28">(a) If the pair is found in the NCBI database or on the site of a scientific/academic organisation, score +1 (b) If the pair is found on any other site, score +0.5 (c) If the pair is not found, score 0.</S>
			<S sid ="114" ssid = "29">Wikipedia mirrors and Wikipedia itself did not count as sources.</S>
			<S sid ="115" ssid = "30">4.</S>
			<S sid ="116" ssid = "31">Automatic precision evaluation.</S>
			<S sid ="117" ssid = "32">Manual annotation is very time-consuming,.</S>
			<S sid ="118" ssid = "33">but the repeated use of a very small set of manual annotations for system development carries a high risk of over-fitting.</S>
			<S sid ="119" ssid = "34">So a program was written to compare all pairs in the results with the NCBI database.</S>
			<S sid ="120" ssid = "35">The number of pairs found gives a ‘minimal precision’ figure which was used in devlopment to investigate the relative precision of different versions of the system.</S>
			<S sid ="121" ssid = "36">4.2 Results.</S>
			<S sid ="122" ssid = "37">Running the initial system on the whole corpus resulted in 3985 relations being extracted, giving a 16.5% ‘rough’ recall figure.</S>
			<S sid ="123" ssid = "38">Manual recall yielded a 14% figure.</S>
			<S sid ="124" ssid = "39">RMRS gave promising results in the treatment of complex structures and long distance dependencies.</S>
			<S sid ="125" ssid = "40">Some examples of the relationships extracted by our system are shown below: 1.</S>
			<S sid ="126" ssid = "41">The Cottontop Tamarin (Saguinus oedipus), also known as the Pinchu Tamarin,.</S>
			<S sid ="127" ssid = "42">is a small New World monkey weighing less than 1lb (0.5 kg): cottontop tamarin is-a new world monkey 2.</S>
			<S sid ="128" ssid = "43">The Norway lobster, Nephrops norvegicus (also called Dublin Bay prawn or.</S>
			<S sid ="129" ssid = "44">langoustine), is a slim orange-pink lobster found in the northeastern Atlantic Ocean and the Mediterranean Sea: norway lobster is-a lobster 3.</S>
			<S sid ="130" ssid = "45">Opah (also known colloquially as moonfish, sunfish, kingfish, and Jerusalem.</S>
			<S sid ="131" ssid = "46">haddock) are large, colourful, deep-bodied pelagic Lampriform fish comprising the small family Lampridae (also spelt Lamprididae): opah is-a fish The precision, as calculated over 100 randomly chosen pairs was 92% – the errors and partially verified pairs (scored as 0.5) are shown below: Pai rs C o m m e n t s s c o r e bear is a spe ctac led bea r I n c o r r e c t o r d e r 0 lam nid ae is-a gre at whi te sha rk I n c o r r e c t o r d e r 0 ne me gtb aat ar is-a dja doc hta the rioid ea Non acad emic web site 0 . 5 ray onn ece ras is-a cep hal op od N o n a c a d e m i c w e b s i t e 0 . 5 bat is-a falc on I n c o r r e c t t r u n c a t i o n 0 tiger is a leo par d ? P e r h a p s i n c o r r e c t p a r s e 0 koo teni a is-a tril obi te N o n a c a d e m i c w e b s i t e 0 . 5 pin-tailed whydah is-a songbird Songbird not a taxonomic type 0 jag uar un di is-a wil d cat W r o n g a n a l y s i s o f w i l d c a t 0 eng rail ed is-a mo th N o n a c a d e m i c w e b s i t e 0 . 5 Out of six incorrect pairs, two resulted from the inverted ‘hypernym is-a hyponym’ pattern mentioned in §3.3 not being catered for.</S>
			<S sid ="132" ssid = "47">As non-experts, we cannot be completely certain whether the Wikipedia entries are correct or not, since even if we find supporting evidence on another site, we cannot be sure that site is correct.</S>
			<S sid ="133" ssid = "48">But these results show no evidence of unreliability in Wikipedia.</S>
			<S sid ="134" ssid = "49">The use of wild cat in the jaguarundi article to refer to species other than domestic cats and big cats is perhaps an infelicity, given that it also refers to a specific species, but is not an error.</S>
			<S sid ="135" ssid = "50">Applying the automatic evaluation to the results yielded a score of 44%, i.e. less than half of the relations could be verified against the NCBI database.</S>
			<S sid ="136" ssid = "51">Inspection of the evaluation output file revealed that 1757 hypernyms were not found in the NCBI names list.</S>
			<S sid ="137" ssid = "52">This was indicative of the potential usefulness of ontology extraction in this domain, even though large-scale ontologies already exist.</S>
			<S sid ="138" ssid = "53">4.3 Evaluation.</S>
			<S sid ="139" ssid = "54">The main problem with our system is obviously the low recall.</S>
			<S sid ="140" ssid = "55">Several factors contribute to explain this result: 1.</S>
			<S sid ="141" ssid = "56">Some correct pairs are lost when checking the terms against the animal.</S>
			<S sid ="142" ssid = "57">lexicon (the list is not comprehensive enough).</S>
			<S sid ="143" ssid = "58">2.</S>
			<S sid ="144" ssid = "59">Incomplete parses affect the final result..</S>
			<S sid ="145" ssid = "60">3.</S>
			<S sid ="146" ssid = "61">The number of extraction rules is small.</S>
			<S sid ="147" ssid = "62">Expanding the rules to include.</S>
			<S sid ="148" ssid = "63">verbs such as encompass, comprise, etc should provide a broader basis for extraction.</S>
			<S sid ="149" ssid = "64">Lexicon Issues In order to ascertain the shortcomings of the lexicon, the first 250 pairs found by the system were printed out prior to any term matching being performed, i.e. non-taxonomic pairs were part of the set.</S>
			<S sid ="150" ssid = "65">A manual check revealed that out of those 250 pairs, 34 taxonomic pairs were already being extracted by the system but 23 additional pairs contained possible valid taxonomic names as their hyponym and hypernym, yielding a potential 67% increase on the number of relations extracted in that particular section of the corpus.</S>
			<S sid ="151" ssid = "66">There were four main reasons for relations being lost during list lookup: 1.</S>
			<S sid ="152" ssid = "67">The search term did appear in Wikipedia but under a variant (for instance,.</S>
			<S sid ="153" ssid = "68">theropod is not an article but theropoda is. Hence only theropoda was listed in the lexicon.)</S>
			<S sid ="154" ssid = "69">2.</S>
			<S sid ="155" ssid = "70">The term did not appear in Wikipedia at all..</S>
			<S sid ="156" ssid = "71">3.</S>
			<S sid ="157" ssid = "72">The parser had not transformed a plural noun into its singular equivalent,.</S>
			<S sid ="158" ssid = "73">leading to a search failure.</S>
			<S sid ="159" ssid = "74">4.</S>
			<S sid ="160" ssid = "75">Compounds were being extracted with the wrong word order..</S>
			<S sid ="161" ssid = "76">An attempt was made at remedying to the lexicon’s shortcomings using Wikipedia redirections.</S>
			<S sid ="162" ssid = "77">It was hoped that recording all animal redirections would provide a comprehensive list of the noun variants used in the encyclopaedia.</S>
			<S sid ="163" ssid = "78">Over 1M redirection pages were extracted from the dump and 21,531 animal entries recorded.</S>
			<S sid ="164" ssid = "79">The system was expanded with a redirection checking stage and plural noun processing.</S>
			<S sid ="165" ssid = "80">The compound issue was solved by ensuring that terms were concatenated in their order of appearance in the RMRS.</S>
			<S sid ="166" ssid = "81">The modified program yielded 4771 pairs, or a 20% increase on the original figure, pushing the rough recall figure to 20%.</S>
			<S sid ="167" ssid = "82">Manual precision dropped slightly to 88.5%.</S>
			<S sid ="168" ssid = "83">Partial Parses Issue An inspection of the RMRS file for the subset used at manual recall stage showed that many instances of ‘be’ in that part of the corpus were contained in partial parses and missing argument values: out of 194 potential pairs, 97 depended on the identity copula.</S>
			<S sid ="169" ssid = "84">Out of those 97, 41 were missing an argument altogether or an argument value, indicating that only about 29% of the manually extracted pairs were recoverable.</S>
			<S sid ="170" ssid = "85">This issue would be partly solvable by expanding the set of rules responsible for converting the syntactic parse into an RMRS parse.</S>
			<S sid ="171" ssid = "86">The other avenue to explore is the syntactic parse itself.</S>
			<S sid ="172" ssid = "87">This work only considers the first parse obtained from RASP.</S>
			<S sid ="173" ssid = "88">Sometime errors occur in parts of the parse that indicate the taxonomic relationship.</S>
			<S sid ="174" ssid = "89">This might be addressed by processing the n-best parses from the RASP output, rather than just the first, although there are cases where the correct parse is not found at all, or has very low rank.</S>
			<S sid ="175" ssid = "90">In the longer term, we intend to investigate the use of deeper parsing in conjunction with RASP.</S>
			<S sid ="176" ssid = "91">Rule Coverage This initial system is restricted by the limited number of patterns considered during extraction.</S>
			<S sid ="177" ssid = "92">The next section describes how we have started implementing a new system that automatically extracts RMRS rules out of a training set and applies them to our corpus to discover new instances.</S>
			<S sid ="178" ssid = "93">This new design ensures that patterns are kept separate from the extraction module and shows potential in increasing recall by using a wider variety of rules.</S>
	</SECTION>
	<SECTION title="A First Attempt at Automatic Pattern Extraction" number = "5">
			<S sid ="179" ssid = "1">5.1 Defining the RMRS Pattern.</S>
			<S sid ="180" ssid = "2">Let A and B be two English terms.</S>
			<S sid ="181" ssid = "3">A and B are known at training stage (they are the training instances) and unknown at pattern matching stage (they are the new pairs extracted by the system).</S>
			<S sid ="182" ssid = "4">The RMRS pattern is the path linking A and B through the RMRS representation of the sentence.</S>
			<S sid ="183" ssid = "5">A path is an ordered set of unique coindexed RMRS trees.</S>
			<S sid ="184" ssid = "6">Each RMRS tree consists of either a lemma with all its identifiable arguments or an INGS relation.</S>
			<S sid ="185" ssid = "7">No loop is allowed in the path.</S>
			<S sid ="186" ssid = "8">An example is shown below: LEMMA::be ARG1::A ARG2::member|LEMMA::member ARG1::group| LEMMA::compound_rel ARG1::group ARG2::B The pattern in the example consists of three trees.</S>
			<S sid ="187" ssid = "9">The ARG2 of the first is co-indexed with the lemma of the second.</S>
			<S sid ="188" ssid = "10">The ARG1 of the second is co-indexed with the ARG1 of the third.</S>
			<S sid ="189" ssid = "11">A is the hyponym and B is the hypernym.</S>
			<S sid ="190" ssid = "12">The hyponymic relationship may correspond to one or more patterns, depending on whether it contains compounds or not.</S>
			<S sid ="191" ssid = "13">Relational patterns (the core of the hyponymy) and compound patterns are extracted and stored separately.</S>
			<S sid ="192" ssid = "14">So for instance, the training pair ‘yellow-bellied elaenia is-a bird’ leads to a relational pattern linking ‘elaenia’ and ‘bird’ and a compound pattern linking ‘yellow-bellied ’ and ‘elaenia’.</S>
			<S sid ="193" ssid = "15">Two assumptions were made here: 1.</S>
			<S sid ="194" ssid = "16">The last word of a compound, and the last word only, constitutes the hy-.</S>
			<S sid ="195" ssid = "17">ponym or hypernym’s core.</S>
			<S sid ="196" ssid = "18">2.</S>
			<S sid ="197" ssid = "19">In the case of multiple element compounds (Northern Brown Bandicoot),.</S>
			<S sid ="198" ssid = "20">each adjective/qualifying noun modifies the main noun, i.e. the last word in the compound.</S>
			<S sid ="199" ssid = "21">(This is a simplification.)</S>
			<S sid ="200" ssid = "22">5.2 Initial Experiments.</S>
			<S sid ="201" ssid = "23">Using the definition given above, the first iteration of our new system was run over a training set consisting of the 194 pairs manually obtained from the corpus when performing manual recall calculations.</S>
			<S sid ="202" ssid = "24">32 relational patterns and 24 compound patterns were extracted.</S>
			<S sid ="203" ssid = "25">These figures are small compared to the size of the training set, but error evaluation shows that the extraction failures are due to issues that could be fixed in further work.</S>
			<S sid ="204" ssid = "26">The incomplete RMRS rule set is once again the main problem.</S>
			<S sid ="205" ssid = "27">In particular rules were not available to treat apposition of the type The Northern Brown Bandicoot, a marsupial species, is a bandicoot.</S>
			<S sid ="206" ssid = "28">or noun plus qualifier constructions of the type the family Drepanidae.</S>
			<S sid ="207" ssid = "29">Wikipedia articles frequently omit commas round appositions, which prevented their recognition.</S>
			<S sid ="208" ssid = "30">Slight tuning or retraining of the parser should improve performance.</S>
			<S sid ="209" ssid = "31">The experiments also demonstrated the necessity for a targeted or sufficiently large training set.</S>
			<S sid ="210" ssid = "32">The rules we extracted in these preliminary experiments did not cover all potential taxonomic terms such as family, genus or species.</S>
			<S sid ="211" ssid = "33">Some over-specific lexical items were also observed on the patterns’ paths.</S>
			<S sid ="212" ssid = "34">In order to get an indication of the potential in RMRS pattern extraction, we replaced extracted taxonomic terms with the generalised dummy entry ‘taxovoc’ in the rules and changed all over-specific lexical entries into general equivalents.</S>
			<S sid ="213" ssid = "35">We then run a pattern matching algorithm over the resulting rules.</S>
			<S sid ="214" ssid = "36">This yielded a large increase in recall with 9142 unique pairs being extracted: a 37% rough recall.</S>
			<S sid ="215" ssid = "37">Manual precision, however, was only 64.5% while the automatic minimum precision figure fell to 30%.</S>
			<S sid ="216" ssid = "38">A systematic rule evaluation showed the presence of highly imprecise patterns, highlighting the need for a thorough automatic rule evaluation method in further iterations of the system development.</S>
	</SECTION>
	<SECTION title="Conclusion and Further Work. " number = "6">
			<S sid ="217" ssid = "1">This work attempted to move away from the traditional regular expression- based approaches in ontology extraction by using a semantic framework.</S>
			<S sid ="218" ssid = "2">It was shown that RMRS offers advantages in terms of tackling structural complexities.</S>
			<S sid ="219" ssid = "3">Applying a systematic treatment of the identity copula’s arguments to a corpus consisting of 12,200 Wikipedia articles resulted in 4771 taxonomic relationships being extracted: roughly 20% of the available pairs, yielding 88.5% precision.</S>
			<S sid ="220" ssid = "4">These promising initial results call for the development of a more complete system, including pattern extraction and pattern matching features.</S>
			<S sid ="221" ssid = "5">Some trials with automatic rule extraction were reported here, showing a large potential for recall increase balanced with a need for a thorough pattern evaluation method.</S>
			<S sid ="222" ssid = "6">Further work will focus on implementing such a system and will attempt to resolve the issues highlighted in this paper.</S>
			<S sid ="223" ssid = "7">In particular, it is expected that expanding the set of syntactic-to-semantic conversion rules in the RMRS and running the system on different syntactic parses might produce a significant improvement in recall without affecting the precision.</S>
			<S sid ="224" ssid = "8">Other domains (chemistry being a possible choice) will also be investigated in order to show whether RMRS can be used in a general purpose tool.</S>
			<S sid ="225" ssid = "9">Acknowledgments This work was supported by the UK Engineering and Physical Science Research Council (EPSRC: project EP/C010035/1).</S>
			<S sid ="226" ssid = "10">We are also grateful to the anonymous reviewers for their comments.</S>
	</SECTION>
</PAPER>
