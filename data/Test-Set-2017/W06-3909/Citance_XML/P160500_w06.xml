<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">Extracting entity hyponymy in Chinese complex sentences can be a highly difficult process.</S>
		<S sid ="2" ssid = "2">This paper proposes a novel hybrid approach that combines parsing with supervised learning and semi-supervised learning.</S>
		<S sid ="3" ssid = "3">First, conditional random fields (CRF) model is employed to obtain the candidate domain named entity.</S>
		<S sid ="4" ssid = "4">Pattern matching is then used to acquire candidate hyponymy.</S>
		<S sid ="5" ssid = "5">Next, predicate and symbol features, syntactic analysis, and semantic roles are introduced into the CRF features template to identify the hyponymy entity pairs.</S>
		<S sid ="6" ssid = "6">Finally, analysis of both the parallel relationship of entities among sentences and entity pairs in simple sentences is conducted to obtain the hyponymy entity pairs in Chinese complex sentences.</S>
		<S sid ="7" ssid = "7">The experimental results show that the proposed method reduces the manual work required for CRF markers and has an improved overall performance in comparison with the baseline methods.</S>
		<S sid ="8" ssid = "8">Keywords: Chinese complex sentences, hyponymy, entity identification, CRF, pattern matching, syntactic analysis DOI: 10.3103/S0146411616050035</S>
	</ABSTRACT>
	<SECTION title="INTRODUCTION" number = "1">
			<S sid ="9" ssid = "9">The automatic extraction of hyponymy between entities in a specific field is often a difficult step to accomplish when developing ontology knowledge bases or during construction of knowledge graphs, which is regarded as a crucial part for developing high-level natural language applications.</S>
			<S sid ="10" ssid = "10">Many algorithms have been developed to achieve hyponymy automatically, including dictionary-based, pattern- based, and statistical machine learning.</S>
			<S sid ="11" ssid = "11">The dictionary-based method used to acquire hyponymy usually depends on field words, synonyms, or approximate synonyms in the man-made dictionary.</S>
			<S sid ="12" ssid = "12">For instance, Nakaya [1] obtained English domain concepts hyponymy with WordNet [2].</S>
			<S sid ="13" ssid = "13">Moreover, Li [3] et al. used the geographical names dictionary for acquisition of toponym ontology concept relations in Chinese.</S>
			<S sid ="14" ssid = "14">However, the coverage of WordNet or HowNet [4] is still limited in the general field, and they are weak in the coverage of domain- specific terms and named entities.</S>
			<S sid ="15" ssid = "15">Pattern-based methods mainly use linguistics and natural language processing technologies, which consider patterns as rules summarized according to some inherent regular language.</S>
			<S sid ="16" ssid = "16">For example, in this Chinese sentence “ѭ⊏ⲴᲟ⛩, ᴹѭ⊏ਔ෾, ⦹嗉䴚ኡ઼⌨⋭⒆ㅹ” (“The scenic spots of Lijiang contains Lijiang old town, Yulong jokul, and Lugu lake, etc.”), here “Lijiang”, “Lijiang old town”, “Yulong jokul”, “Lugu lake” are entities, Ei is used to represent the entity i (i = 1, 2, …), and makes E1 = Lijiang, E2 = Lijiang old town, E3 = Yulong jokul, E4 = Lugu lake, the pattern “E1 contains E2 , E3 and, E4” can be obtained, where E1 is the hypernym of E2, E3, and E4 in this context.</S>
			<S sid ="17" ssid = "17">Several researchers have studied the subject in regards to the English language.</S>
			<S sid ="18" ssid = "18">Hearst [5] raised 6 lexical-syntactic patterns and avoided the use of the pre-coding method of knowledge and automatic recognition hyponymy from large text corpus; Tuan [6] et al. put forward to build a term classification hierarchy model based on the combination of pattern matching and statistical methods; Bansal [7] et al. used an automatic acquisition pattern and a belief propagation algorithm to obtain the high precision hypernym of arbitrary noun phrases.</S>
			<S sid ="19" ssid = "19">In addition 1 The article is published in the original..</S>
			<S sid ="20" ssid = "20">369 to the English language, various studies have been conducted on Chinese.</S>
			<S sid ="21" ssid = "21">For example, Wu [8] et al. established a universal grammar pattern library for the hyponymy relationship according to the part-whole relationship of the six different kinds of forms; In view of the “ISA” pattern, Tang [9] et al. demonstrated hyponym concepts using syntactic parsing results; Tian [10] et al. proposed a combination of a bootstrap- ping method and a Chinese doubly anchored pattern of the hypernym.</S>
			<S sid ="22" ssid = "22">The pattern-based method is highly accurate for specific sentences, but compared to English, Chinese language has the more complicated sentence structure and semantic, so it is difficult to use this technique in generalization.</S>
			<S sid ="23" ssid = "23">The statistical machine learning method is mainly based on corpus, linguistic knowledge, and the statistical language model, and it uses the machine-learning algorithm to obtain the concept hyponymy relationship.</S>
			<S sid ="24" ssid = "24">In the field of English, Fan [11] et al. considered the task as a matrix factorization problem to extract the relation.</S>
			<S sid ="25" ssid = "25">For Chinese, Xia [12] et al. proposed a method of graph clustering to extract the hypo- nymy; Fu [13] et al. joined a variety of features into SVM (support vector machine) based on the RBF (radial basis function) kernel.</S>
			<S sid ="26" ssid = "26">Statistical machine learning is considered the main method for hyponymy extraction due to its advantages of reducing manual annotation and extracting information automatically.</S>
			<S sid ="27" ssid = "27">The three methods described above generally extract entity hyponymy relations in a simple sentence.</S>
			<S sid ="28" ssid = "28">For complex sentences, it is necessary to cooperate syntactic patterns with entity recognition as well as other approaches to improve the overall performances, especially for the Chinese.</S>
			<S sid ="29" ssid = "29">In addition, patterns should be extracted using the bootstrapping method.</S>
			<S sid ="30" ssid = "30">The current paper proceeds as follows: Section 2 describes the methods and the framework; Section 3 discusses the process of hyponymy acquisition; Section 4 reports the results; Section 5 presents the conclusions.</S>
	</SECTION>
	<SECTION title="PROPOSED METHOD. " number = "2">
			<S sid ="31" ssid = "1">In the majority of cases, Chinese sentences are complex.</S>
			<S sid ="32" ssid = "2">For example, consider the following sentence: “ୀйᖙಘ⢙㊫࡛, ྲ⭏⍫⭘૱, ѫ㾱ᴹ⬦ǃ༦ǃ㖀ǃ䫥ǃᶟǃⴈǃⳲǃ ✋ਠǃ⹊ǃ᷅ㅹ, ⁑රᴹӝਠᾬ῝ǃԯᵘ㇡Ḍǃտᡯǃ ԃᓃǃ৅ᡰǃ⢋䖖ǃ傜䖖ㅹ, ؁㊫ᴹ਴⿽Ӫ⢙оࣘ⢙, ྲ䍥ྷǃ䗮ᇈǃ⭧ྣֽǃ↖༛ǃཙ⦻ǃ 㜑Ӫ৺傜ǃ傶催ǃ⥚ǃ㖺ǃ呑ǃ⤇ㅹ” (“The tri-colored glaze pottery of Tang Dynasty has three main categories, including living goods, models, and pottery figurines.</S>
			<S sid ="33" ssid = "3">The living goods mainly include bottles, kettles, pots, alms bowls, cups, plates, containers, candlesticks, inkslabs, and pillows.</S>
			<S sid ="34" ssid = "4">The models include pavilions, imitation wood cabinets, houses, warehouses, toilets, cow carts, and carriages.</S>
			<S sid ="35" ssid = "5">Pottery figurines include all kinds of personage and animals, such as dowagers, high ranking officials, attendants, warriors, heavenly kings, the northern barbarian tribes in ancient China, horses, camels, pigs, sheep, chicken, dogs, etc.”).</S>
			<S sid ="36" ssid = "6">This sentence contains two layers of hyponymy.</S>
			<S sid ="37" ssid = "7">Using pattern matching or the CRF method may not accurately identify these layers.</S>
			<S sid ="38" ssid = "8">Thus, a combined method must be employed.</S>
			<S sid ="39" ssid = "9">Sang [14] et al. extracted the lexical patterns in an English simple sentence that might contain hyponymy and analyzed the dependency relation between the elements in that sentence.</S>
			<S sid ="40" ssid = "10">Liu [15] et al. extracted Chinese entity relations by making use of the syntactic characteristics and semantic characteristics in combination with the SVM algorithm to ensure that the F-Measure value increased significantly; Chen [16] et al. used not only the result of parsing trees, but also assembled six candidate feature sets using constraint conditions to obtain Chinese hyponymy.</S>
			<S sid ="41" ssid = "11">Our work proposes a hybrid method for entity hyponymy acquisition.</S>
			<S sid ="42" ssid = "12">The following steps were expressed as four stages (detailed in Section 3).</S>
			<S sid ="43" ssid = "13">Figure 1 shows the overall framework of the proposed method.</S>
	</SECTION>
	<SECTION title="HYPONYMY ENTITY  PAIRS EXTRACTION. " number = "3">
			<S sid ="44" ssid = "1">3.1.</S>
			<S sid ="45" ssid = "2">Extracting Candidate Domain Entities using the CRF Model.</S>
			<S sid ="46" ssid = "3">In the field of tourism, word segmentation tools cannot accurately identify entities, owing to segmentation tools are not perfect, and there no scenic spots dictionary exists for this field.</S>
			<S sid ="47" ssid = "4">The current work extract candidate domain entities by fusing domain entity feature and CRFs, which ensured that the word was not separated by segmentation tools.</S>
			<S sid ="48" ssid = "5">The process includes 4 steps: (1) Preprocessing.</S>
			<S sid ="49" ssid = "6">The corpus crawled from the Web is first processed by deleting the duplicated corpus, de-noising, separating sentences, word segmentation and part-of-speech tagging [17] et al.</S>
			<S sid ="50" ssid = "7">(2) Feature selection and rules marking.</S>
			<S sid ="51" ssid = "8">By selecting the features to identify the entities and marking the entity features for these sentences as training data of domain entity recognition.</S>
			<S sid ="52" ssid = "9">(3) Obtaining domain entity recognition model.</S>
			<S sid ="53" ssid = "10">Domain entity recognition model is generated by learn Web corpus Preprocessing P a tt e r n m a t c h i n g sentences Parsing and processing Entity pairs with hyponomy in outer layer of complex sentences Preprocessing and marking Marking entity Parsing and marking Marking hyponymy entity pairs The training corpus of domain entity recognition Learning by CRF T h e t r a i n i n g d a t a o f h y p o n y m y e n t i t y p a i r s r e c o g n i t i o n L e a r n i n g b y C R F The test data of domain entity recognition Domain entity recognition Candidate (the CRF model) do main entity The test data of hyponymy entity pairs recognition Hyponymy recognition (the CRF model) E n t i t y p a i r s w i t h h y p o n y m y i n t h e s i m p l e s e n t e n c e s Fig.</S>
			<S sid ="54" ssid = "11">1.</S>
			<S sid ="55" ssid = "12">Overview of the proposed approach.</S>
			<S sid ="56" ssid = "13">ing the training corpus of domain entity recognition based on CRFs.</S>
			<S sid ="57" ssid = "14">(4) Generating candidate entity.</S>
			<S sid ="58" ssid = "15">The test data of domain entity recognition was input into the domain entity recognition model to identify the domain entity, and make the identified entity as the candidate entity.</S>
			<S sid ="59" ssid = "16">Finally, these domain entities are joined into the domain dictionary.</S>
			<S sid ="60" ssid = "17">3.1.1.</S>
			<S sid ="61" ssid = "18">Principle of CRFs.</S>
			<S sid ="62" ssid = "19">CRFs, represented by an undirected probability graph model, are used to markup and serialize data segmentation.</S>
			<S sid ="63" ssid = "20">They can be used to express the long distance dependence and overlap of elements.</S>
			<S sid ="64" ssid = "21">When using CRFs, the specific task is to choose the appropriate feature-set for the model, and the simple feature is often used to ref lect the complex linguistic phenomenon.</S>
			<S sid ="65" ssid = "22">The principle of CRFs can be demonstrated through the following example.</S>
			<S sid ="66" ssid = "23">Suppose X indicates the observed sequence to be marked, and C indicates the respective joint probability distribution of the observed sequence.</S>
			<S sid ="67" ssid = "24">Given an effective observation sequence X, which has a length m, X = x1, x2,..., xm, the marked sequence C, C = c1, c2, c3,..., cm can be obtained, and the set can be defined as follows: 1 ⎧⎪ k ⎫⎪ P (C X ) = exp ⎨∑ λ k f k (ct , ct −1, xt )⎬ , Z ( x ) (1) ⎪⎩ k =1 ⎪⎭ where Z ( x ) indicates a normalization factor constant, which makes all probability values fall into the range [0,1] of the result state sequence.</S>
			<S sid ="68" ssid = "25">Z ( x ) can be expressed as follows: ⎧⎪ k ⎫⎪ Z ( x ) = ∑ exp ⎨∑ λ k f k (ct , ct −1, xt )⎬, (2) c ⎪⎩ k =1 ⎪⎭ where f k (ct , ct −1, xt ) is a transfer functio n and represe nts the transiti on proba bility of the markin gsequence in the observing sequence X when the position in t and t – 1; λ k indicates the corresponding fea ture weight vector, which is calculated in the training sample.</S>
			<S sid ="69" ssid = "26">3.1.2.</S>
			<S sid ="70" ssid = "27">Feature selection and rules marking.</S>
			<S sid ="71" ssid = "28">In the process of named entity extraction, it can be found that some nouns may form a domain named entity if they have an attribute (ATT) relationship after syntactic parsing.</S>
			<S sid ="72" ssid = "29">For example, the “ୀйᖙ” (“Tangsancai”) and “ಘ⢙” (“utensils”) in the above example sentence have an attribute relationship, it can be inference that “ୀйᖙಘ⢙” (“Tangsancai utensils”) may be a named entity.</S>
			<S sid ="73" ssid = "30">Moreover, the nouns grouped between the Chinese punctuation “ ” and the punctuation “ǃ” itself may be domain entities.</S>
			<S sid ="74" ssid = "31">An example in this sentence is “ԯᵘ” (“imitating wood”) Table 1.</S>
			<S sid ="75" ssid = "32">Marking rules of domain entity Tag Description ATTB The prelude noun of the nouns groups which have ATT relationship ATTE The afterbody noun of the nouns groups which have ATT relationship PB The prelude noun of the nouns grouped between the Chinese punctuation “ǃ” and “ǃ” PE The afterbody noun of the nouns grouped between the Chinese punctuation “ǃ” and “ǃ” Table 2.</S>
			<S sid ="76" ssid = "33">Bootstrapping method for pattern extraction Input: the seeds set with hyponymy (Seeds_sets); the corpus of scenic spots of Sougou Baike (Corpus) Output: the patterns set with hyponymy (Pattern_sets); the number of patterns (N) Step: 01: Searching the Seeds_sets in the Corpus and get some instances (S), and then, employing S to produce pattern instances.</S>
			<S sid ="77" ssid = "34">02: Generalizing pattern instances to get the patterns (Candidate_patterns), and joining into the Pattern_sets.</S>
			<S sid ="78" ssid = "35">The number of Candidate_patterns is n, N = N + n. 03: Matching the patterns of Candidate_patterns in the Corpus, obtaining entity pairs of S as NewSeeds_sets.</S>
			<S sid ="79" ssid = "36">Join the NewSeeds_sets into Seeds_sets.</S>
			<S sid ="80" ssid = "37">04: Making use of NewSeeds_sets, repeating the step 01, 02 and 03 until the N no longer increases.</S>
			<S sid ="81" ssid = "38">The iteration is over, and return the Pattern_sets.</S>
			<S sid ="82" ssid = "39">Table 3.</S>
			<S sid ="83" ssid = "40">Examples of hyponymy patterns Pattern Note E (वᤜ /वਜ਼ /ѫ㾱ᴹ /˖) E1, E2, …, En (In English: E ( include/contain/mainly have/:) E1, E2, …, En) E1, E2, …, En (㓴ᡀ /ㅹ) E (In English: E1, E2, …, En (compose of/and so on) E) E is the domain concept in the pattern; E1, E2, …, En are concept instances; E1, E2, …, En is appositive and constitutes a category.</S>
			<S sid ="84" ssid = "41">and “㇡Ḍ” (“bin”).</S>
			<S sid ="85" ssid = "42">Thus, the ATT relationship and the punctuation “ǃ”-were taken as characteristics to be joined in the CRF model to extract a named entity.</S>
			<S sid ="86" ssid = "43">The examples of marking format are “ୀйᖙ/ATTB ಘ⢙/ATTE” and “ԯᵘ/PB ㇡Ḍ/PE”.</S>
			<S sid ="87" ssid = "44">Table 1 describes the marking rules of domain entity.</S>
			<S sid ="88" ssid = "45">It is difficult to extract the hyponymy relation sentences in the tourism domain by pattern matching, due to the fact that there are no unified and fixed patterns, which contain hyponymy in the Chinese tourism field.</S>
			<S sid ="89" ssid = "46">Therefore, the bootstrapping method was applied.</S>
			<S sid ="90" ssid = "47">3.2.</S>
			<S sid ="91" ssid = "48">Extracting Candidate Sentences by Pattern Matching.</S>
			<S sid ="92" ssid = "49">3.2.1.</S>
			<S sid ="93" ssid = "50">Extracting pattern by bootstrapping method.</S>
			<S sid ="94" ssid = "51">Table 2 describes the bootstrapping method algorithm [18] for pattern extraction semi-automatically.</S>
			<S sid ="95" ssid = "52">Whose basic idea is that given a small set of seed instances for a hyponymy relation, the system learns lexical patterns, applies them to extract new instances, the required pattern scale can be obtained finally by progressive learning.</S>
			<S sid ="96" ssid = "53">Table 3 shows some typical examples of the patterns studied.</S>
			<S sid ="97" ssid = "54">Latter experiments proved that these patterns might cover the majority of hyponymy relation sentences.</S>
			<S sid ="98" ssid = "55">3.2.2.</S>
			<S sid ="99" ssid = "56">Extracting candidate sentences.</S>
			<S sid ="100" ssid = "57">The corpus crawled from the Web was first preprocessed by deleting the duplicated web pages, de-noising, separating sentences.</S>
			<S sid ="101" ssid = "58">Then marking candidate entity (obtained in section 3.1) of these sentences and Ei replace the entity with label.</S>
			<S sid ="102" ssid = "59">At Last, extracting the candidate sentences by pattern matching.</S>
			<S sid ="103" ssid = "60">The tri-colored glaze pottery of Tang Dynasty living goods models pottery figurine bottle ... alms bowl ... pillow pavili ons ... houses ... carriage dow ager ... attendans ... dog Fig.</S>
			<S sid ="104" ssid = "61">2.</S>
			<S sid ="105" ssid = "62">Hyponymy model of sentences.</S>
			<S sid ="106" ssid = "63">3.3.</S>
			<S sid ="107" ssid = "64">Hyponymy Entity Pairs Extraction in Simple Sentences.</S>
			<S sid ="108" ssid = "65">Consider the Chinese sentence mentioned in Section 2, “ୀйᖙಘ⢙㊫࡛, ྲ⭏⍫⭘૱, ѫ㾱ᴹ⬦ǃ༦ǃ㖀ǃ䫥 , ᶟǃⴈǃⳲǃ✋ਠǃ⹊ǃ᷅ㅹ, ⁑රᴹӝਠᾬ῝ǃԯᵘ㇡Ḍ , տᡯǃԃᓃǃ৅ᡰǃ⢋䖖ǃ傜䖖ㅹ, ؁㊫ᴹ਴⿽Ӫ⢙оࣘ⢙, ྲ䍥ྷǃ䗮ᇈǃ⭧ྣֽǃ↖༛ǃཙ⦻ 㜑Ӫ৺傜ǃ傶催ǃ⥚ǃ㖺ǃ呑ǃ⤇ㅹǄ”.</S>
			<S sid ="109" ssid = "66">Based on the definition of hyponymy relationship, it can be seen that this example is a complex sentence containing 2 layers of hyponymy (Fig.</S>
			<S sid ="110" ssid = "67">2), and 4 typical simple sentences containing hyponymy.</S>
			<S sid ="111" ssid = "68">For example, it can be seen that “ୀйᖙಘ⢙, ⭏⍫⭘૱” (“the tri-colored glaze pottery of Tang Dynasty, living goods”), “⭏⍫⭘૱, ⬦” (“living goods, bottle”), and “⁑ර, ӝਠᾬ῝” (“model, pavilions”) are hyponymy entity pairs, but this is difficult for automatic recognition.</S>
			<S sid ="112" ssid = "69">By deeply observation, we found that the sentence is complex in most cases.</S>
			<S sid ="113" ssid = "70">Complex sentences are composed of clauses, which are typically simple sentences.</S>
			<S sid ="114" ssid = "71">Thus, hyponymy entity pairs must first be extracted from the clauses (i.e. simple sentences) in a complex sentence.</S>
			<S sid ="115" ssid = "72">3.3.1.</S>
			<S sid ="116" ssid = "73">The process of extract hyponymy entity pairs in simple sentences.</S>
			<S sid ="117" ssid = "74">The procedure contains 4 sections: (1) Marking entity.</S>
			<S sid ="118" ssid = "75">For these candidate sentences, marking entity is first performed.</S>
			<S sid ="119" ssid = "76">(2) Generating the training data.</S>
			<S sid ="120" ssid = "77">Dependency parsing is used to parse the candidate sentences and the hyponymy features are obtained.</S>
			<S sid ="121" ssid = "78">And then, the candidate sentences with hyponymy features labeling as the training data of hyponymy entity pairs recognition.</S>
			<S sid ="122" ssid = "79">(3) Obtaining hyponymy recognition model.</S>
			<S sid ="123" ssid = "80">Hyponymy recognition model is generated by learning the training corpus of hyponymy entity pairs recognition based on CRFs.</S>
			<S sid ="124" ssid = "81">(4) Identifying entity with hyponymy in simple sentences.</S>
			<S sid ="125" ssid = "82">The test data of hyponymy entity pair recognition is injected into the hypo- nymy recognition model to identify the entity with hyponymy in simple sentences.</S>
			<S sid ="126" ssid = "83">3.3.2.</S>
			<S sid ="127" ssid = "84">Feature selection and rules marking.</S>
			<S sid ="128" ssid = "85">In dependency parsing [19], several features can be obtained in addition to the dependency relation (clauses structure feature), such as semantic role labeling (shallow semantic analysis technology, labeling certain phrases in the sentence for a given predicate argument), agent, patient, time, and place.</S>
			<S sid ="129" ssid = "86">Semantic role labeling can identify the predicate verbs, A0 (the agency of action) and A1 (the inf luence of the action).</S>
			<S sid ="130" ssid = "87">Figure 3 shows that A0 generally contains hypernym entities, and A1 contains hyponym entities in simple sentences.</S>
			<S sid ="131" ssid = "88">Moreover, those sentences might contain the hyponymy if they contained the coordinate relationship (COO) during syntactic parsing.</S>
			<S sid ="132" ssid = "89">Table 4 describes the tags of relation types present in Figs.</S>
			<S sid ="133" ssid = "90">3 and 4.</S>
			<S sid ="134" ssid = "91">In addition, there are other characters that can help identify the hyponymy, such as words like “वᤜ” (“include”), “वਜ਼” (“contain”), and “ѫ㾱ᴹ” (“mainly have”), and symbols like “:” and “ǃ”.</S>
			<S sid ="135" ssid = "92">These combinations of features might better express entity hyponymy.</S>
			<S sid ="136" ssid = "93">If the sentences have the deep semantic relations, such as COO, then it will be labeled as COO.</S>
			<S sid ="137" ssid = "94">Table 5 shows the marking rules of hyponymy.</S>
			<S sid ="138" ssid = "95">The current work is combining these features with the CRFs to obtain the hyponymy recognition model.</S>
			<S sid ="139" ssid = "96">Selecting the combination feature involves linear extraction and combination.</S>
			<S sid ="140" ssid = "97">And making ti represent the i-th word, ci is the part of speech of the i-th word, di denote the feature of “include”, “contain” and “:” of the i-th word, ei express the feature of “ǃ” of the i-th word, fi represent the feature of COO HED SBV VOB COO WP ATT COO COO COO COO COO RAD ROOT A0 WP WP WP WP WP A1 Fig.</S>
			<S sid ="141" ssid = "98">3.</S>
			<S sid ="142" ssid = "99">Syntactic parsing and semantic role labeling HED COO WP SBV VOB WP RAD COO COO VOB ROOT ATT ATT WP ATT ADV ADV VOB COO W P A1 SBV A0 A1 Fig.</S>
			<S sid ="143" ssid = "100">4.</S>
			<S sid ="144" ssid = "101">Syntactic parsing and semantic role labeling.</S>
			<S sid ="145" ssid = "102">of the i-th word, gi express the feature of semantic roles of the i-th word.</S>
			<S sid ="146" ssid = "103">Table 6 shows the part of feature template of the hyponymy entity pair recognition.</S>
			<S sid ="147" ssid = "104">In the Table 6, tn denotes the single word feature; tn tn+1 is the combination feature of two words; t0 c0 f0 represents the combination feature of word, part of speech and COO; t0 e1 e+1 expresses the combination feature of word, the former “ǃ” and the next “ǃ”; t0 e1 e+1 f n is the combination feature of word, the former “ǃ”,the next “ǃ” and the COO; t0 e1 e+1 f n g n denotes the combination feature of word, the former “ǃ”, the next “ǃ”, the COO and the semantic roles.</S>
			<S sid ="148" ssid = "105">3.4.</S>
			<S sid ="149" ssid = "106">Hyponymy Entity Pairs Extraction in Outer Layer of Complex Sentences.</S>
			<S sid ="150" ssid = "107">When extracting the outer layer hyponymy relation entity pairs in complex sentences, the hyponymy entity pairs in the clauses obtained from Section 3.3 must first be labeled within the candidate sentences.</S>
			<S sid ="151" ssid = "108">Then, the coordinate relation of hypernyms among clauses can be obtained by syntactic analysis.</S>
			<S sid ="152" ssid = "109">Finally, the entity pairs with hyponymy of the outer layer in the complex sentences can be obtained by analytical processing.Figure 4 shows the COO relation among “⭏⍫⭘૱”, “⁑ර” and “֓㊫”.</S>
			<S sid ="153" ssid = "110">The COO entity relation ship is directly marked out in simple sentences, but the hyponymy relation of the outer layer is marked out by the predicate verbs among them in complex sentences.</S>
			<S sid ="154" ssid = "111">Moreover, these annotations require a certain degree of processing, because the COO relationship of a multilayer is defined as a layer in the process of syntax analysis.</S>
			<S sid ="155" ssid = "112">We first extracted the hyponymy entity pairs in the simple sentences.</S>
			<S sid ="156" ssid = "113">Based on this, we can identify the hyponymy entity pairs of the multilayer structure of the complex sentences, the results can be seen in Fig.</S>
			<S sid ="157" ssid = "114">2.</S>
			<S sid ="158" ssid = "115">In front of “⭏⍫⭘૱”, there is the “ྲ” (“for example”), as shown in Figure 4( In order to show the COO relation of the predicate verbs “ྲ” and “ᴹ” more clearly, the examples of Table 4.</S>
			<S sid ="159" ssid = "116">Tags of relation type Tag Description SBV Subject-verb VOB Verb-object ATT Attribute ADV Adverbial RAD Right adjunct HED Head WP Punctuation Table 5.</S>
			<S sid ="160" ssid = "117">Marking rules Tag Semantic relationships A0 The agency of action A1 The inf luence of the action 0 No specific feature.</S>
			<S sid ="161" ssid = "118">1 Have specific features.</S>
			<S sid ="162" ssid = "119">COO Coordinative relation Table 6.</S>
			<S sid ="163" ssid = "120">Feature templates F e a t u r e t n , n = { − 2 , − 1 , 0 , 1 , 2 } t n t n + 1 , n = { − 2 , − 1 , 0 , 1 } t 0 c 0 f 0 t 0 e − 1 e + 1 t 0 e − 1 e + 1 f n , n = { − 2 , − 1 , 0 , 1 , 2 } t 0 e − 1 e + 1 f n g n , n = { − 2 , − 1 , 0 , 1 , 2 } “䫥ǃᶟǃⴈǃⳲǃ✋ਠǃ⹊ǃ᷅” of “⭏⍫⭘૱” were omitted in Fig.</S>
			<S sid ="164" ssid = "121">4).</S>
			<S sid ="165" ssid = "122">Here, “ྲ” and “ᴹ” (“have”) are the COO relationship, but “⭏⍫⭘૱” is a hypernym of “⫊”.</S>
			<S sid ="166" ssid = "123">Thus, the hyponymy must first be recognized in the simple sentences.</S>
			<S sid ="167" ssid = "124">When combined with the hyponymy entity pairs of the outer layer in complex sentences, there could be interference (Fig.</S>
			<S sid ="168" ssid = "125">5).</S>
	</SECTION>
	<SECTION title="METHODS AND RESULTS. " number = "4">
			<S sid ="169" ssid = "1">4.1.</S>
			<S sid ="170" ssid = "2">Data Preparation.</S>
			<S sid ="171" ssid = "3">Data was crawled by this paper using WebCrawler coding from Sogou Baike tourism field entries.</S>
			<S sid ="172" ssid = "4">A total of 568 entries and 29.045 sentences were analyzed.</S>
			<S sid ="173" ssid = "5">The number of sentences that contained hyponymy was 1.362.</S>
			<S sid ="174" ssid = "6">The corpus is divided into two parts, of which 4/5 as the training corpus, and the rest of 1/5 as the test corpus.</S>
			<S sid ="175" ssid = "7">The experiment applies the 5-fold cross-validation, and uses the mean value as the result.</S>
			<S sid ="176" ssid = "8">4.2.</S>
			<S sid ="177" ssid = "9">Evaluation Standards.</S>
			<S sid ="178" ssid = "10">Certain parameters, including accuracy (P), recall (R), and F-Measure value (F), were employed to evaluate the extraction results of domain hyponymy.</S>
			<S sid ="179" ssid = "11">The parameters are defined as follows: P = A × 100%, B (3) Syntactic analysis (living goods, model) (model, pottery igurine) Coordinate entity Hyponymy extraction (The tri-colored glaze pottery of Tang Dynasty, living oods) (The tri-colored glaze pottery of Tang Dynasty, living goods) (The tri-colored glaze pottery of Tang Dynasty, model) (The tri-colored glaze pottery of Tang Dynasty, pottery figurine) Hyponymy entity Fig.</S>
			<S sid ="180" ssid = "12">5.</S>
			<S sid ="181" ssid = "13">Extracting the entity pairs with hyponymy in outer layer of complex sentences.</S>
			<S sid ="182" ssid = "14">Table 7.</S>
			<S sid ="183" ssid = "15">Experimental results A l g o r i t h m A c c u r a c y R e c a l l F Patt ern mat chi ng 6 3 . 1 5 % 8 0 . 6 0 % 7 0 . 8 2 % Table 8.</S>
			<S sid ="184" ssid = "16">Experimental results from proposed method and traditional methods A l g o r i t h m T e s t T y p e A c c u r a c y R e c a l l F CC RFs (tra diti ona l cha ract erist ic) Clo sed test Op en test 7 3 . 4 5 % 6 4 . 4 3 % 6 8 . 8 2 % 5 9 . 8 3 % 7 1 . 0 6 % 6 2 . 0 4 % CC RFs + SV M (he adw ord pat h) Clo sed test Op en test 8 0 . 1 1 % 7 4 . 5 1 % 7 9 . 8 6 % 7 5 . 8 9 % 7 9 . 9 8 % 7 5 . 1 9 % Patt ern + CC RFs (multi feat ure) Clo sed test Op en test 8 2 . 5 4 % 7 7 . 8 3 % 7 8 . 6 4 % 7 7 . 9 1 % 8 0 . 5 4 % 7 7 . 8 7 % Pro pos ed Met hod Clo sed test Op en test 8 3 . 2 7 % 8 0 . 0 1 % 8 0 . 6 8 % 7 8 . 3 7 % 8 1 . 9 5 % 7 9 . 1 8 % R = A × 100%, C F = 2 × P × R × 100%, P + R (4) (5) where A represents the correct identification number of domain entities hyponymy; B represents the total number of domain entities hyponymy; and C represents the total number of domain entities hyponymy in the corpus.</S>
			<S sid ="185" ssid = "17">4.3.</S>
			<S sid ="186" ssid = "18">Results.</S>
			<S sid ="187" ssid = "19">The candidate sentences with hyponymy were first extracted using the defined patterns.</S>
			<S sid ="188" ssid = "20">Here, the top 10 high-frequency patterns were used.</S>
			<S sid ="189" ssid = "21">Table 7 shows the experimental results.</S>
			<S sid ="190" ssid = "22">In the test process of extracting hyponymy, 4 groups of experiments were made, including the current method and 3 traditional methods for comparison.</S>
			<S sid ="191" ssid = "23">The first method was CCRFs (cascaded conditional random fields) with traditional characteristics proposed in the literature [20]; the second was the method presented in literature [21], which applied the part of speech and the suffix of characteristic combined with CCRFs to extract entities, and combined the feature of headword path with SVM [22] to extract entity hyponymy; the third was CCRFs with multi-features plus the pattern-based method, and the CRF++ toolkit [23] was used.</S>
			<S sid ="192" ssid = "24">Table 8 shows the comparison of the results from the various methods.</S>
			<S sid ="193" ssid = "25">Although the proposed method resulted in some errors due to pattern matching to extract hyponymy sentences, it does not require a great deal of manual annotation.</S>
			<S sid ="194" ssid = "26">Thus, it saves a large amount of manpower and time.</S>
			<S sid ="195" ssid = "27">Moreover, it has a better performance than the other methods in terms of accuracy and recall rate.</S>
			<S sid ="196" ssid = "28">Table 7 indicates that the factors affecting the experimental data are as follows: (1) A small number of domain entities failed to be recognized.</S>
			<S sid ="197" ssid = "29">(2) Some sentences that might contain hyponymy were filtered out by pattern matching, which resulted in part of the entity pairs being unable to be extracted.</S>
			<S sid ="198" ssid = "30">(3) There was an error associated with the syntactic parser tool.</S>
			<S sid ="199" ssid = "31">Though syntactic parsers are evolving and improving, an error rate still exists.</S>
			<S sid ="200" ssid = "32">This paper used the NLP (natural language processing) parser from MIT (Massachusetts Institute of Technology) [24].</S>
	</SECTION>
	<SECTION title="CONCLUSIONS. " number = "5">
			<S sid ="201" ssid = "1">This article proposed a hybrid method for extracting hyponymy in a complex sentence by combining syntactic analysis features and other features with CRFs model.</S>
			<S sid ="202" ssid = "2">Chinese language contains many complicated characteristics that are worth studying.</S>
			<S sid ="203" ssid = "3">Manual annotation is one of the greatest limitations in the proposed method, along with the use of the syntactic.</S>
			<S sid ="204" ssid = "4">Future studies will involve improving the current method and finding deep semantic combination features for hyponymy acquisition.</S>
	</SECTION>
	<SECTION title="ACKNOWLEDGMENTS">
			<S sid ="205" ssid = "5">This research was supported in part by the National Natural Science Foundation of China (Grant nos.</S>
			<S sid ="206" ssid = "6">61262 041, 61472168, and 61562 052) and the key project of National Natural Science Foundation of Yunnan province (Grant no. 2013FA030).</S>
	</SECTION>
</PAPER>
