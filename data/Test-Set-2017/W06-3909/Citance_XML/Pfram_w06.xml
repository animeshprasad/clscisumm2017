<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">The vast majority of text freely available on the Internet is not available in a form that computers can understand.</S>
		<S sid ="2" ssid = "2">There have been numerous approaches to automatically extract information from human- readable sources.</S>
		<S sid ="3" ssid = "3">The most successful attempts rely on vast training sets of data.</S>
		<S sid ="4" ssid = "4">Others have succeeded in extracting restricted subsets of the available information.</S>
		<S sid ="5" ssid = "5">These approaches have limited use and require domain knowledge to be coded into the application.</S>
		<S sid ="6" ssid = "6">The current thesis proposes a novel framework for Information Extraction.</S>
		<S sid ="7" ssid = "7">From large sets of documents, the system develops statistical models of the data the user wishes to query which generally avoid the limitations and complexity of most Information Extractions systems.</S>
		<S sid ="8" ssid = "8">The framework uses a semi-supervised approach to minimize human input.</S>
		<S sid ="9" ssid = "9">It also eliminates the need for external Named Entity Recognition systems by relying on freely available databases.</S>
		<S sid ="10" ssid = "10">The final result is a query-answering system which extracts information from large corpora with a high degree of accuracy.</S>
		<S sid ="11" ssid = "11">Keywords : Information Extraction, Natural Language Processing, Support Vector Machine, Machine Learning, Information Retrieval, unstructured text Chapter 1</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="12" ssid = "12">The amount of information available on the World Wide Web was estimated in 2003 at 167 terabytes [27].</S>
			<S sid ="13" ssid = "13">This number is triple what was available in 2000, when a previous study was performed.</S>
			<S sid ="14" ssid = "14">The annual amount of email generated in 2003 worldwide was 667,585 terabytes.</S>
			<S sid ="15" ssid = "15">There is obviously a vast amount of text information available in digital form.</S>
			<S sid ="16" ssid = "16">There are many documents that are about the same topic on the Internet, and therefore contain very similar information using different wordings.</S>
			<S sid ="17" ssid = "17">Their information can be compared to verify the correctness of the source.</S>
			<S sid ="18" ssid = "18">The redundancy is an asset that can be exploited.</S>
			<S sid ="19" ssid = "19">While the amount of text being produced is continually increasing, so is the amount of computing power available to process it.</S>
			<S sid ="20" ssid = "20">The large majority of these computers are dedicated to indexing for a human to search through.</S>
			<S sid ="21" ssid = "21">Further, there is a growing awareness of the richness of the text information available.</S>
			<S sid ="22" ssid = "22">Thousands of people contribute to Wikipedia, a free encyclopedia, creating millions of entries.</S>
			<S sid ="23" ssid = "23">There is a strong desire to make this information available not only to the 1.4 billion Internet users [12], but to make it available for entry into databases, question-answering systems, and Artificial Intelligence efforts.</S>
			<S sid ="24" ssid = "24">The efforts to make the large amount of textual information available in a structured, machine-usable form have been largely successful.</S>
			<S sid ="25" ssid = "25">However, these efforts, in general, have focused on domain-dependant approaches which do not transfer well to the problem in the large.</S>
			<S sid ="26" ssid = "26">Presented here is a framework on which a semi-supervised Information Extraction system can be built.</S>
			<S sid ="27" ssid = "27">The framework itself is relatively dynamic and flexible.</S>
			<S sid ="28" ssid = "28">It can be easily adapted by the end user to a wide variety of domains with minimal effort.</S>
			<S sid ="29" ssid = "29">A system built on this framework will extract highly structured data from large, unstructured text sources as typically found on the World Wide Web.</S>
			<S sid ="30" ssid = "30">The current research borrows from work in the literature in a number of ways.</S>
			<S sid ="31" ssid = "31">Firstly, the current work relies on and takes advantage of the redundancy of the information contained in large text databases.</S>
			<S sid ="32" ssid = "32">Textual sources can be aggregated into large databases.</S>
			<S sid ="33" ssid = "33">The accuracy of the algorithm increases with the size of the database.</S>
			<S sid ="34" ssid = "34">This idea is used in Etzioni et al. [15, 16] and Agichtein and Gravano [1].</S>
			<S sid ="35" ssid = "35">Secondly, the current work approaches the problem from a typical point of view.</S>
			<S sid ="36" ssid = "36">Instead of modeling the task as a textual understanding problem, the system models the problem as one of statistical correlation.</S>
			<S sid ="37" ssid = "37">In essence, the system attempts to correlate syntactical and lexical features with semantic meaning.</S>
			<S sid ="38" ssid = "38">The semantic meaning is inputed by the user in the form of a query.</S>
			<S sid ="39" ssid = "39">It is therefore a query-answering system as opposed to a free-form extraction engine.</S>
			<S sid ="40" ssid = "40">Finally, a semi-supervised algorithm is used to reduce human input.</S>
			<S sid ="41" ssid = "41">Several papers [1, 3, 14, 33] use a bootstrapping algorithm which trains a system with a minimal set of seed values instead of the vast number of training examples needed in a supervised learning method.</S>
			<S sid ="42" ssid = "42">Although the current research owes a great debt to prior work, the system presented here diverges in three important ways.</S>
			<S sid ="43" ssid = "43">Firstly, the current work does not depend on any one domain (as do the majority of previous research; see Etzioni et al. [15] and Brin [3] for exceptions).</S>
			<S sid ="44" ssid = "44">Extending the system to work in new contexts is trivially simple and requires minimal domain expertise.</S>
			<S sid ="45" ssid = "45">The system is also not dependant on a particular representation of the sentence nor on the choice of classifier.</S>
			<S sid ="46" ssid = "46">Most prior work relies heavily on these two choices.</S>
			<S sid ="47" ssid = "47">Secondly, most systems that generate statistical models throw out features that correlate with undesirable information [1, 6, 23, 33, 36, 37].</S>
			<S sid ="48" ssid = "48">However, those features can help filter out information.</S>
			<S sid ="49" ssid = "49">The current system uses patterns that correlate well with desirable data and patterns that correlate with undesirable data to classify unknown values into the appropriate category.</S>
			<S sid ="50" ssid = "50">Lastly, the system does not depend on sophisticated, statistical Named Entity Recognition systems (see Section 1.4).</S>
			<S sid ="51" ssid = "51">The current Named Entity Recognition systems have limited domains or require large, tagged training sets to extend their domain.</S>
			<S sid ="52" ssid = "52">The current system uses a simplified, lexical Named Entity Extraction step that is simple to extend or modify.</S>
			<S sid ="53" ssid = "53">There is a growing need to give programmatic access to the vast amount of information provided in unstructured text on the Internet.</S>
			<S sid ="54" ssid = "54">The current work grows out of lessons learned from prior research, while pursuing a novel approach to the task.</S>
			<S sid ="55" ssid = "55">The system described in this paper is a practical query- answering system that can extract information from large document sets in a domain-independent way.</S>
			<S sid ="56" ssid = "56">A demonstration system is developed that can accurately extract a variety of different kinds of information from Wikipedia.</S>
			<S sid ="57" ssid = "57">1.1 Information Extraction.</S>
			<S sid ="58" ssid = "58">This section will review the field of Information Extraction, its goals, and its relationship to other fields.</S>
			<S sid ="59" ssid = "59">By the end of this chapter, the reader should have a feeling for the problems Information Extraction attempts to solve and the potential issues that arise.</S>
			<S sid ="60" ssid = "60">It is helpful to rely on a metaphor to explain the concept of Information Extraction.</S>
			<S sid ="61" ssid = "61">In describing the problem and challenge of Information Extraction, this text will rely on the metaphor of reading and understanding a completely foreign language.</S>
			<S sid ="62" ssid = "62">The reader might imagine text in a language as alien to him or her as possible, such as Icelandic or Mandarin.</S>
			<S sid ="63" ssid = "63">When given a sentence in Icelandic, a person unfamiliar with the language would have a difficult time trying to understand it.</S>
			<S sid ="64" ssid = "64">The text is written in an unfamiliar script, with words and grammar that are incomprehensible.</S>
			<S sid ="65" ssid = "65">One could imagine the difficulty the person would have to identify all of the place names in the sentence.</S>
			<S sid ="66" ssid = "66">This is a typical task asked of Information Extraction systems.</S>
			<S sid ="67" ssid = "67">The challenge of Information Extraction is to create an automated system that can identify specific information that is contained in that sentence or texts like it.</S>
			<S sid ="68" ssid = "68">The definition found in Moens [30] describes the field more precisely.</S>
			<S sid ="69" ssid = "69">Information extraction is the identification, and consequent or concurrent classification and structuring into semantic classes, of specific information found in unstructured data sources, such as natural language text, making the information more suitable for information processing tasks.</S>
			<S sid ="70" ssid = "70">Information Extraction seeks to use computers to automatically apply structure to unstructured information.</S>
			<S sid ="71" ssid = "71">In the case of the current research, the unstructured information used is textual.</S>
			<S sid ="72" ssid = "72">Other possible sources are audio, image, and video files [30].</S>
			<S sid ="73" ssid = "73">The definition of the goal is left purposefully general.</S>
			<S sid ="74" ssid = "74">Any kind of structural information can be applied to the unstructured source.</S>
			<S sid ="75" ssid = "75">Not only is Information Extraction applied to extract content from text, it is also applied to extract meta-data such as authoring information (who wrote it, etc).</S>
			<S sid ="76" ssid = "76">Some typical examples of the kinds of structure applied to text are: • Names of people, places, and organizations • Relationship between two people • Geographic relationships (X is near Y) • Dates of an event The distinguishing characteristic between structured and unstructured data is that unstructured text is computationally opaque [30].</S>
			<S sid ="77" ssid = "77">That is, a computer cannot immediately interpret and make use of the data, as one could with a database or XML file.</S>
			<S sid ="78" ssid = "78">Information Extraction creates structured information which can be added to a database or queried in a structured way.</S>
			<S sid ="79" ssid = "79">1.2 Data Mining.</S>
			<S sid ="80" ssid = "80">Data mining is often used in Information Extraction tasks.</S>
			<S sid ="81" ssid = "81">Data mining seeks to find patterns and relationships in data [38].</S>
			<S sid ="82" ssid = "82">The methods developed in data mining include classifiers and statistical modeling techniques.</S>
			<S sid ="83" ssid = "83">Information Extraction tasks often (but not always) include a data mining step.</S>
			<S sid ="84" ssid = "84">Unstructured information textual information is converted to some structured, numerical form.</S>
			<S sid ="85" ssid = "85">That structured data is then processed using standard data mining techniques, such as clustering, probabilistic networks, and statistical classifiers.</S>
			<S sid ="86" ssid = "86">The data mining methods used to train statistical models include supervised, unsupervised, and semi- supervised.</S>
			<S sid ="87" ssid = "87">Supervised training requires a training set that is completely labeled—that is, given a set of data points, each data point in the set is correctly classified into the appropriate class.</S>
			<S sid ="88" ssid = "88">The computer then learns to classify other points in the same way.</S>
			<S sid ="89" ssid = "89">Unsupervised training uses properties of the data alone to find patterns.</S>
			<S sid ="90" ssid = "90">No other information is given to the system.</S>
			<S sid ="91" ssid = "91">The system often finds new, unexpected patterns (like dividing the set into more classes than a human would).</S>
			<S sid ="92" ssid = "92">The typical data mining technique in this category is clustering, where data points are grouped based solely on similarity.</S>
			<S sid ="93" ssid = "93">Semi-supervised learning is where only a (usually small) portion of the training data points are classified into their categories.</S>
			<S sid ="94" ssid = "94">One could choose to ignore all of the unclassified data—leaving only a small number of classified points.</S>
			<S sid ="95" ssid = "95">However, one is often able to improve the performance of the classification technique by incorporating the unclassified data into the training phase.</S>
			<S sid ="96" ssid = "96">1.3 Natural Language Processing.</S>
			<S sid ="97" ssid = "97">As will become clear in section 2, many approaches (including the current work) use Natural Language Processing techniques.</S>
			<S sid ="98" ssid = "98">Natural Language Processing studies the understanding and generation of human languages.</S>
			<S sid ="99" ssid = "99">The language understanding portion is what is mainly used in Information Extraction.</S>
			<S sid ="100" ssid = "100">Three general subtasks of Natural Language Processing are often used in Information Extraction [18].</S>
			<S sid ="101" ssid = "101">They are used because the information they generate can be useful to the pattern matchers and classifiers used in Information Extraction.</S>
			<S sid ="102" ssid = "102">When one is presented with a sentence in Icelandic, one might like to know which words were nouns, which were verbs, and which were prepositions.</S>
			<S sid ="103" ssid = "103">That information could help one decipher the sentence.</S>
			<S sid ="104" ssid = "104">The task of identifying the part of speech of words in a sentence is called Part of speech tagging.</S>
			<S sid ="105" ssid = "105">This information can be useful for subsequent tasks because it provides more information than the sequence of characters that make up the words.</S>
			<S sid ="106" ssid = "106">See Figure 1.1 for an example.</S>
			<S sid ="107" ssid = "107">In English, some things are described with multiple words.</S>
			<S sid ="108" ssid = "108">One common examples is the “World Health Organization”.</S>
			<S sid ="109" ssid = "109">Instead of interpreting those words separately, it could be helpful to group them together for the purposes of interpretation.</S>
			<S sid ="110" ssid = "110">Noun phrase identification is another Natural Language Processing method which serves to group nouns into noun phrases.</S>
			<S sid ="111" ssid = "111">Some Information Extraction methods treat noun phrase groups in the same way they treat nouns.</S>
			<S sid ="112" ssid = "112">Given a sentence in a foreign language, it could be useful to know which words were the subjects of which verbs, what words are modified by adjectives, and so on.</S>
			<S sid ="113" ssid = "113">This information is gleaned from the text through the action called deep parsing.</S>
			<S sid ="114" ssid = "114">Parsing is the task of grammatically deconstructing a sentence to understand its syntactic structure.</S>
			<S sid ="115" ssid = "115">Parsing generates a tree or a graph from a sentence.</S>
			<S sid ="116" ssid = "116">It is thought by some that a parse tree reveals more useful information than representing it as a series of words.</S>
			<S sid ="117" ssid = "117">However, parsing at a Figure 1.1: The result of Part of Speech tagging on a sample sentence.</S>
			<S sid ="118" ssid = "118">Figure 1.2: An example Noun Phrase Grouping.</S>
			<S sid ="119" ssid = "119">Highlighting represent noun phrases.</S>
			<S sid ="120" ssid = "120">high accuracy can be computationally expensive.</S>
			<S sid ="121" ssid = "121">Figure 1.3 shows a syntax tree of a sentence.</S>
			<S sid ="122" ssid = "122">Figure 1.4 shows a dependency parse, which shows dependency relationships between words and phrases.</S>
			<S sid ="123" ssid = "123">These three methods are all considered to be forms of parsing (with varying computational costs).</S>
			<S sid ="124" ssid = "124">1.4 Common Information Extraction Tasks.</S>
			<S sid ="125" ssid = "125">The Message Understanding Conference (MUC) has essentially defined the tasks that Information Extraction attempts to perform [19].</S>
			<S sid ="126" ssid = "126">Named Entity Recognition is the task of identifying and classifying the words associated with “entities”.</S>
			<S sid ="127" ssid = "127">In the MUC sponsored tasks, the entities were classified as one of Person, Location, and Organization.</S>
			<S sid ="128" ssid = "128">The task occasionally included Time/Date and Money.</S>
			<S sid ="129" ssid = "129">Named Entity Recognition is often performed as a preprocessing step of other Information Extraction tasks.</S>
			<S sid ="130" ssid = "130">It is also sometimes used instead of a parsing step.</S>
			<S sid ="131" ssid = "131">Figure 1.5 gives an example of the result of Named Entity Recognition.</S>
			<S sid ="132" ssid = "132">Relation Extraction is the identification and classification of the relation between two entities in a text.</S>
			<S sid ="133" ssid = "133">The current work addresses this task.</S>
			<S sid ="134" ssid = "134">The fundamental concept of this task is that much information that is pertinent to the structure of a database deals with how the entities interact and relate.</S>
			<S sid ="135" ssid = "135">It is therefore fruitful to extract information pertaining to the relations between entities.</S>
			<S sid ="136" ssid = "136">Relations can include anything from familial relations to geographic relations (“Paris is the capital of France” relates Paris to France; “Russia is near China” relates those two countries).</S>
			<S sid ="137" ssid = "137">Relation Extraction attempts to determine what the nature of the relation is from textual evidence.</S>
			<S sid ="138" ssid = "138">Coreference resolution seeks to identify cases where different words refer to the same entity or concept.</S>
			<S sid ="139" ssid = "139">This occurs in several cases: when the same name is used in two different places to refer to the same entity; when two different names refer to the same entity; when pronouns are used; when anaphoric phrases are used (such as in the two sentences “I took a trip to Paris.</S>
			<S sid ="140" ssid = "140">When I arrived in the city, I found a hotel”; “the city” refers to the same thing as “Paris”).</S>
			<S sid ="141" ssid = "141">This task can also inform later extraction tasks.</S>
			<S sid ="142" ssid = "142">Figure 1.3: A syntax tree.</S>
			<S sid ="143" ssid = "143">Figure 1.4: An example dependency parse.</S>
			<S sid ="144" ssid = "144">Note the labeled edges.</S>
			<S sid ="145" ssid = "145">1.5 Evaluation Metrics.</S>
			<S sid ="146" ssid = "146">There are three standard metrics for evaluating an Information Extraction task.</S>
			<S sid ="147" ssid = "147">They are borrowed from Information Retrieval [40].</S>
			<S sid ="148" ssid = "148">Recall measures the proportion of target facts in a text that are correctly extracted.</S>
			<S sid ="149" ssid = "149">Recall is a measure of completeness without attention to the incorrectly extracted facts.</S>
			<S sid ="150" ssid = "150">Figure 1.5: An example result Named Entity Recognition task.</S>
			<S sid ="151" ssid = "151">Recall = |{extracted facts} ∩ {true facts}| |{true facts}| (1.1) where the truth value of the fact is domain dependent.</S>
			<S sid ="152" ssid = "152">The fact can be compared to a database of known facts or can be hand-tagged in the document.</S>
			<S sid ="153" ssid = "153">Precision measures the proportion of extracted facts that are correct.</S>
			<S sid ="154" ssid = "154">Precision is a measure of correctness.</S>
			<S sid ="155" ssid = "155">Precision = |{extracted facts} ∩ {true facts}| |{extracted facts}| (1.2) F-measure combines Recall and Precision into a single metric.</S>
			<S sid ="156" ssid = "156">The F-measure is a weighted harmonic mean of Recall and Precision.</S>
			<S sid ="157" ssid = "157">It allows for a single metric that weights Recall and Precision by their relative importance to the task at hand.</S>
			<S sid ="158" ssid = "158">Fβ = (1 + β2 ) × Precision × Recall β2 × Precision + Recall (1.3) where β is the relative importance of Recall over Precision.</S>
			<S sid ="159" ssid = "159">F1 weights Recall equally to Precision.</S>
			<S sid ="160" ssid = "160">F2 weights Recall twice as important as Precision.</S>
			<S sid ="161" ssid = "161">F0.5 weights Precision twice as important as Recall.</S>
			<S sid ="162" ssid = "162">These metrics all fall in the range [0, 1].</S>
			<S sid ="163" ssid = "163">This makes them useful to compare evaluations across algorithms and implementations.</S>
			<S sid ="164" ssid = "164">There is, however, discrepancies in how the notion of truth is calculated.</S>
			<S sid ="165" ssid = "165">In general, supervised training methods consider the annotations in the training and testing documents as truth.</S>
			<S sid ="166" ssid = "166">There is therefore an explicitly defined set of true facts—those that occur in the annotations.</S>
			<S sid ="167" ssid = "167">In semi-supervised methods, where no (or very few) annotations are available, other methods of determining truth are required [1].</S>
			<S sid ="168" ssid = "168">When no annotations exist, it is possible to evaluate one’s methods over a domain with known truth values.</S>
			<S sid ="169" ssid = "169">The truth value of a fact can then be checked using that knowledge.</S>
			<S sid ="170" ssid = "170">The question then becomes whether it is reasonable to expect the system to extract facts that are not available in the text.</S>
			<S sid ="171" ssid = "171">A measure of what is extractable is then required.</S>
			<S sid ="172" ssid = "172">The common method for evaluating a domain where no complete model of truth can be used is simply to count the number of returned facts.</S>
			<S sid ="173" ssid = "173">Two algorithms can then compare the size of the dataset returned.</S>
			<S sid ="174" ssid = "174">Chapter 2 Prior Works This chapter organizes the related work in the field along three axes.</S>
			<S sid ="175" ssid = "175">Each axis forms a continuum along which the techniques fall.</S>
			<S sid ="176" ssid = "176">The majority of research involved in evaluating different classifiers and their parameters applied as different feature sets.</S>
			<S sid ="177" ssid = "177">The triadic taxonomy done here will encompass the majority of prior research.</S>
			<SUBSECTION>2.1 Training.</SUBSECTION>
			<S sid ="178" ssid = "178">The primary axis determines the type of training the system uses.</S>
			<S sid ="179" ssid = "179">The type of training that a research approach uses is one of the ways the techniques differ from each other.</S>
			<S sid ="180" ssid = "180">The type training also determines to a large extent how much human work is required to train the system.</S>
			<S sid ="181" ssid = "181">Training techniques can range from fully handwritten to totally unsupervised methods.</S>
			<S sid ="182" ssid = "182">Figure 2.1 shows an illustration of the tradeoffs made when choosing a training method.</S>
			<S sid ="183" ssid = "183">Handwritten techniques are the most time consuming.</S>
			<S sid ="184" ssid = "184">People must analyze hundreds of documents looking for patterns that will be useful for extracting the information.</S>
			<S sid ="185" ssid = "185">Not only is it expensive—it is also error-prone, inaccurate, and tends to miss a large portion of patterns.</S>
			<S sid ="186" ssid = "186">Some approaches to handwritten techniques do show promise, such as Fundel et al. [17] and Daraselia et al. [11], but they are still the most time-consuming and inflexible.</S>
			<S sid ="187" ssid = "187">Unsupervised methods require no human input to train the system.</S>
			<S sid ="188" ssid = "188">This can take the form of automatically determining different groupings of data.</S>
			<S sid ="189" ssid = "189">Since no human input is required, the system can be applied to many different domains without the expense of developing a new training corpus for each one.</S>
			<S sid ="190" ssid = "190">However, these systems must deal with a grave difficulty: the data they get do not necessarily correspond to the user’s idea of relevance.</S>
			<S sid ="191" ssid = "191">The systems have no human guide to learn from [38].</S>
			<S sid ="192" ssid = "192">Between the two extremes are supervised and semi-supervised methods (sometimes called weakly supervised methods).</S>
			<S sid ="193" ssid = "193">Supervised methods generally require a large training corpus that is completely annotated by hand by a domain expert.</S>
			<S sid ="194" ssid = "194">The system uses machine learning techniques to mimic the annotation choices made by humans.</S>
			<S sid ="195" ssid = "195">It can be rather costly, but usually gives very accurate results.</S>
			<S sid ="196" ssid = "196">Often the results can take into account the subtleties of human discernment.</S>
			<S sid ="197" ssid = "197">Semi-supervised methods try to gain the advantages of human knowledge without the intensive labor of a completely annotated corpus.</S>
			<S sid ="198" ssid = "198">These methods typically require only a fraction of the annotated data given to supervised methods.</S>
			<S sid ="199" ssid = "199">Others provide a handful of examples of the kind of data one wishes to extract.</S>
			<S sid ="200" ssid = "200">The disadvantage is that they are less accurate than supervised methods.</S>
			<SUBSECTION>2.2 Depth of Parsing.</SUBSECTION>
			<S sid ="201" ssid = "201">The second axis is the depth of parsing performed on the sentences (see Section 1.3).</S>
			<S sid ="202" ssid = "202">A deeper parse is computationally more expensive.</S>
			<S sid ="203" ssid = "203">Many algorithms have been derived using only part of speech tagging or Figure 2.1: In general, training methods that result in higher accuracy require more human effort to port to a new domain.</S>
			<S sid ="204" ssid = "204">noun phrase clustering.</S>
			<S sid ="205" ssid = "205">Some systems use a Named Entity Recognizer as the only parse.</S>
			<S sid ="206" ssid = "206">Named Entity Recognition can also be performed in addition to another form of parsing.</S>
			<S sid ="207" ssid = "207">Still others perform no parsing at all and rely only on textual matching (such as Grishman [18]).</S>
			<S sid ="208" ssid = "208">In general, the more computationally expensive an operation, the more information can be gleaned from the sentence.</S>
			<S sid ="209" ssid = "209">Figure 2.2 visualizes this point.</S>
			<SUBSECTION>2.3 Machine Learning Technique.</SUBSECTION>
			<S sid ="210" ssid = "210">The third axis is how the system learns to generalize from a training set.</S>
			<S sid ="211" ssid = "211">This axis can range from rote techniques to advanced statistical machine learning.</S>
			<S sid ="212" ssid = "212">Figure 2.3 illustrates the compromise necessary when choosing among the following classification techniques.</S>
			<SUBSECTION>2.3.1 Rote techniques Rote techniques use a deterministic predicate to extract the information.</SUBSECTION>
			<S sid ="213" ssid = "213">A simple example is a regular expression.</S>
			<S sid ="214" ssid = "214">If the regular expression matches a sentence, then the information contained in the groupings (parentheses) of the regular expression form the entities in the data value.</S>
			<S sid ="215" ssid = "215">In general, rote techniques use one or more patterns that match the parsed representation of the sentence.</S>
			<S sid ="216" ssid = "216">If at least one pattern matches, Figure 2.2: Investing more computational time to parsing leads to higher syntactic information gains.</S>
			<S sid ="217" ssid = "217">the data in the sentence is considered relevant and the system extracts it.</S>
			<S sid ="218" ssid = "218">If no pattern matches, the data is not extracted.</S>
			<S sid ="219" ssid = "219">The rote patterns are typically generated in one of two ways.</S>
			<S sid ="220" ssid = "220">The first way is exact matching.</S>
			<S sid ="221" ssid = "221">This approach is where each training instance generates a single pattern.</S>
			<S sid ="222" ssid = "222">Those patterns are not modified, though they can be kept or discarded (see Etzioni et al. [15] for an example).</S>
			<S sid ="223" ssid = "223">The second way is called generalization.</S>
			<S sid ="224" ssid = "224">This is where some simple form of machine learning is used to make the generated patterns more general, and therefore more resistant to the presence of noise (Califf and Mooney [6], Huffman [23], and Soderland [35] use this method).</S>
			<SUBSECTION>2.3.2 Information retrieval methods In information retrieval methods, metrics of document relevance are used to measure the relevance of individual sequences of words (example: Agichtein and Gravano [1]).</SUBSECTION>
			<SUBSECTION>2.3.3 Statistical techniques Statistical techniques are typified by the use of many training points.</SUBSECTION>
			<S sid ="225" ssid = "225">They rely on statistical averaging or probability to find patterns in the data.</S>
			<S sid ="226" ssid = "226">Probabilistic networks are trained statistical methods that label sequences of data [8].</S>
			<S sid ="227" ssid = "227">The sentence can be treated as a sequence of words.</S>
			<S sid ="228" ssid = "228">The network then predicts labels for the words that correspond to the roles in the relation that is being extracted [25].</S>
			<S sid ="229" ssid = "229">For instance, in the relation CapitalCityOf, Paris could Figure 2.3: Techniques that are less sensitive to noise require more training.</S>
			<S sid ="230" ssid = "230">be labeled as CITY and France could be labeled as COUNTRY.</S>
			<S sid ="231" ssid = "231">One can then extract the words with a meaningful label.</S>
			<S sid ="232" ssid = "232">Examples of probabilistic networks are Hidden Markov Models and Conditional Random Fields.</S>
			<S sid ="233" ssid = "233">Statistical classifiers use data mining techniques.</S>
			<S sid ="234" ssid = "234">Sentences or facts can be modelled as feature vectors appropriate for the classifier chosen.</S>
			<S sid ="235" ssid = "235">The classifier can be trained using traditional supervised, semi-supervised, or unsupervised approaches.</S>
			<S sid ="236" ssid = "236">Examples of statistical classifiers are Naive Bayes and Support Vector Machines.</S>
			<S sid ="237" ssid = "237">Examples include Culotta and Sorensen [10], Jie and Min [24], and Bunescu and Mooney [5].</S>
			<SUBSECTION>2.4 Thought Experiment.</SUBSECTION>
			<S sid ="238" ssid = "238">This chapter also describes the problem definition each paper attempts to solve.</S>
			<S sid ="239" ssid = "239">There is a wide variety of problem definitions, and their explanations can get quite tedious.</S>
			<S sid ="240" ssid = "240">To make it easier for the reader, a thought experiment has been devised.</S>
			<S sid ="241" ssid = "241">It will make use of the same metaphor used previously which was about deciphering a foreign language.</S>
			<S sid ="242" ssid = "242">The thought experiment is called the Icelandic Library.</S>
			<S sid ="243" ssid = "243">It goes as follows.</S>
			<S sid ="244" ssid = "244">A person, named Bob, is in a library in Iceland.</S>
			<S sid ="245" ssid = "245">To simplify matters, all books are written in Icelandic—and there are no pictures.</S>
			<S sid ="246" ssid = "246">The person does not speak Icelandic.</S>
			<S sid ="247" ssid = "247">Bob is given a task, which is defined differently with each research paper description.</S>
			<S sid ="248" ssid = "248">Bob is to use the resources of the library, which can differ with each prior research, to perform the task.</S>
			<S sid ="249" ssid = "249">It should be understood that though the explanation for each problem is stated as if it were in Icelandic, all papers in fact operate on English language text.</S>
			<SUBSECTION>2.5 Literature Review.</SUBSECTION>
			<S sid ="250" ssid = "250">The following sections divide the literature into four categories along the axis of type of training.</S>
			<S sid ="251" ssid = "251">An explanation of where each prior work falls in the remaining two axes is detailed in its description.</S>
			<SUBSECTION>2.5.1 Handwritten methods The handwritten methods generally consist of people writing regular expression-like patterns to match certain patterns in text.</SUBSECTION>
			<S sid ="252" ssid = "252">The patterns are typically very specific to a few syntactic patterns.</S>
			<S sid ="253" ssid = "253">These kinds of methods do not offer very much help for changing domains.</S>
			<S sid ="254" ssid = "254">The following papers are classified as handwritten methods because they require a large, domain-specific portion to be hand-coded.</S>
			<S sid ="255" ssid = "255">Fundel et al. [17] was built to extract protein-protein interactions from biological paper abstracts.</S>
			<S sid ="256" ssid = "256">In this paper, Bob’s task in the Icelandic Library to go through every book in the library, sentence by sentence, and create a list of protein-protein interactions, cataloguing the type of interaction.</S>
			<S sid ="257" ssid = "257">Each sentence in the library is already parsed into a dependency tree (an example of deep parsing.</S>
			<S sid ="258" ssid = "258">See Section 1.3) for Bob to use.</S>
			<S sid ="259" ssid = "259">Bob also has a dictionary of protein names (in Icelandic) to guide the search.</S>
			<S sid ="260" ssid = "260">The paper proposes the following solution.</S>
			<S sid ="261" ssid = "261">After finding a sentence with a protein name from the dictionary, Bob will perform certain simple transformations to the dependency tree.</S>
			<S sid ="262" ssid = "262">These transformations include building noun phrases and reconstructing lists from their syntactic interpretation.</S>
			<S sid ="263" ssid = "263">Bob then looks for three syntactic patterns in the resulting tree.</S>
			<S sid ="264" ssid = "264">These patterns correspond to what the authors claim are the three most important syntactic forms for expressing relations.</S>
			<S sid ="265" ssid = "265">Quoting the text: Currently, we use three rules that reflect the constructs that are most frequently used in English language for describing relations, namely: 1.</S>
			<S sid ="266" ssid = "266">effector-relation-effectee (‘A activates B’).</S>
			<S sid ="267" ssid = "267">2.</S>
			<S sid ="268" ssid = "268">relation-of-effectee-by-effector (‘Activation of A by B’).</S>
			<S sid ="269" ssid = "269">3.</S>
			<S sid ="270" ssid = "270">relation-between-effector-and-effectee (‘Interaction between A and B’).</S>
			<S sid ="271" ssid = "271">The triplet &lt;effector, relation, effectee &gt;is extracted if it matches one of the patterns above.</S>
			<S sid ="272" ssid = "272">Each of the patterns is hard coded (an example of a rote technique.</S>
			<S sid ="273" ssid = "273">See Section 1.3).</S>
			<S sid ="274" ssid = "274">These patterns are fixed at design-time—and they are chosen based on the language patterns of biological abstracts.</S>
			<S sid ="275" ssid = "275">It is easy to see that extending this system to new domains would necessarily require adding a new dictionary (to replace the protein dictionary) and to reanalyze the new text sources for possible syntactic patterns that correspond with the semantic meaning that is desired.</S>
			<S sid ="276" ssid = "276">Daraselia et al. [11] uses a hand-generated ontology of protein-protein interaction.</S>
			<S sid ="277" ssid = "277">An ontology, in this sense, is a collection of data structures describing how to translate between an input sentence and another data structure called a frame.</S>
			<S sid ="278" ssid = "278">A frame is just a template with slots.</S>
			<S sid ="279" ssid = "279">The slots define admissible values.</S>
			<S sid ="280" ssid = "280">Synonyms, keywords, and protein names are all defined in the ontology.</S>
			<S sid ="281" ssid = "281">In this problem, Bob’s task is to choose a form (called a frame in the paper) from a list of possible forms based on rules in the ontology.</S>
			<S sid ="282" ssid = "282">Then each form is filled out based on the same rules.</S>
			<S sid ="283" ssid = "283">Bob is again given a dependency parse for each sentence.</S>
			<S sid ="284" ssid = "284">The rules are of the type “use the form called Inhibition when the verb of the sentence is ’inhibits”’.</S>
			<S sid ="285" ssid = "285">The paper analyzes the example sentence “P53 inhibits apoptosis.” The system performs a dependency parse of the sentence, then applies the ontology to the resulting tree.</S>
			<S sid ="286" ssid = "286">The word “inhibits” is in the ontology, and activates a frame.</S>
			<S sid ="287" ssid = "287">The frame is called “Inhibition” and describe what useful information the system should look for in terms of chemical inhibition.</S>
			<S sid ="288" ssid = "288">The “Inhibition” frame has an “agent” slot and a “patient” slot.</S>
			<S sid ="289" ssid = "289">The “agent” slot needs a protein name that is the subject of the verb.</S>
			<S sid ="290" ssid = "290">A search through the ontology reveals that “P53” is a protein name, and fills the requirements for “agent” in this frame.</S>
			<S sid ="291" ssid = "291">“P53” is inserted into the agent slot.</S>
			<S sid ="292" ssid = "292">The “patient” slot needs a direct object that is a cell process.</S>
			<S sid ="293" ssid = "293">“apoptosis” is a cell process and a direct object of “inhibits” and therefore fulfils the requirements for “patient”.</S>
			<S sid ="294" ssid = "294">The frame has been filled in successfully and can be stored in a database.</S>
			<S sid ="295" ssid = "295">The tree is walked this way, until there is no more information to be extracted.</S>
			<S sid ="296" ssid = "296">This can be considered a rote process since no machine learning is performed.</S>
			<S sid ="297" ssid = "297">The construction of the ontology is very time-consuming.</S>
			<S sid ="298" ssid = "298">It is constructed by hand by domain experts.</S>
			<S sid ="299" ssid = "299">And the ontology is domain-specific.</S>
			<S sid ="300" ssid = "300">Little or none of the domain knowledge encoded in the ontology can be transfered to another application domain.</S>
			<S sid ="301" ssid = "301">For instance, in addition to the complex network of frames and other concepts, the ontology includes 6,000 words and their meanings in the ontology.</S>
			<S sid ="302" ssid = "302">These words are domain specific—words not meaningful to the search were not included.</S>
			<S sid ="303" ssid = "303">It would be very expensive to generate a dictionary of that size for every domain one would like to query.</S>
			<S sid ="304" ssid = "304">Although this technique is very powerful, the expense is prohibitive.</S>
			<SUBSECTION>2.5.2 Supervised methods The Message Understanding Conferences (MUC’s) encourage supervised models of the problem domain [19].</SUBSECTION>
			<S sid ="305" ssid = "305">The corpora used in its proceedings are fully annotated.</S>
			<S sid ="306" ssid = "306">The domain is completely specified ahead of time.</S>
			<S sid ="307" ssid = "307">This makes it easy to apply traditional machine learning techniques.</S>
			<S sid ="308" ssid = "308">The focus is placed on choosing an appropriate feature set.</S>
			<S sid ="309" ssid = "309">The main choices that must be made in a supervised model are the choice of feature set and the choice of classifier.</S>
			<S sid ="310" ssid = "310">Rote methods The simplest classifier is a pattern matcher.</S>
			<S sid ="311" ssid = "311">It is a simple, deterministic function that classifies the type of relation present in a sentence.</S>
			<S sid ="312" ssid = "312">Huffman [23] presents a system that creates a dictionary of patterns from training examples that can be later used to extract information from other documents.</S>
			<S sid ="313" ssid = "313">In this paper, Bob is given the task of generating tree patterns that indicate a certain semantic meaning and can be applied to new sentences.</S>
			<S sid ="314" ssid = "314">Bob is given a book of sentences that are parsed into a syntax tree.</S>
			<S sid ="315" ssid = "315">In each sentence, two words are marked as different from the others.</S>
			<S sid ="316" ssid = "316">These are the two entities in the relation.</S>
			<S sid ="317" ssid = "317">From this book, Bob must generate a small set of patterns that will be able to match entities that have the same relationship as the words in the book.</S>
			<S sid ="318" ssid = "318">The solution presented in the paper is that Bob should determine the path along the parse trees that are important to the relation using a set of rules.</S>
			<S sid ="319" ssid = "319">The rules specify which words to ignore and which to keep.</S>
			<S sid ="320" ssid = "320">These paths are written down, with the marked words replaced by blanks.</S>
			<S sid ="321" ssid = "321">When all of the sentences in the book have been processed, Bob is to compare all of the patterns to each other, finding patterns that have similar structure.</S>
			<S sid ="322" ssid = "322">When two patterns are similar, words from one pattern that do not match the corresponding word in the other pattern are replaced by a wild-card and that new pattern replaces the other two.</S>
			<S sid ="323" ssid = "323">In this way, the patterns are generalized The list of patterns can then be applied to new sentences parsed into a syntax tree.</S>
			<S sid ="324" ssid = "324">If any other patterns match, the words that correspond to blanks in the pattern are returned as extracted information.</S>
			<S sid ="325" ssid = "325">Transferring this system to new domains is better than with the handwritten methods.</S>
			<S sid ="326" ssid = "326">In this case, one needs only create a new training set (the book of marked sentences given to Bob).</S>
			<S sid ="327" ssid = "327">However, with small training sets, the system can be inaccurate.</S>
			<S sid ="328" ssid = "328">If only one sentence exists in the training set, only one pattern can be generated.</S>
			<S sid ="329" ssid = "329">A sentence must match it exactly to be extracted.</S>
			<S sid ="330" ssid = "330">Considering how many ways there are to phrase the same fact, it would take many training examples to generate a system with many generalized patterns to result in high Recall.</S>
			<S sid ="331" ssid = "331">Califf and Mooney [6] has a similar system.</S>
			<S sid ="332" ssid = "332">It was designed to extract information from job postings on Usenet.</S>
			<S sid ="333" ssid = "333">Bob is given one form to fill out that contain the attributes of job postings—including job title, company, and salary.</S>
			<S sid ="334" ssid = "334">Bob is also given a set of postings in Icelandic and their corresponding filled-in form.</S>
			<S sid ="335" ssid = "335">From this, Bob must generate a small set of patterns that can be applied to new job postings to automatically fill in the forms.</S>
			<S sid ="336" ssid = "336">The job postings are given as-is—that is, no parsing is performed.</S>
			<S sid ="337" ssid = "337">The solution is to have Bob write out the words surrounding the words from each blank in the form as a pattern.</S>
			<S sid ="338" ssid = "338">When all of the training examples have been done this way, the patterns corresponding to the same blanks are compared.</S>
			<S sid ="339" ssid = "339">Bob chooses two patterns at random, finds the similarities between them, and generalizes the differences so that they will match the same set of sentences.</S>
			<S sid ="340" ssid = "340">The generalizations are fixed.</S>
			<S sid ="341" ssid = "341">One example is to generalize “house” and “cup” to match any noun.</S>
			<S sid ="342" ssid = "342">The new generalized pattern is then matched over the training set, extracting values.</S>
			<S sid ="343" ssid = "343">If it extracts any wrong values, the generalization is discarded.</S>
			<S sid ="344" ssid = "344">If it does not match any wrong values, Bob iterates through generalizations until no more generalizations can be performed that produce only correct extractions.</S>
			<S sid ="345" ssid = "345">The generalized patterns are added back into the list, replacing the two patterns they were generalized from.</S>
			<S sid ="346" ssid = "346">When there are no more possible generalizations, the list of patterns is returned.</S>
			<S sid ="347" ssid = "347">Generalizations are performed in order to avoid over-fitting patterns to the training data.</S>
			<S sid ="348" ssid = "348">This process lets the set of patterns remain small and also allows the system to deal with noise in the training set.</S>
			<S sid ="349" ssid = "349">Although this method is more powerful than Huffman [23], it still requires an expert to create a training set for each new domain.</S>
			<S sid ="350" ssid = "350">It is therefore time consuming and inflexible.</S>
			<S sid ="351" ssid = "351">Califf et al. [7] extends the system from Califf and Mooney [6] to allow for generalizations from Wordnet classes.</S>
			<S sid ="352" ssid = "352">For example, combining patterns for the words “house” and “apartment” could lead to a pattern that matches any word in the “dwelling” category.</S>
			<S sid ="353" ssid = "353">Soderland [35] uses a simple pattern matcher similar to regular expressions.</S>
			<S sid ="354" ssid = "354">The way it creates patterns is not significantly different from other pattern matching systems.</S>
			<S sid ="355" ssid = "355">Bob is given the task of generating patterns that will match a given relation between entities.</S>
			<S sid ="356" ssid = "356">In this research paper, Bob is allowed to ask a librarian to read sentences and identify the relationship stated in the sentence.</S>
			<S sid ="357" ssid = "357">This lets Bob build a new training set.</S>
			<S sid ="358" ssid = "358">The solution the paper proposes is one that tries to minimize the number of sentences that are required of the librarian.</S>
			<S sid ="359" ssid = "359">It interactively asks the user to tag sentences.</S>
			<S sid ="360" ssid = "360">The pattern generation method is not materially different from the previously described methods.</S>
			<S sid ="361" ssid = "361">The system selects the sentences the user will label based on three categories: Instances covered by an existing pattern—to check the patterns, Instances not covered by a pattern but covered by a generalization of a pattern—to confirm that a generalization is correct, and Instances not covered by any pattern—to expand the number of patterns.</S>
			<S sid ="362" ssid = "362">By randomly training and retraining from these three classes of sentence, the user slowly increases the number of training instances available to the system.</S>
			<S sid ="363" ssid = "363">This process is called active learning.</S>
			<S sid ="364" ssid = "364">It uses feedback to minimize the number of training instances required.</S>
			<S sid ="365" ssid = "365">The drawback is that the fundamental means of learning has not changed, so only a small measure of efficiency is gained.</S>
			<S sid ="366" ssid = "366">Statistical methods Support Vector Machines are a state of the art statistical classifier.</S>
			<S sid ="367" ssid = "367">The kernel function is essentially a measure of similarity.</S>
			<S sid ="368" ssid = "368">Much research is being done on the choice of features and the kernel function.</S>
			<S sid ="369" ssid = "369">Research is ongoing into new kernel functions that can act on trees—dependency parse trees specifically.</S>
			<S sid ="370" ssid = "370">Bunescu and Mooney [4] builds a system that uses a kernel tailored for subgraphs of a dependency tree.</S>
			<S sid ="371" ssid = "371">Bob is given a task of classifying the relationship between two given entities in a sentence into one of a set of classes.</S>
			<S sid ="372" ssid = "372">He has at his disposal a set of dependency trees from sentences and the categories they should be classified into.</S>
			<S sid ="373" ssid = "373">The solution the authors propose is for Bob to find all sentences with the same training class.</S>
			<S sid ="374" ssid = "374">Bob then must extract the shortest path in the tree from one entity to the next (since it works only on binary relations).</S>
			<S sid ="375" ssid = "375">Bob can compare two sentences based on the number of words the shortest paths have in common.</S>
			<S sid ="376" ssid = "376">An SVM is trained with this data.</S>
			<S sid ="377" ssid = "377">A new sentence is classified by extracting the shortest path between entities and classifying it with the SVM.</S>
			<S sid ="378" ssid = "378">The authors make the hypothesis that the most important syntactic and lexical features of a relation occur along the shortest path between the two entities on the dependency tree.</S>
			<S sid ="379" ssid = "379">The shortest path is augmented with part of speech and Wordnet hypernym information.</S>
			<S sid ="380" ssid = "380">Bunescu and Mooney [5] develops a kernel function that applies to sequences of words.</S>
			<S sid ="381" ssid = "381">It is equivalent to the previous work except that it applies to word subsequences instead of dependency graphs.</S>
			<S sid ="382" ssid = "382">The subsequence kernel counts the number of matching subsequences.</S>
			<S sid ="383" ssid = "383">The target domain is protein-protein interactions in biological abstracts.</S>
			<S sid ="384" ssid = "384">The length of the sequences is limited to four words.</S>
			<S sid ="385" ssid = "385">The insight in this paper is that only three common expressions of relationship are considered.</S>
			<S sid ="386" ssid = "386">By restricting the feature set, they both speed up the algorithm and look only at very compelling data.</S>
			<S sid ="387" ssid = "387">Since the sequences are no longer than four, this is computationally inexpensive.</S>
			<S sid ="388" ssid = "388">Using a subsequence kernel allows for a shallow parse or no parse at all instead of an expensive deep parse.</S>
			<S sid ="389" ssid = "389">Culotta and Sorensen [10] develops a kernel function that operates on the dependency graph.</S>
			<S sid ="390" ssid = "390">The hypothesis laid out is that the syntactic relation between two named entities is local—that it is expressed in the shortest subtree of the dependency parse tree containing both entities.</S>
			<S sid ="391" ssid = "391">This hypothesis is not as strong as the thesis proposed in Bunescu and Mooney [4].</S>
			<S sid ="392" ssid = "392">The kernel recursively counts the number of common subtrees two trees share.</S>
			<S sid ="393" ssid = "393">The dependency tree is augmented with many features—including the part of speech and Wordnet hypernyms.</S>
			<S sid ="394" ssid = "394">The entities of interest are identified in the sentence by using a Named Entity Recognition phase.</S>
			<S sid ="395" ssid = "395">This technique allows for a fairly robust identification of names, places, and organizations.</S>
			<S sid ="396" ssid = "396">However, the Named Entity Recognition system used and those in common use are limited in what types of entities they identify.</S>
			<S sid ="397" ssid = "397">They also typically require supervised learning, so they are costly to extend to new domains.</S>
			<S sid ="398" ssid = "398">Harabagiu et al. [20] augments the work in Culotta and Sorensen [10] by adding new features to the dependency graph.</S>
			<S sid ="399" ssid = "399">An ontology of one million words was added to provide information about what noun phrases are the arguments of which predicates.</S>
			<S sid ="400" ssid = "400">Jie and Min [24] uses a Support Vector Machine to classify extracted relations.</S>
			<S sid ="401" ssid = "401">It performs noun-phrase chunking instead of doing a deep parse.</S>
			<S sid ="402" ssid = "402">It argues (and its results confirm) that little extra precision is gained from doing a full dependency parse.</S>
			<S sid ="403" ssid = "403">Its feature set is not different from the other work on SVM’s. Liu et al. [26] considers a set of syntactic features to combine into a feature vector for input to a kernel.</S>
			<S sid ="404" ssid = "404">The feature extractions are hand-coded.</S>
			<S sid ="405" ssid = "405">The syntactic features they develop include patterns such as “parent node of protein name” in the parse tree.</S>
			<S sid ="406" ssid = "406">This is important because it tries to combine syntactic features into a feature vector to be used in a classifier.</S>
			<S sid ="407" ssid = "407">Unfortunately, the syntactic features are selected by hand specifically for the domain.</S>
			<S sid ="408" ssid = "408">This means that the features are likely not to work in a new domain.</S>
			<S sid ="409" ssid = "409">The typical statistical approach is to find a sentence that has the entities in question and to try to extract their relationship from the sentence.</S>
			<S sid ="410" ssid = "410">Culotta et al. [8] turns that around and assumes that the text is about some entity—the subject of the text.</S>
			<S sid ="411" ssid = "411">The goal, then, is to find the relationships between the subject and the other entities mentioned in the text.</S>
			<S sid ="412" ssid = "412">In this approach, Bob is given a sentence and the subject of the document from which it is taken.</S>
			<S sid ="413" ssid = "413">Bob then is asked to find the relationship of the entities in the sentence and the subject.</S>
			<S sid ="414" ssid = "414">This approach models context in a simple way in which implicit mentions of the subject of a text can be resolved to an explicit entity.</S>
			<S sid ="415" ssid = "415">For instance, in an article about Germany, one might find the sentence “The capital is Berlin.” No where in the sentence is Germany mentioned.</S>
			<S sid ="416" ssid = "416">It is implied that Germany should be understood because the entire document is about Germany.</S>
			<S sid ="417" ssid = "417">Most approaches miss these references.</S>
			<S sid ="418" ssid = "418">Section 6.3 discusses a way to augment the current work with a similar kind of context.</S>
			<S sid ="419" ssid = "419">Culotta et al. [8] trains a Conditional Random Field (See Section 2.3) to label the words in a sentence.</S>
			<S sid ="420" ssid = "420">The labels can be either IRRELEVANT or the name of the class.</S>
			<S sid ="421" ssid = "421">For instance, in an article about George W. Bush, the sentence “He is married to Laura Bush.” would label the name “Laura Bush” as WIFE and the rest of the words as IRRELEVANT.</S>
			<S sid ="422" ssid = "422">It is then trivial to extract out the information.</S>
			<S sid ="423" ssid = "423">Another approach is taken in Xiao et al. [41].</S>
			<S sid ="424" ssid = "424">The classification is done using a maximum entropy model.</S>
			<S sid ="425" ssid = "425">Features include the words surrounding the entities.</S>
			<S sid ="426" ssid = "426">It performs a dependency parse, and uses features from those trees.</S>
			<S sid ="427" ssid = "427">The Supervised methods follow basically the same approach: use a standard classifier on a feature vector derived from the sentence.</S>
			<S sid ="428" ssid = "428">The choice of classifier and the feature set are thus very important and form the bulk of the research.</S>
			<SUBSECTION>2.5.3 Unsupervised methods Unsupervised methods do not require human input.</SUBSECTION>
			<S sid ="429" ssid = "429">They typically categorize or cluster data automatically using standard clustering techniques.</S>
			<S sid ="430" ssid = "430">Etzioni et al. [15] describes a system called “KnowItAll” that uses the World Wide Web as a giant corpus of sentences (the library in the Icelandic Library metaphor).</S>
			<S sid ="431" ssid = "431">The user can ask Bob to give a list of entities that are of a certain type, or to give a list of pairs of entities that are in a certain relationship.</S>
			<S sid ="432" ssid = "432">The authors have developed a set of domain-independent extraction rules.</S>
			<S sid ="433" ssid = "433">These rules are not meant to exhaustively cover every way an English sentence can describe a relation.</S>
			<S sid ="434" ssid = "434">The rules instead leverage the sheer size of the Internet to “play the averages”.</S>
			<S sid ="435" ssid = "435">The principle is that on average, there is a sentence that does match a certain rule somewhere on the Internet that contains the desired information.</S>
			<S sid ="436" ssid = "436">The following are some example patterns.</S>
			<S sid ="437" ssid = "437">NP means noun phrase and {} means the surrounded text is optional.</S>
			<S sid ="438" ssid = "438">• NP1 {“,”} “such as” NPList2 • NP1 {“,”} “and other” NP2 • NP1 {“,”} “including” NPList2 • NP1 “is a” NP2 • NP1 “is the” NP2 “of ” NP3 • “the” NP1 “of ” NP2 “is” NP3 The user can query KnowItAll for “cities in France”.</S>
			<S sid ="439" ssid = "439">It will then search various search engines with the queries “cities in France such as”, “and other cities in France” and “is a city in France”.</S>
			<S sid ="440" ssid = "440">The resulting pages are scraped for the sentence containing the text.</S>
			<S sid ="441" ssid = "441">The patterns are applied and the resulting information is extracted.</S>
			<S sid ="442" ssid = "442">This system is interesting for three reasons.</S>
			<S sid ="443" ssid = "443">Firstly, it is more active than the normal approach.</S>
			<S sid ="444" ssid = "444">It seeks the information that it knows how to extract instead of learning how to extract information that is given to it.</S>
			<S sid ="445" ssid = "445">Secondly, it uses the redundancy of the size of the dataset (effectively, the entire searchable Internet) to make up for its lack of intelligence.</S>
			<S sid ="446" ssid = "446">Lastly, it allows for a wide range of domains.</S>
			<S sid ="447" ssid = "447">The only human input needed is the expression of the query.</S>
			<S sid ="448" ssid = "448">The KnowItAll system is classified here as shallow parsing and rote.</S>
			<S sid ="449" ssid = "449">It is considered unsupervised since it requires no human input to extend its domain.</S>
			<S sid ="450" ssid = "450">Etzioni et al. [16] extends the KnowItAll system.</S>
			<S sid ="451" ssid = "451">Three unsupervised methods are added.</S>
			<S sid ="452" ssid = "452">The Rule Learning system augments the domain-independent rules from the original KnowItAll system by extracting text patterns using seeds generated by the domain-independent rules.</S>
			<S sid ="453" ssid = "453">This could be considered a case of semi-supervised learning (i.e., learning from a small number of examples) but the seed examples are automatically generated by the system itself.</S>
			<S sid ="454" ssid = "454">It has been classified here because there is no human input required.</S>
			<S sid ="455" ssid = "455">The second extension to KnowItAll is Subclass Extraction.</S>
			<S sid ="456" ssid = "456">The reasoning behind the system is simple.</S>
			<S sid ="457" ssid = "457">If the user wants to query the system for a list of scientists, the original KnowItAll would use patterns equivalent to “scientists such as” to find sentences that contain scientists.</S>
			<S sid ="458" ssid = "458">However, the system would miss sentences that match “physicists such as”.</S>
			<S sid ="459" ssid = "459">The Subclass Extraction system uses KnowItAll to extract a list of highly probable subclass names to augment the query.</S>
			<S sid ="460" ssid = "460">The system finds new subclass names by querying itself for “types of scientist”.</S>
			<S sid ="461" ssid = "461">The third extension is called List Extraction.</S>
			<S sid ="462" ssid = "462">In List Extraction, the system queries a search engine for one of the many structured lists of items on the Internet.</S>
			<S sid ="463" ssid = "463">The items are chosen at random from the lists generated by the original KnowItAll system.</S>
			<S sid ="464" ssid = "464">The goal is to find many structured lists containing the items and correlate the results together.</S>
			<S sid ="465" ssid = "465">Many queries are made, and the items are ranked by the number of lists they appear in.</S>
			<S sid ="466" ssid = "466">This method is interesting because it shows that a high precision algorithm can be used as an initial stage to generate high-precision seed candidates.</S>
			<S sid ="467" ssid = "467">Those seeds can then be fed to higher recall stages.</S>
			<S sid ="468" ssid = "468">It also shows how useful redundancy can be.</S>
			<S sid ="469" ssid = "469">Instead of trying to deduce what a single sentence is saying, the system uses the redundant nature of multiple documents to extract and verify the information.</S>
			<S sid ="470" ssid = "470">Hasegawa et al. [21] introduces a system that clusters pairs of entities together based on similar contexts.</S>
			<S sid ="471" ssid = "471">The algorithm works as follows: given a set of documents, a shallow parse is performed.</S>
			<S sid ="472" ssid = "472">The system identifies pairs of entities that are near each other.</S>
			<S sid ="473" ssid = "473">The words that come between the pairs in the sentences are stored.</S>
			<S sid ="474" ssid = "474">The system then clusters the pairs of entities based on the similarities of the set of intervening words.</S>
			<S sid ="475" ssid = "475">After the clustering is performed, the most common words from each cluster are chosen as the cluster label.</S>
			<S sid ="476" ssid = "476">The results indicated that this word was accurate for clusters of at least a certain size.</S>
			<S sid ="477" ssid = "477">Shinyama and Sekine [34] develops a system for automatically classifying relations among entities.</S>
			<S sid ="478" ssid = "478">Their system works on an entire document (as opposed to a sentence).</S>
			<S sid ="479" ssid = "479">It identifies entities in the document.</S>
			<S sid ="480" ssid = "480">The system records the context words surrounding each entity.</S>
			<S sid ="481" ssid = "481">It then assumes that a relationship exists between each pair of entities in the document by reasoning that if they did not have a relationship, they wouldn’t be in the same document.</S>
			<S sid ="482" ssid = "482">The system performs this analysis on multiple documents, keeping the entities separate.</S>
			<S sid ="483" ssid = "483">The system then performs clustering on the pairs of entities across multiple documents.</S>
			<S sid ="484" ssid = "484">The goal is to use the context surrounding each word to cluster entities with similar “roles” together.</S>
			<S sid ="485" ssid = "485">For instance, in an article about Hurricane Katrina, the entity “New Orleans” might be surrounded by “was hit”.</S>
			<S sid ="486" ssid = "486">“Katrina” would be surrounded by “headed” as in “Katrina headed North”.</S>
			<S sid ="487" ssid = "487">In another document about the tsunami that ravaged Myanmar, “Myanmar” also is found near “was hit”.</S>
			<S sid ="488" ssid = "488">“Tsunami” contains the context “headed” as well.</S>
			<S sid ="489" ssid = "489">These two pairs of entities would be clustered near each other, indicating the same basic relation.</S>
			<S sid ="490" ssid = "490">Although this clustering approach was not taken in the current research, Shinyama and Sekine [34] is interesting because it looks at a document as a whole.</S>
			<S sid ="491" ssid = "491">Most systems rely on the information contained in one sentence.</S>
			<S sid ="492" ssid = "492">It has the possibility to extract information other systems miss. Unsupervised methods are still cutting-edge.</S>
			<S sid ="493" ssid = "493">They do not perform as well as supervised methods.</S>
			<S sid ="494" ssid = "494">However, there is much promise that they will be able to recognize patterns and relations that humans cannot.</S>
			<SUBSECTION>2.5.4 Semi-supervised methods Semi-supervised methods usually involve applying machine learning to a set of seed values.</SUBSECTION>
			<S sid ="495" ssid = "495">These values are a handful of examples, as opposed to an exhaustively tagged document set.</S>
			<S sid ="496" ssid = "496">These examples are then used with an untagged document set to train the machine learning classifier.</S>
			<S sid ="497" ssid = "497">Very often, the classifier is then applied to the documents to extract more values.</S>
			<S sid ="498" ssid = "498">These values are added to the seed set, and the algorithm is iterated.</S>
			<S sid ="499" ssid = "499">By doing this, the seed set “grows” to a large enough size to achieve a high recall.</S>
			<S sid ="500" ssid = "500">If the seeds are chosen well, high precision is possible as well.</S>
			<S sid ="501" ssid = "501">The advantage of this approach is that only a few examples are needed from a human.</S>
			<S sid ="502" ssid = "502">The training document set can be as large as one wants—no extra human input is required.</S>
			<S sid ="503" ssid = "503">It has the advantage of generalizing well to many different domains.</S>
			<S sid ="504" ssid = "504">A domain is defined by its examples.</S>
			<S sid ="505" ssid = "505">But it also avoids the disadvantage of unsupervised methods in that the categories are defined by the person giving the examples.</S>
			<S sid ="506" ssid = "506">Riloff [33] develops a system that extracts relations from text.</S>
			<S sid ="507" ssid = "507">It requires only texts classified as relevant or irrelevant to the domain.</S>
			<S sid ="508" ssid = "508">Bob is tasked with identifying sentences that specify a particular relation among the entities in the sentence.</S>
			<S sid ="509" ssid = "509">At his disposal, Bob has a set of documents that he knows are relevant to the relation at hand.</S>
			<S sid ="510" ssid = "510">The solution is simple.</S>
			<S sid ="511" ssid = "511">Every potential entity is extracted from the document, including the surrounding text.</S>
			<S sid ="512" ssid = "512">That text is made into a pattern.</S>
			<S sid ="513" ssid = "513">The patterns are then evaluated: they are rated as the ratio of the number of times that pattern occurs in a relevant document over how many times it occurs in any document.</S>
			<S sid ="514" ssid = "514">A confidence metric is then calculated from the matching patterns.</S>
			<S sid ="515" ssid = "515">Entries with high confidence are considered relevant.</S>
			<S sid ="516" ssid = "516">The system generates thousands of patterns, so only the highest ranked patterns are maintained.</S>
			<S sid ="517" ssid = "517">This technique is interesting because it does not require the same amount of work a supervised system would need.</S>
			<S sid ="518" ssid = "518">Instead, one only needs to indicate which documents are relevant to the domain.</S>
			<S sid ="519" ssid = "519">However, the task of classifying and reclassifying documents for each domain would become tedious.</S>
			<S sid ="520" ssid = "520">Brin [3] describes a program that uses the scale of the World Wide Web to extract information.</S>
			<S sid ="521" ssid = "521">Bob is asked to find other pairs of entities that are in the same relation as a few examples.</S>
			<S sid ="522" ssid = "522">He can only use the text of the books in the library for his search.</S>
			<S sid ="523" ssid = "523">The solution the author proposes is to search for the examples in the books and record the interleaving text between them.</S>
			<S sid ="524" ssid = "524">Then, that interleaving text is searched for in the books.</S>
			<S sid ="525" ssid = "525">The words on either end of the text (beginning and end) are assumed to be correct values.</S>
			<S sid ="526" ssid = "526">They are added to the seed set and the system iterates.</S>
			<S sid ="527" ssid = "527">There were several design decisions in this system.</S>
			<S sid ="528" ssid = "528">The first was that it was unimportant to have a high recall since the scale of the Internet made even a poor recall system return many thousands of values.</S>
			<S sid ="529" ssid = "529">Secondly, the precision was of utmost importance since bad seeds could cause the entire set to become polluted with more bad seeds.</S>
			<S sid ="530" ssid = "530">The system therefore made no attempt at generalizing the patterns—it relied only on the scale of the Web to generate enough values.</S>
			<S sid ="531" ssid = "531">Unfortunately, this system had no automated method for making sure few bad seeds got into the seed set.</S>
			<S sid ="532" ssid = "532">A manual “cleaning” stage was necessary to avoid very bad values.</S>
			<S sid ="533" ssid = "533">Agichtein and Gravano [1] introduces a system called SnowBall.</S>
			<S sid ="534" ssid = "534">It follows the basic semi-supervised model outlined above.</S>
			<S sid ="535" ssid = "535">Given a few seed values and a set of training documents, the system develops a set of patterns.</S>
			<S sid ="536" ssid = "536">The patterns match using an information retrieval algorithm.</S>
			<S sid ="537" ssid = "537">Specifically, it uses a method commonly used to compare documents.</S>
			<S sid ="538" ssid = "538">The pattern is a weighted bag of words of all the words occurring around the two entities in a sentence.</S>
			<S sid ="539" ssid = "539">The number of common words is summed up, weighted by the weight of each word.</S>
			<S sid ="540" ssid = "540">This lets a score be calculated for how related a pattern is to a piece of text.</S>
			<S sid ="541" ssid = "541">An implied negative set is created.</S>
			<S sid ="542" ssid = "542">The domain is assumed to be “many-to-one” or “one-to-one”.</S>
			<S sid ="543" ssid = "543">For instance, the concept of which country is in which continent is many-to-one.</S>
			<S sid ="544" ssid = "544">A country can only be in one continent and many countries are in a continent.</S>
			<S sid ="545" ssid = "545">The idea of capital cities is often one-to-one.</S>
			<S sid ="546" ssid = "546">A capital belongs to one country, and the country belongs to one capital.</S>
			<S sid ="547" ssid = "547">Because there is an assumed unique component (the country in the country-continent relation above), a negative set is created.</S>
			<S sid ="548" ssid = "548">For instance, if “Paris is the capital of France” is a known value, it is implied that no other city is the capital of France.</S>
			<S sid ="549" ssid = "549">This allows the seed set to be much larger than what the user enters by hand.</S>
			<S sid ="550" ssid = "550">The patterns are rated by how many positive and negative seeds they match in the text.</S>
			<S sid ="551" ssid = "551">This rating is called the confidence.</S>
			<S sid ="552" ssid = "552">Patterns with high confidence match a high proportion of positive seeds and a low proportion of negative seeds.</S>
			<S sid ="553" ssid = "553">New values are generated by these patterns from the documents.</S>
			<S sid ="554" ssid = "554">The values are rated based on the confidence of the patterns that match them.</S>
			<S sid ="555" ssid = "555">The highest rated values are then fed back into the seed set and the entire algorithm is iterated.</S>
			<S sid ="556" ssid = "556">The algorithm showed good results.</S>
			<S sid ="557" ssid = "557">There are several disadvantages to this approach, though.</S>
			<S sid ="558" ssid = "558">Firstly, it assumes that a negative set can be created.</S>
			<S sid ="559" ssid = "559">This is not true in domains that are “many-to-many”.</S>
			<S sid ="560" ssid = "560">Many- to-many domains do not have, in general, any easily calculable negative set.</S>
			<S sid ="561" ssid = "561">The range of many-to-many domains is very large.</S>
			<S sid ="562" ssid = "562">Imagine the domain of what countries are allied together.</S>
			<S sid ="563" ssid = "563">Secondly, the algorithm relies on a Named Entity Recognition step.</S>
			<S sid ="564" ssid = "564">While the authors claim that they have used a very reliable and accurate NER system, the problem still remains of training that system.</S>
			<S sid ="565" ssid = "565">The system they use categorizes entities into three broad categories: LOCATION, ORGANIZATION, and PERSON.</S>
			<S sid ="566" ssid = "566">The paper also claims that its system can be trained for other categories.</S>
			<S sid ="567" ssid = "567">However, one of the main advantages of a semi-supervised model is the need for very little human input during training.</S>
			<S sid ="568" ssid = "568">If the NER system needs to be trained for every domain, then the advantage is lost.</S>
			<S sid ="569" ssid = "569">SnowBall does present interesting ideas.</S>
			<S sid ="570" ssid = "570">First of all, it combines the results of multiple patterns over many sentences.</S>
			<S sid ="571" ssid = "571">It relies on the idea of data redundancy in multiple documents to achieve higher accuracy.</S>
			<S sid ="572" ssid = "572">Secondly, it presents a very clear bootstrapping technique.</S>
			<S sid ="573" ssid = "573">Both of these ideas are essential to the current work.</S>
			<S sid ="574" ssid = "574">Agichtein et al. [2] improves on the SnowBall system.</S>
			<S sid ="575" ssid = "575">It changes the pattern matching algorithm.</S>
			<S sid ="576" ssid = "576">The original SnowBall system worked on a bag-of-words model of the words surrounding the entities.</S>
			<S sid ="577" ssid = "577">The improvement is to take word order into account in the pattern matcher.</S>
			<S sid ="578" ssid = "578">The results of the two systems are then combined to achieve better performance.</S>
			<S sid ="579" ssid = "579">The interesting part of this is that SnowBall gives a framework to work in: the system only changed in one part—the pattern matching algorithm.</S>
			<S sid ="580" ssid = "580">This shows that the overall bootstrapping algorithm is sound and extensible.</S>
			<S sid ="581" ssid = "581">Culotta and McCallum [9] creates a system to apply active learning techniques to the semi-supervised approach.</S>
			<S sid ="582" ssid = "582">It takes the normal active learning approach of choosing the most important unknown values to classify.</S>
			<S sid ="583" ssid = "583">However, it also weighs into the ranking a measure of the difficulty of classification.</S>
			<S sid ="584" ssid = "584">This allows the system to more effectively reduce the human input necessary to achieve a desired level of precision.</S>
			<S sid ="585" ssid = "585">Mann and Yarowsky [28] combines three different classifiers to match patterns.</S>
			<S sid ="586" ssid = "586">It uses a Rote system (basic string pattern matching), Naive Bayes (bag of words), and a Conditional Random Field.</S>
			<S sid ="587" ssid = "587">Combining the results of all of them (using a voting system) increased the accuracy significantly compared to using only one.</S>
			<S sid ="588" ssid = "588">The system bootstraps not only the seed set but also the document set.</S>
			<S sid ="589" ssid = "589">After generating the patterns from a small corpus of tagged documents, it performs a web search of the seed values.</S>
			<S sid ="590" ssid = "590">The resulting documents are then used to test the patterns and generate new values.</S>
			<S sid ="591" ssid = "591">Stevenson and Greenwood [36] presents an interesting approach.</S>
			<S sid ="592" ssid = "592">It follows the basic bootstrapping method described above.</S>
			<S sid ="593" ssid = "593">However, instead of adding new values to the seed set, it adds new patterns to a pattern set.</S>
			<S sid ="594" ssid = "594">It compares the patterns “semantically” to existing, reliable patterns.</S>
			<S sid ="595" ssid = "595">The patterns are compared based on Wordnet categories.</S>
			<S sid ="596" ssid = "596">Pennacchiotti and Pantel [32] describes a system called Espresso.</S>
			<S sid ="597" ssid = "597">The system differs from the standard bootstrapping algorithm by an adaptation to insufficient data.</S>
			<S sid ="598" ssid = "598">In small document sets, it queries the web to expand the number of documents available.</S>
			<S sid ="599" ssid = "599">It also develops metrics for evaluating a patterns and the generated values.</S>
			<S sid ="600" ssid = "600">These are helpful for filtering the seed set and pattern dictionary.</S>
			<S sid ="601" ssid = "601">Pantel and Pennacchiotti [31] extends Espresso by treating patterns with high recall differently from patterns with high precision.</S>
			<S sid ="602" ssid = "602">Their results are combined differently, giving patterns with high precision the role of evaluating the high-recall patterns.</S>
			<S sid ="603" ssid = "603">This allows for a higher recall with a small loss in precision.</S>
			<S sid ="604" ssid = "604">Suchanek et al. [37] builds a system called LEILA.</S>
			<S sid ="605" ssid = "605">LEILA parses sentences using a link grammar.</S>
			<S sid ="606" ssid = "606">A link grammar builds links between pairs of words, similar to a dependency graph.</S>
			<S sid ="607" ssid = "607">The resulting graph can be traversed as a sequence of words (nodes).</S>
			<S sid ="608" ssid = "608">The patterns LEILA generates use the path between the two entities in the binary relation.</S>
			<S sid ="609" ssid = "609">LEILA is restricted to binary relations.</S>
			<S sid ="610" ssid = "610">LEILA generates a set of patterns from a seed set of values and an untagged document set.</S>
			<S sid ="611" ssid = "611">Patterns are then used to generate values.</S>
			<S sid ="612" ssid = "612">Any patterns that produce values that are in the negative seed set are discarded.</S>
			<S sid ="613" ssid = "613">The remaining patterns are fed to a classifier, which is trained to identify good patterns.</S>
			<S sid ="614" ssid = "614">This system avoids the problem of feature explosion.</S>
			<S sid ="615" ssid = "615">Since it trains a classifier to identify good patterns, it does not need to compare each sentence with hundreds of generated patterns.</S>
			<S sid ="616" ssid = "616">It is different from other approaches which aim to train a classifier with interleaving text ([4, 10]) in that it first filters the interleaving text to make sure it does not generate known negative values.</S>
			<S sid ="617" ssid = "617">Turney [39] describes a novel approach to relation extraction.</S>
			<S sid ="618" ssid = "618">The system, at heart, operates like this: given two pairs of entities and a document set, the system discovers all of the intervening text between the pairs in the documents.</S>
			<S sid ="619" ssid = "619">The system finds the pattern that is shared the most between them.</S>
			<S sid ="620" ssid = "620">The idea is that what is important is what common relation they share.</S>
			<S sid ="621" ssid = "621">The system answers analogy problems like those on the SAT.</S>
			<S sid ="622" ssid = "622">The approach is novel because it takes the opposite approach to what is commonly taken.</S>
			<S sid ="623" ssid = "623">Instead of looking for a pattern that will extract a value from a sentence, it compares the patterns generated by two values.</S>
			<S sid ="624" ssid = "624">In other words, the system asks the question “what is the relationship between the relationship of these values?” For small domains (such as multiple choice analogy problems), this approach has a lot of merit.</S>
			<S sid ="625" ssid = "625">Many questions could be formulated in this way.</S>
			<S sid ="626" ssid = "626">For instance “Is Paris the capital of France?” could be formulated as “Does Paris have the same relation to France as Berlin has to Germany’ ?”.</S>
			<S sid ="627" ssid = "627">Pa pe r Tr ai ni ng M et ho d De pt h of Pa rsi ng M ac hi ne Le ar ni ng Te ch ni qu e Fu nd el et al. [1 7] Ha nd Wr itt en De ep Ex ac t M at chi ng Da ras eli a et al. [1 1] Ha nd Wr itt en De ep Ex ac t M at chi ng Hu ff m an [2 3] Su pe rvi se d De ep Ge ne ral iza tio n Ca liff an d M oo ne y [6] Su pe rvi se d No ne Ge ne ral iza tio n So de rla nd [3 5] Su pe rvi se d No ne Ge ne ral iza tio n Bu ne sc u an d M oo ne y [4] Su pe rvi se d De ep Su pp ort Ve ct or M ac hi ne Bu ne sc u an d M oo ne y [5] Su pe rvi se d No ne Su pp ort Ve ct or M ac hi ne C ul ott a an d So re ns en [1 0] Su pe rvi se d De ep Su pp ort Ve ct or M ac hi ne Jie an d Mi n [2 4] Su pe rvi se d No un ph ras e Ch un kin g Su pp ort Ve ct or M ac hi ne Li u et al. [2 6] Su pe rvi se d De ep Su pp ort Ve ct or M ac hi ne C ul ott a et al. [8] Su pe rvi se d No ne Co nd iti on al Ra nd o m Fi eld Xi ao et al. [4 1] Su pe rvi se d De ep M axi m u m En tro py Ril off [3 3] Se mi su pe rvi se d Pa rt of Sp ee ch Ba ye sia n Co m bi na tio n Bri n [3] Se mi su pe rvi se d No ne Ex ac t M at chi ng Ag ich tei n an d Gr av an o [1] Se mi su pe rvi se d Na m ed Entity Re co gn iti on Inf or m ati on Retrieval and Ba ye sia n Co m bi na tio n C ul ott a an d M cC all u m [9] Se mi su pe rvi se d No ne Co nd iti on al Ra nd o m Fi eld M an n an d Ya ro ws ky [2 8] Se mi su pe rvi se d No ne Ex ac t, Na ive Ba ye s, an d Con dit io na l Ra nd o m Fi eld St ev en so n an d Gr ee nw oo d [3 6] Se mi su pe rvi se d No ne Inf or m ati on Re tri ev al Pe nn ac chi ott i an d Pa nt el [3 2] Se mi su pe rvi se d Pa rt of Sp ee ch Ba ye sia n Co m bi na tio n Su ch an ek et al. [3 7] Se mi su pe rvi se d De epk Ne ar est Ne ig hb or an d Sup po rt Ve ct or M ac hi ne Tu rn ey [3 9] Se mi su pe rvi se d No nek Ne ar est Ne ig hb or Et zio ni et al. [1 5] Un su pe rvi se d Sh all ow Ex ac t M at chi ng Ha se ga wa et al. [2 1] Un su pe rvi se d Sh all ow Cl us ter in g Figure 2.4: The prior works broken down according to the three axes.</S>
			<S sid ="628" ssid = "628">Chapter 3 Approach This chapter deals with the problem of extracting text.</S>
			<S sid ="629" ssid = "629">The various decisions that have to be made will be explained.</S>
			<S sid ="630" ssid = "630">The reasoning behind each decision will be detailed.</S>
			<S sid ="631" ssid = "631">And a list of advantages and disadvantages will be made.</S>
			<S sid ="632" ssid = "632">The following are system requirements interpreted from practical usage requirements and the limitations of the systems presented in Chapter 2.</S>
			<S sid ="633" ssid = "633">1. Many specific kinds of relations need to be extracted.</S>
			<S sid ="634" ssid = "634">The relations could be unary, binary, or nary..</S>
			<S sid ="635" ssid = "635">The extraction framework cannot be limited to the order of the relation.</S>
			<S sid ="636" ssid = "636">2.</S>
			<S sid ="637" ssid = "637">The relations are often unbounded.</S>
			<S sid ="638" ssid = "638">This means that the size of the set of facts corresponding to that.</S>
			<S sid ="639" ssid = "639">relation is unknown by anyone.</S>
			<S sid ="640" ssid = "640">3.</S>
			<S sid ="641" ssid = "641">The relations will be used as specific fields in a database.</S>
			<S sid ="642" ssid = "642">They are therefore somewhat well-defined..</S>
			<S sid ="643" ssid = "643">They must match an actual concept that is trying to be captured.</S>
			<S sid ="644" ssid = "644">Precision is more important than recall since the extracted data will be inserted into a database to be used by other systems as known facts.</S>
			<S sid ="645" ssid = "645">4.</S>
			<S sid ="646" ssid = "646">The relations are not specified ahead of time.</S>
			<S sid ="647" ssid = "647">They need to be able to be added and modified by end.</S>
			<S sid ="648" ssid = "648">users.</S>
			<S sid ="649" ssid = "649">This implies that the human effort required to define a new relation is minimized.</S>
			<S sid ="650" ssid = "650">5.</S>
			<S sid ="651" ssid = "651">The domains of the relations (types of entities) are not specified ahead of time.</S>
			<S sid ="652" ssid = "652">New entity types may. be added later.</S>
			<S sid ="653" ssid = "653">No domain-specific knowledge can be defined in the algorithm.</S>
			<S sid ="654" ssid = "654">6.</S>
			<S sid ="655" ssid = "655">Large, untagged sets of documents are available..</S>
			<S sid ="656" ssid = "656">7.</S>
			<S sid ="657" ssid = "657">The choice of classifier should be unimportant to the functioning of the framework.</S>
			<S sid ="658" ssid = "658">New classification.</S>
			<S sid ="659" ssid = "659">techniques should be used as they become available.</S>
			<S sid ="660" ssid = "660">Research is going on into new data mining techniques at a fast rate.</S>
			<S sid ="661" ssid = "661">The system should be able to incorporate the new research.</S>
			<S sid ="662" ssid = "662">8.</S>
			<S sid ="663" ssid = "663">The type and level of parsing should not factor into the framework.</S>
			<S sid ="664" ssid = "664">They should be considered.</S>
			<S sid ="665" ssid = "665">implementation details.</S>
			<S sid ="666" ssid = "666">A review of the literature indicates contentious ideas involving the benefits of parsing [10, 24].</S>
			<S sid ="667" ssid = "667">The best practices in parsing have yet to be determined and are likely to change.</S>
			<S sid ="668" ssid = "668">3.1 The Three Major Axes.</S>
			<S sid ="669" ssid = "669">Each of the three axes described in Section 2 is a major decision point.</S>
			<S sid ="670" ssid = "670">These decisions must be made regardless of the problem formulation.</S>
			<S sid ="671" ssid = "671">Type of training will be analyzed first.</S>
			<S sid ="672" ssid = "672">Handwritten techniques allow for very well-defined domains 2.5.1.</S>
			<S sid ="673" ssid = "673">Any level of detail is available.</S>
			<S sid ="674" ssid = "674">It depends only on the amount of effort and time available.</S>
			<S sid ="675" ssid = "675">Handwritten techniques work well for untagged documents, since they do not require a statistical training stage.</S>
			<S sid ="676" ssid = "676">Handwritten methods, however, are largely disused in more recent works.</S>
			<S sid ="677" ssid = "677">This could be due to the fact that they are extremely time consuming.</S>
			<S sid ="678" ssid = "678">They do not extend well to new domains.</S>
			<S sid ="679" ssid = "679">Daraselia et al. [11] builds a large, handwritten ontology.</S>
			<S sid ="680" ssid = "680">This case is exceptional, however, since the perceived value of extracting very high-quality information exceeds the cost of generating the ontology.</S>
			<S sid ="681" ssid = "681">The domain of the ontology is very large.</S>
			<S sid ="682" ssid = "682">However, handwritten methods do not meet the requirements enumerated above.</S>
			<S sid ="683" ssid = "683">Handwritten methods do not minimize the amount of effort required to add new relations.</S>
			<S sid ="684" ssid = "684">They also require the domain to be known ahead of time.</S>
			<S sid ="685" ssid = "685">Supervised techniques have achieved very high Precision in the literature.</S>
			<S sid ="686" ssid = "686">This is their strong point.</S>
			<S sid ="687" ssid = "687">They allow for relations to be well-defined.</S>
			<S sid ="688" ssid = "688">They can take into account as much subtlety of meaning as can be encoded in the annotations of the documents.</S>
			<S sid ="689" ssid = "689">Supervised methods, by definition, require much human input, usually in the form of hand-tagged text.</S>
			<S sid ="690" ssid = "690">Either the domain of the relations must be known at the outset of training, or the text must be tagged anew for each domain.</S>
			<S sid ="691" ssid = "691">This, too, does not meet the system’s requirements.</S>
			<S sid ="692" ssid = "692">The tagging of documents requires experts in the domain.</S>
			<S sid ="693" ssid = "693">Those experts must also be trained to tag the documents consistently—which requires a different kind of expertise.</S>
			<S sid ="694" ssid = "694">Supervised methods are therefore ruled out because they require an excess of human input.</S>
			<S sid ="695" ssid = "695">Unsupervised methods do not require the human input of handwritten and supervised methods.</S>
			<S sid ="696" ssid = "696">They can adapt to new domains easily.</S>
			<S sid ="697" ssid = "697">However, unsupervised methods cannot be relied on to create categories of relations that correspond to a specific category in a database.</S>
			<S sid ="698" ssid = "698">This works for new domain discovery, but not for extracting a specific kind of information, such as in response to a query from the user.</S>
			<S sid ="699" ssid = "699">Unsupervised methods will not meet the requirements.</S>
			<S sid ="700" ssid = "700">Semi-supervised methods strike a compromise between supervised and unsupervised methods.</S>
			<S sid ="701" ssid = "701">They require domain knowledge.</S>
			<S sid ="702" ssid = "702">However, the required amount and precision of the domain knowledge is very low.</S>
			<S sid ="703" ssid = "703">Often the required human input is trivial.</S>
			<S sid ="704" ssid = "704">Semi-supervised approaches rely on labeled examples and a large set of unlabeled points [14].</S>
			<S sid ="705" ssid = "705">The examples are very natural for humans to provide and large document sets are free on the Internet.</S>
			<S sid ="706" ssid = "706">They allow users to tell the system “give me more facts like these”.</S>
			<S sid ="707" ssid = "707">By providing examples, the user is also defining a well-understood concept.</S>
			<S sid ="708" ssid = "708">The facts extracted can thus be placed into a database.</S>
			<S sid ="709" ssid = "709">Because the human input is minimal, adding new relations is trivial.</S>
			<S sid ="710" ssid = "710">A semi-supervised technique has been chosen as the best way to achieve the stated goals for the system.</S>
			<S sid ="711" ssid = "711">The next decision is level of parsing.</S>
			<S sid ="712" ssid = "712">As stated in section 1.3, parsing can range from deep parsing (full syntax or dependency tree) to part of speech (POS) tagging to no parsing at all.</S>
			<S sid ="713" ssid = "713">There are disadvantages to deep parsing.</S>
			<S sid ="714" ssid = "714">Besides the cost of parsing, there is a dependence on the parser.</S>
			<S sid ="715" ssid = "715">Every parser is different, with differing strengths and advantages.</S>
			<S sid ="716" ssid = "716">The parser used is usually trained from a corpus.</S>
			<S sid ="717" ssid = "717">The most common corpus is the Penn TreeBank [29], that has a large set of sentences with their corresponding parse trees.</S>
			<S sid ="718" ssid = "718">The training parse trees were hand-generated by expert grammarians.</S>
			<S sid ="719" ssid = "719">The information gained by deep parsing seems to subsume all of the other levels of parsing.</S>
			<S sid ="720" ssid = "720">It contains information that is highly correlated to Part Of Speech tagging and noun phrase chunking [18].</S>
			<S sid ="721" ssid = "721">The question therefore is one of cost versus benefit.</S>
			<S sid ="722" ssid = "722">It is assumed in Jie and Min [24] that by throwing more data at the problem, deep parsing is unnecessary.</S>
			<S sid ="723" ssid = "723">That is, as the number of training points goes to infinity, the difference in accuracy between a deep-parse solution and a no-parse solution goes to 0.</S>
			<S sid ="724" ssid = "724">That being said, there is not infinite data.</S>
			<S sid ="725" ssid = "725">In fact, at the low number of points (around a few thousand), there is in fact a large benefit from having a fully parsed solution.</S>
			<S sid ="726" ssid = "726">Parsing is a relatively expensive operation.</S>
			<S sid ="727" ssid = "727">Depending on the parser, a sentence could take up to 3 seconds to parse.</S>
			<S sid ="728" ssid = "728">This is not trivial, especially when considering the sheer number of sentences needed for statistical classification methods.</S>
			<S sid ="729" ssid = "729">However, there are several mitigating factors: 1.</S>
			<S sid ="730" ssid = "730">Parallel.</S>
			<S sid ="731" ssid = "731">Each sentence can be parsed independently of the others.</S>
			<S sid ="732" ssid = "732">This allows for massive parallelization of the parsing operation.</S>
	</SECTION>
	<SECTION title="Cacheable. " number = "2">
			<S sid ="733" ssid = "1">For a deterministic parser, the parse for a sentence will always be the same.</S>
			<S sid ="734" ssid = "2">This means that a given sentence will only need to be parsed once—no matter how many classifiers it passes through.</S>
	</SECTION>
	<SECTION title="Easily Filtered. " number = "3">
			<S sid ="735" ssid = "1">A simple dynamic programming optimization can be performed.</S>
			<S sid ="736" ssid = "2">An O(n) scan of the sentence can determine if the sentence is worth parsing.</S>
			<S sid ="737" ssid = "3">If no value for the particular query one is looking for can be extracted from the sentence, it is not worth parsing.</S>
			<S sid ="738" ssid = "4">Given these three properties of the system, deep parsing is the best option.</S>
			<S sid ="739" ssid = "5">Culotta and Sorensen [10] and Bunescu and Mooney [4] indicate that the dependency tree is the most fruitful form of parsing.</S>
			<S sid ="740" ssid = "6">The framework of the current system does not rely on the level of parsing.</S>
			<S sid ="741" ssid = "7">The system is defined in a general sense.</S>
			<S sid ="742" ssid = "8">It is perhaps not necessary to perform any parsing at all.</S>
			<S sid ="743" ssid = "9">The evaluation of the usefulness of parsing is left as a subject of future research.</S>
			<S sid ="744" ssid = "10">The final decision that must be made is the type of classifier used.</S>
			<S sid ="745" ssid = "11">Since one of the stated requirements is that the system does not depend on any one specific kind of classifier, it is necessary to model the problem in a way that can be classified by a large set of classifiers.</S>
			<S sid ="746" ssid = "12">The Icelandic Library will serve as a metaphor for presenting a clear description of the problem.</S>
			<S sid ="747" ssid = "13">Bob is in the Icelandic Library, but he is alone.</S>
			<S sid ="748" ssid = "14">He is given a sheet of paper.</S>
			<S sid ="749" ssid = "15">On the left side of the paper, in a column, one word per line, are many Icelandic words.</S>
			<S sid ="750" ssid = "16">The person does not understand them.</S>
			<S sid ="751" ssid = "17">On the right side, there is another list of words, one word per line, in Icelandic.</S>
			<S sid ="752" ssid = "18">The words appear as no more than a cryptic sequence of characters.</S>
			<S sid ="753" ssid = "19">There are lines connecting each of the first five words on the left to words on the right.</S>
			<S sid ="754" ssid = "20">No pattern is discernible.</S>
			<S sid ="755" ssid = "21">One line leaves from every word on the left.</S>
			<S sid ="756" ssid = "22">Some words on the right have two lines connecting to them.</S>
			<S sid ="757" ssid = "23">Some words on the left have two lines connecting to them.</S>
			<S sid ="758" ssid = "24">The lines are examples that are to be used in the task.</S>
			<S sid ="759" ssid = "25">See Figure 3.1.</S>
			<S sid ="760" ssid = "26">The task is to draw lines from the remaining words on the left to the appropriate word on the right, based on the same relationship given in the lines already on the page.</S>
			<S sid ="761" ssid = "27">Any and all of the books in the library can be used.</S>
			<S sid ="762" ssid = "28">This paper proposes that Bob proceeds as follows.</S>
			<S sid ="763" ssid = "29">Bob picks a pair of words connected by lines.</S>
			<S sid ="764" ssid = "30">He searches through all of the books in the library, looking for sentences that contain that pair of words.</S>
			<S sid ="765" ssid = "31">He notes the shortest path on the dependency tree of the sentence in a notebook.</S>
			<S sid ="766" ssid = "32">He does this for each of the example pairs.</S>
			<S sid ="767" ssid = "33">He then searches through the books again, this time looking for sentences that match those patterns and who also have pairs of words from the sheet of paper.</S>
			<S sid ="768" ssid = "34">He notes which patterns matched each pair.</S>
			<S sid ="769" ssid = "35">This information can then be used to determine which lines to draw.</S>
			<S sid ="770" ssid = "36">How this information is used makes the current research novel.</S>
			<S sid ="771" ssid = "37">This model is very similar to that used in the semi-supervised methods in [1, 3, 28, 31–33, 36, 37].</S>
			<S sid ="772" ssid = "38">However, it differs in that the system does not look at one small portion of text at a time.</S>
			<S sid ="773" ssid = "39">It attempts to model the information contained in the entire document set.</S>
			<S sid ="774" ssid = "40">The current research proposes that a feature vector be constructed for each candidate fact to be extracted.</S>
			<S sid ="775" ssid = "41">Each feature in the feature vector will represent a single pattern matching at least one sentence from the document set.</S>
			<S sid ="776" ssid = "42">Each pattern represents a syntactic-lexical feature of the entities.</S>
			<S sid ="777" ssid = "43">The classifier is used to determine a relationship between those syntactic-lexical features and semantic meaning.</S>
			<S sid ="778" ssid = "44">The system will use the standard bootstrapping method to iteratively build a set of values from a small initial set of examples.</S>
			<S sid ="779" ssid = "45">The approach is described more rigorously in Chapter 4.</S>
			<S sid ="780" ssid = "46">Figure 3.1: A query task definition given to Bob in the Icelandic library.</S>
			<S sid ="781" ssid = "47">The task is to connect the remaining words on the left with the words on the right in the same way as the examples.</S>
			<S sid ="782" ssid = "48">3.2 Comments on the Approach.</S>
			<S sid ="783" ssid = "49">3.2.1 Choice of classifier The choice of classifier ranges over many possibilities.</S>
			<S sid ="784" ssid = "50">In this report, Naive Bayes and Support Vector machines are evaluated.</S>
			<S sid ="785" ssid = "51">However, most classifiers can be trained on vectors of numeric features.</S>
			<S sid ="786" ssid = "52">The framework, therefore, remains general.</S>
			<S sid ="787" ssid = "53">The Bayesian approach has some advantages (despite requiring some very strong assumptions).</S>
			<S sid ="788" ssid = "54">First, Bayesian prediction does not require 100% knowledge.</S>
			<S sid ="789" ssid = "55">Bayesian prediction works on estimates of the various parameters in Bayes’ formula.</S>
			<S sid ="790" ssid = "56">These estimates can be made with incomplete knowledge (see section 5.3).</S>
			<S sid ="791" ssid = "57">The second reason the Bayesian approach was chosen was that it accumulates.</S>
			<S sid ="792" ssid = "58">Adding a new training data point is a constant-time operation, as is reclassifying a point after a new training point is added.</S>
			<S sid ="793" ssid = "59">It is quite simple to formulate a Bayesian classifier that operates over long periods of time.</S>
			<S sid ="794" ssid = "60">As more documents are read containing the information to extract, the estimate of the probability of class membership becomes more accurate.</S>
			<S sid ="795" ssid = "61">This is important in long-running databases, and in cases where the relation can change over time.</S>
			<S sid ="796" ssid = "62">Support Vector Machines have a high tolerance for noise and show strong resilience when facing complex feature vectors.</S>
			<S sid ="797" ssid = "63">Support Vector Machines are expected to perform very well [38].</S>
			<S sid ="798" ssid = "64">Figure 3.2: The result of Bob completing the task.</S>
			<S sid ="799" ssid = "65">Dotted lines are those drawn by Bob.</S>
			<S sid ="800" ssid = "66">The three principle decisions have been made: Semi-supervised learning using dependency graph and a statistical classifier (Naive Bayes and Support Vector Machine).</S>
			<S sid ="801" ssid = "67">3.2.2 Use of domain knowledge No domain knowledge is needed by the system besides what is given in the query.</S>
			<S sid ="802" ssid = "68">The possible entities in the relationships are those listed on the page (in the metaphor).</S>
			<S sid ="803" ssid = "69">This is in contrast to most other research which use a Named Entity Recognition system that is previously trained with domain knowledge, a static list of possible entities (in the case of protein-protein interaction papers), or no system at all to limit the types of entities returned.</S>
			<S sid ="804" ssid = "70">The advantage of specifying the domain completely (as in the current system) are many.</S>
			<S sid ="805" ssid = "71">The first advantage is that the query limits the search space to a large degree—leading to more refined results than those returned by systems that do not limit the space.</S>
			<S sid ="806" ssid = "72">The second advantage is that the domains are easily specified and are usually specified already in database form.</S>
			<S sid ="807" ssid = "73">Many organizations already have a database of the kinds of information that is important to them.</S>
			<S sid ="808" ssid = "74">These databases can be reused in the queries.</S>
			<S sid ="809" ssid = "75">Also, if the information is to be added to a database anyway, the lists of entities in the domain probably already exist.</S>
			<S sid ="810" ssid = "76">The drawback to the system is that it must be specified completely by a human.</S>
			<S sid ="811" ssid = "77">The Named Entity Recognition systems in use today primarily use machine learning to identify entities that were not conceived of by a human.</S>
			<S sid ="812" ssid = "78">However, those machine learning techniques require much more human input than a complete specification of the domain.</S>
			<S sid ="813" ssid = "79">The current approach is a balance between the human input and expressive power.</S>
			<S sid ="814" ssid = "80">3.2.3 Linguistic pitfalls Many linguistic pitfalls exist, including ambiguous names and the idea of negation.</S>
			<S sid ="815" ssid = "81">Ambiguous names exist—for instance “Paris” names a city in France and a city in Texas.</S>
			<S sid ="816" ssid = "82">This phenomenon is not resolved in the current work.</S>
			<S sid ="817" ssid = "83">It is assumed that the structure of the query will, on statistical average, eliminate the ambiguity.</S>
			<S sid ="818" ssid = "84">For instance, if one wants to identify the capital cities of countries, it is unlikely that a sentence talking about Paris, Texas will also talk about a country in the same way a sentence will talk about Paris, France.</S>
			<S sid ="819" ssid = "85">Negation is also not addressed.</S>
			<S sid ="820" ssid = "86">Negation is a problem because a sentence that says “Paris is the capital of France” differs from a sentence that says “ Paris is not the capital of France” by one word.</S>
			<S sid ="821" ssid = "87">But that one word makes the whole sentence mean exactly the opposite of what one would think it would mean based on similarity of the sentences.</S>
			<S sid ="822" ssid = "88">This problem is usually dealt with either by throwing out negative sentences [17] or by including negation as a feature in the patterns [4].</S>
			<S sid ="823" ssid = "89">The reason for neglecting negation is that it was desired to minimize the complexity of the model.</S>
			<S sid ="824" ssid = "90">Evaluating the importance of dealing with the negation problem is outside of the scope of the current research.</S>
			<S sid ="825" ssid = "91">Pronouns and anaphoric phrases are not attempted to be resolved.</S>
			<S sid ="826" ssid = "92">The low accuracy of the current coreference resolution solutions does not indicate that they would add value to the system.</S>
			<S sid ="827" ssid = "93">No context is taken into account.</S>
			<S sid ="828" ssid = "94">Each pattern matches individual sentences, with no accounting for ideas that surround the sentence in the text.</S>
			<S sid ="829" ssid = "95">It is hypothesized that this identifying context is not strictly necessary, though simple models of context might make for fruitful future work.</S>
			<S sid ="830" ssid = "96">Chapter 4 Formal Methods This chapter presents a formalized model of the problem.</S>
			<S sid ="831" ssid = "97">It is this model that will form the framework for actually developing a solution.</S>
			<S sid ="832" ssid = "98">The definitions in this section will be referred to in later sections.</S>
			<SUBSECTION>4.1 Definitions.</SUBSECTION>
			<SUBSECTION>4.1.1 Tuples Data must be represented in a structured way in the computer.</SUBSECTION>
			<S sid ="833" ssid = "99">This section therefore defines a flexible data structure that will be used for the known information and for the unknown information that is to be extracted.</S>
			<S sid ="834" ssid = "100">A tuple is defined as an ordered series of strings of characters.</S>
			<S sid ="835" ssid = "101">The choice of character set is arbitrary to the algorithm and should be chosen to accord with the data being analyzed.</S>
			<S sid ="836" ssid = "102">tk ≡ tk1 , tk2 , · · · , tkn (4.1) Tuples represent relational data.</S>
			<S sid ="837" ssid = "103">That is, the strings in the tuple are in some relationship to each other by the very act of being together in a tuple.</S>
			<S sid ="838" ssid = "104">The relationship might not be what is being looked for, or it could be exactly what is being looked for.</S>
			<S sid ="839" ssid = "105">The strings that make up the tuples each themselves represent the name of something.</S>
			<S sid ="840" ssid = "106">Resolving exactly what each name refers to is its own research project.</S>
			<S sid ="841" ssid = "107">The problem will not be addressed here.</S>
			<S sid ="842" ssid = "108">For instance, the system treats the string “Paris” which in one sentence refers to the capital of France as equivalent to the string “Paris” that refers to the city in Texas.</S>
			<S sid ="843" ssid = "109">They are treated equivalently because there is no simple way to disambiguate their meaning.</S>
			<S sid ="844" ssid = "110">It is hypothesized—and later confirmed (see section 5)—that on average, the system performs well even under that kind of ambiguity.</S>
			<S sid ="845" ssid = "111">It must be stressed that tuples can contain ambiguity.</S>
			<S sid ="846" ssid = "112">The following is an example: 1.</S>
			<S sid ="847" ssid = "113">President Bush flew from Paris to his ranch in Texas..</S>
			<S sid ="848" ssid = "114">2.</S>
			<S sid ="849" ssid = "115">A flash flood struck the city of Paris, Texas early Friday morning.</S>
			<S sid ="850" ssid = "116">The tuple P aris, T exas can be extracted from each of these sentences.</S>
			<S sid ="851" ssid = "117">Though the meaning of each is different, the system has no privilege to such knowledge.</S>
			<S sid ="852" ssid = "118">They are considered the same tuple.</S>
			<S sid ="853" ssid = "119">The basic unit of data is now defined.</S>
			<S sid ="854" ssid = "120">The tuple will be the input to queries.</S>
			<S sid ="855" ssid = "121">It will also be the output of queries.</S>
			<SUBSECTION>4.1.2 Classes The number of possible tuples makes it practically difficult to perform searches over all of them.</SUBSECTION>
			<S sid ="856" ssid = "122">A notion of classes is defined to help focus the search.</S>
			<S sid ="857" ssid = "123">Classes refer to the type of entity a string names.</S>
			<S sid ="858" ssid = "124">Classes are defined in a domain- and implementation-dependant way.</S>
			<S sid ="859" ssid = "125">If one wants to define a domain of geographic entities, one might classify strings into Country, City, Mountain, etc. Every string can belong to multiple classes.</S>
			<S sid ="860" ssid = "126">For instance, the string “France” refers to the country or to many cities by the same name around the world.</S>
			<S sid ="861" ssid = "127">It would therefore be a member of the class Country and the class City.</S>
			<S sid ="862" ssid = "128">We can refer to the set of classes of a string str as classstr . To formalize classes more concretely, we can define an inclusion function that is a predicate indicating whether a string belongs to the class.</S>
			<S sid ="863" ssid = "129">country(str) ≡ (true if str belongs to the class Country, f alse otherwise.</S>
			<S sid ="864" ssid = "130">(4.2) Similarly, one can define inclusion functions for Continent, City, River, etc. The inclusion functions can be implemented simply using a database lookup.</S>
			<S sid ="865" ssid = "131">Large databases of geographic names are available publicly.</S>
			<S sid ="866" ssid = "132">An inclusion function can return true if a string is contained in the database of countries.</S>
			<S sid ="867" ssid = "133">An alternative implementation is to use a regular expression.</S>
			<S sid ="868" ssid = "134">As with all concrete implementations, this implementation will inevitably miss some names—particularly colloquial names.</S>
			<S sid ="869" ssid = "135">The system relies again on the law of averages to mitigate the problem.</S>
			<S sid ="870" ssid = "136">One must take care to define the classes with knowledge of the kinds of information one is likely to find in the documents.</S>
			<S sid ="871" ssid = "137">For example, one could limit the definition of Continent to “North America”, “South America”, “Europe”, “Asia”, “Africa”, “Australia”, and “Antarctica”.</S>
			<S sid ="872" ssid = "138">However, the documents one is analyzing could use a different model of the continents.</S>
			<S sid ="873" ssid = "139">Many people do not differentiate North and South America as two separate continents, and so the continent of America is disregarded.</S>
			<S sid ="874" ssid = "140">Similar troubles occur with names such as “Eurasia” or “Oceania”.</S>
			<S sid ="875" ssid = "141">In order to allow multiple names for the same entity, an optional canonicalization function can be defined.</S>
			<S sid ="876" ssid = "142">The canonicalization function takes a string and returns the canonical name for the entity the input string names.</S>
			<S sid ="877" ssid = "143">Example: CanonicalizeCountry(str) ≡ F rance if str == “France”, F rance if str == “Republic of France”, F rance if str == “Republique Francaise”, (4.3)  etc . . .</S>
			<S sid ="878" ssid = "144">Similarly, one can define canonicalization functions for Continent, City, River, etc. Classes are used to limit the search of a query.</S>
			<S sid ="879" ssid = "145">There are far too many possible tuples (all possible pairs of words) to perform calculations on all of them.</S>
			<S sid ="880" ssid = "146">Limiting the query to focus on the kinds of information that is important is a necessary step.</S>
			<S sid ="881" ssid = "147">It is also desirable to limit the number of tuples the system looks at.</S>
			<SUBSECTION>4.1.3 Types The system limits the focus of its search to strings that fall within a given class.</SUBSECTION>
			<S sid ="882" ssid = "148">Even with this limit, there are still far too many tuples to process.</S>
			<S sid ="883" ssid = "149">It becomes important to define a limit on what tuples the system should process.</S>
			<S sid ="884" ssid = "150">Many of the queries that one would perform are the relations between known classes of entities.</S>
			<S sid ="885" ssid = "151">If one would like to know the capital cities of all of the countries, one is only interested in tuples that represent C ity, C ountry pairs.</S>
			<S sid ="886" ssid = "152">When the system is queried for the cities near bodies of water, one is interested in tuples that represent C ity, BodyOf W ater pairs.</S>
			<S sid ="887" ssid = "153">Types define the range of interest.</S>
			<S sid ="888" ssid = "154">A type is an ordered series of classes.</S>
			<S sid ="889" ssid = "155">T ≡ c1 , c2 , . . .</S>
			<S sid ="890" ssid = "156">, cn (4.4) A tuple belongs to a type if each string in the tuple belongs to the corresponding class in the type.</S>
			<S sid ="891" ssid = "157">For instance, the tuple F rance, Europe belongs to the type C ountry, C ontinent . Because of the way classes are defined above, the same tuple belongs to the type C ity, C ontinent (it is noted that “France” is also the name of many cities).</S>
			<S sid ="892" ssid = "158">One can refer to the set of tuples that belong to a type T as {T }.</S>
			<S sid ="893" ssid = "159">Types define the kinds of entities one is interested in.</S>
			<S sid ="894" ssid = "160">They inform the system of the classes of entities that could possibly fulfill the query.</S>
			<S sid ="895" ssid = "161">However, not all possible tuples of a given type represent data that one would like to extract.</S>
			<S sid ="896" ssid = "162">Not all C ity, C ountry pairs represent capital cities.</S>
			<S sid ="897" ssid = "163">It becomes necessary therefore to define even more precisely what relationship one is looking for.</S>
			<SUBSECTION>4.1.4 Relations Until now, all of the definitions have been precisely defined.</SUBSECTION>
			<S sid ="898" ssid = "164">They all lend themselves to concrete implementations.</S>
			<S sid ="899" ssid = "165">Even ambiguity was resolved by considering equivalent sequences of characters as equal.</S>
			<S sid ="900" ssid = "166">Now, however, a way of describing human concepts must be formalized.</S>
			<S sid ="901" ssid = "167">Most text is written by a person to communicate with another human.</S>
			<S sid ="902" ssid = "168">The concepts they use are fuzzy and imprecise.</S>
			<S sid ="903" ssid = "169">It is therefore important to define a way to allow for that imprecision.</S>
			<S sid ="904" ssid = "170">This definition must allow for the widest possible variety of concepts.</S>
			<S sid ="905" ssid = "171">As in most bootstrapping methods, the system represents those human concepts as a set of examples.</S>
			<S sid ="906" ssid = "172">The set of capital cities is represented by the set of C ity, C ountry pairs where the first element is the capital of the second element.</S>
			<S sid ="907" ssid = "173">The set can be complete, if all of the members of the set are known, or incomplete if only some are given.</S>
			<S sid ="908" ssid = "174">Relations (the set of examples) are how one defines what a query should search for.</S>
			<S sid ="909" ssid = "175">They are also the result of the query.</S>
			<S sid ="910" ssid = "176">The system tries to approximate a complete set as best it can from the documents available to it.</S>
			<S sid ="911" ssid = "177">A relation R is a set of tuples of a given type that define the same relationship between the elements of the tuple.</S>
			<S sid ="912" ssid = "178">A tuple can belong to more than one relation.</S>
			<S sid ="913" ssid = "179">M adrid, Spain belongs to the relation one might call “Capital Cities” and also to the relation “Cities in countries”.</S>
			<S sid ="914" ssid = "180">Shanghai, C hina would belong to the latter and not the former.</S>
			<S sid ="915" ssid = "181">The letter R will be used to refer to the complete set of tuples the user is querying for, whether they are known or not.</S>
			<S sid ="916" ssid = "182">The letter K is used for the subset of R that is known.</S>
			<SUBSECTION>4.1.5 Sentence Information Extraction requires unstructured text to extract information from.</SUBSECTION>
			<S sid ="917" ssid = "183">English and many other language break text up into sentences.</S>
			<S sid ="918" ssid = "184">The system will do the same, though it does not have to represent them as a simple series of words.</S>
			<S sid ="919" ssid = "185">Sentences need to be represented in a way that makes it convenient to search them.</S>
			<S sid ="920" ssid = "186">The specific implementation of sentences will be defined later, since there are many possible ways it can be done.</S>
			<S sid ="921" ssid = "187">It is possible, however, to define certain properties of sentences that do not depend on the implementation.</S>
			<S sid ="922" ssid = "188">A sentence is a representation of a natural language sentence made to be matched by a pattern.</S>
			<S sid ="923" ssid = "189">A tuple tk is in a sentence si if all strings in the tuple are in the sentence.</S>
			<S sid ="924" ssid = "190">tk ∈ si ↔ ∀n(tkn ∈ si ) (4.5) Sentences are the text the system will extract information from.</S>
			<S sid ="925" ssid = "191">Of course, since there are many of them, it is useful to talk about the collection of sentences.</S>
			<SUBSECTION>4.1.6 Corpus A corpus C is a set of sentences.</SUBSECTION>
			<S sid ="926" ssid = "192">C ≡ {s1 , s2 , · · · , sn } (4.6) Note that information about the sequence of the sentences is not maintained, nor does the system keep track of which sentences come from the same documents.</S>
			<S sid ="927" ssid = "193">All sentences are treated in the same way, though supplementing the current algorithm with that information could prove fruitful in future research.</S>
			<S sid ="928" ssid = "194">Just as a tuple can be in a sentence, a tuple can be in a corpus.</S>
			<S sid ="929" ssid = "195">tk ∈ C ↔ ∃si (si ∈ C ∧ tkn ∈ si ) (4.7) One can express the subset of tuples in a corpus with a superscript, e.g., {T }C means all of the tuples of type T in the corpus C . 4.1.7 Patterns Patterns represent lexical and syntactic features of a sentence.</S>
			<S sid ="930" ssid = "196">They are used to match tuples that have a certain grammatical relationship in a sentence.</S>
			<S sid ="931" ssid = "197">Patterns allow the system to search for syntactic features, which will later be correlated with semantic meaning.</S>
			<S sid ="932" ssid = "198">For example, a pattern could match “City, Country”, where the bold words are classes and the comma is significant.</S>
			<S sid ="933" ssid = "199">This pattern would match tuples of type C ity, C ountry with only a comma between them.</S>
			<S sid ="934" ssid = "200">The patterns are generated automatically.</S>
			<S sid ="935" ssid = "201">How they are generated and represented will be addressed in Sections 5.1.2 and 5.1.3.</S>
			<S sid ="936" ssid = "202">The system defines set of patterns P ≡ {p1 , p2 , . . .</S>
			<S sid ="937" ssid = "203">, pn }.</S>
			<S sid ="938" ssid = "204">One expresses a matching function m that returns the set of tuples matched by pattern pi in sentence sj . m(pi , sj ) ⊆ {T }C (4.8) m can return many tuples or no tuples at all (the empty set).</S>
			<S sid ="939" ssid = "205">m is constrained to not return a tuple that is not in the sentence.1 More formally: ∀pi ∀sj (tk ∈ m(pi , sj ) ↔ tk ∈ sj ) (4.9) If tk ∈ m(pi , sj ), then one can say that pi matches tk in sj . The system needs to know what tuples a pattern matches over the entire corpus from different sets of tuples.</S>
			<S sid ="940" ssid = "206">For instance, it might be useful to know what tuples from the relation R a particular pattern matches.</S>
			<S sid ="941" ssid = "207">The system also needs to know what tuples from the entire type T a pattern matches.</S>
			<S sid ="942" ssid = "208">A match function is defined using a set parameter G as the set over which the matches are accumulated.</S>
			<S sid ="943" ssid = "209">If G is a set of tuples of type T , the system defines a value matchGpi as the set of tuples from G matched by pi in C . This value is the number of times pi matches a tuple from G in the corpus.</S>
			<S sid ="944" ssid = "210">It should be noted that G is a placeholder and could be any named set.</S>
			<S sid ="945" ssid = "211">matchGpi = G ∩ sj ∈C m(pi , sj ) (4.10) 4.2 Formal Problem Definition.</S>
			<S sid ="946" ssid = "212">Now that the terms have been defined precisely, the problem can be formulated using them: Given corpus C , T , and K ⊆ R, determine whether a given tk ∈ {T } is also in R, the theoretical “complete” set.</S>
			<S sid ="947" ssid = "213">A solution will give a set approximating RC . This is the definition of the problem this paper attempts to solve.</S>
			<S sid ="948" ssid = "214">For evaluation purposes, a relation one can have complete knowledge of (such as the capital cities of countries) will be used.</S>
			<S sid ="949" ssid = "215">However, in general, one does not have complete knowledge.</S>
			<S sid ="950" ssid = "216">In fact, if one did, there would be no need to use the system.</S>
			<S sid ="951" ssid = "217">It is useful to use the case where complete knowledge is at hand to evaluate one’s algorithm.</S>
			<S sid ="952" ssid = "218">If one does not know the right answers, one cannot grade the system.</S>
			<S sid ="953" ssid = "219">1 In theory, a pattern can use other information besides information directly stated in the sentence (i.e., context).</S>
			<S sid ="954" ssid = "220">This is outside the scope of the current research.</S>
			<SUBSECTION>4.2.1 Proposed solution Given C , T , and K ⊂ R, generate patterns P . Create feature vectors for each tuple tk ∈ {T }C . Use those feature vectors to train a classifier.</SUBSECTION>
			<S sid ="955" ssid = "221">Classify the tuples in {T }C using the classifier.</S>
			<S sid ="956" ssid = "222">Those that are classified as in R are added to K . Repeat until no more tuples are added to K . This algorithm is a standard bootstrapping algorithm.</S>
			<S sid ="957" ssid = "223">Bootstrapping Bootstrapping refers to a semi-unsupervised technique.</S>
			<S sid ="958" ssid = "224">The bootstrapping process starts with a handful of seed tuples.</S>
			<S sid ="959" ssid = "225">These seed tuples are a subset of the positive set (R).</S>
			<S sid ="960" ssid = "226">They constitute a known set of positive values.</S>
			<S sid ="961" ssid = "227">Bootstrapping occurs iteratively.</S>
			<S sid ="962" ssid = "228">Using tuples from the seed set, the system generates patterns from the corpus.</S>
			<S sid ="963" ssid = "229">The matches of those patterns are used as features in a feature vector and trained in a classifier.</S>
			<S sid ="964" ssid = "230">Those tuples that are classified positively are added to the seed set and the process is iterated.</S>
			<S sid ="965" ssid = "231">The process stops when no new tuples are added during an iteration.</S>
			<S sid ="966" ssid = "232">1.</S>
			<S sid ="967" ssid = "233">K ′ ← K ⊂ R 2.</S>
			<S sid ="968" ssid = "234">Generate patterns P using C and tuples from K ′ ..</S>
			<S sid ="969" ssid = "235">3.</S>
			<S sid ="970" ssid = "236">Generate feature vectors of positive matches..</S>
			<S sid ="971" ssid = "237">4.</S>
			<S sid ="972" ssid = "238">Train classifier using K as class 1, and g randomly selected values from {T }C − K ′ as class 2..</S>
			<S sid ="973" ssid = "239">5.</S>
			<S sid ="974" ssid = "240">Apply classifier to {T }C ..</S>
			<S sid ="975" ssid = "241">6.</S>
			<S sid ="976" ssid = "242">Add the tuples classified as class 1 to K ′ ..</S>
			<S sid ="977" ssid = "243">7.</S>
			<S sid ="978" ssid = "244">if K ′ grew, go to step 2.</S>
			<S sid ="979" ssid = "245">8. else return Either the tuples in K ′ can be returned or the patterns in P can be returned.</S>
			<S sid ="980" ssid = "246">If the tuples are returned, the system can be considered a query system.</S>
			<S sid ="981" ssid = "247">It accepts a query definition and returns an answer in the form of a set of tuples.</S>
			<S sid ="982" ssid = "248">If the patterns are returned from this algorithm, the bootstrapping phase can be considered a training phase.</S>
			<S sid ="983" ssid = "249">The patterns can be used later to extract more tuples from new document sources.</S>
			<S sid ="984" ssid = "250">g can be chosen to tune the algorithm.</S>
			<S sid ="985" ssid = "251">A low value of g will tend to accept more tuples into K ′ with each iteration.</S>
			<S sid ="986" ssid = "252">This inevitably will accept more incorrect tuples (lower Precision).</S>
			<S sid ="987" ssid = "253">A higher value will tend to be more conservative leading to a higher Precision but a lower Recall.</S>
			<S sid ="988" ssid = "254">When g = 0, all tuples in {T }C will be added to K ′ since no training examples from class 2 were given.</S>
			<S sid ="989" ssid = "255">Chapter 5 Evaluation Part of the purpose of the current research is to create a general model for the problem of Information Extraction used.</S>
			<S sid ="990" ssid = "256">It is desirable to perform many different extraction tasks with minimal human effort.</S>
			<S sid ="991" ssid = "257">It is therefore important to show here that the algorithm achieves a high level of accuracy on a variety of extraction tasks.</S>
			<S sid ="992" ssid = "258">Consequently, the system was queried for the following relations: which countries are located in which continent and identifying the capital cities of countries.</S>
			<S sid ="993" ssid = "259">The definition of how sentences are represented and consequently how patterns are matched is described here since they are implementation details.</S>
			<S sid ="994" ssid = "260">5.1 Level of Parsing.</S>
			<S sid ="995" ssid = "261">Of the two most promising levels of parsing, dependency graphs were chosen over word sequences (see Section 3.1).</S>
			<S sid ="996" ssid = "262">Dependency graphs capture much more information.</S>
			<S sid ="997" ssid = "263">Also, a proper parse of a sentence can alleviate the problems of interleaving dependant clauses.</S>
			<S sid ="998" ssid = "264">For instance, in the following sentence, the words interleaving Paris and France are unimportant to the capital city relation.</S>
			<S sid ="999" ssid = "265">Paris, which has some of the best restaurants in the world, is the capital of France.</S>
			<S sid ="1000" ssid = "266">In a dependency tree, the dependant clause about the quality of restaurants would be a subtree of the node for Paris.</S>
			<S sid ="1001" ssid = "267">The uninteresting subtree can be ignored by the pattern.</S>
			<S sid ="1002" ssid = "268">This alleviates the ordering problem, and allows a clear view of the relationship between words and phrases that are not adjacent.</S>
			<S sid ="1003" ssid = "269">5.1.1 Formal dependency tree model A dependency tree is a tree structure with labeled nodes and labeled edges.</S>
			<S sid ="1004" ssid = "270">The label at a node is a word from the sentence.</S>
			<S sid ="1005" ssid = "271">The label at an edge is the grammatical relationship between the two nodes.</S>
			<S sid ="1006" ssid = "272">A node may have 0 or more subtrees.</S>
			<S sid ="1007" ssid = "273">The subtrees are unordered.</S>
			<S sid ="1008" ssid = "274">If a node has no subtrees, it is called a leaf.</S>
			<S sid ="1009" ssid = "275">All nodes but one have exactly one parent.</S>
			<S sid ="1010" ssid = "276">The single node without a parent is called the root node.</S>
			<S sid ="1011" ssid = "277">For more information about parsing dependency trees, see de Marneffe et al. [13].</S>
			<S sid ="1012" ssid = "278">It is necessary to define a few conventions: One can refer to nodes with the letter n. The label of a node is labeln . The set of subtrees of node n subtreesn → edgelabel, subtree . Subtrees of n with a specific edge label are noted subtreesn (label).</S>
			<S sid ="1013" ssid = "279">The root node of s is roots . 5.1.2 Pattern matching Since it has been decided to use the dependency tree of the sentence as its representation.</S>
			<S sid ="1014" ssid = "280">A pattern matching mechanism can therefore be defined.</S>
			<S sid ="1015" ssid = "281">A pattern p is a tree.</S>
			<S sid ="1016" ssid = "282">Each node has a matcher and each edge has a label.</S>
			<S sid ="1017" ssid = "283">A matcher is a predicate that takes a word and returns true to represent a match (to be defined shortly).</S>
			<S sid ="1018" ssid = "284">The label at an edge is the grammatical relationship between the two nodes.</S>
			<S sid ="1019" ssid = "285">Each node also has an optional return label.</S>
			<S sid ="1020" ssid = "286">If the pattern matches a given tree, the word from a node in s that matches a corresponding node in p is given a label.</S>
			<S sid ="1021" ssid = "287">All of these are combined into the final tuple.</S>
			<S sid ="1022" ssid = "288">For instance, a node could have the return label arg1.</S>
			<S sid ="1023" ssid = "289">Another could have the return label arg2.</S>
			<S sid ="1024" ssid = "290">It may be that the node with label arg1 matches “Paris” and the node with label arg2 matches “France”.</S>
			<S sid ="1025" ssid = "291">If the entire pattern matches, the pattern will return the tuple P aris, F rance since a tuple is constructed using the arguments in order.</S>
			<S sid ="1026" ssid = "292">If |s| is the number of nodes (number of words) in s, then there are |s| potential matches of a pattern p in s. Each node in s could potentially match p and contribute to the set of tuples returned by m(p, s).</S>
			<S sid ="1027" ssid = "293">m is extended to operate also on individual nodes (m(p, n)).</S>
			<S sid ="1028" ssid = "294">Intuitively, a pattern p matches a node n if the root of p matches the label of n and all of the subtrees of rootp match unique subtrees of n. When matching subtrees, both the label of the node and the label of the edge have to match.</S>
			<S sid ="1029" ssid = "295">Matching a pattern to a node is defined recursively and non-deterministically to make the intention more clear.</S>
			<S sid ="1030" ssid = "296">where m ( p , s ) = m ( p , r o o t s ) ( 5 . 1 ) m(p, n) = subtree sp = ∅ ∨ matche rrootp (labeln ) ∧ alltree smatch (subtre esp , subtree sn ) (5.2) a l l t r e e s m a t c h ( j , k ) = ∃ x ∈ j , y ∈ k m ( x , y ) ∧ a l l t r e e s m a t c h ( j − x , k − y ) ( 5 . 3 ) The matcher function stored at each node of the pattern tree has yet to be defined.</S>
			<S sid ="1031" ssid = "297">The matcher function’s role is to encode what kind of match is to be performed.</S>
			<S sid ="1032" ssid = "298">Two kinds of matchers are implemented, though more are possible.</S>
			<S sid ="1033" ssid = "299">The first type of matcher is the Exact match.</S>
			<S sid ="1034" ssid = "300">The function matches one and only one sequence of characters.</S>
			<S sid ="1035" ssid = "301">For instance, an exact match for the word “car” does not match the word “cars”.</S>
			<S sid ="1036" ssid = "302">Class inclusion functions can also serve as matcher functions.</S>
			<S sid ="1037" ssid = "303">This is done for the nodes in a pattern that return a value to become part of the returned tuple.</S>
			<S sid ="1038" ssid = "304">This ensures that the returned tuples are of the desired type.</S>
			<S sid ="1039" ssid = "305">Other matchers can be implemented that use Wordnet hypernym data, wild-card matchers, or regular expression matchers.</S>
			<S sid ="1040" ssid = "306">Integrating these matchers into the system is left to future work.</S>
			<S sid ="1041" ssid = "307">5.1.3 Pattern generation A pattern can be generated from a tuple and a sentence with that tuple.</S>
			<S sid ="1042" ssid = "308">The nodes along the shortest path between the strings in the tuple from the dependency tree are extracted.</S>
			<S sid ="1043" ssid = "309">A pattern tree is created in the same form (corresponding nodes and links).</S>
			<S sid ="1044" ssid = "310">Each tuple value in the shortest path corresponds to its class inclusion function in the pattern tree.</S>
			<S sid ="1045" ssid = "311">All other strings correspond to exact string matchers.</S>
			<S sid ="1046" ssid = "312">Figure 5.3 shows an example of creating a pattern from a sentence.</S>
			<S sid ="1047" ssid = "313">5.2 Evaluation Criteria.</S>
			<S sid ="1048" ssid = "314">The standard Information Retrieval metrics detailed in Section 1.5 are used to evaluate the algorithms.</S>
			<S sid ="1049" ssid = "315">There are certain difficulties with evaluating the knowledge contained in documents that are not read and annotated by an expert.</S>
			<S sid ="1050" ssid = "316">It is therefore necessary to calculate them using an objective, algorithmic metric.</S>
			<S sid ="1051" ssid = "317">Specifically, Recall (equation 1.1) is calculated as follows: |K ′ ∩ R| Recall = |R| (5.4) Figure 5.1: A pattern can match a sentence represented as a dependency tree.</S>
			<S sid ="1052" ssid = "318">All nodes and their labels must match.</S>
			<S sid ="1053" ssid = "319">Figure 5.2: Patterns match only specific patterns.</S>
			<S sid ="1054" ssid = "320">In this example, the pattern does not match the root of the dependency tree (its label is not a city) and “Berlin” does not have a subtree.</S>
			<S sid ="1055" ssid = "321">The pattern fails to match.</S>
			<S sid ="1056" ssid = "322">Precision (equation 1.2) is calculated as follows: Precision = |K ′ ∩ R| |K ′ | (5.5) Figure 5.3: The stages of generating a pattern from a dependency tree and a tuple.</S>
			<S sid ="1057" ssid = "323">Note that the values “Paris” and “France” get replaced in the pattern by their class inclusion functions.</S>
			<S sid ="1058" ssid = "324">The Recall formulation punishes the algorithm when a tuple in R is not returned by the algorithm because it is not in any sentence in the corpus.</S>
			<S sid ="1059" ssid = "325">This is fair since this algorithm will need to be compared to ground truth (R)—not an unfairly selected subset of it—and a more advanced algorithm which can extract more information (i.e. an algorithm that is not limited to extracting tuples from RC ).</S>
			<S sid ="1060" ssid = "326">In order to value Precision twice as much as Recall (to value a low False Positive rate), β = 0.5 in the F-measure (equation 1.3).</S>
			<S sid ="1061" ssid = "327">5.3 Naive Bayes Classifier.</S>
			<S sid ="1062" ssid = "328">The Naive Bayes Classifier is one of two classifiers used to evaluate the framework.</S>
			<S sid ="1063" ssid = "329">It is important to evaluate the framework using two different classifiers.</S>
			<S sid ="1064" ssid = "330">The choice of classifier is left up to the implementor of the final system.</S>
			<S sid ="1065" ssid = "331">Two classifiers are tested here to evaluate whether the framework can support different classifiers and that the accuracy of the results is not due solely to the qualities of any one classifier.</S>
			<S sid ="1066" ssid = "332">The specifics of the Naive Bayes Classifier will be derived here.</S>
			<S sid ="1067" ssid = "333">First, in order to use Naive Bayes, the system must assume that the patterns match statistically independent features.</S>
			<S sid ="1068" ssid = "334">Because of the above assumption, Bayes’ formula holds.</S>
			<S sid ="1069" ssid = "335">P (C |tk ∈ K ′ )P (tk ∈ K ′ ) P (tk ∈ R|C ) = (5.6) P (C ) and P (tk ∈/ R|C ) = P ( C | t k ∈ { T } C − K ′ ) P ( t k ∈ { T } C − K ′ ) (5.7 ) P ( C ) where C is the corpus.</S>
			<S sid ="1070" ssid = "336">The category of tk (either R or −R) is determined by the one that has the highest probability.</S>
			<S sid ="1071" ssid = "337">inR(tk ) = (true P (tk ∈ R|C ) &gt; P (tk ∈/ R|C ) f alse otherwise (5.8) P (tk ∈ R|C ) &gt;P (tk ∈/ R|C ) (5.9) C ′ C ′ P (C |tk ∈ R)P (tk ∈ R) &gt; P (C |tk ∈ {T } P (C ) − K )P (tk ∈ {T } P (C ) − K ) (5.10) P (C |tk ∈ R)P (tk ∈ R) &gt;P (C |tk ∈ {T }C − K ′ )P (tk ∈ {T }C − K ′ ) (5.11) Because the patterns are independent, one can define the likelihood P (C |tk ∈ R) therefore as P (C |tk ∈ R) = P (tk ∈ match{T }C p1 |tk ∈ R) × P (tk ∈ match{T }C p2 |tk ∈ R) . × P (tk ∈ match{T }C pn |tk ∈ R) P (C |tk ∈ R) = TI P (tk ∈ match{T }C pi |tk ∈ R) (5.12) pi ∈P And its is noted that where P (tk ∈ match{T }C pi |tk ∈ R) ≈ P (tk ∈ matchK ′ pi ) (5.13) | m a t c h K ′ p i | P (tk ∈ matchK ′ pi ) = |K ′ | (5.14) Described another way, it is the proportion of tuples in K ′ matched by pattern pi . So Similarly, The initial prior is P (C |tk ∈ R) = TI P (tk ∈ matchK ′ pi ) (5.15) pi ∈P P (C |tk ∈/ R) = TI P (tk ∈ match({T }C −K ′ )pi ) (5.16) pi ∈P and | K ′ | P (tk ∈ R) = |K ′ | + |{T }C − K ′ | (5.17) | { T } C − K ′ | P (tk ∈/ R) = |K ′ | + |{T }C − K ′ | (5.18) The inR function is now specified and will determine whether a tuple is desirable.</S>
			<S sid ="1072" ssid = "338">Practical details There are a handful of details that must be discussed.</S>
			<S sid ="1073" ssid = "339">These details arise from the practical need to implement the system in order to evaluate it.</S>
			<S sid ="1074" ssid = "340">Firstly, this is a statistical algorithm.</S>
			<S sid ="1075" ssid = "341">The algorithm cannot work with a small number of sentences.</S>
			<S sid ="1076" ssid = "342">It relies on the redundancy inherent in large corpora of documents.</S>
			<S sid ="1077" ssid = "343">Since all of the calculations are statistical, it is important to remove patterns that match less than a certain number of tuples.</S>
			<S sid ="1078" ssid = "344">This exclusion will ensure a level of statistical certainty.</S>
			<S sid ="1079" ssid = "345">For instance, a pattern that matches only one tuple will be unreliable.</S>
			<S sid ="1080" ssid = "346">Similarly, the tuples that are matched by less than a certain number of patterns should also be excluded.</S>
			<S sid ="1081" ssid = "347">The statistical methods used here break down with a small number of samples.</S>
			<S sid ="1082" ssid = "348">They are only accurate when the number of samples is very large.</S>
			<S sid ="1083" ssid = "349">The current system throws out sentences matched by less than three patterns.</S>
			<S sid ="1084" ssid = "350">And it removes patterns that match fewer than six tuples.</S>
			<S sid ="1085" ssid = "351">Secondly, there are certain minor changes to be made to the evaluation metrics.</S>
			<S sid ="1086" ssid = "352">Specifically, the way they are currently calculated allows for P (tk ∈ R) = 1 or P (tk ∈ R) = 0.</S>
			<S sid ="1087" ssid = "353">Both of these cases should be avoided, since they indicate certainty—the system is never certain.</S>
			<S sid ="1088" ssid = "354">It is necessary to add in “dummy tuples” to the calculation.</S>
			<S sid ="1089" ssid = "355">More specifically, four dummy tuples are added—one from each of the following cases: 1.</S>
			<S sid ="1090" ssid = "356">True Positive—a tuple in R matched by the pattern.</S>
			<S sid ="1091" ssid = "357">2.</S>
			<S sid ="1092" ssid = "358">False Positive—a tuple not in R matched by the pattern.</S>
			<S sid ="1093" ssid = "359">3.</S>
			<S sid ="1094" ssid = "360">True Negative—a tuple not in R not matched by the pattern.</S>
	</SECTION>
	<SECTION title="False Negative—a tuple in R not matched by the pattern. " number = "4">
</PAPER>
