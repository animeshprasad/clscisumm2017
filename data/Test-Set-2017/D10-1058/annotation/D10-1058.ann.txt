Citance Number: 1 | Reference Article: D10-1058 | Citing Article: C16-1060 | Citation Marker Offset: '48' | Citation Marker: 2010 | Citation Offset: '48' | Citation Text: <S sid ="48" ssid = "27">Zhao and Gildea (2010) explored a model with a word order and fertility model as described above, but based their work on the EM algorithm, using Gibbs sampling only for approximating the expectations.</S> | 
Citance Number: 2 | Reference Article: D10-1058 | Citing Article: P13-2002 | Citation Marker Offset: '24' | Citation Marker: Zhao and Gildea, 2010 | Citation Offset: '24' | Citation Text: <S sid ="24" ssid = "24">Recent work (Zhao and Gildea, 2010) described an extension to the HMM with a fertility model, using MCMC techniques for parameter estimation.</S> | 
Citance Number: 3 | Reference Article: D10-1058 | Citing Article: P13-2002 | Citation Marker Offset: '33' | Citation Marker: Zhao and Gildea, 2010 | Citation Offset: '33' | Citation Text: <S sid ="33" ssid = "4">, fJ and word alignment vectors a = estimate the posterior distribution using Markov chain Monte Carlo methods such as Gibbs sampling (Zhao and Gildea, 2010).</S> | 
Citance Number: 4 | Reference Article: D10-1058 | Citing Article: P13-2002 | Citation Marker Offset: '43' | Citation Marker: Zhao and Gildea, 2010 | Citation Offset: '43' | Citation Text: <S sid ="43" ssid = "14">Following prior work (Zhao and Gildea, 2010), we augment the standard HMM with a fertility distribution.</S> | 
Citance Number: 5 | Reference Article: D10-1058 | Citing Article: P13-2002 | Citation Marker Offset: '82' | Citation Marker: Zhao and Gildea, 2010 | Citation Offset: '82' | Citation Text: <S sid ="82" ssid = "3">Prior work addressed this by using the single parameter Poisson distribution, forcing infrequent words to share a global parameter estimated from the fertility of all words in the corpus (Zhao and Gildea, 2010).</S> | 
Citance Number: 6 | Reference Article: D10-1058 | Citing Article: P13-2002 | Citation Marker Offset: '99' | Citation Marker: Zhao and Gildea, 2010 | Citation Offset: '99' | Citation Text: <S sid ="99" ssid = "7">The prior work compared Viterbi with a form of local search (sampling repeatedly and keeping the max), finding little difference between the two (Zhao and Gildea, 2010).</S> | 
Citance Number: 7 | Reference Article: D10-1058 | Citing Article: P59105ca | Citation Marker Offset: '45' | Citation Marker: 15 | Citation Offset: '45' | Citation Text: <S sid ="45" ssid = "45">Zhao and Gildea [15] use sampling in their proposed fertility extensions to IBM Model 1 and HMM, but they do not place any prior on the parameters.</S> | 
Citance Number: 8 | Reference Article: D10-1058 | Citing Article: P87-94 | Citation Marker Offset: '79' | Citation Marker: Zhao | Citation Offset: '79' | Citation Text: <S sid ="79" ssid = "2">Zhao proposes a brief fertility based HMM model,8 which also decreases the complexity of Model A Fully Bayesian Inference for Word Alignment 93 Table 2.</S> | 
Citance Number: 9 | Reference Article: D10-1058 | Citing Article: Pbulletin | Citation Marker Offset: '104' | Citation Marker: 2010 | Citation Offset: 103','104' | Citation Text: <S sid ="103" ssid = "24">For models with fertility computing the expectations instead becomes intractable, and previous authors have solved this by using approximative 2 The approximation consists of ignoring the dependence between the two draws from the word order jump distribution (second and third factors).</S><S sid ="104" ssid = "25">134 R. stling, J. Tiedemann Ecient Word Alignment with MCMC (125146) greedy optimization techniques (Brown et al., 1993) or local Gibbs sampling (Zhao and Gildea, 2010).</S> | 
Citance Number: 10 | Reference Article: D10-1058 | Citing Article: Pbulletin | Citation Marker Offset: '131' | Citation Marker: 2010 | Citation Offset: '131' | Citation Text: <S sid ="131" ssid = "13">Zhao and Gildea (2010) instead chose to use Gibbs sampling to approximate these expectations, which allowed them to perform efficient inference with EM for a HMM model with fertility.</S> | 
Citance Number: 11 | Reference Article: D10-1058 | Citing Article: Pcoling_D10 | Citation Marker Offset: '232' | Citation Marker: 2010 | Citation Offset: '232' | Citation Text: <S sid ="232" ssid = "9">Another interesting extension of the HMM alignment is presented in Zhao and Gildea (2010) who added a fertility distribution to the HMM.</S> | 
Citance Number: 12 | Reference Article: D10-1058 | Citing Article: Pproc_D10 | Citation Marker Offset: '24' | Citation Marker: Zhao and Gildea, 2010 | Citation Offset: '24' | Citation Text: <S sid ="24" ssid = "24">Recent work (Zhao and Gildea, 2010) described an extension to the HMM with a fertility model, using MCMC techniques for parameter es timation.</S> | 
Citance Number: 13 | Reference Article: D10-1058 | Citing Article: Pproc_D10 | Citation Marker Offset: '38' | Citation Marker: Zhao and Gildea, 2010 | Citation Offset: '38' | Citation Text: <S sid ="38" ssid = "9">Following prior work (Zhao and Gildea, 2010), we augment the standard HMM with a fertility dis tribution.</S> | 
Citance Number: 14 | Reference Article: D10-1058 | Citing Article: Pproc_D10 | Citation Marker Offset: '39' | Citation Marker: Zhao and Gildea, 2010 | Citation Offset: '39' | Citation Text: <S sid ="39" ssid = "10">I Pr(f, ale) =p(JII) ITP(cPilei) estimate the posterior distribution using Markov chain Monte Carlo methods such as Gibbs sam pling (Zhao and Gildea, 2010).</S> | 
Citance Number: 15 | Reference Article: D10-1058 | Citing Article: Pproc_D10 | Citation Marker Offset: '86' | Citation Marker: Zhao and Gildea, 2010 | Citation Offset: '86' | Citation Text: <S sid ="86" ssid = "3">Prior work addressed this by using the single parameter Pois son distribution, forcing infrequent words to share a global parameter estimated from the fertility of all words in the corpus (Zhao and Gildea, 2010).</S> | 
Citance Number: 16 | Reference Article: D10-1058 | Citing Article: Pproc_D10 | Citation Marker Offset: '104' | Citation Marker: Zhao and Gildea, 2010 | Citation Offset: '104' | Citation Text: <S sid ="104" ssid = "7">The prior work compared Viterbi with a form of local search (sampling repeatedly and keeping the max), finding little difference between the two (Zhao and Gildea, 2010).</S> | 
Citance Number: 17 | Reference Article: D10-1058 | Citing Article: Q13-1024 | Citation Marker Offset: '60' | Citation Marker: Zhao and Gildea, 2010 | Citation Offset: '60' | Citation Text: <S sid ="60" ssid = "3">The sequence-based model is easier to implement, and recent experiments have shown that appropriately modified sequence-based model can produce comparable performance with fertility-based models (Lopez and Resnik, 2005; Liang et al., 2006; DeNero and Klein, 2007; Zhao and Gildea, 2010; Bansal et al., 2011).</S> | 
Citance Number: 18 | Reference Article: D10-1058 | Citing Article: Q13-1024 | Citation Marker Offset: '130' | Citation Marker: Zhao and Gildea, 2010 | Citation Offset: '130' | Citation Text: <S sid ="130" ssid = "22">Our Gibbs sampler is similar to the MCMC algorithm in Zhao and Gildea (2010), but we assume Dirichlet priors when sampling model parameters and take a different sampling approach based on the source side dependency tree.</S> | 
