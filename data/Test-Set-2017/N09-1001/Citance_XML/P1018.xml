<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">In this paper we propose a method to build fine-grained subjectivity lexicons including nouns, verbs and adjectives.</S>
		<S sid ="2" ssid = "2">The method, which is applied for Dutch, is based on the comparison of word frequencies of three corpora: Wikipedia, News and News comments.</S>
		<S sid ="3" ssid = "3">Comparison of the corpora is carried out with two measures: log-likelihood ratio and a percentage difference calculation.</S>
		<S sid ="4" ssid = "4">The first step of the method involves subjectivity identification, i.e. determining if a word is subjective or not.</S>
		<S sid ="5" ssid = "5">The second step aims at the identification of more fine-grained subjectivity which is the distinction between actor subjectivity and speaker / writer subjectivity.</S>
		<S sid ="6" ssid = "6">The results suggest that this approach can be usefully applied producing subjectivity lexicons of high quality.</S>
		<S sid ="7" ssid = "7">Keywords: subjectivity, sentiment, lexicon building</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="8" ssid = "8">In this paper we present a method to build a fine-grained subjectivity lexicon for Dutch on the basis of three corpora, while making use of the dissimilarities between these corpora.</S>
			<S sid ="9" ssid = "9">Early work in automatic building of subjectivity lexicons focused mainly on polarity identification which is knowing whether a lexical item is negative, positive or neutral (Kamps et al., 2004; Hatzivassiloglou and McKeown, 1997; Esuli and Sebastiani, 2006).</S>
			<S sid ="10" ssid = "10">In more recent work it has been argued that the classification of subjectivity vs. objectivity needs to be done independently from the polarity identification (Gyamfi et al., 2009; Su and Markert, 2009).</S>
			<S sid ="11" ssid = "11">Items may be subjective without having polarity.</S>
			<S sid ="12" ssid = "12">For example, words like know, feeling, and interested are subjective since they express thoughts, speculations and emotions, but they do not refer to positive or negative sentiment (Gyamfi et al., 2009).</S>
			<S sid ="13" ssid = "13">Moreover, research has shown that sentiment analysis benefits from subdividing the annotation task in distinguishing subjective and objective instances prior to polarity classification (Yu and Hatzivassiloglou, 2003; Wilson et al., 2005).</S>
			<S sid ="14" ssid = "14">Annotation schemas have been developed which show that human annotators can annotate words and word senses in a reliable manner, both with regard to polarity and with regard to subjectivity annotation (Wiebe and Mihalcea, 2006; Su and Markert, 2008).</S>
			<S sid ="15" ssid = "15">In recent annotation studies (Maks and Vossen, 2010; 2011), we argued that a third task which we call ‘attitude holder identification’, needs to be defined.</S>
			<S sid ="16" ssid = "16">Attitude holder identification regards the classification of subjective items in a subclass of subjectivity: the distinction between so-called speaker/writer and actor subjectivity where the speaker/writer is the producer of the utterance and the actor is some other person referred to or quoted in the text.</S>
			<S sid ="17" ssid = "17">This distinction is illustrated by the following examples: Ex.(1) Bush is angry over Obama&apos;s leeking of private conversation .....</S>
			<S sid ="18" ssid = "18">[attitude/judgment of Bush on Obama] Ex.(2) Bush is bad for the economy ….</S>
			<S sid ="19" ssid = "19">[attitude/judgement of Speaker/Writer on Bush] The subjectivity cues angry and bad imply different kinds of information relevant to subjectivity analysis: (a) they are – as opposed to other words in the sentence like economy and Obama – subjective as they refer to somebody’s private state; (b) they both have polarity; and (c) they give information about the person whose private state is expressed, the attitude holder.</S>
			<S sid ="20" ssid = "20">In example (1), representing actor subjectivity, the attitude holder is the person the adjective is attributed to, in this case represented by the logical subject of the sentence.</S>
			<S sid ="21" ssid = "21">In example (2), representing speaker/writer subjectivity, the attitude of the implicit speaker/writer is expressed.</S>
			<S sid ="22" ssid = "22">These different kinds of subjectivity can be found with verbs, nouns and adjectives as illustrated below: Ex.</S>
			<S sid ="23" ssid = "23">(3) He is my hero (Positive attitude of Speaker/Writer towards ‘he’) Ex.</S>
			<S sid ="24" ssid = "24">(4) They are nagging all day long (Negative attitude of Speaker/Writer towards ‘they’) Ex.</S>
			<S sid ="25" ssid = "25">(5) His hatred for religion ….</S>
			<S sid ="26" ssid = "26">(Negative Attitude of ‘his’ (he) towards ‘religion’) Ex.</S>
			<S sid ="27" ssid = "27">(6) T.F. criticizes her daughter … (Negative Attitude of ‘T.F.’ towards ‘her daughter’) Ex.</S>
			<S sid ="28" ssid = "28">(7) He is boasting about his work … (Positive Attitude of ‘he’ towards ‘his work’; Negative attitude of Speaker/writer towards ‘he’) Sentences (3) and (4) are illustrations of speaker subjectivity.</S>
			<S sid ="29" ssid = "29">Both express the speaker’s attitude towards the participants, i.e., ‘he’ and ‘they’, respectively.</S>
			<S sid ="30" ssid = "30">Sentences (5) and (6) are illustrations of actor subjectivity as they both express attitudes from persons referred to in the text.</S>
			<S sid ="31" ssid = "31">Sentence (7) shows that speaker’s and actor’s attitude can also be combined in one word: ‘boast’, which expresses both the attitude of the actor (‘he’) and the attitude of the speaker.</S>
			<S sid ="32" ssid = "32">These different perspectives, and the possible inferences implied by them, are part of the semantics of the word itself.</S>
			<S sid ="33" ssid = "33">As the subjectivity type, in combination with the argument structure, can be used to identify the attitude holder, we suggest that this is an important word feature to be stored in a subjectivity lexicon.</S>
			<S sid ="34" ssid = "34">In earlier studies we showed that attitude holder annotation can be done in a reliable manner manually (Maks and Vossen, 2010; 2011).</S>
			<S sid ="35" ssid = "35">In this paper we explore whether this task can also be performed reliably in an automatic way.</S>
			<S sid ="36" ssid = "36">We present a method to perform the two subtasks of subjectivity identification (subjective vs. objective) and attitude holder identification.</S>
			<S sid ="37" ssid = "37">First, a distinction is made between subjective and objective words.</S>
			<S sid ="38" ssid = "38">In addition, we make a distinction between actor and speaker/writer subjectivity, leaving polarity identification for future work.</S>
			<S sid ="39" ssid = "39">In the following section, we explain in more detail the general idea behind the method, the corpus comparison measures and the design of the corpus.</S>
			<S sid ="40" ssid = "40">In section 3, we briefly discuss the gold standards used for the evaluation of the obtained lexicons.</S>
			<S sid ="41" ssid = "41">In section 4 we present the results of the lexicon-building process and in section 5 we conclude with a discussion of the results.</S>
	</SECTION>
	<SECTION title="Subjective word extraction method. " number = "2">
			<S sid ="42" ssid = "1">The main assumption of the proposed method is that words that express different types of subjectivity are distributed differently depending on the text type.</S>
			<S sid ="43" ssid = "2">The method is based on comparison between these texts using and testing two different calculations: the log-likelihood technique developed by Garson et al.</S>
			<S sid ="44" ssid = "3">(2000) and the percentage difference calculations (DIFF, from now on) developed by Gabrielatos and Marchi (2011).</S>
			<S sid ="45" ssid = "4">Both measures have been used for keyword extraction and allow identification of words that are significantly more frequent in one corpus than in the other.</S>
			<S sid ="46" ssid = "5">The higher the value, the more representative the word is for that particular corpus and so, in our view, the more indicative for that specific type of subjectivity.</S>
			<S sid ="47" ssid = "6">2.1 Corpus composition.</S>
			<S sid ="48" ssid = "7">For this kind of method, it is important to design an appropriate corpus.</S>
			<S sid ="49" ssid = "8">In our case, we need a corpus which first helps to distinguish subjective from objective words, and then to distinguish actor from speaker/writer subjectivity.</S>
			<S sid ="50" ssid = "9">We propose that both types of subjectivity can be found in texts related to news.</S>
			<S sid ="51" ssid = "10">In our view, the ideal corpus would consist of one part containing news articles and another part containing user comments on these news articles.</S>
			<S sid ="52" ssid = "11">With respect to subjective words, the first part primarily includes words carrying actor subjectivity expressing emotions and attitude of the persons in the text (e.g. politicians, experts, victims, etc.) reported on by journalists.</S>
			<S sid ="53" ssid = "12">The second part primarily includes words carrying speaker/writer subjectivity that refer to speaker/writer attitudes towards the issues and persons reported on in these news articles.</S>
			<S sid ="54" ssid = "13">In this design, the two parts of the corpus have in common the objective words which are used to refer to the news issues and their differences ca be found in the subjective words that represent two types, i.e., speaker/writer and actor subjectivity.</S>
			<S sid ="55" ssid = "14">The common par would then be filtered out by our corpus comparison method leaving the subjective words which can be distinguished by futher constrasting of the two corpus parts.</S>
			<S sid ="56" ssid = "15">However, it proved to be difficult to compose a corpus that is sufficiently large for our purposes and that includes news articles and their user comments.</S>
			<S sid ="57" ssid = "16">Therefore, we decided on a slightly different design.</S>
			<S sid ="58" ssid = "17">To distinguish between speaker/writer and actor subjectivity, we collected news articles and user comments in the same period but not directly related to each other.</S>
			<S sid ="59" ssid = "18">In addition we added a large amount of Wikipedia articles as an extra help to filter out objective words.</S>
			<S sid ="60" ssid = "19">The corpus consists of three components: a random selection of Dutch Wikipedia articles (DWIKI); a collection of news articles from four Dutch newspapers (DNEWS) and a collection of reader comments on a part of the news articles (DCOMM).</S>
			<S sid ="61" ssid = "20">Texts included in the news and reader comment corpus have been published in 2010 and 2011 and were collected directly from the respective website’s archive.</S>
			<S sid ="62" ssid = "21">Table 1 gives an overview of the three components of the corpus.</S>
			<S sid ="63" ssid = "22">Table 1: Corpus Overview (K= thousand; M= million) Concerning the language use in the different corpus components we have the following assumptions: A. Subjectivity is expressed differently in the three components with respect to both the amount and the type of subjective expressions; B. Wikipedia articles contain mainly facts and can hence be considered as maximally objective; C. Both news articles and news comments contain subjective text; D. News articles contain a large amount of actor subjectivity expressions; E. News comments contain a large amount of speaker/writer subjectivity expressions.</S>
			<S sid ="64" ssid = "23">In view of a comparison of normalised frequencies in the three corpora, the assumption is that if a word occurs more frequently in Wikipedia than in the other two corpora, it is most likely not to be a subjective word; if a words occurs more frequently in Comments than in the other two corpora, it is most likely to be a word expressing speaker/writer subjectivity; and if a word occurs more frequently in News than in the other two corpora, it is most likely to be a word expressing actor subjectivity.</S>
			<S sid ="65" ssid = "24">Our method consists of a preprocessing step where the original files of different source formats are converted into structured text format, converting them into lower case, cleaning them by removing hyperlinks, html tags, and the like.</S>
			<S sid ="66" ssid = "25">During this step we keep track of information such as author, title, subject, date of publication, whenever these are available.</S>
			<S sid ="67" ssid = "26">Linguistic preprocessing consists of a shallow and limited process of lemmatization where the corpus tokens are linked to their basic lemma form using a 430,000 word form lexicon for Dutch (e-Lex1.1).</S>
			<S sid ="68" ssid = "27">2.2 Corpus comparison.</S>
			<S sid ="69" ssid = "28">To build the lexicon we used a two-step procedure: • Step 1: Identifying subjective words in the corpus by comparing Wikipedia with News and Comments.</S>
			<S sid ="70" ssid = "29">Words that are over-represented, i.e., relatively more frequent, in News and Comments are considered subjective and will be used in the next step.</S>
			<S sid ="71" ssid = "30">Words that are over-represented in Wikipedia are considered objective and not taken into further consideration.</S>
			<S sid ="72" ssid = "31">• Step 2: Comparing the remaining (subjective) words of News and Comments.</S>
			<S sid ="73" ssid = "32">Words that are over-represented in News are considered having speaker subjectivity; words that are over-represented in Comments are considered having actor subjectivity.</S>
			<S sid ="74" ssid = "33">The overuse of words in the different corpora when compared to each other is calculated by two metrics used for corpus comparison, i.e. the log-likelihood test (Garson et al., 2000) and the DIFF calculation (Gabrielatos and Marchi, 2011).</S>
			<S sid ="75" ssid = "34">The information needed for the log-likelihood (LL) test is the frequency of the word in the one corpus, the frequency of the word in the other corpus and the total amount of words in both corpora.</S>
			<S sid ="76" ssid = "35">If the LL of the result is greater than 3.84, 6.63 or 10.83, the probability of the result happening by chance is less than 5 % (p &lt; 0,05), 1% (p&lt;0.01) or 0.1% (p&lt;0,001), respectively.</S>
			<S sid ="77" ssid = "36">The higher the log-likelihood, the more significant the difference between the two frequency scores and the more we expect that the difference between the two corpora actually means something and helps us to identify the words we are interested in.</S>
			<S sid ="78" ssid = "37">The percentage difference is calculated using the following formula: (((fr1 – fr2) * 100) / fr2) where fr1 is the word’s normalized frequency in the target corpus and fr2 is the word’s normalized frequency in the reference corpus.</S>
			<S sid ="79" ssid = "38">The higher the DIFF score, the higher the frequency difference between the corpora.</S>
			<S sid ="80" ssid = "39">Moreover, these experiments only include words with a frequency &gt; 2 within the compared corpora to exclude misspellings and the like.</S>
	</SECTION>
	<SECTION title="Gold standards. " number = "3">
			<S sid ="81" ssid = "1">For the evaluation of the results for Dutch we use the gold standard for nouns, verbs and adjectives developed by Maks and Vossen (2010, 2011).</S>
			<S sid ="82" ssid = "2">The gold standard includes word-sense level annotations for subjectivity (subjective (S) vs. objective (O)), and attitude holdership (Speaker/Writer (SW) vs. Actor (AC) vs. Objective (O)).</S>
			<S sid ="83" ssid = "3">Inter-annotator agreement for the subjectivity vs. objectivity version is 89% (89%, 90% and 86% for adjectives, nouns and verbs, respectively) with a Cohen kappa of 0.79.</S>
			<S sid ="84" ssid = "4">Inter-annotator agreement for the attitude holder gold standard is 85% (87%, 87% and 83% for adjectives, nouns and verbs, respectively) with a Cohen kappa of 0.77.</S>
			<S sid ="85" ssid = "5">For the purpose of this study, we derived word level standards from these word sense level gold standards, with one annotation for each word.</S>
			<S sid ="86" ssid = "6">The subjective-objective gold standard (gs-so) consists of 406 objective and 610 subjective words.</S>
			<S sid ="87" ssid = "7">The attitude holder standard sub-categorises the subjective words into speaker/writer subjectivity (SW) and actor subjectivity (AC) and also includes the 406 objective words.</S>
			<S sid ="88" ssid = "8">If a word has senses with different annotations, the annotations of the (alleged) most frequent sense is chosen.</S>
			<S sid ="89" ssid = "9">The total number of words included in these gold standards is 1016 (cf.</S>
			<S sid ="90" ssid = "10">table 2) distributed among the different parts-of-speech nouns, verbs and adjectives.</S>
			<S sid ="91" ssid = "11">O S SW AC total GS-SO 406 610 1016 GS-SWACO 406 426 184 1016 Table 2: Composition Gold Standards Each word received one annotation in one gold standard (cf.</S>
			<S sid ="92" ssid = "12">table 3).</S>
			<S sid ="93" ssid = "13">This is a simplification with respect to the examples given earlier (cf.</S>
			<S sid ="94" ssid = "14">section 1, ex.</S>
			<S sid ="95" ssid = "15">7) where the verb boast expresses both SW and AC subjectivity.</S>
			<S sid ="96" ssid = "16">In the present gold standards – with one value for each word - we preferred the SW value over AC with the assumption that SW expresses a stronger sentiment than AC.</S>
			<S sid ="97" ssid = "17">gs-so gs-swaco held (hero) S SW weigeren (refuse) S AC slecht (bad) S SW boos (angry) S AC huis (house) O O opscheppen (boast) S SW Table 3: Sample of Gold Standard entries</S>
	</SECTION>
	<SECTION title="Experiments and Results. " number = "4">
			<S sid ="98" ssid = "1">In this section we present the results of the consecutive steps of the method and hold them against the gold standards.</S>
			<S sid ="99" ssid = "2">4.1 Objective vs. Subjective.</S>
			<S sid ="100" ssid = "3">First, we created a baseline that assigns the most frequent category ‘subjective’ to all words of the corpus.</S>
			<S sid ="101" ssid = "4">The baseline achieves an accuracy of 59% on the gold standard gs-so (cf.</S>
			<S sid ="102" ssid = "5">table 4, base-so).</S>
			<S sid ="103" ssid = "6">Second, we checked our assumptions (cf.</S>
			<S sid ="104" ssid = "7">section 3.1) which state that objective words are relatively frequent in Wikipedia (assumption B) and subjective words are relatively frequent in News and Comments (assumption C).</S>
			<S sid ="105" ssid = "8">We built a word list including all words more frequent in the News and Comments corpus than in Wikipedia and label them as subjective.</S>
			<S sid ="106" ssid = "9">This ‘zero word list’ makes use of the frequency differences between the corpus parts, but no LL or DIFF threshold is applied to make smaller selections.</S>
			<S sid ="107" ssid = "10">Accuracy of this list on gold standard gs-so is calculated for all three part-of-speeches (ANV) together and for adjectives (A), nouns (N) and verbs (V) separately.</S>
			<S sid ="108" ssid = "11">The accuracy rate is 72% (cf.</S>
			<S sid ="109" ssid = "12">table 4: zero) which outperforms the baseline with 13%.</S>
			<S sid ="110" ssid = "13">Hence, we conclude that the assumptions are correct.</S>
			<S sid ="111" ssid = "14">Next, we applied the log-likelihood tests and DIFF calculations in order to build smaller lexicons with higher accuracy.</S>
			<S sid ="112" ssid = "15">Table 4 presents the results for the different log-likelihood thresholds (LL) evaluated against the gs-so.</S>
			<S sid ="113" ssid = "16">The columns ‘gscov’ and ‘lsize’ report the overlap of the gold standard and the lexicon and the size of the lexicon, respectively.</S>
			<S sid ="114" ssid = "17">Accuracy is calculated for all parts-of-speeches together and separately.</S>
			<S sid ="115" ssid = "18">As can be seen from table 4, accuracy increases with 14% from 59% (the baseline) to 73% when applying the LL threshold of 3.84.</S>
			<S sid ="116" ssid = "19">Although there is a performance increase with all parts-of-speech, high scores on subjectivity are only found with adjectives, while nouns and verbs do not surpass 66% and 63%, respectively.</S>
			<S sid ="117" ssid = "20">Moreover, the application of the log-likelihood ratio does not raise the scores with respect to the zero line: the lexicons get smaller but accuracy on subjectivity increases only with 1%.</S>
			<S sid ="118" ssid = "21">As can be seen from table (4), the application of the DIFF calculation is quite successful.</S>
			<S sid ="119" ssid = "22">With the heightening of the threshold from 25 to 100 (cf.</S>
			<S sid ="120" ssid = "23">table (4), rows dif25, dif50 and dif100), the size of the lexicon decreases and accuracy increases from 73 to 80 %.</S>
			<S sid ="121" ssid = "24">High performance is achieved with respect to all parts-of speech, with 90, 73 and 76 % for adjectives, nouns and verbs, respectively.</S>
			<S sid ="122" ssid = "25">A N V A N V gsc ov lsiz e base so 5 9 66 55 54 zer o 7 2 84 66 63 LL 3.8 4 7 3 88 66 63 3 6 4 74 K LL 6.6 3 7 2 89 65 63 3 3 1 47 K LL 10.</S>
			<S sid ="123" ssid = "26">83 7 1 88 64 63 2 9 5 32 K DI FF 25 7 3 86 67 65 4 4 3 54 K DI FF 50 7 6 88 70 68 4 0 6 51 K DI FF 10 0 8 0 90 73 76 3 2 2 46 K DIFF=percentage difference LL=log-likelihood ratio gscov= gold standard coverage lsize= lexicon size A=adjectives N=nouns V=verbs Table 4: Results tested against gs-so We conclude that the log-likelihood method works fine with respect to adjectives, but subjectivity identification on verbs and nouns seems more difficult.</S>
			<S sid ="124" ssid = "27">However, subjectivity identification using DIFF calculations performs quite well with respect to all parts-of-speech.</S>
			<S sid ="125" ssid = "28">subjectivity The next step aims at a further classification of the subjective words into the subcategories AC and SW.</S>
			<S sid ="126" ssid = "29">We performed two sets of evaluations.</S>
			<S sid ="127" ssid = "30">The first set starts from the assumption that the previous step was completely successful.</S>
			<S sid ="128" ssid = "31">The second set of evaluations starts with the true results of the subjectivity identification and presents a more realistic scenario as it takes into account the errors of the previous step.</S>
			<S sid ="129" ssid = "32">• Evaluation I In order to test for the potential of the method in case of a 100% successful identification of subjective words, we deleted the objective words from the gold standard gs-swaco and tested our results on the restricted gold standard which is called gs-swaco-subjective.</S>
			<S sid ="130" ssid = "33">We created a baseline that assigns the most frequent category SW to all words of the news and comments corpus.</S>
			<S sid ="131" ssid = "34">On gs-swaco-subjective the baseline achieves an accuracy of 53% (cf.</S>
			<S sid ="132" ssid = "35">table 5: base-sw-I).</S>
			<S sid ="133" ssid = "36">AN V A N V base SW I 53 65 53 42 zer o 74 71 81 66 Table 5: Results tested against gs-swaco-subjective Assumptions D and E (cf.</S>
			<S sid ="134" ssid = "37">section 3.1) are tested by compiling a word list with all words relatively more frequent in News labelled as AC and all words relatively more frequent in Comments labelled as SW.</S>
			<S sid ="135" ssid = "38">Accuracy of this list on the gold standard swaco-subjective (cf.</S>
			<S sid ="136" ssid = "39">table 5: zero) is 74% which outperforms the baseline with 21%.</S>
			<S sid ="137" ssid = "40">We conclude that assumptions D and E are correct.</S>
			<S sid ="138" ssid = "41">• Evaluation II The second set of evaluations is more realistic as it builds on the real outcome of the subjective vs. objective classification.</S>
			<S sid ="139" ssid = "42">In this scenario, we cannot achieve accuracy scores higher than 73 % and 84 % which are the best performances of the previous step with respect to LL and DIFF respectively.</S>
			<S sid ="140" ssid = "43">The baseline which assigns the most frequent category SW to all words has an accuracy of 46% on gs-swaco (cf.</S>
			<S sid ="141" ssid = "44">table.</S>
			<S sid ="142" ssid = "45">6, base-sw-II).</S>
			<S sid ="143" ssid = "46">Table (6) presents the results obtained with the different log-likelihood thresholds evaluated against gs-swaco.</S>
			<S sid ="144" ssid = "47">In addition to accuracy (acc), we report precision rates for SW (p-sw) and AC (paw).</S>
			<S sid ="145" ssid = "48">Highest accuracy (59%) is achieved with a log-likelihood threshold of 3.86 and outperforms the baseline considerably with 13%.</S>
			<S sid ="146" ssid = "49">However, precision part-of-speeches have equal performance as in particular the verbs score rather poorly.</S>
			<S sid ="147" ssid = "50">Again, the application of the log-likelihood threshold seems to have a low impact on the results, as accuracy hardly changes when the threshold is raised.</S>
			<S sid ="148" ssid = "51">A N V A N V gsc ov lsiz e basesw II acc 4 6 59 33 31 LL 3.8 4/3 .84 acc 5 9 78 60 40 23 8 15 Kp sw 6 2 81 65 41p ac 4 5 43 50 39 LL 6.6 3/6 .63 acc 5 8 79 59 38 21 3 11 Kp sw 6 1 82 63 37p ac 4 9 50 52 44 acc=accuracy p-sw=precision on SW p-ac=precision on AC Table 6: LL results tested against gs-swaco With respect to DIFF calculations, we experiment with different settings.</S>
			<S sid ="149" ssid = "52">As can be seen from table (7), accuracy increases when the DIFF score is raises.</S>
			<S sid ="150" ssid = "53">The higher the performance of the subjectivity lexicon (i.e., the result of the previous step), the higher the scores of the AC/SW lexicon on the gold standard.</S>
			<S sid ="151" ssid = "54">Precision on SW has the same trend, ranging from 66 to 77%.</S>
			<S sid ="152" ssid = "55">However, precision on AC does not reflect this trend and remains very low with scores between 30 and 36 %.</S>
			<S sid ="153" ssid = "56">accp swp ac gsc ov lsiz e DI FF 25/ 25 5 8 6 6 3 3 3 7 9 49 K DI FF 25/ 10 0 6 4 7 1 3 5 2 8 9 43 K DI FF 25/ 20 0 6 6 7 1 2 8 2 0 7 39 K DI FF 10 0/2 5 6 3 7 0 3 0 2 8 8 42 K DI FF 10 0/2 5 6 7 7 2 3 6 2 6 7 40 K DI FF 10 0/1 00 6 9 7 1 3 1 2 3 5 37 K DI FF 20 0/2 5 6 8 7 5 2 6 2 2 9 38 K DI FF 20 0/5 0 7 1 7 7 3 2 2 1 6 36 K d100/25= DIFF&gt;100% on S vs. O combined with DIFF&gt;25% on AC vs. SW Table 7: Diff results tested against gs-swaco Table (8) presents detailed results of the combinations of the lowest (DIFF25/25) and the highest scores (d200/50).</S>
			<S sid ="154" ssid = "57">In all settings, verbs perform considerably poorer as compared to adjectives and nouns, and AC scores low on all parts-of-speech.</S>
			<S sid ="155" ssid = "58">AN V A N V gsc ov lsiz e DI FF 25/ 25 acc 5 8 67 63 46 3 7 9 49 Kp sw 6 6 79 72 50p ac 3 3 29 41 28 DI FF 20 0/5 0 acc 7 1 75 72 66 2 1 6 36 Kp sw 7 7 84 80 68p ac 3 2 31 30 40 Table 8: Detailed DIFF results</S>
	</SECTION>
	<SECTION title="Discussion. " number = "5">
			<S sid ="156" ssid = "1">We tested our hypotheses B, C, D and E and found that they were correct, suggesting that the general idea behind the method and the design of the corpus is appropriate for the task of coarse-grained (subjective vs. objective) and fine-grained (actor vs. accspeaker/writer) subjectivity identification.</S>
			<S sid ="157" ssid = "2">We saw that the application of a log-likehood treshold to improve accuracy does not perform well, neither with respect to the identification of coarse-grained subjectivity nor with respect to the identification of fine-grained subjectivity.</S>
			<S sid ="158" ssid = "3">However, DIFF calculations perform quite well on the first task, giving high scores on subjectivity across all parts-of-speech.</S>
			<S sid ="159" ssid = "4">The identification of fine-grained subjectivity is more problematic.</S>
			<S sid ="160" ssid = "5">With the DIFF tresholds, high accuracy is achieved but this is largely due to high precision on SW subjectivity while AC subjectivity scores rather low.</S>
			<S sid ="161" ssid = "6">Whether the results are useful depends on what they are intended for.</S>
			<S sid ="162" ssid = "7">We think that coarse-grained subjectivity identification performs quite well and produces useful results without further processing.</S>
			<S sid ="163" ssid = "8">If we consider the results of the fine-grained subjectivity identification as a preliminary identification with a certain degree of errors, they may be useful for further automatic or manual processing.</S>
			<S sid ="164" ssid = "9">A closer look at the data shows that errors are due to different causes.</S>
			<S sid ="165" ssid = "10">They may be due to the fact that subjectivity labels are associated with words instead of word senses.</S>
			<S sid ="166" ssid = "11">For example, according to our gold standard zeepbel (soap bubble) is an objective word.</S>
			<S sid ="167" ssid = "12">However, in the corpus zeepbel is mostly used in the figurative and subjective sense (similar to English bubble or house of cards).</S>
			<S sid ="168" ssid = "13">This contrast between gold standard and actual use may be due to the fact that in the gold standard the annotation of the alleged most frequent sense is preferred, but it may also be caused by novel and creative uses of the word.</S>
			<S sid ="169" ssid = "14">With respect to the confusion of actor and speaker/writer subjectivity, corpus design may play a role.</S>
			<S sid ="170" ssid = "15">Many of the AC words refer to emotions.</S>
			<S sid ="171" ssid = "16">For attributed to the actor (he) in the sentence.</S>
			<S sid ="172" ssid = "17">However, these attitudes can also be attributed to the personal pronoun I , as in I am angry and I hate and in that case the combination expresses the attitude of the speaker being the I in the sentence.</S>
			<S sid ="173" ssid = "18">Thus, words typically expressing actor subjectivity, may frequently occur in news comment when explicitly attributed to the actor (I) and then be incorrectly classified by the system as SW.</S>
			<S sid ="174" ssid = "19">The resulting lexicons are rather large, ranging from 11.000 to 56.000 words.</S>
			<S sid ="175" ssid = "20">This is partly due to the fact that we used only shallow NLP techniques in the tagging and lemmatizing procedures.</S>
			<S sid ="176" ssid = "21">As a consequence, most of the lexicon items are word forms instead of lemmas.</S>
			<S sid ="177" ssid = "22">Moreover, we did not apply techniques to filter out html-tags, typos, English words, and so on.</S>
			<S sid ="178" ssid = "23">We think that, if lemmatizing and text cleaning were performed properly, the size of the lexicons may be reduced by 50 %.</S>
	</SECTION>
	<SECTION title="Comparison to other work. " number = "6">
			<S sid ="179" ssid = "1">There are some studies for English which identify objective and subjective words and word senses in a lexicon, in particular WordNet, which report high accuracy rates.</S>
			<S sid ="180" ssid = "2">For example, Su and Markert (2009) make use of both Wordnet definitions and Wordnet relations and achieve an accuracy of 84.6% on all parts-of-speech.</S>
			<S sid ="181" ssid = "3">However, these studies differ from this study as they are not aimed at finding novel words.</S>
			<S sid ="182" ssid = "4">There are many studies which perform a slightly different task to ours, by creating polarity (positive and negative) lexicons from a corpus.</S>
			<S sid ="183" ssid = "5">For example, Kaji and Kitsuregawa (2007) report 80% precision with respect to positive and negative polarity on adjective and adjective phrases extracted from a corpus.</S>
			<S sid ="184" ssid = "6">Their performance seems to be comparable with ours as we achieved 80 % accuracy with respect to all parts-of-speech (cf.</S>
			<S sid ="185" ssid = "7">table 4).</S>
			<S sid ="186" ssid = "8">To our knowledge, no comparable studies exist as far as fine-grained subjectivity classification is concerned.</S>
	</SECTION>
	<SECTION title="Conclusion. " number = "7">
			<S sid ="187" ssid = "1">In this paper we presented a method to build a fine-grained subjectivity lexicon for Dutch on the basis of three corpora.</S>
			<S sid ="188" ssid = "2">We used two different comparison measures and found that DIFF performs better than log-likelihood.</S>
			<S sid ="189" ssid = "3">The results on subjectivity identification are quite promising with accuracy rates of up to 80%.</S>
			<S sid ="190" ssid = "4">We think that the obtained subjectivity lexicon can be used in applications without further automatic or manual processing.</S>
			<S sid ="191" ssid = "5">Identification of more fine-grained type of subjectivity, i.e., actor vs. speaker/writer subjectivity proves to be more problematic.</S>
			<S sid ="192" ssid = "6">In particular, the identification of actor subjectivity scores rather low.</S>
			<S sid ="193" ssid = "7">Future work regards the development of additional techniques to improve the identification of actor subjectivity.</S>
			<S sid ="194" ssid = "8">Moreover, we will test the obtained lexicons also within sentiment analysis and opinion mining applications.</S>
	</SECTION>
	<SECTION title="Acknowledgements. " number = "8">
			<S sid ="195" ssid = "1">This research has been carried out within the project From Text To Political Positions and is funded by the VUA Interfaculty Research Institute CAMeRA.</S>
			<S sid ="196" ssid = "2">http://www2.let.vu.nl/oz/cltl/t2pp/</S>
	</SECTION>
	<SECTION title="References. " number = "9">
</PAPER>
