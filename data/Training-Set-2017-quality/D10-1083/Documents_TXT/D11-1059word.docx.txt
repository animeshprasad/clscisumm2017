A Bayesian Mixture Model for Part-of-Speech Induction
Using Multiple Features





Christos Christodoulopoulos 
School of Informatics 
University of Edinburgh 
christos.c@ed.ac.uk


Sharon Goldwater School of 
Informatics University of 
Edinburgh 
sgwater@inf.ed.ac.uk


Mark Steedman School of 
Informatics University of 
Edinburgh 
steedman@inf.ed.ac.uk










Abstract

In this paper we present a fully unsupervised 
syntactic class induction  system formulated as 
a Bayesian multinomial mixture model, where 
each word type is constrained to belong to a 
single class. By using a mixture model rather 
than a sequence model  (e.g., HMM), we are 
able to easily add multiple kinds of features, 
including those at both the type level (mor- 
phology features) and token level (context and 
alignment features, the latter from parallel cor- 
pora). Using only context features, our sys- 
tem yields results comparable to state-of-the 
art, far better than a similar model without the 
one-class-per-type constraint. Using the addi- 
tional features provides added benefit, and our 
final system outperforms  the best published 
results on most of the 25 corpora tested.


1   Introduction

Research on unsupervised learning for NLP has be- 
come widespread recently,  with part-of-speech in- 
duction, or syntactic class induction,  being a partic- 
ularly popular task.1  However, despite a recent pro- 
liferation of syntactic class induction  systems (Bie- 
mann, 2006; Goldwater  and Griffiths, 2007; John- 
son, 2007; Ravi and Knight, 2009; Berg-Kirkpatrick 
et al., 2010; Lee et al., 2010), careful compari- 
son indicates that very few systems perform better 
than some much simpler and quicker methods dating 
back ten or even twenty years (Christodoulopoulos

  1 The task is more commonly referred to as part-of-speech 
induction,  but we prefer the term syntactic class induction  since 
the induced classes may not coincide  with part-of-speech tags.


et al., 2010). This fact suggests that we should con- 
sider which features of the older systems led to their 
success, and attempt to combine these features with 
some of the machine learning methods introduced 
by the more recent systems.  We pursue this strat- 
egy here, developing  a system based on Bayesian 
methods where the probabilistic model incorporates 
several insights from previous work.
  Perhaps the most important  property of our model 
is that it is type-based, meaning that all tokens of 
a given word type are assigned to the same clus- 
ter.  This property is not strictly true of linguistic 
data,  but is a  good approximation: as  Lee et al. 
(2010)  note, assigning each word type to its most 
frequent part of speech yields an upper bound ac- 
curacy of 93% or more for most languages.  Since 
this is much better than the performance of cur- 
rent unsupervised syntactic class induction  systems, 
constraining the model in this way seems likely to 
improve  performance by reducing the number of 
parameters in the model and incorporating useful 
linguistic knowledge. Both of the older systems 
discussed by Christodoulopoulos et al. (2010), i.e., 
Clark (2003) and Brown et al. (1992), included this 
constraint and achieved very good performance rel- 
ative to token-based systems. More recently, Lee et 
al. (2010)  presented a new type-based model, and 
also reported very good results.
  A second property  of our model, which distin- 
guishes it from the type-based Bayesian model of 
Lee et al. (2010), is that the underlying probabilistic 
model is a clustering model, (specifically,  a multino- 
mial mixture  model) rather than a sequence model 
(HMM). In this sense, our model is more closely re-




638


Proceedings of the 2011 Conference on Empirical  Methods in Natural  Language Processing, pages 638–647, 
Edinburgh, Scotland, UK, July 27–31, 2011. Qc 2011 Association for Computational Linguistics


lated to several non-probabilistic  systems that clus- 
ter context vectors or lower-dimensional  represen- 
tations of them (Redington et al., 1998; Schu¨ tze,
1995; Lamar et al., 2010). Sequence models  are 
by far the most common method of supervised part- 
of-speech tagging,  and have also been widely used 
for unsupervised part-of-speech tagging both with 
and without a dictionary  (Smith  and Eisner, 2005; 
Haghighi and Klein, 2006; Goldwater and Griffiths,
2007; Johnson, 2007; Ravi and Knight,  2009; Lee et 
al., 2010).  However,  systems based on context vec- 
tors have also performed well in these latter scenar- 
ios (Schu¨ tze, 1995; Lamar et al., 2010; Toutanova 
and Johnson, 2007) and present a viable alternative 
to sequence models.
  One advantage of using a clustering model rather 
than a sequence model  is that the features used for 
clustering  need not be restricted to context words. 
Additional  types of features can easily be incorpo- 
rated into the model and inference procedure using 
the same general framework  as in the basic model 
that uses only context word features. In particu- 
lar, we present two extensions to the basic model. 
The first uses morphological  features, which serve 
as cues to syntactic  class and seemed to partly ex- 
plain the success of two best-performing  systems 
analysed by Christodoulopoulos et al. (2010). The 
second extension to our model uses alignment  fea- 
tures gathered from parallel corpora. Previous work 
suggests that using parallel  text can improve  perfor- 
mance on various unsupervised NLP tasks (Naseem 
et al., 2009; Snyder and Barzilay, 2008).
  We evaluate our model on 25 corpora in 20 lan- 
guages that vary substantially in both syntax and 
morphology. As in previous work (Lee et al., 2010), 
we find that the one-class-per-type restriction boosts 
performance considerably over a comparable token- 
based model and yields results that are comparable 
to state-of-the-art even without  the use of morphol- 
ogy or alignment features. Including morphology 
features yields the best published results on 14 or 15 
of our 25 corpora (depending on the measure) and 
alignment features can improve results further.

2   Models

Our model is a  multinomial mixture model with
Bayesian  priors over the mixing weights θ and





α 	θ





z





β	φ	f
Z 	nj
M


Figure 1: Plate diagram of the basic model with a single 
feature per token (the observed variable f ). M , Z , and 
nj  are the number of word types, syntactic  classes z, and 
features (= tokens) per word type, respectively.


multinomial class output parameters ϕ. The model 
is defined  so that all observations  associated with 
a  single word type are generated  from the same 
mixing component (syntactic class). In the basic 
model, these observations are token-level  features; 
the morphology  model  adds type-level  features as 
well. We begin by describing the simplest version of 
our model, where each word token is associated with 
a single  feature,  for example its left context word 
(the word that occurs to its left in the corpus).  We 
then show how to generalise the model to multiple 
token-level  features and to type-level features.

2.1   Basic model

In the basic model, each word token is represented 
by a  single feature  such  as its left context word. 
These features are the observed data; the model ex- 
plains the data by assuming that it has been gener- 
ated from some set of latent syntactic classes. The 
ith class is associated with a multinomial  parameter 
vector ϕi  that defines the distribution  over features 
generated from that class, and with a mixing  weight 
θi  that defines the prior probability of that class. θ 
and ϕi are drawn from symmetric Dirichlet distribu- 
tions with parameters α and β respectively.
  The generative story goes as follows: First, gen- 
erate the prior class probabilities  θ. Next, for each


word type j = 1 . . . M , choose a class assignment zj 
from the distribution  θ. For each class i = 1 . . . Z , 
choose an output distribution  over features ϕi.  Fi- 
nally, for each token k = 1 . . . nj  of word type j, 
generate a feature fjk  from ϕzj , the distribution  as- 
sociated with the class that word type j is assigned


where fj  are the features associated with word type 
j (one feature for each token of j). The first (prior) 
factor is easy to compute due to the conjugacy be- 
tween the Dirichlet and multinomial  distributions, 
and is equal to

nz + α


to. The model is illustrated graphically in Figure 1
and is defined formally as follows:


P (zj  = z | z−j , α) =
·


(3)
+ Z α


θ | α 	∼ Dirichlet(α)
zj | θ	∼ Multinomial(θ)
ϕi | β	∼ Dirichlet(β)
fjk | ϕzj    ∼ Multinomial(ϕzj )
  In addition to the variables defined above, we will 
use F to refer to the number of different possible
values a feature can take on (so that ϕ is a Z × F
matrix). Thus, one way to think of the model is as a

vector-based clustering system, where word type j is 
associated with a 1 × F vector of feature counts rep-


where nz  is the number of types in class z and n·
is the total number of word types in all classes. All

counts in this and the following equations are com- 
puted with respect to z−j  (e.g., n· = M − 1).
  Computing the second (likelihood) factor is 
slightly more complex due to the dependencies be- 
tween the different  variables in fj  that are induced 
by integrating out the ϕ parameters. Consider first a 
simple case where word type j occurs exactly twice 
in the corpus, so fj  contains two features. The prob- 
ability of the first feature fj1 is equal to
nf,z + β


resenting the features of all nj  tokens of j, and these
vectors are clustered into similar  classes. The differ-


P (fj1  = f | zj  = z, z−j , f−j , β) = n



·,z


(4)
+ F β


ence from other vector-based syntactic class induc- 
tion systems is in the method of clustering. Here, 
we define a Gibbs  sampler  that samples from the 
posterior distribution  of the clusters given the ob- 
served features;  other systems  have  used various 
standard distance-based vector clustering methods. 
Some systems also include dimensionality reduction 
(Schu¨ tze, 1995; Lamar et al., 2010) to reduce the 
size of the context vectors; we simply use the F most 
common words as context features.

2.2   Inference


where nf,z is the number of times feature f has been
seen in class z, n·,z  is the total number of feature 
tokens in the class, and F is the number of different
possible features.
  The probability of the second feature fj2  can be 
calculated similarly,  except that it is conditioned on 
fj1  in addition to the other variables, so the counts 
for previously  observed features must include the 
counts due to fj1  as well as those due to f−j . Thus, 
the probability is
P (fj2  = f | fj1, zj  = z, z−j , f−j , β)


At inference time we want to sample a syntactic 
class assignment z from the posterior of the model.


nf,z + δ(fj1, fj2) + β
=
n·,z + 1 + F β



(5)


We use a collapsed Gibbs sampler, integrating  out 
the parameters θ and ϕ and sampling from the fol- 
lowing distribution:
      P (z|f , α, β) ∝ P (z|α)P (f |z, β). 	(1) 
Rather than sampling the joint class assignment
P (z|f , α, β) directly,  the sampler iterates over each
word type j,  resampling  its class  assignment  zj
given the current assignments z−j  of all other word 
types. The posterior over zj  can be computed as


where δ is the Kronecker delta function,  equal to 1
if its arguments are equal and 0 otherwise.
  Extending this example to the general  case, the 
probability of a sequence of features fj  is computed 
using the chain rule, where the counts used in each 
factor are incremented  as necessary for each addi- 
tional conditioning  feature, yielding the following 
expression:
P (fj | f−j , zj  = z, z−j , β)


∏F 	∏njk −1


P (zj | z−j , f , α, β)
∝   P (zj | z−j , α, β)P (fj | f−j , z, α, β)   (2)


=    k=1      i=0     (njk,z  + i + β)
i=0   (n·,z + i + F β)



(6)


where njk  is the number of instances of feature k in 
word type j.2

2.3   Extended models
We can extend the model above in two different 
ways: by adding more features at the word token 
level, or by adding features at the type level. To add 
more token-level  features, we simply assume that 
each word token generates multiple features,  one 
feature from each of several different  kinds.3  For 
example, the left context word might be one kind of 
feature and the right context word another.  We as- 
sume conditional  independence between the gener- 
ated features given the syntactic class, so each kind 
of feature t has its own output parameters ϕ(t).  A 
plate diagram of the model with T kinds of features 
is shown in Figure 2 (a type-level feature is also in- 
cluded in this diagram, as described below).
  Due to the independence assumption between the 
different kinds of features, the basic Gibbs sampler 
is easy to extend to this case by simpling multiplying 
in extra factors for the additional kinds of features, 
with the prior (Equation 3) unchanged.  The likeli- 
hood becomes:
  

Note that this model with multiple context fea- 
tures is deficient: it can generate data that are in- 
consistent with any actual corpus, because there is 
no mechanism to constrain the left context word 
of token ei   to be the same  as  the right context 
word of token ei−1  (and similarly with alignment 
features).  However,  deficient  models have proven 
useful in other unsupervised NLP tasks (Klein and 
Manning,  2002; Toutanova and Johnson, 2007). In 
particular,  Toutanova and Johnson (2007) demon- 
strate good performance on unsupervised part-of- 
speech tagging (using a dictionary) with a Bayesian 
model similar to our own. If we remove the part of 
their model that relies on the dictionary (the mor- 
phological ambiguity classes), their model is equiv- 
alent to our own, without the restriction of one class 
per type. We use this token-based version of our 
model  as a baseline in our experiments.
  The final extension to our model introduces type- 
level features, specifically morphology features. 
The model is illustrated in Figure 2.  We assume 
conditional  independence between the morphology 
features and other features, so again we can simply 
multiply another factor into the likelihood during in- 
ference. There is only one morphological feature per


P (f (1)


(T )


(1...T )


j  , . . . , fj	| f−j	, zj  = z, z−j , β)
T
= ∏ P (f (t) | f (t)


type, so this factor has the form of Equation 
4. Since
frequent words will have many token-level  
features



t=1


j	−j , zj  = z, z−j 
, β)   (7)


contributing to the 
likelihood and only 
one morphol-
ogy feature, the 
morphology  
features will  have  
a



where each factor in the product is computed using
Equation 6.
  In addition to monolingual  context features, we 
also explore the use of alignment features for those 
languages where we have parallel  corpora. These 
features  are  extracted  for  language  ℓ by word-
aligning ℓ to another  language  ℓ′ (details of the
alignment  procedure are described in Section 3.1). 
The features used for each token  e in ℓ are the left 
and right context words of the word token that is 
aligned to e (if there is one). As with the mono- 
lingual  context features, we use only the F most fre-
quent words in ℓ′ as possible features.

  2 One could approximate this likelihood term by assuming 
independence between all nj   feature tokens of word type j. 
This is the approach taken by Lee et al. (2010).
     3 We use the word kind here to avoid confusion with type, 
which we reserve for the type-token distinction, which can ap- 
ply to features as well as words.


greater effect for infrequent words (as appropriate, 
since there is less evidence from context and align- 
ments). As with the other kinds of features, we use 
only a limited number Fm  of morphology features, 
as described  below.

3   Experiments

3.1   Experimental  setup

We evaluate our models using an increasing level 
of complexity, starting with a model  that uses only 
monolingual  context features. We use the F = 100 
most frequent  words as features, and consider two 
versions of this model: one with two kinds of fea- 
tures (one left and one right context word) and one 
with four (two context words on each side).
  For the model with morphology  features we ran 
the unsupervised morphological  segmentation sys- 
tem Morfessor  (Creutz and Lagus, 2005) to get a



θ	α




f (1) 	φ(1)	β(1)
z	nj	Z
. . .	. . .	. . .


m 	f (T )	φ(T )	β(T )

nj		Z 
M


φ(m)	β(m)

Z



Figure 2: Plate diagram of the extended model with T 
kinds of token-level features (f (t) variables)  and a single 
kind of type-level feature (morphology, m).


segmentation for each word type in the corpus. We 
then extracted the suffix of each word type4  and used 
it as a feature type. This process yielded on average 
Fm  = 110 morphological feature types5. Each word 
type generates at most one of these possible features. 
If there are overlapping possibilities (e.g. -ingly and
-y) we take the longest possible match.
  We also explore the idea of extending the mor- 
phology  feature space beyond suffixes,  by including 
features like capitalisation and punctuation.  Specif- 
ically we use  the features described  in Haghighi 
and Klein (2006), namely initial-capital, contains- 
hyphen, contains-digit  and we add an extra feature 
contains-punctuation.
  For the model with alignment features, we fol- 
low (Naseem et al., 2009) in using only bidirectional 
alignments: using Giza++ (Och and Ney, 2003), 
we get the word alignments in both directions be- 
tween all possible language pairs in our parallel cor- 
pora (i.e., alternating the source and target languages 
within each pair).  We  then use only those align- 
ments that are found in both directions. As discussed
  4 Since Morfessor yields multiple affixes for each word we 
concatenated all the suffixes into a single suffix.
5 There was large variance in the number of feature types for
each language ranging from 11 in Chinese to more than 350 in
German and Czech.


left and right context words of the aligned token in 
the other language.  The feature space is set to the 
F = 100 most frequent words in that language.
  Instead of fixing the hyperparameters α and β, we 
used the Metropolis-Hastings  sampler presented by 
Goldwater and Griffiths (2007) to get updated values 
based on the likelihood of the data with respect to 
those hyperparameters6. In order to improve conver- 
gence of the sampler, we used simulated annealing 
with a sigmoid-shaped cooling schedule from an ini- 
tial temperature of 2 down to 1. Preliminary experi- 
ments indicated that we could achieve better results 
by cooling even further (approximating  the MAP so- 
lution  rather than a sample from the posterior),  so for 
all experiments reported here, we ran the sampler for 
a total of 2000 iterations, with the last 400 of these 
decreasing the temperature from 1 to 0.66.
  Finally, we investigated two different initialisa- 
tion techniques: First, we use  random  class  as- 
signments to word types (referred to as method  1) 
and second, we assign each of the Z most frequent 
word types to a separate class and then  randomly 
distribute the rest of the word types to the classes 
(method 2).

3.2   Datasets
Although  unsupervised systems should in principle 
be language- and corpus-independent, most part-of- 
speech induction  systems (especially in the early lit- 
erature) have been developed on English. Whether 
because English  is simply  an easier language, or be- 
cause of bias introduced during development, these 
systems’ performance is considerably worse in other 
languages (Christodoulopoulos  et al., 2010)
  Since we aim to use our system mostly on non- 
English corpora, and ones  that are significantly 
smaller than the large English treebank corpora, we 
developed our models using one of the languages of 
the MULTEXT-East corpus (Erjavec, 2004), namely 
Bulgarian.  The other languages in the corpus were 
used during  development  as a source of word align- 
ments, but otherwise were only used for testing final 
versions of our models. Since none of the authors 
speak any of the languages in the MULTEXT col-

  6 For simplicity,  we tied the β parameters for the two or four 
kinds of context features to the same value, and similarly the β 
parameters for the two kinds of alignment features.


pus (Marcus et al., 1993) for development. Fol- 
lowing Christodoulopoulos  et al. (2010) we created 
a smaller  version  of the WSJ corpus (referred to 
as wsj-s)  to approximate  the size of the corpora in 
MULTEXT-East. For comparison to other systems, 
we also used the full WSJ at test time.
  For further testing, we used the remaining MUL- 
TEXT languages,  as well as the languages of the 
CONNL-X (Buchholz  and Marsi, 2006) shared task. 
This dataset contains  13 languages,  4 of which 
are  freely available  (Danish, Dutch, Portuguese 
and Swedish)  and 9 that are used with permission 
from the creators of the corpora ( Arabic7, Bul- 
garian8, Czech9, German10, Chinese11, Japanese12, 
Slovene13, Spanish14, Turkish15  ). Following Lee et 
al. (2010) we used only the training  sections for each 
language.
  Finally, to widen the scope of our system, we gen- 
erated two more corpora in French16   and Ancient 
Greek17, extracting the gold standard parts of speech 
from the respective dependency treebanks.

3.3   Baselines

We chose three baselines for comparison. The first 
is the basic k-means clustering algorithm, which we 
applied to the same feature vectors we extracted for 
our system (context + extended morphology),  using 
a Euclidean  distance metric. This provides  a very 
simple vector-based clustering baseline. The second 
baseline is a more recent vector-based syntactic class 
induction method, the SVD approach of (Lamar et 
al., 2010), which extends Schu¨ tze (1995)’s original 
method and, like ours, enforces a one-class-per-tag 
restriction. As a third baseline we use the system of 
Clark (2003) since it is a type-level  system that mod-

  7 Part of the Prague Arabic Treebank (Hajicˇ et al., 2003; 
Smrzˇ and Pajas, 2004)
8 Part of the BulTreeBank (Simov et al., 2004).
9 Part of the Prague Dep. Treebank (Bo¨ hmova´ et al., 2001)
10 Part of the TIGER Treebank (Brants et al., 2002)
11 Part of the Sinica Treebank (Keh-Jiann et al., 2003)
    12 Part of the Tu¨ bingen Treebank of Spoken  Japanese (for- 
merly VERMOBIL Treebank - Kawata and Bartels (2000)).
13 Part of the Slovene Dep. Treebank (Dzˇeroski et al., 2006)
14 Part of the Cast3LB Treebank (Civit et al., 2006)
15 Part of the METU-Sabanci  Treebank (Oflazer et al., 2003).
16 French Treebank (Abeille´ et al., 2000)
17 Greek Dependency Treebank (Bamman et al., 2009)


on multilingual corpora.

4   Results and Analysis

4.1   Development results

Tables 1 and 2 present the results from develop- 
ment runs, which were used to decide which fea- 
tures to incorporate in the final system. We used V- 
Measure (Rosenberg and Hirschberg,  2007) as our 
primary evaluation score, but also present many-to- 
one matching accuracy (M-1) scores for better com- 
parison with previously published results. We chose 
V-Measure (VM) as our evaluation  score because it 
is less sensitive to the number of classes induced by 
the model (Christodoulopoulos  et al., 2010), allow- 
ing us to develop our models without using the num- 
ber of classes as a parameter. We fixed the number 
of classes in all systems to 45 during development; 
note however that the gold standard tag set for Bul- 
garian contains only 12 tags, so the results in Ta- 
ble 1 (especially the M-1 scores) are not comparable 
to previous results. For results using the number of 
gold-standard tags refer to Table 4.
  The first conclusion that can be drawn from these 
results is the large difference  between the token- 
and type-based versions of our system, which con- 
firms that the one-class-per-type restriction is help- 
ful for unsupervised syntactic class induction. We 
also see that for both languages, the performance of
the model using 4 context words (±2 on each side) is
worse than the 2 context words model. We therefore
used only two context words for all of our additional 
test languages (below).
  We can clearly see that morphological  features 
are helpful in both languages; however the extended 
features of Haghighi and Klein (2006) seem to help 
only on the English data. This could be due to the 
fact that Bulgarian  has a much  richer morphology 
and thus the extra features contribute  little to the 
overall performance of the model.
  The contribution of the alignment features on the 
Bulgarian corpus (aligned with English) is less sig- 
nificant than that of morphology but when com- 
bined, the two sets of features yield the best per- 
formance. This provides evidence in favor of using 
multiple features.
Finally, initialisation method  2 does  not yield



sy
st
e
m
±
1 
w
or
d
s
V
M
/
M
-
1
±
2 
w
or
d
s
V
M
/
M
-
1
d
e
v
e
l
o
p
m
e
n
t
 
r
e
s
u
l
t
s
,
 
a
d
d
i
n
g
 
m
o
r
p
h
o
l
o
g
y
 
t
o
 
t
h
e
 
b
a
-
 
s
i
c
 
m
o
d
e
l
 
i
s
 
g
e
n
e
r
a
l
l
y
 
u
s
e
f
u
l
.
 
T
h
e
 
a
l
i
g
n
m
e
n
t
 
r
e
s
u
l
t
s
ba
se
58
.1 
/ 
70
.8
55
.4 
/ 
67
.6
a
r
e
 
m
i
x
e
d
:
 
o
n
 
t
h
e
 
o
n
e
 
h
a
n
d
,
 
c
h
o
o
s
i
n
g
 
t
h
e
 
b
e
s
t
 
p
o
s
-
ba
se
(to
ke
ns
)
48
.3 
/ 
62
.5
37
.0 
/ 
54
.4
s
i
b
l
e
 
l
a
n
g
u
a
g
e
 
t
o
 
a
l
i
g
n
 
y
i
e
l
d
s
 
i
m
p
r
o
v
e
m
e
n
t
s
,
 
w
h
i
c
h
ba
se
(in
it)
57
.6 
/ 
70
.1
56
.1 
/ 
68
.6
c
a
n
 
b
e
 
i
m
p
r
o
v
e
d
 
f
u
r
t
h
e
r
 
b
y
 
a
d
d
i
n
g
 
m
o
r
p
h
o
l
o
g
i
c
a
l
+
m
or
ph
58
.3 
/ 
74
.9
57
.4 
/ 
71
.9
f
e
a
t
u
r
e
s
,
 
r
e
s
u
l
t
i
n
g
 
i
n
 
t
h
e
 
b
e
s
t
 
s
c
o
r
e
s
 
o
f
 
a
l
l
 
m
o
d
e
l
s
+
m
or
ph
(e
xt)
57
.8 
/ 
73
.7
57
.8 
/ 
70
.1
f
o
r
 
m
o
s
t
 
l
a
n
g
u
a
g
e
s
.
	On the other hand,  without
(in
it)
+
m
or
ph
57
.8 
/ 
74
.3
57
.3 
/ 
69
.5
k
n
o
w
i
n
g
 
w
h
i
c
h
 
l
a
n
g
u
a
g
e
 
t
o
 
c
h
o
o
s
e
,
 
a
l
i
g
n
m
e
n
t
 
f
e
a
-
(in
it)
+
m
or
ph
(e
xt)
58
.1 
/ 
74
.3
57
.2 
/ 
71
.3
t
u
r
e
s
 
d
o
 
n
o
t
 
h
e
l
p
 
o
n
 
a
v
e
r
a
g
e
.
  
W
e
 
n
o
t
e
,
 
h
o
w
e
v
e
r
,
+a
lig
ns
(E
N)
58
.1 
/ 
72
.6
56
.7 
/ 
71
.1
t
h
a
t
 
t
h
r
e
e
 
o
u
t
 
o
f
 
t
h
e
 
s
e
v
e
n
 
l
a
n
g
u
a
g
e
s
 
h
a
v
e
 
E
n
g
l
i
s
h
+a
lig
ns
(E
N)
+
m
or
ph
59
.0 
/ 
75
.4
57
.5 
/ 
69
.7
a
s
 
t
h
e
i
r
 
b
e
s
t
-
a
l
i
g
n
e
d
 
p
a
i
r
 
(
p
e
r
h
a
p
s
 
d
u
e
 
t
o
 
i
t
s
 
b
e
t
t
e
r



Table 1: V-measure (VM) and many-to-one (M-1) results 
on the MULTEXT-Bulgarian corpus for various mod-
els using either ±1 or ±2 context words as features.
base: context features only; (tokens): token-based model;
(init): Initialisation  method 2—other results use method
1; (ext): Extended morphological  features.

sy
st
e
m
±
1 
w
or
d
s
V
M
/
M
-
1
±
2 
w
or
d
s
V
M
/
M
-
1
ba
se
63
.3 
/ 
64
.3
62
.4 
/ 
63
.3
ba
se
(to
ke
ns
)
48
.6 
/ 
57
.8
49
.3 
/ 
38
.3
ba
se
(in
it)
62
.7 
/ 
62
.9
62
.2 
/ 
62
.4
+
m
or
ph
66
.4 
/ 
66
.7
65
.1 
/ 
67
.2
+
m
or
ph
(e
xt)
67
.7 
/ 
72
.0
65
.6 
/ 
67
.0
(in
it)
+
m
or
ph
64
.8 
/ 
66
.9
64
.2 
/ 
66
.0
(in
it)
+
m
or
ph
(e
xt)
67
.4 
/ 
71
.3
65
.7 
/ 
67
.1

Table 2: V-measure and many-to-one results on the wsj-s 
corpus for various models, as described in Table 1.
.


consistent improvements  over the standard ran- 
dom initialisation—if  anything, it seems to perform 
worse. We therefore use only method 1 in the re- 
maining experiments.

4.2   Overall results

Table 3 presents the results on our parallel corpora. 
We tested all possible combinations of two lan- 
guages to align, and present both the average score 
over all alignments, and the score under  the best 
choice of aligned language.18   Also shown are the 
results of adding morphology  features to the basic 
model (context features only) and to the best align- 
ment model for each language.  In accord with our

  18 The choice of language was based on the same test data, so 
the ‘best-language’ results should be viewed as oracle scores.


overall scores), which suggests that in the absence
of other knowledge, aligning with English may be a 
good choice.
  The low average performance  of the alignment 
features is disappointing, but there are many  
pos- sible variations on our method for extracting  
these features that we have not yet tested.  For 
example, we used only bidirectional alignments in 
an effort to improve alignment precision, but these 
alignments typically cover less than 40% of 
tokens.  It is pos- sible that a higher-recall  set of 
alignments could be more useful.
  We turn now to our results on all 25 corpora, 
shown in Table 4 along with corpus statistics, base- 
line results, and the best published  results for each 
language  (when available).    Our system,  
includ- ing morphology  features in all cases,  is 
listed as BMMM  (Bayesian  Multinomial Mixture 
Model). We do not include alignment features for 
the MUL- TEXT languages since these features 
only yielded improvements for the oracle case 
where we know which aligned language to choose. 
Nevertheless, our MULTEXT scores mostly 
outperform  all other sys- tems. Overall, we 
acheive the highest published re- sults on 14 (VM) 
or 15 (M-1) of the 25 corpora.
  One surprising discovery is the high performance 
of the k-means clustering system.  Despite its sim- 
plicity, it is competitive with the other systems 
and in a few cases even achieves the best 
published  re- sults.

5   Conclusion

We have presented a Bayesian model  for syntactic 
class induction  that has two important  properties. 
First, it is type-based, assigning the same class to 
every token of a word type.  We have shown by




La
n
g.
B
A
S
E
A
L
I
G
N
M
E
N
T
S

b
a
s
e
	
+
m
o
r
p
h
V
M
/
M
-
1
 	VM/M-1
A
v
g
.
	
B
e
s
t
	
+
m
o
r
p
h
V
M
/
M
-
1 	VM/M1 	VM/M1
B
ul
ga
ria
n
C
z
e
c
h 
E
n
gl
is
h 
E
st
o
ni
a
n 
H
u
n
g
ar
ia
n 
R
o
m
a
ni
a
n 
Sl
o
v
e
n
e 
S
e
r
bi
a
n
54
.4 
/ 
61
.5	54.5 / 64.3
54
.2 
/ 
58
.9	53.9 / 64.2
62
.9 
/ 
72
.4	63.3 / 73.3
52
.8 
/ 
63
.5	53.3 / 67.4
53
.3 
/ 
60
.4	54.8 / 68.2
53
.9 
/ 
62
.4	52.3 / 61.1
57
.2 
/ 
65
.9	56.7 / 67.9
49
.1 
/ 
56
.6	49.0 / 62.0
53
.1 
/ 
60
.5	55.2 / 64.5(EN)	55.7 / 66.0
52
.6 
/ 
58
.4	53.8 / 59.7(EN)	55.4 / 66.4
62
.5 
/ 
72
.0	63.2 / 71.9(HU)	63.5 / 73.7
52
.8 
/ 
63
.9	53.5 / 65.0(EN)	54.3 / 66.9
53
.3 
/ 
60
.8	53.9 / 61.1(RO)	55.9 / 67.1
56
.2 
/ 
63
.7	57.5 / 64.6(ES)	54.5 / 63.4
54
.7 
/ 
64
.1	55.9 / 64.4(HU)	56.7 / 67.9
47
.3 
/ 
55
.6	48.9 / 59.4(CZ)	48.3 / 60.8


Table 3: V-measure (VM) and many-to-one  (M-1) results on the languages in the MULTEXT-East  corpus using 
the gold standard number of classes shown  in Table 4. BASE results use ±1-word  context features alone or with
morphology. ALIGNMENTS adds alignment features, reporting  the average score across all possible choices of paired 
language and the scores under the best performing paired language (in parens), alone or with morphology features.


La
ng
ua
ge
T
y
p
e
s	Tags
k-
m
e
a
n
s	SVD2	clark	Best Pub.	BMMM
W
SJ
ws
j
ws
j-s
4
9,
1
9
0	45
1
6,
8
5
0	45
59
.5 
/ 
61
.6	58.2 / 64.0	65.6 / 71.2	68.8 / 76.1∗	66.1 / 72.8
56
.7 
/ 
60
.1	54.3 / 60.7	63.8 / 68.8	62.3 / 70.7∗	67.7 / 72.0
M
U
L
T
E
X
T
-
E
a
s
t
Bu
lg
ari
an
C
z
e
c
h 
E
n
g
li
s
h 
E
s
t
o
n
i
a
n 
H
u
n
g
a
ri
a
n 
R
o
m
a
n
i
a
n 
S
l
o
v
e
n
e 
S
e
r
b
i
a
n
1
6,
3
5
2	12
1
9,
1
1
5	12
9
,
7
7
3	12
1
7,
8
4
5	11
2
0,
3
2
1	12
1
5,
1
8
9	14
1
7,
8
7
1	12
1
8,
0
9
5	12
50
.3 
/ 
59
.3	41.7 / 51.0	55.6 / 66.5	- 	54.5 / 64.4
48
.6 
/ 
56
.7	35.5 / 50.9	52.6 / 64.1	- 	53.9 / 64.2
56
.5 
/ 
65
.4	52.3 / 65.5	60.5 / 70.6	- 	63.3 / 73.3
45
.3 
/ 
55
.6	38.7 / 55.3	44.4 / 58.4	- 	53.3 / 64.4
46
.7 
/ 
53
.9	39.8 / 49.5	48.9 / 61.4	- 	54.8 / 68.2
45
.2 
/ 
55
.1	42.1 / 52.6	40.9 / 49.9	- 	52.3 / 61.1
46
.9 
/ 
56
.2	39.5 / 54.2	54.9 / 69.4	- 	56.7 / 67.9
41
.4 
/ 
47
.0	39.1 / 54.6	51.0 / 64.1	- 	49.0 / 62.0
C
o
N
L
L
0
6
 
S
h
a
r
e
d
 
T
a
s
k
Ar
ab
ic
B
ul
g
a
ri
a
n 
C
hi
n
e
s
e 
C
z
e
c
h 
D
a
ni
s
h 
D
ut
c
h 
G
e
r
m
a
n 
J
a
p
a
n
e
s
e 
P
or
tu
g
u
e
s
e 
S
lo
v
e
n
e 
S
p
a
ni
s
h 
S
w
e
di
s
h 
T
u
rk
is
h
1
2,
9
1
5	20
3
2,
4
3
9	54
4
0,
5
6
2	15
1
3
0
,
2
0
8
	12
1
8,
3
5
6	25
2
8,
3
9
3	13
7
2,
3
2
6	54
3
,
2
3
1
	80
2
8,
9
3
1	22
7
,
1
2
8
	29
1
6,
4
5
8	47
2
0,
0
5
7	41
1
7,
5
6
3	30
43
.3 
/ 
60
.7	27.6 / 49.0	40.6 / 59.8	- 	42.4 / 61.5
53
.6 
/ 
65
.6	49.0 / 65.3	59.6 / 70.4	- 	58.8 / 68.9
32
.6 
/ 
61
.1	24.5 / 54.6	31.8 / 56.7	- 	42.6 / 69.4
-
 
	
-
 
	
4
7
.
1
 
/
 
6
5
.
5
	
-
 
	
4
8
.
4
 
/
 
6
5
.
7
51
.7 
/ 
61
.6	40.8 / 57.6	52.7 / 65.3	- / 66.7†	59.0 / 71.1
45
.3 
/ 
60
.5	36.7 / 52.4	52.2 / 67.9	- / 67.3‡	54.7 / 71.1
58
.7 
/ 
67
.5	54.1 / 64.2	63.0 / 73.9	- / 68.4‡	61.9 / 74.4
76
.1 
/ 
76
.2	74.4 / 75.5	78.6 / 77.4	- 	77.4 / 78.5
51
.6 
/ 
64
.4	45.9 / 63.1	57.4 / 69.2	- / 75.3†	63.9 / 76.8
52
.6 
/ 
64
.2	44.0 / 60.3	53.9 / 63.5	- 	49.4 / 56.2
59
.5 
/ 
69
.2	54.8 / 68.2	61.6 / 71.9	- / 73.2†	63.2 / 71.7
53
.2 
/ 
62
.2	47.4 / 59.1	58.9 / 68.7	- / 60.6‡	58.0 / 68.2
40
.8 
/ 
62
.8	27.4 / 52.4	36.8 / 58.1	- 	40.2 / 58.7

Fr
en
ch
A.
Gr
ee
k
4
9,
9
6
4	23
1
5,
1
9
4	15
48
.2 
/ 
68
.6	46.3 / 68.5	57.3 / 77.8	- 	55.0 / 76.6
38
.6 
/ 
44
.8	24.2 / 38.5	33.3 / 45.4	- 	40.5 / 45.1

Table 4: Final results on 25 corpora in 20 languages, with the number of induced  classes equal to the number of gold 
standard tags in all cases. k-means and SVD2  models could not produce a clustering  in the Czech CoNLL corpus due
its size. Best published results are from ∗Christodoulopoulos et al. (2010), †Berg-Kirkpatrick et al. (2010) and ‡Lee
et al. (2010). The latter two papers do not report VM scores. No best published results are shown for the MULTEXT 
languages; Christodoulopoulos  et al. (2010) report results based on 45 tags suggesting that clark performs  best on 
these corpora.


comparison with a token-based version of the model 
that this restriction is very helpful.  Second, it is 
a clustering  model rather than a sequence  model. 
This property  makes it easy to incorporate multi- 
ple kinds of features into the model at either the to- 
ken or the type level. Here, we experimented with 
token-level  context features and alignment features 
and type-level  morphology  features, showing that 
morphology features are helpful in nearly all cases, 
and alignment features can be helpful  if the aligned 
language is properly chosen. Our results even with- 
out these extra features are competitive  with state- 
of-the-art; with the additional  features we achieve 
the best published results in the majority of the 25 
corpora tested.
  Since it is so easy to add extra features to our 
model, one direction  for future work is to explore 
other possible features. For example, it could be 
useful to add dependency features from an unsuper- 
vised dependency parser.  We are also interested in 
improving our morphology features, either by con- 
sidering other ways to extract features during pre- 
processing (for example, including  prefixes or not 
concatenating together all suffixes), or by develop- 
ing a joint model for inducing both morphology and 
syntactic  classes simultaneously. Finally, our model 
could be extended by replacing the standard mixture 
model with an infinite mixture  model (Rasmussen,
2000) in order to induce the number of syntactic 
classes automatically.

Acknowledgments

The authors would like to thank Emily Thomforde, 
Ioannis Konstas, Tom Kwiatkowski  and the anony- 
mous reviewers for their comments and suggestions. 
We would also like to thank Kiril Simov, Toni Marti, 
Tomaz  Erjavec,  Jess Lin and Kathrin Beck for pro- 
viding us with CoNLL data. This work was sup- 
ported by an EPSRC graduate Fellowship,  and by 
ERC Advanced Fellowship 249520 GRAMPLUS.


References

Anne Abeille´, Lionel Cle´ment, and Alexandra  Kinyon.
2000. Building a treebank  for French. In In Proceed- 
ings of the LREC 2000.
David Bamman, Francesco  Mambrini,  and Gregory
Crane. 2009. An ownership model of annotation: The


Ancient Greek dependency treebank. In TLT 2009- 
Eighth International Workshop on Treebanks and Lin- 
guistic Theories.
Taylor Berg-Kirkpatrick, Alexandre B. Coˆ te´, John DeN- 
ero, and Dan Klein.   2010.  Painless unsupervised 
learning with features.  In Proceedings of NAACL
   2010, pages 582–590, Los Angeles, California, June. 
Chris Biemann. 2006. Unsupervised part-of-speech tag-
ging employing efficient graph clustering. In Proceed-
ings of COLING  ACL 2006, pages 7–12, Morristown, 
NJ, USA.
Alena Bo¨ hmova´,  Jan Hajicˇ, Eva Hajicˇova´, and Barbora 
Hladka´.    2001.  The Prague dependency treebank: 
Three-level annotation scenario. In Anne Abeille´, ed- 
itor, Treebanks: Building and Using Syntactically An- 
notated Corpora,  pages 103 – 126. Kluwer Academic 
Publishers.
Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolfgang 
Lezius, and George Smith. 2002. The TIGER tree- 
bank. In Proceedings of the Workshop on Treebanks 
and Linguistic Theories, Sozopol.
Peter F. Brown,  Vincent J. Della Pietra, Peter V. Desouza, 
Jennifer C. Lai, and Robert L. Mercer. 1992. Class- 
based n-gram models of natural language. Computa- 
tional Linguistics, 18(4):467–479.
Sabine Buchholz  and Erwin Marsi.   2006.  CoNLL- 
X shared  task on multilingual dependency parsing. 
In Proceedings of the Tenth Conference on Compu- 
tational Natural Language Learning, CoNLL-X ’06, 
pages 149–164,  Stroudsburg,  PA,  USA. Association 
for Computational Linguistics.
Christos Christodoulopoulos,  Sharon Goldwater, and 
Mark Steedman. 2010. Two decades of unsupervised 
POS induction:  How far have we come? In Proceed- 
ings of the 2010 Conference on Empirical  Methods in 
Natural Language Processing, pages 575–584, Cam- 
bridge, MA, October. Association for Computational 
Linguistics.
Montserrat Civit, Ma. Mart´ı, and Nu´ ria Buf´ı.	2006.
Cat3lb and cast3lb: From constituents to dependen- 
cies. In Tapio Salakoski, Filip Ginter, Sampo Pyysalo, 
and Tapio Pahikkala,  editors, Advances  in Natural 
Language Processing, volume 4139 of Lecture Notes 
in Computer Science, pages 141–152. Springer Berlin
/ Heidelberg.
Alexander Clark.  2003. Combining distributional and 
morphological information for part of speech induc- 
tion.   In Proceedings of EACL 2003, pages 59–66, 
Morristown, NJ, USA.
Mathias Creutz and Krista Lagus.    2005.    Induc- 
ing the morphological lexicon of a natural  language 
from unannotated text.   In In Proceedings of the 
International and Interdisciplinary Conference  on


Adaptive  Knowledge  Representation and Reasoning
(AKRR’05), volume 5, pages 106–113.
Sasˇo Dzˇeroski,  Tomazˇ Erjavec, Nina Ledinek,  Petr Pajas, 
Zdenek Zˇ abokrtsky, and Andreja Zˇ ele. 2006. Towards 
a Slovene  dependency  treebank. In Proceedings Int. 
Conf. on Language Resources and Evaluation (LREC).
Tomazˇ Erjavec.  2004. MULTEXT-East version 3: Mul- 
tilingual morphosyntactic specifications, lexicons and 
corpora.  In Fourth International  Conference on Lan- 
guage Resources and Evaluation,  (LREC’04),  pages
1535 – 1538, Paris. ELRA.
Sharon Goldwater  and Tom Griffiths.  2007.  A fully 
bayesian approach to unsupervised part-of-speech tag- 
ging.  In Proceedings of ACL 2007, pages 744–751, 
Prague, Czech Republic, June.
Aria Haghighi  and Dan Klein.  2006. Prototype-driven 
learning for sequence  models.   In Proceedings  of 
NAACL  2006, pages 320–327, Morristown, NJ, USA.
Jan Hajicˇ, Jarmila Panevova´, Zdenˇ ka Uresˇova´, Alevtina 
Be´mova´,  and Petr Pajas.  2003. PDTVALLEX: cre- 
ating a large-coverage  valency  lexicon for treebank 
annotation.  In Proceedings of The Second Workshop 
on Treebanks and Linguistic Theories, pages 57–68. 
Vaxjo University Press.
Mark Johnson. 2007. Why doesn’t EM find good HMM 
POS-taggers?	In Proceedings of EMNLP-CoNLL
   2007, pages 296–305, Prague, Czech Republic,  June. 
Yasushira Kawata and Julia Bartels. 2000. Stylebook
for the Japanese treebank  in VERMOBIL.  Technical
report, Universita¨t Tu¨ ubingen.
Chen Keh-Jiann, Chu-Ren Huang, Feng-Yi Chen, Chi- 
Ching Luo, Ming-Chung  Chang, Chao-Jan Chen, and 
Zhao-Ming Gao. 2003. Sinica treebank: Design cri- 
teria, representational issues and implementation.   In 
Anne Abeille´,  editor, Treebanks:  Building and Us- 
ing Syntactically  Annotated Corpora,  pages 231–248. 
Kluwer Academic Publishers.
Dan Klein and Christopher D. Manning. 2002. A gener- 
ative constituent-context model for improved grammar 
induction. In Proceedings of ACL 40, pages 128–135.
Michael Lamar, Yariv Maron, Mark Johnson, and Elie 
Bienenstock.  2010. SVD and clustering for unsuper- 
vised POS tagging. In Proceedings of the ACL 2010
Conference  Short Papers,  pages 215–219,  Strouds- 
burg, PA, USA. Association for Computational Lin- 
guistics.
Yoong Keok Lee, Aria Haghighi,  and Regina Barzilay.
2010. Simple type-level unsupervised POS tagging. 
In Proceedings of the 2010 Conference on Empirical 
Methods in Natural Language  Processing,  EMNLP
’10, pages 853–861, Stroudsburg, PA, USA. Associ- 
ation for Computational Linguistics.


Mitchell Marcus, Beatrice Santorini, and Mary Ann 
Marcinkiewicz.  1993. Building a large annotated cor- 
pus of English: the Penn Treebank. Computational 
Linguistics, 19(2):331–330.
Tahira Naseem, Benjamin Snyder, Jacob Eisenstein, and 
Regina Barzilay. 2009. Multilingual Part-of-Speech 
tagging: Two unsupervised approaches. Journal of Ar- 
tificial Intelligence  Research, 36:341–385.
Franz  J. Och and Hermann Ney.  2003. A systematic 
comparison of various statistical alignment models. 
Comput. Linguist., 29(1):19–51.
Kemal Oflazer,  Bilge Say, Dilek Z. Hakkani-Tu¨ r, and 
Go¨ khan Tu¨ r, 2003.   Building A Turkish Treebank, 
chapter 1, pages 1–17. Kluwer Academic Publishers.
Carl Rasmussen.   2000. The infinite Gaussian mixture 
model. In Advances in Neural Information Processing 
Systems 12.
Sujith Ravi and Kevin Knight. 2009. Minimized mod- 
els for unsupervised Part-of-Speech tagging. In Pro- 
ceedings of ACL-IJCNLP 2009, pages 504–512, Sun- 
tec, Singapore, August.
Martin Redington, Nick Chater, and Steven Finch.  1998.
Distributional  information:  a powerful cue for acquir- 
ing syntactic categories. Cognitive Science, 22:425 –
469.
Andrew Rosenberg  and Julia Hirschberg.  2007.  V- 
measure:  A conditional  entropy-based external clus- 
ter evaluation measure. In Proceedings of EMNLP- 
CoNLL  2007, pages 410–420.
Hinrich Schu¨ tze.  1995.  Distributional  part-of-speech 
tagging. In Proceedings of EACL 7, pages 141–148, 
San Francisco, CA, USA.
Kiril Simov, Petya Osenova, Alexander Simov, and Milen 
Kouylekov. 2004. Design and implementation  of the 
Bulgarian  HPSG-based treebank. Research on Lan- 
guage &amp; Computation, 2(4):495–522.
Noah A. Smith and Jason Eisner.  2005.  Contrastive  esti- 
mation: training log-linear models on unlabeled data. 
In Proceedings of ACL 2005, pages 354–362, Morris- 
town, NJ, USA.
Otakar Smrzˇ and Petr Pajas. 2004. Morphotrees of Ara- 
bic and their annotation in the TrEd environment.  In 
Proceedings of the NEMLAR International Conference 
on Arabic Language Resources and Tools, pages 38–
41.
Ben Snyder and Regina Barzilay. 2008. Unsupervised 
multilingual learning for morphological segmentation. 
In Proceedings of ACL.
Kristina Toutanova  and Mark Johnson.   2007.    A 
Bayesian LDA-based model for semi-supervised part- 
of-speech tagging. In Proceedings of NIPS 2007.










