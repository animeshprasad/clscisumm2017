<S sid ="0">Estimation of Conditional ProbabilitiesWith Decision Trees and an Application to Fine-Grained POS Tagging</S>
<S sid ="1" ssid = "1">We present a HMM part-of-speech tagging method which is particularly suited for POS tagsets with a large number of fine-grained tags.</S>
<S sid ="4" ssid = "4">A Hidden-Markov-Model part-of-speech tagger (Brants, 2000, e.g.) computes the most probable POS tag sequence tË†N = tË†1, ..., tË†N for a given word sequence wN . POS taggers are usually trained on corpora with between 50 and 150 different POS tags.</S>
<S sid ="5" ssid = "5">Tagsets of this size contain little or no information about number, gender, case and similar morphosyntac- tic features.</S>
<S sid ="6" ssid = "6">For languages with a rich morphology such as German or Czech, more fine-grained tagsets are often considered more appropriate.</S>
<S sid ="12" ssid = "12">The German Tiger treebank (Brants et al., 2002) is an example of a corpus with a more fine-grained tagset (over 700 tags overall).</S>
<S sid ="54" ssid = "15">The probability of an attribute (such as â€œNomâ€) is always conditioned on the respective base POS (such as â€œNâ€) (unless the predicted attribute is theFigure 1: Probability estimation tree for the nomi native case of nouns.</S>
<S sid ="59" ssid = "20">Our tagger generates a predictor for each feature (such as base POS, number, gender etc.) Instead of using a single tree for the prediction of all possible values of a feature (such as noun, article, etc. for base POS), the tagger builds a separate decision tree for each value.</S>
<S sid ="68" ssid = "29">A typical context attribute is â€œ1:ART.Nomâ€ which states that the preceding tag is an article with the attribute â€œNomâ€.</S>
<S sid ="95" ssid = "1">Our tagger is a HMM tagger which decomposes the context probabilities into a product of attribute probabilities.</S>
<S sid ="100" ssid = "6">The tagger may use an external lexicon which supplies entries for additional words which are not found in the training corpus, and additional tags for words which did occur in the training data.</S>
<S sid ="124" ssid = "4">We took standard features from a 5 word window and M4LRL training without optimization of the regular- ization parameter C</S>
<S sid ="127" ssid = "7">It is annotated with POS tags from the coarse-grained STTS tagset and with additional features encoding information about number, gender, case, person, degree, tense, and mood.</S>
<S sid ="167" ssid = "47">3 9 97.57 97.97 Table 3: STTS accuracies of the TnT tagger trained on the STTS tagset, the TnT tagger trained on the Tiger tagset, and our tagger trained on the Tiger tagset.</S>
<S sid ="224" ssid = "1">We presented a HMM POS tagger for fine-grained tagsets which splits the POS tags into attribute vectors and estimates the conditional probabilities of the attributes with decision trees.</S>