<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">We describe an unsupervised system for learning narrative schemas, coherent sequences or sets of events (arrested(POLICE,SUSPECT), convicted( JUDGE, SUSPECT)) whose arguments are filled with participant semantic roles defined over words (JUDGE = {judge, jury, court}, POLICE = {police, agent, authorities}).</S>
		<S sid ="2" ssid = "2">Unlike most previous work inevent structure or semantic role learning, our system does not use supervised techniques, hand-built knowledge, or predefined classes of events or roles.</S>
		<S sid ="3" ssid = "3">Our unsupervised learning algorithm uses corefer- ring arguments in chains of verbs to learn both rich narrative event structure and argument roles.</S>
		<S sid ="4" ssid = "4">By jointly addressing both tasks, we improve on previous results in narrative/frame learning and induce rich frame-specific semantic roles.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="5" ssid = "5">be learned.</S>
			<S sid ="6" ssid = "6">Even unsupervised attempts to learn semantic roles have required a pre defined set of roles (Grenager and Manning, 2006) and often a hand-labeled seed corpus (Swier and Stevenson, 2004; He and Gildea, 2006).</S>
			<S sid ="7" ssid = "7">In this paper, we describe our attempts to learn script-like information about the world, including both event structures and the roles of their participants, but without pre defined frames, roles, or tagged corpora.</S>
			<S sid ="8" ssid = "8">Consider the following Narrative Schema, to be defined more formally later.</S>
			<S sid ="9" ssid = "9">The events on the left follow a set of participants through a series of connected events that constitute a narrative: Events Roles This paper describes a new approach to event semantics that jointly learns event relations and their A search B A arrest B B plead C A = Police B = Suspect C = Plea participants from unlabeled corpora.</S>
			<S sid ="10" ssid = "10">The early years of natural language processing (NLP) took a “top-down” approach to language D acquit B D convict B D sentence B D = Jury understanding, using representations like scripts (Schank and Abelson, 1977) (structured representations of events, their causal relationships, and their participants) and frames to drive interpretation of syntax and word use.</S>
			<S sid ="11" ssid = "11">Knowledge structures such as these provided the interpreter rich information about many aspects of meaning.</S>
			<S sid ="12" ssid = "12">The problem with these rich knowledge structures is that the need for hand construction, specificity, and domain dependence prevents robust and flexible language understanding.</S>
			<S sid ="13" ssid = "13">Instead, modern work on understanding has focused on shallower representations like semantic roles, which express at least one aspect of the semantics of events and have proved amenable to supervised learning from corpora like PropBank (Palmer et al., 2005) and Framenet (Baker et al., 1998).</S>
			<S sid ="14" ssid = "14">Unfortunately, creating these supervised corpora is an expensive and difficult multi-year effort, requiring complex decisions about the exact set of roles to Being able to robustly learn sets of related events (left) and frame-specific role information about the argument types that fill them (right) could assist a variety of NLP applications, from question answering to machine translation.</S>
			<S sid ="15" ssid = "15">Our previous work (Chambers and Jurafsky, 2008) relied on the intuition that in a coherent text, any two events that are about the same participants are likely to be part of the same story or narrative.</S>
			<S sid ="16" ssid = "16">The model learned simple aspects of narrative structure (‘narrative chains’) by extracting events that share a single participant, the protagonist.</S>
			<S sid ="17" ssid = "17">In this paper we extend this work to represent sets of situation-specific events not unlike scripts, caseframes (Bean and Riloff, 2004), and FrameNet frames (Baker et al., 1998).</S>
			<S sid ="18" ssid = "18">This paper shows that verbs in distinct narrative chains can be merged into an improved single narrative schema, while the shared arguments across verbs can provide rich information for inducing semantic roles.</S>
			<S sid ="19" ssid = "19">602 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 602–610, Suntec, Singapore, 27 August 2009.</S>
			<S sid ="20" ssid = "20">Qc 2009 ACL and AFNLP</S>
	</SECTION>
	<SECTION title="Background. " number = "2">
			<S sid ="21" ssid = "1">This paper addresses two areas of work in event semantics, narrative event chains and semantic role labeling.</S>
			<S sid ="22" ssid = "2">We begin by highlighting areas in both that can mutually inform each other through a narrative schema model.</S>
			<S sid ="23" ssid = "3">2.1 Narrative Event Chains.</S>
			<S sid ="24" ssid = "4">Narrative Event Chains are partially ordered sets of events that all involve the same shared participant, the protagonist (Chambers and Jurafsky, 2008).</S>
			<S sid ="25" ssid = "5">A chain contains a set of verbs representing events, and for each verb, the grammatical role filled by the shared protagonist.</S>
			<S sid ="26" ssid = "6">An event is a verb together with its constellation of arguments.</S>
			<S sid ="27" ssid = "7">An event slot is a tuple of an event and a particular argument slot (grammatical rela tion), represented as a pair (v, dl where v is a verband d ∈ {subject, object, prep}.</S>
			<S sid ="28" ssid = "8">A chain is a tu ple (L, O) where L is a set of event slots and O is a partial (temporal) ordering.</S>
			<S sid ="29" ssid = "9">We will write event slots in shorthand as (X pleads) or (pleads X) for (pleads, subjectl and (pleads, objectl.</S>
			<S sid ="30" ssid = "10">Below is an example chain modeling criminal prosecution.</S>
			<S sid ="31" ssid = "11">L = (X pleads), (X admits), (convicted X), (sentenced X) Our previous work, however, has two major limitations.</S>
			<S sid ="32" ssid = "12">First, the model did not express any information about the protagonist, such as its type or role.</S>
			<S sid ="33" ssid = "13">Role information (such as knowing whether a filler is a location, a person, a particular class of people, or even an inanimate object) could crucially inform learning and inference.</S>
			<S sid ="34" ssid = "14">Second, the model only represents one participant (the protagonist).</S>
			<S sid ="35" ssid = "15">Representing the other entities involved in all event slots in the narrative could potentially provide valuable information.</S>
			<S sid ="36" ssid = "16">We discuss both of these extensions next.</S>
			<S sid ="37" ssid = "17">2.1.1 The Case for Arguments The Chambers and Jurafsky (2008) narrative chains do not specify what type of argument fills the role of protagonist.</S>
			<S sid ="38" ssid = "18">Chain learning and clustering is based only on the frequency with which two verbs share arguments, ignoring any features of the arguments themselves.</S>
			<S sid ="39" ssid = "19">Take this example of an actual chain from an article in our training data.</S>
			<S sid ="40" ssid = "20">Given this chain of five events, we want to choose other events most likely to occur in this scenario.</S>
			<S sid ="41" ssid = "21">hunt use O = {(pleads, convicted), (convicted, sentenced), ...}</S>
			<S sid ="42" ssid = "22">A graphical view is often more intuitive: suspect accuse fly ? charge admits pleads convicted sentenced (X admits) (X pleads) (convicted X) (sentenced X) search One of the top scoring event slots is (fly X).</S>
			<S sid ="43" ssid = "23">Narrative chains incorrectly favor (fly X) because it is observed during training with all five event slots, although not frequently with any one of them.</S>
			<S sid ="44" ssid = "24">An In this example, the protagonist of the chain is the person being prosecuted and the other unspecified event slots remain unfilled and uncon- strained.</S>
			<S sid ="45" ssid = "25">Chains in the Chambers and Jurafsky (2008) model are ordered; in this paper rather than address the ordering task we focus on event and argument induction, leaving ordering as future work.</S>
			<S sid ="46" ssid = "26">The Chambers and Jurafsky (2008) model learns chains completely unsupervised, (albeit after parsing and resolving coreference in the text) by counting pairs of verbs that share corefer- ring arguments within documents and computing the pointwise mutual information (PMI) between these verb-argument pairs.</S>
			<S sid ="47" ssid = "27">The algorithm creates chains by clustering event slots using their PMI scores, and we showed this use of co-referring arguments improves event relatedness.</S>
			<S sid ="48" ssid = "28">event slot like (charge X) is much more plausible, but is unfortunately scored lower by the model.</S>
			<S sid ="49" ssid = "29">Representing the types of the arguments can help solve this problem.</S>
			<S sid ="50" ssid = "30">Few types of arguments are shared between the chain and (fly X).</S>
			<S sid ="51" ssid = "31">However, (charge X) shares many arguments with (accuse X), (search X) and (suspect X) (e.g., criminal and suspect).</S>
			<S sid ="52" ssid = "32">Even more telling is that these arguments are jointly shared (the same or coreferent) across all three events.</S>
			<S sid ="53" ssid = "33">Chains represent coherent scenarios, not just a set of independent pairs, so we want to model argument overlap across all pairs.</S>
			<S sid ="54" ssid = "34">2.1.2 The Case for Joint Chains The second problem with narrative chains is that they make judgments only between protagonist arguments, one slot per event.</S>
			<S sid ="55" ssid = "35">All entities and slots in the space of events should be jointly considered when making event relatedness decisions.</S>
			<S sid ="56" ssid = "36">As an illustration, consider the verb arrest.</S>
			<S sid ="57" ssid = "37">Which verb is more related, convict or capture?</S>
			<S sid ="58" ssid = "38">A narrative chain might only look at the objects of these verbs and choose the one with the highest score, usually choosing convict.</S>
			<S sid ="59" ssid = "39">But in this case the subjects offer additional information; the subject of arrest (police) is different from that of convict (judge).</S>
			<S sid ="60" ssid = "40">A more informed decision prefers capture because both the objects (suspect) and subjects (police) are identical.</S>
			<S sid ="61" ssid = "41">This joint reasoning is absent from the narrative chain model.</S>
			<S sid ="62" ssid = "42">2.2 Semantic Role Labeling.</S>
			<S sid ="63" ssid = "43">The task of semantic role learning and labeling is to identify classes of entities that fill predicate slots; semantic roles seem like they’d be a good model for the kind of argument types we’d like to learn for narratives.</S>
			<S sid ="64" ssid = "44">Most work on semantic role labeling, however, is supervised, using Prop- bank (Palmer et al., 2005), FrameNet (Baker et al., 1998) or VerbNet (Kipper et al., 2000) as gold standard roles and training data.</S>
			<S sid ="65" ssid = "45">More recent learning work has applied bootstrapping approaches (Swier and Stevenson, 2004; He and Gildea, 2006), but these still rely on a hand labeled seed corpus as well as a predefined set of roles.</S>
			<S sid ="66" ssid = "46">Grenegar and Manning (2006) use the EM algorithm to learn PropBank roles from unlabeled data, and unlike bootstrapping, they don’t need a labeled corpus from which to start.</S>
			<S sid ="67" ssid = "47">However, they do require a predefined set of roles (arg0, arg1, etc.) to define the domain of their probabilistic model.</S>
			<S sid ="68" ssid = "48">Green and Dorr (2005) use WordNet’s graph structure to cluster its verbs into FrameNet frames, using glosses to name potential slots.</S>
			<S sid ="69" ssid = "49">We differ in that we attempt to learn frame-like narrative structure from untagged newspaper text.</S>
			<S sid ="70" ssid = "50">Most similar to us, Alishahi and Stevenson (2007) learn verb specific semantic profiles of arguments using WordNet classes to define the roles.</S>
			<S sid ="71" ssid = "51">We learn situation-specific classes of roles shared by multiple verbs.</S>
			<S sid ="72" ssid = "52">Thus, two open goals in role learning include (1) unsupervised learning and (2) learning the roles themselves rather than relying on predefined role classes.</S>
			<S sid ="73" ssid = "53">As just described, Chambers and Jurafsky (2008) offers an unsupervised approach to event learning (goal 1), but lacks semantic role knowledge (goal 2).</S>
			<S sid ="74" ssid = "54">The following sections describe a model that addresses both goals.</S>
	</SECTION>
	<SECTION title="Narrative Schemas. " number = "3">
			<S sid ="75" ssid = "1">The next sections introduce typed narrative chains and chain merging, extensions that allow us to jointly learn argument roles with event structure.</S>
			<S sid ="76" ssid = "2">3.1 Typed Narrative Chains.</S>
			<S sid ="77" ssid = "3">The first step in describing a narrative schema is to extend the definition of a narrative chain to include argument types.</S>
			<S sid ="78" ssid = "4">We now constrain the protagonist to be of a certain type or role.</S>
			<S sid ="79" ssid = "5">A Typed Narrative Chain is a partially ordered set of event slots that share an argument, but now the shared argument is a role defined by being a member of a set of types R. These types can be lexical units (such as observed head words), noun clusters, or other semantic representations.</S>
			<S sid ="80" ssid = "6">We use head words in the examples below, but we also evaluate with argument clustering by mapping head words to member clusters created with the CBC clustering algorithm (Pantel and Lin, 2002).</S>
			<S sid ="81" ssid = "7">We define a typed narrative chain as a tuple (L, P, O) with L and O the set of event slots and partial ordering as before.</S>
			<S sid ="82" ssid = "8">Let P be a set of argument types (head words) representing a single role.</S>
			<S sid ="83" ssid = "9">An example is given here: L = {(hunt X), (X use), (suspect X), (accuse X), (search X)} P = {person, government, company, criminal, ...}</S>
			<S sid ="84" ssid = "10">O = {(use, hunt), (suspect, search), (suspect, accuse) ...</S>
			<S sid ="85" ssid = "11">} 3.2 Learning Argument Types.</S>
			<S sid ="86" ssid = "12">As mentioned above, narrative chains are learned by parsing the text, resolving coreference, and extracting chains of events that share participants.</S>
			<S sid ="87" ssid = "13">In our new model, argument types are learned simultaneously with narrative chains by finding salient words that represent coreferential arguments.</S>
			<S sid ="88" ssid = "14">We record counts of arguments that are observed with each pair of event slots, build the referential set for each word from its coreference chain, and then represent each observed argument by the most frequent head word in its referential set (ignoring pronouns and mapping entity mentions with person pronouns to a constant PERSON identifier).</S>
			<S sid ="89" ssid = "15">As an example, the following contains four worker mentions: But for a growing proportion of U.S. workers, the troubles really set in when they apply for unemployment benefits.</S>
			<S sid ="90" ssid = "16">Many workers find their benefits challenged.</S>
			<S sid ="91" ssid = "17">L = {X arrest, X charge, X raid, X seize, X confiscate, X detain, X deport } P = {police, agent, authority, government} Figure 1: A typed narrative chain.</S>
			<S sid ="92" ssid = "18">The four top Using this chain score, we finally extend chainsim to score a new event slot based on the argument that maximizes the entire chain’s score: chainsim (C, (f, g)) = arguments are given.</S>
			<S sid ="93" ssid = "19">The ordering O is not shown.</S>
			<S sid ="94" ssid = "20">n max(score(C, a) + Xsim((ei , di ) , (f, g) , a)) (4) The four bolded terms are coreferential and (hopefully) identified by coreference.</S>
			<S sid ="95" ssid = "21">Our algorithm chooses the head word of each phrase and ignores the pronouns.</S>
			<S sid ="96" ssid = "22">It then chooses the most frequent head word as the most salient mention.</S>
			<S sid ="97" ssid = "23">In this example, the most salient term is workers.</S>
			<S sid ="98" ssid = "24">If any pair of event slots share arguments from this set, we count workers.</S>
			<S sid ="99" ssid = "25">In this example, the pair (X find) and (X apply) shares an argument (they and workers).</S>
			<S sid ="100" ssid = "26">The pair ((X find),(X apply)) is counted once for narrative chain induction, and ((X find), (X apply), workers) once for argument induction.</S>
			<S sid ="101" ssid = "27">Figure 1 shows the top occurring words across all event slot pairs in a criminal scenario chain.</S>
			<S sid ="102" ssid = "28">This chain will be part of a larger narrative schema, described in section 3.4.</S>
			<S sid ="103" ssid = "29">3.3 Event Slot Similarity with Arguments.</S>
			<S sid ="104" ssid = "30">We now formalize event slot similarity with arguments.</S>
			<S sid ="105" ssid = "31">Narrative chains as defined in (Chambers and Jurafsky, 2008) score a new event slot (f, gl against a chain of size n by summing over the scores between all pairs: n chainsim(C, (f, g)) = X sim((ei , di ) , (f, g)) (1) i=1 where C is a narrative chain, f is a verb with grammatical argument g, and sim(e, et) is the pointwise mutual information pmi(e, et).</S>
			<S sid ="106" ssid = "32">Grow ing a chain by one adds the highest scoring event.</S>
			<S sid ="107" ssid = "33">We extend this function to include argument types by defining similarity in the context of a specific argument a: sim((e, d) , ˙e , d ¸ , a) = pmi((e, d) , ˙e , d ¸) + λ log f req((e, d) , ˙e , d ¸ , a) (2) where λ is a constant weighting factor and f req(b, bt, a) is the corpus count of a filling the arguments of events b and bt.</S>
			<S sid ="108" ssid = "34">We then score the entire chain for a particular argument: i=1 The argument is now directly influencing event slot similarity scores.</S>
			<S sid ="109" ssid = "35">We will use this definition in the next section to build Narrative Schemas.</S>
			<S sid ="110" ssid = "36">3.4 Narrative Schema: Multiple Chains.</S>
			<S sid ="111" ssid = "37">Whereas a narrative chain is a set of event slots, a Narrative Schema is a set of typed narrative chains.</S>
			<S sid ="112" ssid = "38">A schema thus models all actors in a set of events.</S>
			<S sid ="113" ssid = "39">If (push X) is in one chain, (Y push) is in another.</S>
			<S sid ="114" ssid = "40">This allows us to model a document’s entire narrative, not just one main actor.</S>
			<S sid ="115" ssid = "41">3.4.1 The Model A narrative schema is defined as a 2tuple N = (E, C ) with E a set of events (here defined as verbs) and C a set of typed chains over the event slots.</S>
			<S sid ="116" ssid = "42">We represent an event as a verb v and its grammatical argument positions Dv ⊆ {subject, object, prep}.</S>
			<S sid ="117" ssid = "43">Thus, each event slot (v, dl for all d ∈ Dv belongs to a chain c ∈ C in the schema.</S>
			<S sid ="118" ssid = "44">Further, each c must be unique for each slot of a single verb.</S>
			<S sid ="119" ssid = "45">Using the criminal prosecution domain as an example, a narrative schema in this domain is built as in figure 2.</S>
			<S sid ="120" ssid = "46">The three dotted boxes are graphical representations of the typed chains that are combined in this schema.</S>
			<S sid ="121" ssid = "47">The first represents the event slots in which the criminal is involved, the second the police, and the third is a court or judge.</S>
			<S sid ="122" ssid = "48">Although our representation uses a set of chains, it is equivalent to represent a schema as a constraint satisfactionproblem between (e, dl event slots.</S>
			<S sid ="123" ssid = "49">The next sec tion describes how to learn these schemas.</S>
			<S sid ="124" ssid = "50">3.4.2 Learning Narrative Schemas Previous work on narrative chains focused on re- latedness scores between pairs of verb arguments (event slots).</S>
			<S sid ="125" ssid = "51">The clustering step which built chains depended on these pairwise scores.</S>
			<S sid ="126" ssid = "52">Narrative schemas use a generalization of the entire verb with all of its arguments.</S>
			<S sid ="127" ssid = "53">A joint decision can be made such that a verb is added to a schema if both its subject and object are assigned to chains in the n−1 score(C, a) = X n X sim((ei , di ) , (ej , dj ) , a) (3) schema with high confidence.</S>
			<S sid ="128" ssid = "54">i=1 j=i+1 For instance, it may be the case that (Y pull over) scores well with the ‘police’ chain in arrest charge police,agent arrest charge plead convict sentence criminal,suspect convict sentence judge,jury police, agent judge, jury arrest charge plead convict sentence criminal, suspect guilty, innocent Figure 2: Merging typed chains into a single unordered Narrative Schema.</S>
			<S sid ="129" ssid = "55">figure 3.</S>
			<S sid ="130" ssid = "56">However, the object of (pull over A) is not present in any of the other chains.</S>
			<S sid ="131" ssid = "57">Police pull over cars, but this schema does not have a chain involving cars.</S>
			<S sid ="132" ssid = "58">In contrast, (Y search) scores well with the ‘police’ chain and (search X) scores well in the ‘defendant’ chain too.</S>
			<S sid ="133" ssid = "59">Thus, we want to favor search instead of pull over because the schema is already modeling both arguments.</S>
			<S sid ="134" ssid = "60">This intuition leads us to our event relatedness function for the entire narrative schema N , not raid arrest charge seize confiscate detain deport defendant, nichols, smith, simpson police, agent, authorities, government license immigrant, reporter, cavalo, migrant, alien just one chain.</S>
			<S sid ="135" ssid = "61">Instead of asking which event slot (v, dl is a best fit, we ask if v is best by considering all slots at once: narsim(N, v) = ) max(β, max chainsimt(c, (v, dl)) (5) c∈CN ∈ v where CN is the set of chains in our narrative N . If (v, dl does not have strong enough similarity with any chain, it creates a new one with base score β.</S>
			<S sid ="136" ssid = "62">The β parameter balances this decision of adding to an existing chain in N or creating a new one.</S>
			<S sid ="137" ssid = "63">3.4.3 Building Schemas We use equation 5 to build schemas from the set of events as opposed to the set of event slots that previous work on narrative chains used.</S>
			<S sid ="138" ssid = "64">In Chambers and Jurafsky (2008), narrative chains add the best (e, dl based on the following: Figure 3: Graphical view of an unordered schema automatically built starting from the verb ‘arrest’.</S>
			<S sid ="139" ssid = "65">A β value that encouraged splitting was used.</S>
	</SECTION>
	<SECTION title="Sample Narrative Schemas. " number = "4">
			<S sid ="140" ssid = "1">Figures 3 and 4 show two criminal schemas learned completely automatically from the NYT portion of the Gigaword Corpus (Graff, 2002).</S>
			<S sid ="141" ssid = "2">We parse the text into dependency graphs and resolve coreferences.</S>
			<S sid ="142" ssid = "3">The figures result from learning over the event slot counts.</S>
			<S sid ="143" ssid = "4">In addition, figure 5 shows six of the top 20 scoring narrative schemas learned by our system.</S>
			<S sid ="144" ssid = "5">We artificially required the clustering procedure to stop (and sometimes continue) at six events per schema.</S>
			<S sid ="145" ssid = "6">Six was chosen as the size to enable us to compare to FrameNet in the next section; the mean number of verbs in FrameNet frames is between five and six.</S>
			<S sid ="146" ssid = "7">A low max j:0&lt;j&lt;m chainsim(c, (vj , gj l) (6) β was chosen to limit chain splitting.</S>
			<S sid ="147" ssid = "8">We built a new schema starting from each verb that occurs in where m is the number of seen event slots in the corpus and (vj , gj l is the jth such possible event slot.</S>
			<S sid ="148" ssid = "9">Schemas are now learned by adding events that maximize equation 5: more than 3000 and less than 50,000 documents in the NYT section.</S>
			<S sid ="149" ssid = "10">This amounted to approximately 1800 verbs from which we show the top 20.</S>
			<S sid ="150" ssid = "11">Not surprisingly, most of the top schemas con-.</S>
			<S sid ="151" ssid = "12">max j:0&lt;j&lt;|v| narsim(N, vj ) (7) cern business, politics, crime, or food.</S>
	</SECTION>
	<SECTION title="Frames and. " number = "5">
			<S sid ="152" ssid = "1">Roles where |v| is the number of observed verbs and vj is the jth such verb.</S>
			<S sid ="153" ssid = "2">Verbs are incrementally added to a narrative schema by strength of similarity.</S>
			<S sid ="154" ssid = "3">Most previous work on unsupervised semantic role labeling assumes that the set of possible A p r o d u c e B A ∈ {company, inc, corp, microsoft, A s e l l B iraq, co, unit, maker, ...}</S>
			<S sid ="155" ssid = "4">A m a n u f a c t u r e B A * m a r k e t B B ∈ {drug, product, system, test, A d i s t r i b u t e B software, funds, movie, ...}</S>
			<S sid ="156" ssid = "5">A d e v e l o p B B t r a d e C A ∈ {} B f e ll C B ∈ {dollar, share, index, mark, currency, A * q u o t e B stock, yield, price, pound, ...}</S>
			<S sid ="157" ssid = "6">B f a ll C C ∈ {friday, most, year, percent, thursday B s li p C monday, share, week, dollar, ...}</S>
			<S sid ="158" ssid = "7">B ri s e C A b o i l B A s l i c e B A ∈ { w a s h , h e a t , t h i n l y , o n i o n , n o t e } A p e e l B A s a u t e B B ∈ { p o t a t o , o n i o n , m u s h r o o m , c l o v e , A c o o k B o r a n g e , g n o c c h i } A c h o p B A d et ai n B A ∈ {police, agent, officer, authorities, A c o nf is c at e B troops, official, investigator, ...</S>
			<S sid ="159" ssid = "8">} A s ei z e B A r a i d B B ∈ {suspect, government, journalist, A s e ar c h B monday, member, citizen, client, ...</S>
			<S sid ="160" ssid = "9">} A a rr e st B A * u p h ol d B A ∈ { c o u rt , ju d g e, ju st ic e, p a n el , o s t e e n , A * c h al le n g e B circuit, nicolau, sporkin, majority, ...}</S>
			<S sid ="161" ssid = "10">A r ul e B A e nf or c e B B ∈ {law, ban, rule, constitutionality, A * o v e rt u r n B conviction, ruling, lawmaker, tax, ...}</S>
			<S sid ="162" ssid = "11">A * s tr ik e d o w n B A o w n B A ∈ {company, investor, trader, corp, A * b o rr o w B enron, inc, government, bank, itt, ...}</S>
			<S sid ="163" ssid = "12">A s el l B A b u y b a c k B B ∈ { s h a r e , s t o c k , s t o c k s , b o n d , c o m p a n y , A b u y B security, team, funds, house, ...</S>
			<S sid ="164" ssid = "13">} A *r e p u rc h a s e B Figure 5: Six of the top 20 scored Narrative Schemas.</S>
			<S sid ="165" ssid = "14">Events and arguments in italics were marked misaligned by FrameNet definitions.</S>
			<S sid ="166" ssid = "15">* indicates verbs not in FrameNet.</S>
			<S sid ="167" ssid = "16">- indicates verb senses not in FameNet.</S>
			<S sid ="168" ssid = "17">deliberate deadlocked found convict acquit sentence defendant, nichols, smith, simpson jury, juror, court, judge, tribunal, senateof frame specific semantic roles called frame elements that can be arguments of the lexical units in the frame.</S>
			<S sid ="169" ssid = "18">FrameNet frames share commonali- ties with narrative schemas; both represent aspects of situations in the world, and both link semantically related words into frame-like sets in which each predicate draws its argument roles from a frame specific set.</S>
			<S sid ="170" ssid = "19">They differ in that schemas focus on events in a narrative, while frames focus on Figure 4: Graphical view of an unordered schema automatically built from the verb ‘convict’.</S>
			<S sid ="171" ssid = "20">Each node shape is a chain in the schema.</S>
			<S sid ="172" ssid = "21">classes is very small (i.e, PropBank roles ARG0 and ARG1) and is known in advance.</S>
			<S sid ="173" ssid = "22">By contrast, our approach induces sets of entities that appear in the argument positions of verbs in a narrative schema.</S>
			<S sid ="174" ssid = "23">Our model thus does not assume the set of roles is known in advance, and it learns the roles at the same time as clustering verbs into frame-like schemas.</S>
			<S sid ="175" ssid = "24">The resulting sets of entities (such as {police, agent, authorities, government} or {court, judge, justice}) can be viewed as a kind of schema-specific semantic role.</S>
			<S sid ="176" ssid = "25">How can this unsupervised method of learning roles be evaluated?</S>
			<S sid ="177" ssid = "26">In Section 6 we evaluate the schemas together with their arguments in a cloze task.</S>
			<S sid ="178" ssid = "27">In this section we perform a more qualitative evalation by comparing our schema to FrameNet.</S>
			<S sid ="179" ssid = "28">FrameNet (Baker et al., 1998) is a database of frames, structures that characterize particular situations.</S>
			<S sid ="180" ssid = "29">A frame consists of a set of events (the verbs and nouns that describe them) and a set events that share core participants.</S>
			<S sid ="181" ssid = "30">Nonetheless, the fact that FrameNet defines frame-specific argument roles suggests that comparing our schemas and roles to FrameNet would be elucidating.</S>
			<S sid ="182" ssid = "31">We took the 20 learned narrative schemas described in the previous section and used FrameNet to perform qualitative evaluations on three aspects of schema: verb groupings, linking structure (the mapping of each argument role to syntactic subject or object), and the roles themselves (the set of entities that constitutes the schema roles).</S>
			<S sid ="183" ssid = "32">Verb groupings To compare a schema’s event selection to a frame’s lexical units, we first map the top 20 schemas to the FrameNet frames that have the largest overlap with each schema’s six verbs.</S>
			<S sid ="184" ssid = "33">We were able to map 13 of our 20 narratives to FrameNet (for the remaining 7, no frame contained more than one of the six verbs).</S>
			<S sid ="185" ssid = "34">The remaining 13 schemas contained 6 verbs each for a total of 78 verbs.</S>
			<S sid ="186" ssid = "35">26 of these verbs, however, did not occur in FrameNet, either at all, or with the correct sense.</S>
			<S sid ="187" ssid = "36">Of the remaining 52 verb mappings, 35 (67%) occurred in the closest FrameNet frame or in a frame one link away.</S>
			<S sid ="188" ssid = "37">17 verbs (33%) occurred in a different frame than the one chosen.</S>
			<S sid ="189" ssid = "38">We examined the 33% of verbs that occurred in a different frame.</S>
			<S sid ="190" ssid = "39">Most occurred in related frames, but did not have FrameNet links between them.</S>
			<S sid ="191" ssid = "40">For instance, one schema includes the causal verb trade with unaccusative verbs of change like rise and fall.</S>
			<S sid ="192" ssid = "41">FrameNet separates these classes of verbs into distinct frames, distinguishing motion frames from caused-motion frames.</S>
			<S sid ="193" ssid = "42">Even though trade and rise are in different FrameNet frames, they do in fact have the narrative relation that our system discovered.</S>
			<S sid ="194" ssid = "43">Of the 17 misaligned events, we judged all but one to be correct in a narrative sense.</S>
			<S sid ="195" ssid = "44">Thus although not exactly aligned with FrameNet’s notion of event clusters, our induction algorithm seems to do very well.</S>
			<S sid ="196" ssid = "45">Linking structure Next, we compare a schema’s linking structure, the grammatical relation chosen for each verb event.</S>
			<S sid ="197" ssid = "46">We thus decide, e.g., if the object of the verb arrest (arrest B) plays the same role as the object of detain (detain B), or if the subject of detain (B detain) would have been more appropriate.</S>
			<S sid ="198" ssid = "47">We evaluated the clustering decisions of the 13 schemas (78 verbs) that mapped to frames.</S>
			<S sid ="199" ssid = "48">For each chain in a schema, we identified the frame element that could correctly fill the most verb arguments in the chain.</S>
			<S sid ="200" ssid = "49">The remaining arguments were considered incorrect.</S>
			<S sid ="201" ssid = "50">Because we assumed all verbs to be transitive, there were 156 arguments (subjects and objects) in the 13 schema.</S>
			<S sid ="202" ssid = "51">Of these 156 arguments, 151 were correctly clustered together, achieving 96.8% accuracy.</S>
			<S sid ="203" ssid = "52">The schema in figure 5 with events detain, seize, arrest, etc. shows some of these errors.</S>
			<S sid ="204" ssid = "53">The object of all of these verbs is an animate theme, but confiscate B and raid B are incorrect; people cannot be confiscated/raided.</S>
			<S sid ="205" ssid = "54">They should have been split into their own chain within the schema.</S>
			<S sid ="206" ssid = "55">Argument Roles Finally, we evaluate the learned sets of entities that fill the argument slots.</S>
			<S sid ="207" ssid = "56">As with the above linking evaluation, we first identify the best frame element for each argument.</S>
			<S sid ="208" ssid = "57">For example, the events in the top left schema of figure 5 map to the Manufacturing frame.</S>
			<S sid ="209" ssid = "58">Argument B was identified as the Product frame element.</S>
			<S sid ="210" ssid = "59">We then evaluate the top 10 arguments in the argument set, judging whether each is a reasonable filler of the role.</S>
			<S sid ="211" ssid = "60">In our example, drug and product are correct Product arguments.</S>
			<S sid ="212" ssid = "61">An incorrect argument is test, as it was judged that a test is not a product.</S>
			<S sid ="213" ssid = "62">We evaluated all 20 schemas.</S>
			<S sid ="214" ssid = "63">The 13 mapped schemas used their assigned frames, and we created frame element definitions for the remaining 7 that were consistent with the syntactic positions.</S>
			<S sid ="215" ssid = "64">There were 400 possible arguments (20 schemas, 2 chains each), and 289 were judged correct for a precision of 72%.</S>
			<S sid ="216" ssid = "65">This number includes Person and Organization names as correct fillers.</S>
			<S sid ="217" ssid = "66">A more conservative metric removing these classes results in 259 (65%) correct.</S>
			<S sid ="218" ssid = "67">Most of the errors appear to be from parsing mistakes.</S>
			<S sid ="219" ssid = "68">Several resulted from confusing objects with adjuncts.</S>
			<S sid ="220" ssid = "69">Others misattached modifiers, such as including most as an argument.</S>
			<S sid ="221" ssid = "70">The cooking schema appears to have attached verbal arguments learned from instruction lists (wash, heat, boil).</S>
			<S sid ="222" ssid = "71">Two schemas require situations as arguments, but the dependency graphs chose as arguments the subjects of the embedded clauses, resulting in 20 incorrect arguments in these schema.</S>
	</SECTION>
	<SECTION title="Evaluation: Cloze. " number = "6">
			<S sid ="223" ssid = "1">The previous section compared our learned knowledge to current work in event and role semantics.</S>
			<S sid ="224" ssid = "2">We now provide a more formal evaluation against untyped narrative chains.</S>
			<S sid ="225" ssid = "3">The two main contributions of schema are (1) adding typed arguments and (2) considering joint chains in one model.</S>
			<S sid ="226" ssid = "4">We evaluate each using the narrative cloze test as in (Chambers and Jurafsky, 2008).</S>
			<S sid ="227" ssid = "5">6.1 Narrative Cloze.</S>
			<S sid ="228" ssid = "6">The cloze task (Taylor, 1953) evaluates human understanding of lexical units by removing a random word from a sentence and asking the subject to guess what is missing.</S>
			<S sid ="229" ssid = "7">The narrative cloze is a variation on this idea that removes an event slot from a known narrative chain.Performance is measured by the position of the missing event slot in a system’s ranked guess list.</S>
			<S sid ="230" ssid = "8">This task is particularly attractive for narrative schemas (and chains) because it aligns with one of the original ideas behind Schankian scripts, namely that scripts help humans ‘fill in the blanks’ when language is underspecified.</S>
			<S sid ="231" ssid = "9">6.2 Training and Test Data.</S>
			<S sid ="232" ssid = "10">We count verb pairs and shared arguments over the NYT portion of the Gigaword Corpus (years 19942004), approximately one million articles.</S>
			<S sid ="233" ssid = "11">1350 1300 1250 1200 1150 1100 1050 1000 Narrati ve Cloze Test Chai n Typ ed Cha in Sch em a Type d Sche ma of 4).</S>
			<S sid ="234" ssid = "12">The dotte d line ‘Ch ain’ and solid ‘Sch ema’ sho w perfo rman ce resul ts in figur e 6.</S>
			<S sid ="235" ssid = "13">Narr ative Sche mas have bette r rank ed scor es in all data sizes and follo w the previ ous expe rime nt in impr ovin g resul ts as more data is adde d even thou gh unty ped chain s trend upwa rd. We see a 3.3 % gain at 200 4.</S>
			<S sid ="236" ssid = "14">6 . 5 T y p e d N a r r a t i v e S c h e m a The final eval uatio n com bine s sche mas with ar- gum ent type s to mea sure over all gain . We.</S>
			<S sid ="237" ssid = "15">evaluate d with both head wor ds and CB C clust ers as argu ment repre sent ation s. Not only do type d chai ns and sche mas outp erfor m unty ped chai ns, 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 Training Data from 1994−X Figure 6: Results with varying sizes of training data.</S>
			<S sid ="238" ssid = "16">We parse the text into typed dependency graphs with the Stanford Parser (de Marneffe et al., 2006), recording all verbs with subject, object, or prepositional typed dependencies.</S>
			<S sid ="239" ssid = "17">Unlike in (Chambers and Jurafsky, 2008), we lemmatize verbs and argument head words.</S>
			<S sid ="240" ssid = "18">We use the OpenNLP1 coreference engine to resolve entity mentions.</S>
			<S sid ="241" ssid = "19">The test set is the same as in (Chambers and Jurafsky, 2008).</S>
			<S sid ="242" ssid = "20">100 random news articles were selected from the 2001 NYT section of the Gigaword Corpus.</S>
			<S sid ="243" ssid = "21">Articles that did not contain a protagonist with five or more events were ignored, leaving a test set of 69 articles.</S>
			<S sid ="244" ssid = "22">We used a smaller development set of size 17 to tune parameters.</S>
			<S sid ="245" ssid = "23">6.3 Typed Chains.</S>
			<S sid ="246" ssid = "24">The first evaluation compares untyped against typed narrative event chains.</S>
			<S sid ="247" ssid = "25">The typed model uses equation 4 for chain clustering.</S>
			<S sid ="248" ssid = "26">The dotted line ‘Chain’ and solid ‘Typed Chain’ in figure 6 shows the average ranked position over the test set.</S>
			<S sid ="249" ssid = "27">The untyped chains plateau and begin to worsen as the amount of training data increases, but the typed model is able to improve for some time after.</S>
			<S sid ="250" ssid = "28">We see a 6.9% gain at 2004 when both lines trend upwards.</S>
			<S sid ="251" ssid = "29">6.4 Narrative Schema.</S>
			<S sid ="252" ssid = "30">The second evaluation compares the performance of the narrative schema model against single narrative chains.</S>
			<S sid ="253" ssid = "31">We ignore argument types and use untyped chains in both (using equation 1 instead 1 http://opennlp.sourceforge.net/ combining the two gives a further performance boost.</S>
			<S sid ="254" ssid = "32">Clustered arguments improve the results further, helping with sparse argument counts (‘Typed Schema’ in figure 6 uses CBC arguments).</S>
			<S sid ="255" ssid = "33">Overall, using all the data (by year 2004) shows a 10.1% improvement over untyped narrative chains.</S>
	</SECTION>
	<SECTION title="Discussion. " number = "7">
			<S sid ="256" ssid = "1">Our significant improvement in the cloze evaluation shows that even though narrative cloze does not evaluate argument types, jointly modeling the arguments with events improves event clustering.</S>
			<S sid ="257" ssid = "2">Likewise, the FrameNet comparison suggests that modeling related events helps argument learning.</S>
			<S sid ="258" ssid = "3">The tasks mutually inform each other.</S>
			<S sid ="259" ssid = "4">Our argument learning algorithm not only performs unsupervised induction of situation-specific role classes, but the resulting roles and linking structures may also offer the possibility of (unsupervised) FrameNet-style semantic role labeling.</S>
			<S sid ="260" ssid = "5">Finding the best argument representation is an important future direction.</S>
			<S sid ="261" ssid = "6">The performance of our noun clusters in figure 6 showed that while the other approaches leveled off, clusters continually improved with more data.</S>
			<S sid ="262" ssid = "7">The exact balance between lexical units, clusters, or more general (traditional) semantic roles remains to be solved, and may be application specific.</S>
			<S sid ="263" ssid = "8">We hope in the future to show that a range of NLU applications can benefit from the rich inferential structures that narrative schemas provide.</S>
	</SECTION>
	<SECTION title="Acknowledgments">
			<S sid ="264" ssid = "9">This work is funded in part by NSF (IIS0811974).</S>
			<S sid ="265" ssid = "10">We thank the reviewers and the Stanford NLP Group for helpful suggestions.</S>
	</SECTION>
</PAPER>
