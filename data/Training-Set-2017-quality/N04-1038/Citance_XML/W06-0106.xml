<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">Coreference resolution is the process of identifying expressions that refer to the same entity.</S>
		<S sid ="2" ssid = "2">This paper presents a clustering algorithm for unsupervised Chinese coreference resolution.</S>
		<S sid ="3" ssid = "3">We investigate why Chinese coreference is hard and demonstrate that techniques used in coreference resolution for phoric reference to克林頓 (Clinton).</S>
		<S sid ="4" ssid = "4">克林頓總 統 (President Clinton) is described as the antecedent of 他 (he).</S>
		<S sid ="5" ssid = "5">克林頓 (Clinton), 克林頓總統 (President Clinton) and the second 他 (he) are all mentions of the same entity that refers to former U.S. president Bill Clinton.</S>
		<S sid ="6" ssid = "6">[克林頓1]說，華盛頓將逐步落實對[韓國2] 的 經濟援助。[金大中 ]對[克林頓 ]的講話報以 English can be extended to Chinese.</S>
		<S sid ="7" ssid = "7">The 3 1 proposed system exploits clustering as it has advantages over traditional classification methods, such as the fact that no training data is required and it is easily extended to accommodate additional features.</S>
		<S sid ="8" ssid = "8">We conduct a set of experiments to investigate how noun phrase identification and feature selection can contribute to coreference resolution performance.</S>
		<S sid ="9" ssid = "9">Our system is evaluated on an annotated version of the TDT3 corpus using the MUC7 scorer, and obtains comparable performance.</S>
		<S sid ="10" ssid = "10">We believe that this is the first attempt at an unsupervised approach to Chinese noun phrase coreference resolution.</S>
	</ABSTRACT>
	<SECTION title="INTRODUCTION" number = "1">
			<S sid ="11" ssid = "11">Noun phrase coreference resolution is the process of detecting noun phrases (NPs) in a document and determining whether the NPs refer to the same entity, where an entity is defined as “a construct that represents an abstract identity”.</S>
			<S sid ="12" ssid = "12">The NPs that refer to the entity are known as mentions.</S>
			<S sid ="13" ssid = "13">Mentions can be antecedents or anaphors.</S>
			<S sid ="14" ssid = "14">An anaphor is an expression that refers back to a previous expression in a discourse.</S>
			<S sid ="15" ssid = "15">In Figure 1, 克林頓總統 (President Clinton) refersto 克林頓 (Clinton) and is described as an ana 掌聲。[他3]說：「[克林頓總統1]在會談中 重 申，[他1]堅定地支持[韓國2]擺脫經濟 危 機。 」 [Clinton1] said that Washington would progressively follow through on economic aid to [Korea2].</S>
			<S sid ="16" ssid = "16">[Kim DaeJung3] applauded [Clinton1]’s speech.</S>
			<S sid ="17" ssid = "17">[He1] said, “[President Clinton1] reiterated in the talks that [he1] would provide solid support for [Korea2] to shake off the economic crisis.</S>
			<S sid ="18" ssid = "18">Figure 1: An excerpt from the text, with core- ferring noun phrases annotated.</S>
			<S sid ="19" ssid = "19">English translation in italics.</S>
			<S sid ="20" ssid = "20">NP coreference resolution is an important sub- task in natural language processing (NLP) applications such as text summarization, information extraction, data mining and question answering.</S>
			<S sid ="21" ssid = "21">This task has attracted much attention in recent years (Cardie and Wagstaff, 1999; Harabagiu et al., 2001; Soon et al., 2001; Ng and Cardie, 2002; Yang et al., 2004; Florian et al., 2004; Zhou et al., 2005), and has been included as a subtask in the MUC (Message Understanding Conferences) and ACE (Automatic Content Extraction) competitions.</S>
			<S sid ="22" ssid = "22">Coreference resolution is a difficult task for various reasons.</S>
			<S sid ="23" ssid = "23">Firstly, a list of features can play a role to support coreference resolution such as 40 Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 40–47, Sydney, July 2006.</S>
			<S sid ="24" ssid = "24">Qc 2006 Association for Computational Linguistics gender agreement, number agreement, head noun matches, semantic class, positional information, contextual information, appositive, abbreviation etc. Ng and Cardie (2002) found 53 features which are useful for this problem.</S>
			<S sid ="25" ssid = "25">However, no single feature is completely reliable since there are always exceptions: e.g. the number agree ment test returns false when 這 個 部 隊 (this army, singular) is matched against 眾隊員 (army members, plural), despite the two phrases being coreferential.</S>
			<S sid ="26" ssid = "26">Secondly, identifying features automatically and accurately is hard.</S>
			<S sid ="27" ssid = "27">Features such as semantic class come from named entity recognition (NER) systems and ontologies and gazetteers, but they are not always accurate, especially where new terms are concerned.</S>
			<S sid ="28" ssid = "28">Thirdly, coreference resolution subsumes the pronoun resolution problem, which is already difficult since pronouns carry limited lexical and semantic information.</S>
			<S sid ="29" ssid = "29">In addition to the aforementioned, Chinese coreference resolution is also made more difficult due to the lack of morphological and orthographic clues.</S>
			<S sid ="30" ssid = "30">Chinese words contain less exterior information than words in many Indoeuropean languages.</S>
			<S sid ="31" ssid = "31">For example, in English, number agreement can be detected through word inflections and part-of-speech (POS) tags, but there are no simple rules in Chinese to distinguish whether a word is singular or plural.</S>
			<S sid ="32" ssid = "32">Proper name and abbreviations are identified by capitalization in English, but Chinese does not use capitalization.</S>
			<S sid ="33" ssid = "33">Moreover, written Chinese does not have word boundaries, so word segmentation is a crucial problem, as we cannot get the true meaning of the sentence based on characters alone.</S>
			<S sid ="34" ssid = "34">A simple sentence can be segmented in several different ways to get different meanings.</S>
			<S sid ="35" ssid = "35">This characteristic affects the performance of all parts and leads to irrecoverable errors.</S>
			<S sid ="36" ssid = "36">In addition, there are very few Chinese coreference data sets available for research purposes (none of them freely available) and as a result, no easily obtainable benchmark- ing dataset for training and measuring performance.</S>
			<S sid ="37" ssid = "37">Building a reasonably large coreference corpus is a labor-consuming task.</S>
			<S sid ="38" ssid = "38">To our knowledge, there have only been two Chinese coreference systems in previously published work: Florian et al.</S>
			<S sid ="39" ssid = "39">(2004), which presents a statistical framework and reports experiment results on Chinese texts; and Zhou et al.</S>
			<S sid ="40" ssid = "40">(2005), which proposed a unified transformation based learning framework for Chinese entity detection and tracking.</S>
			<S sid ="41" ssid = "41">It consists of two models: the detection model locates possibly coreferring NPs and the tracking model links the coreference relations.</S>
			<S sid ="42" ssid = "42">This paper presents research performed on Chinese noun phrase coreference resolution.</S>
			<S sid ="43" ssid = "43">Since there are no freely available Chinese coreference resources, we used an unsupervised method that partially borrows from Cardie and Wagstaff’s (1999) clustering-based technique, with features that are specially designed for Chinese.</S>
			<S sid ="44" ssid = "44">In addition, we perform and present the results of experiments designed to investigate the contribution of each feature.</S>
	</SECTION>
	<SECTION title="Experiment Setup. " number = "2">
			<S sid ="45" ssid = "1">Identifying coreferent NPs in an unannotated document actually involves two tasks: mention detection, which identifies the anaphors and antecedents in a document, followed by noun phrase coreference resolution.</S>
			<S sid ="46" ssid = "2">In order to reduce the complexity of the final system, we follow the usual approach in handling these two phases separately.</S>
			<S sid ="47" ssid = "3">2.1 Corpus.</S>
			<S sid ="48" ssid = "4">Even though we are using an unsupervised approach, a gold standard corpus is still needed for experiment evaluation.</S>
			<S sid ="49" ssid = "5">Since we did not have access to the ACE multilingual entity tracking corpus, we created our own corpus by selecting 30 documents from the TDT3 Chinese corpus.</S>
			<S sid ="50" ssid = "6">This resulted in a corpus of approximately 36K Chinese characters, about the same size as the MUC dryrun test sets.</S>
			<S sid ="51" ssid = "7">We then had our corpus annotated by a native Chinese speaker following the MUC7 (Hirschman and Chinchor, 1997) and ACE Chinese entity guidelines (LDC, 2004) by picking out noun phrase mentions corresponding to one of the following nine types of entities: Person, Organization, Location, GeoPolitical Entity (GPE), Facility, Vehicle, Weapon, Date and Money, and for each pair of mentions, deciding whether they refer to the same entity following MUC7 definitions.</S>
			<S sid ="52" ssid = "8">According to the guidelines, each mention participates in exactly one entity, and all mentions in the same entity are coreferent.</S>
			<S sid ="53" ssid = "9">The NPs that are marked include proper nouns, nominal nouns and pronouns and the entity types are a superset of those used in the MUC and ACE competitions.</S>
			<S sid ="54" ssid = "10">The resulting corpus includes 1640 mentions, referring to 410 entities.</S>
			<S sid ="55" ssid = "11">Once our corpus had been determined, the first step was to determine the possible mentions in a plain text.</S>
			<S sid ="56" ssid = "12">We first used a dictionary-based word segmentation system (Lancashire, 2005) to segment the Chinese characters into words.</S>
			<S sid ="57" ssid = "13">The segmented words are then labeled with POS tags by a statistical POS tagging system (Fung et al., 2004).</S>
	</SECTION>
	<SECTION title="Mention Detection. " number = "3">
			<S sid ="58" ssid = "1">After the corpus has been preprocessed, mention detection involves the identification of NPs in the corpus that refer to some entity.</S>
			<S sid ="59" ssid = "2">Most of these NPs correspond to non-recursive NPs, which makes this task simpler as most syntactic parsers identify NPs as part of the parsing process.</S>
			<S sid ="60" ssid = "3">This approach, however, suffers from two problems: firstly, the parser itself is unlikely to be 100% accurate; and secondly, the boundaries of the NPs identified by the parser may not correspond exactly with those of the entities identified by the human annotator.</S>
			<S sid ="61" ssid = "4">Another approach is simply to use heuristics based on the POS tag sequence to identify potential NPs of interest.</S>
			<S sid ="62" ssid = "5">The advantage of this method is that the NPs thus extracted should be closer to the human-annotated entities since the heuristics will be constructed specifically for this task.</S>
			<S sid ="63" ssid = "6">To investigate the effect of different approaches on the result of the coreference resolution, we applied both methods separately to our corpus.</S>
			<S sid ="64" ssid = "7">The corpus was parsed with a state-of- the-art multilingual statistical parser (Bikel 2004), which is trained on the Chinese Penn Treebank.</S>
			<S sid ="65" ssid = "8">After parsing, we extracted all non- recursive NP chunks tagged by the parser as possible mentions.</S>
			<S sid ="66" ssid = "9">For the heuristic-based approach, we applied a few simple heuristics, which had been previously developed during unrelated work for English named-entity resolution (i.e. they were not written with foreknowledge of the gold standard entities) and which are based on the part-of- speech tags of the words.</S>
			<S sid ="67" ssid = "10">Some examples of our heuristics were to look for pronouns, or to extract all noun sequences, or sequences of determiners followed by adjectives and nouns.</S>
			<S sid ="68" ssid = "11">Table 1 shows the performance of the parsing-based approach versus the heuristic-based approach.</S>
			<S sid ="69" ssid = "12">The parser-based approach suffers mainly because the NPs that it extracts tend to be on the long side, resulting in recall errors when the boundaries of the parser-identified NPs mismatch with the human-annotated entities.</S>
			<S sid ="70" ssid = "13">In addition, the parser also tends to extract more NPs than needed, which results in a hit to precision.</S>
	</SECTION>
	<SECTION title="Coreference Resolution. " number = "4">
			<S sid ="71" ssid = "1">The final step after the mention detection phase is to determine which of the extracted phrases refer to the same entity, or are coreferent.The small size of our corpus made it quite ob vious that we would not be able to perform supervised learning, as there would not be enough data for generalization purposes.</S>
			<S sid ="72" ssid = "2">Therefore we chose to use an unsupervised clustering approach for this step.</S>
			<S sid ="73" ssid = "3">Clustering is a natural choice as it partitions the data into groups; used on coreference resolution, we expect to gather coreferrent NPs into the same cluster.</S>
			<S sid ="74" ssid = "4">Furthermore, most clustering methods can easily incorporate both context-dependent and independent constraints into their features.</S>
			<S sid ="75" ssid = "5">4.1 Features.</S>
			<S sid ="76" ssid = "6">Our features use both lexical and syntactic information designed to capture both the content of the phrase and its role within the sentence.</S>
			<S sid ="77" ssid = "7">With the exception of the last three features, which are defined with respect to a noun phrase pair, all our features describe various aspects of a single noun phrase: Lexical String – This is just simply the string of words in the phrase.</S>
			<S sid ="78" ssid = "8">Head Noun – The head noun in a phrase is the noun that is not a modifier for another noun.</S>
			<S sid ="79" ssid = "9">Sentence Position – This measures the position of the phrase within the document.</S>
			<S sid ="80" ssid = "10">Gender – For each phrase, we use a gazetteer to assign it a gender.</S>
			<S sid ="81" ssid = "11">The possible values are male(e.g. 先生, mister), female (e.g. 小姐, miss), ei ther (e.g. 團長, leader) and neither (e.g. 工廠, factory).</S>
			<S sid ="82" ssid = "12">Number – A phrase can be either singular (e.g. 一隻貓, one cat), plural (e.g. 兩隻狗, two dogs), either (e.g. 產品, product) or neither (e.g. 安全, safety).</S>
			<S sid ="83" ssid = "13">R e c a l l P r e c i s i o n F M e a s u r e H e u r i s t i c s 8 3 5 9 . 3 6 9 . 2 P a r s e r B a s e d 6 2 . 7 2 8 . 7 3 9 . 4 Table 1: Mention Detection Results Semantic Class – To give the system more information on each phrase, we generated our own gazetteer from a combination of gazetteers compiled from web sources and heuristics.</S>
			<S sid ="84" ssid = "14">Our gazetteer consists of 4700 entries, each of which is labeled with one of the following semantic classes: person, organization, location, facility, GPE, date, money, vehicle and weapon.</S>
			<S sid ="85" ssid = "15">Phrases in the corpus that are found in the gazetteer are given the same semantic class label; phrases not in the gazetteer are marked as UNKNOWN.</S>
			<S sid ="86" ssid = "16">Proper Name – The part-of-speech tag “NR” and a list of common proper names were used to label each noun phrase as to whether it is a proper name (values: true/false).</S>
			<S sid ="87" ssid = "17">Pronoun – Determined by the part-of-speech “PN”.</S>
			<S sid ="88" ssid = "18">Values: true/false.</S>
			<S sid ="89" ssid = "19">Demonstrative Noun Phrase – A demonstrative noun phrase is a phrase that consists of a noun phrases preceded by one of the characters [這那 該] (this/that/some).</S>
			<S sid ="90" ssid = "20">Appositive – Two noun phrases are in apposition when the first phrase is headed by a common noun while the second one is a proper name with no space or punctuation between them.</S>
			<S sid ="91" ssid = "21">e.g. [美 國 總 統 ][ 克 林 頓 ] 上 星 期 到 朝 鮮 訪 問 。 ([US president] [Clinton] visited Pyongyang last week.)</S>
			<S sid ="92" ssid = "22">This differs from English where two nouns are considered to be in apposition when one of them is an anaphor and separated by a comma from the other phrase, which is the most immediate proper name.</S>
			<S sid ="93" ssid = "23">(e.g. “Bill Gates, the chairman of Microsoft Corp”) Abbreviation – A noun phrase is an abbreviation when it is formed by using part of another noun phrase, e.g. 朝鮮中央通訊社 (Pyongyang Central Communications Office) is commonly abbreviated as 朝中社.</S>
			<S sid ="94" ssid = "24">Since name abbreviations in Chinese are often given in an ad-hoc manner, it would be infeasible to generate a list of nam and abbreviations in advance.</S>
			<S sid ="95" ssid = "25">We therefore use the following heuristic: given two phrases, we test if one is an abbreviation of another by extracting each successive character from the shorter phrase and testing to see if it is included in the corresponding word from the longer phrase.</S>
			<S sid ="96" ssid = "26">Intuitively, we know that this is a common way of abbreviating terms; empirically, it usually gives us a correct result.</S>
			<S sid ="97" ssid = "27">Edit Distance – Abbreviations and nicknames F e a t u r e f F u n c t i o n N o u n P h r a s e M a t c h 1 i f t h e s t r i n g o f N P i m a t c h e s t h e s t r i n g o f N P j ; e l s e 0 H e a d N o u n M a t c h 1 i f h e a d n o u n o f N P i m a t c h e s t h e h e a d n o u n o f N P j ; e l s e 0 S e n t e n c e D i s t a n c e 0 i f N P i a n d N P j a r e i n t h e s a m e s e n t e n c e ; F o r n o n p r o n o u n s : 1 / 1 0 i f t h e y a r e o n e s e n t e n c e a p a r t ; a n d s o o n w i t h m a x i m u m v a l u e 1 ; F o r p r o n o u n s : i f m o r e t h a n t w o s e n t e n c e s a p a r t , t h e n 1 G e n d e r A g r e e m e n t 1 i f t h e y d o n o t m a t c h i n g e n d e r ; e l s e 0 N u m b e r A g r e e m e n t 1 i f t h e y d o n o t m a t c h i n n u m b e r ; e l s e 0 S e m a n t i c A g r e e m e n t 1 i f t h e y d o n o t m a t c h i n s e m a n t i c c l a s s o r u n k n o w n ; e l s e 0 P r o p e r N a m e A g r e e m e n t 1 i f b o t h a r e p r o p e r n a m e s , b u t m i s m a t c h o n e v e r y w o r d ; e l s e 0 P r o n o u n A g r e e m e n t 1 i f e i t h e r N P i o r N P j i s p r o n o u n a n d m i s m a t c h i n g e n d e r o r n u m b e r ; e l s e 0 D e m o n s t r a t i v e N o u n P h r a s e 1 i f N P i i s d e m o n s t r a t i v e a n d N P i c o n t a i n s N P j ; e l s e 0 A p p o s i t i v e 1 i f N P i a n d N P j a r e i n a n a p p o s i t i v e r e l a t i o n s h i p ; e l s e 0 A b b r e v i a t i o n 1 i f N P i a n d N P j a r e i n a n a b b r e v i a t i v e r e l a t i o n s h i p ; e l s e 0 E d i t D i s t a n c e 0 i f N P i a n d N P j a r e t h e s a m e , 1 / ( l e n g t h o f l o n g e r s t r i n g ) i f o n e e d i t i s n e e d e d t o t r a n s f o r m o n e t o a n o t h e r , a n d s o o n . Table 2: Features and functions used in clustering algorithm are very commonly used in Chinese and even though the previous feature will work on most of them, there are some common exceptions.</S>
			<S sid ="98" ssid = "28">To make sure that we catch those as well, we introduced a Chinese-specific feature as a further test.</S>
			<S sid ="99" ssid = "29">Since abbreviations and nicknames are not usually substrings of the original strings, but will still share some common characters, we measure the Levenshtein distance, defined as the number of character insertions, deletions and substitutions, between every potential antecedent- anaphor pair.</S>
			<S sid ="100" ssid = "30">4.2 Distance Metric.</S>
			<S sid ="101" ssid = "31">In order for the clustering algorithm to be able to group instances together by similarity, we need to determine a distance metric between two instances – in our case, two noun phrases.</S>
			<S sid ="102" ssid = "32">For our system, we borrowed a simple distance metric from Cardie and Wagstaff (1999) that sums up the results of a series of functions over the two phrases: dist ( NPi , NPj ) = &quot; function f (NPi , NPj ) f !F Table 2 presents the features and the corresponding functions that were used in our system.</S>
			<S sid ="103" ssid = "33">Each function calculates a distance between the two phrases that is an indicator of the degree of incompatibility between the two phrases with respect to a particular feature.</S>
			<S sid ="104" ssid = "34">The NOUN PHRASE, HEAD NOUN, DEMONSTRATIVE, APPOSITIVE and ABBREVIATIVE functions test for compatibility and return a negative value when the two phrases are compatible for that term’s feature.</S>
			<S sid ="105" ssid = "35">The reason for the negative value returned is that if the two phrases match on this particular feature, then it is a strong indicator of coreference.</S>
			<S sid ="106" ssid = "36">Therefore, we reduce the distance between two phrases, making it more likely that they will be clustered together into the same entity.</S>
			<S sid ="107" ssid = "37">When there is a mismatch, however, it does not necessarily indicate that the two NPs are non- coreferential, so we leave the distance between the NPs unchanged.</S>
			<S sid ="108" ssid = "38">Conversely, there are some features where a mismatch would indicate that the two NPs are absolutely non-compatible and will definitely not refer to the same entity.</S>
			<S sid ="109" ssid = "39">The DISTANCE, GENDER, NUMBER, SEMANTIC, PROPER NAME, PRONOUN and EDIT_DISTANCE functions return a positive value when the two phrases mismatch on that particular feature.</S>
			<S sid ="110" ssid = "40">A positive value results in a greater distance between two phrases, which makes it less likely for them to be clustered together.</S>
			<S sid ="111" ssid = "41">4.3 Clustering Algorithm.</S>
			<S sid ="112" ssid = "42">Most of the previous work in clustering-based noun phrase coreference resolution has centered around the use of bottom-up clustering methods, where each noun phrase is initially assigned to a singleton cluster by itself, and clusters which are “close enough” to each other are merged (Cardie &amp; Wagstaff, 1999; Angheluta et al., 2004).</S>
			<S sid ="113" ssid = "43">In our system, we use a method called modified k-means clustering (Wilpon &amp; Rabiner 1985), which takes the opposite approach and uses a top-down approach to split clusters, interleaved with a k-means iterative phase.</S>
			<S sid ="114" ssid = "44">Modified k-means clustering has been successfully applied to speech recognition and it has the advantage of always being able to come to the optimal clustering (i.e. it is not dependent upon the starting state or merging order).</S>
			<S sid ="115" ssid = "45">Modified k-means starts off with all the instances in one big cluster.</S>
			<S sid ="116" ssid = "46">The system then iteratively performs the following steps: 1.</S>
			<S sid ="117" ssid = "47">For each cluster, find its centroid, de-.</S>
			<S sid ="118" ssid = "48">fined as the instance which is the closest to all other instances in the same cluster.</S>
			<S sid ="119" ssid = "49">2.</S>
			<S sid ="120" ssid = "50">For each instance:.</S>
			<S sid ="121" ssid = "51">a. Calculate its distance to all the centroids.b. Find the centroid with the mini mum distance, and join its cluster.</S>
			<S sid ="122" ssid = "52">3.</S>
			<S sid ="123" ssid = "53">Iterate 12 until instances stop moving.</S>
			<S sid ="124" ssid = "54">between clusters.</S>
			<S sid ="125" ssid = "55">4.</S>
			<S sid ="126" ssid = "56">Find the cluster with the largest intra-.</S>
			<S sid ="127" ssid = "57">cluster distance.</S>
			<S sid ="128" ssid = "58">(Call this Clustermax and its centroid, Centroidmax.)</S>
			<S sid ="129" ssid = "59">If this distance is smaller than some threshold r, stop.</S>
	</SECTION>
	<SECTION title="From the instances inside Clustermax, find. " number = "5">
			<S sid ="130" ssid = "1">the pair that are the furthest apart from each other.</S>
			<S sid ="131" ssid = "2">a. Add the pair of instances to the list of centroids and remove Centroidmax from the list.</S>
			<S sid ="132" ssid = "3">b. Repeat from Step 2.</S>
			<S sid ="133" ssid = "4">The algorithm thus alternates traditional k-means clustering with a step that adds new clusters to the pool of existing ones.</S>
			<S sid ="134" ssid = "5">Used for coreference resolution, it splits up the instances into clusters in which the instances are more similar to each other than to instances in other clusters.</S>
			<S sid ="135" ssid = "6">The only thing left to do is to determine a suitable threshold.</S>
			<S sid ="136" ssid = "7">As functions that check for compatibility return negative values while positive distances indicate incompatibility, a threshold of 0 would separate compatible and incompatible Re cal l Pr eci sio nF M ea su re Go ld St an da rd En titi es 7 8 8 8 . 5 8 2 . 9 Ba sel ine (H eu ris tic ba se d En titi es) 8 0.</S>
			<S sid ="137" ssid = "8">9 4 4 . 1 5 7 . 1 Ba sel ine (N ou n Ph ras e M atc h On ly) 5 0.</S>
			<S sid ="138" ssid = "9">9 7 7 . 2 6 1 . 3 He uri stic Ba se d En tit y Re co gn iti on 6 2.</S>
			<S sid ="139" ssid = "10">9 7 7 . 1 6 9 . 3 Pa rsi ng Ba se d En tit y Re co gn iti on 4 2.</S>
			<S sid ="140" ssid = "11">5 6 2 . 9 5 0 . 7 Table 3: Coreference Resolution Performance elements.</S>
			<S sid ="141" ssid = "12">However, since the feature extraction will not be totally accurate, (especially for the GENDER and NUMBER features which test for incompatibility) we chose to be more lenient with deciding whether two phrases should be clustered together, and used a threshold of r = 1 to allow for possible errors.</S>
			<S sid ="142" ssid = "13">5 Evaluation.</S>
			<S sid ="143" ssid = "14">Evaluation of coreference resolution systems has traditionally been performed with precision and recall.</S>
			<S sid ="144" ssid = "15">The MUC competition defines recall as follows (Vilain et al., 1995): R = &quot; (| Ci | ! | p(Ci ) |) &quot; (| Ci | !1) Each Ci is a gold standard cluster (i.e. a set of phrases which we know refer to the same entity), and p(Ci) is the partitioning of Ci by the automatically-generated clusters.</S>
			<S sid ="145" ssid = "16">For precision, the role of the automatic and gold standard clusters are reversed.</S>
			<S sid ="146" ssid = "17">Our results were evaluated using the MUC scoring program which reports recall, precision and F-measure, where the F-measure is defined as the harmonic mean of precision and recall: F = 2PR P + R Table 3 presents the results of our coreference resolution system on the outputs of both the parsing-based and heuristic-based entity detection systems, as measured by the MUC7 scoring program.</S>
			<S sid ="147" ssid = "18">For the purposes of comparison, we also present results of our clustering algorithm on the gold standard entities.</S>
			<S sid ="148" ssid = "19">This gives us a sense of the upper bound that we could potentially achieve if we got 100% accuracy on our mention detection phase.</S>
			<S sid ="149" ssid = "20">An additional baseline is generated by implementing a system that assumes that all phrases refer to the same entity – i.e. it takes all the heuristically-generated phrases and puts them into one big cluster.</S>
			<S sid ="150" ssid = "21">This gives us an upper bound on the recall of the system.</S>
			<S sid ="151" ssid = "22">Yet another baseline, to see how easy the task is, is to merge mentions together if the “Noun Phrase Match” function tests true.</S>
			<S sid ="152" ssid = "23">From the results, it can be seen that our system achieves a performance gain of over 10 F- Measure points over the simplest baseline, and over 8 F-Measure points over the more sophisticated baseline.</S>
			<S sid ="153" ssid = "24">Unfortunately, due to corpus differences, we cannot conduct a comparison with results found in previous work.</S>
			<S sid ="154" ssid = "25">An interesting observation is the fact that the heuristic-based entity recognizer achieves better performance than the one based on statistical parsing.</S>
			<S sid ="155" ssid = "26">The parser is trained on the Chinese Penn Treebank, which tends to have relatively longer noun phrases, and as result, the phrases generated by the parser also tend to be on the long side.</S>
			<S sid ="156" ssid = "27">This causes errors at the entity recognition phase, which results in a performance hit for the overall system.</S>
	</SECTION>
	<SECTION title="Analysis. " number = "6">
			<S sid ="157" ssid = "1">One interesting question to ask about the results is the contribution of any given individual feature to the result of the overall system.</S>
			<S sid ="158" ssid = "2">We have already investigated the effect of entity recognition, and in this section, we take a look at the features for the clustering algorithm.</S>
			<S sid ="159" ssid = "3">Error!</S>
			<S sid ="160" ssid = "4">Reference source not found.</S>
			<S sid ="161" ssid = "5">presents the results of a series of experiments in which one feature at a time was removed from the clustering algorithm.</S>
			<S sid ="162" ssid = "6">The last entry in the table shows the results of the full system; the drop in performance when a feature is removed is indicative of its contribution.</S>
			<S sid ="163" ssid = "7">Judging from the results, the 3 features that contribute the most to performance are the NOUN PHRASE MATCH, SEMANTIC AGREEMENT and EDIT DISTANCE features.</S>
			<S sid ="164" ssid = "8">Two out of the three, NOUN PHRASE and EDIT DISTANCE, operate on lexical information.</S>
			<S sid ="165" ssid = "9">The importance of string matching to coreference resolution is consistent with findings in previous work (Yang et al. 2004), which arrived at the same conclusion for English.In addition, we note that the two Chinese specific features that were introduced, ABBREVIATION and EDIT DISTANCE, both contribute significantly (as measured by a student’s t- test) to the performance of the final system.</S>
			<S sid ="166" ssid = "10">Re m ov ed fe at ur e Re cal l Pr eci sio nF m ea su re No un Ph ra se M at ch 5 9 . 8 7 5 . 9 6 6 . 9 He ad No un M atc h 6 0 . 4 7 6 . 2 6 7 . 4 Se nte nc e Di sta nc e 6 3 . 2 7 3 . 3 6 7 . 8 Ge nd er A gr ee me nt 6 2 . 9 7 6 . 3 6 8 . 9 Nu m be r Ag re e m ent 6 3 . 2 7 5 . 9 6 9 Se m an tic A gr ee m en t 6 0 . 5 7 3 6 6 . 2 Pr op er Na me Ag re e me nt 6 3 7 6 . 2 6 9 Pr on ou n Ag re e m ent 6 1 . 3 7 6 . 9 6 8 . 2 De m on str ati ve No un Ph ras e 6 2 . 2 7 7 . 9 6 9 . 2 Ap po sit iv e 6 0 . 1 7 6 . 9 6 7 . 5 Ab br ev iat io n 6 1 . 6 7 7 6 8 . 4 Ed it Di st an ce 6 2 . 4 7 2 . 8 6 7 . 2 No ne (A ll Fe at ur es) 6 2 . 9 7 7 . 1 6 9 . 3 Table 4: Contribution of individual features to overall performance.</S>
			<S sid ="167" ssid = "11">Of our features, those that contribute the least to the overall performance are the GENDER, NUMBER and DEMONSTRATIVE NOUN PHRASE features.</S>
			<S sid ="168" ssid = "12">For DEMONSTRATIVE NOUN PHRASE, the reason is because of data sparsity – there are just simply not enough examples that it would make any significant impact.</S>
			<S sid ="169" ssid = "13">For the GENDER and NUMBER features, we find that the problem is mostly with errors in feature generation.</S>
			<S sid ="170" ssid = "14">To our knowledge, this is the first published result on unsupervised Chinese coreference resolution.</S>
			<S sid ="171" ssid = "15">Due to differences in data, it is not possible to conduct a comparison of our work with previous results.</S>
	</SECTION>
	<SECTION title="Related Work. " number = "7">
			<S sid ="172" ssid = "1">Coreference resolution has attracted much attention in recent years, especially as a result of the MUC and ACE competitions.</S>
			<S sid ="173" ssid = "2">The approaches taken have exhibited a shift from knowledge- based approaches to learning-based approaches.</S>
			<S sid ="174" ssid = "3">Many of the learning-based approaches recast coreference resolution as a binary classification task, which, given a pair of NPs, uses a trained classifier to determine whether they are coreferent.</S>
			<S sid ="175" ssid = "4">Soon et al.</S>
			<S sid ="176" ssid = "5">(2001) used this approach with a 12-feature decision tree-based classifier and Ng and Cardie (2002) extended this approach with extra machine learning frameworks and a larger set of features.</S>
			<S sid ="177" ssid = "6">Yang et al.</S>
			<S sid ="178" ssid = "7">(2004) extended this approach into an NP-cluster based approach, which considers the relationships between phrases and coreferential clusters.</S>
			<S sid ="179" ssid = "8">In addition, several unsupervised approaches have been proposed.</S>
			<S sid ="180" ssid = "9">Cardie and Wagstaff (1999) recast the problem as a clustering task which applied a set of incompatibility functions and weights in the distance metric.</S>
			<S sid ="181" ssid = "10">Bean and Riloff (2004) used information extraction patterns to identify contextual clues that would determine the compatibility between NPs.</S>
			<S sid ="182" ssid = "11">All of the previously mentioned work has been for English.</S>
			<S sid ="183" ssid = "12">There has been relatively little work in Chinese: Florian et al.</S>
			<S sid ="184" ssid = "13">(2004) provides results using a language-independent framework on the Entity Detection and Tracking task (EDT).</S>
			<S sid ="185" ssid = "14">They formulate the detection subtask as a classification problem using a Robust Risk Minimization classifier combined with a Maximum Entropy classifier.</S>
			<S sid ="186" ssid = "15">Their system performs significantly well on English, Chinese and Arabic, however, the system suffers from small amount of training data (90K characters for Chinese, in contrast with 340K words for English).</S>
			<S sid ="187" ssid = "16">Their system obtained an ACE value of 58.8 on the ACE evaluation data on Chinese.</S>
			<S sid ="188" ssid = "17">Finally, Zhou et al.</S>
			<S sid ="189" ssid = "18">(2005) proposed a unified Transformation-Based Learning framework on Chinese EDT.</S>
			<S sid ="190" ssid = "19">The TBL tracking model looks at pairs of NPs at a time and classifies them as being coreferent or not based on the values of six features.</S>
			<S sid ="191" ssid = "20">They report an ACE score of 63.3 on their dataset.</S>
	</SECTION>
	<SECTION title="Conclusions and Future Work. " number = "8">
			<S sid ="192" ssid = "1">In this paper, we have presented an unsupervised approach to Chinese coreference resolution.</S>
			<S sid ="193" ssid = "2">Our approach performs resolution by clustering, with the advantage that no annotated training data is needed.</S>
			<S sid ="194" ssid = "3">We evaluated our approach using a corpus which we developed using standard annotation schemes, and find that our system achieves an error reduction rate of almost 30% over the baseline.</S>
			<S sid ="195" ssid = "4">We also analyze the performance of our system by investigating the contribution of individual features to our system.</S>
			<S sid ="196" ssid = "5">The analysis illus trates the contribution of the new language- specific features.</S>
			<S sid ="197" ssid = "6">While the results produced by our system are impressive, it should be noted that all our features consider only the mention phrase itself.</S>
			<S sid ="198" ssid = "7">We consider this to be a rather simplistic and incomplete.</S>
			<S sid ="199" ssid = "8">In future work, we plan to investigate the use of more sophisticated features, including contextual features, to improve the performance of our system.</S>
	</SECTION>
</PAPER>
