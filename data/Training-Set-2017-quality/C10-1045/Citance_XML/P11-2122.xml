<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">This work introduces a new approach to checking treebank consistency.</S>
		<S sid ="2" ssid = "2">Derivation trees based on a variant of Tree Adjoining Grammar are used to compare the annotation of word sequences based on their structural similarity.</S>
		<S sid ="3" ssid = "3">This overcomes the problems of earlier approaches based on using strings of words rather than tree structure to identify the appropriate contexts for comparison.</S>
		<S sid ="4" ssid = "4">We report on the result of applying this approach to the Penn Arabic Treebank and how this approach leads to high precision of error detection.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="5" ssid = "5">The internal consistency of the annotation in a tree- bank is crucial in order to provide reliable training and testing data for parsers and linguistic research.</S>
			<S sid ="6" ssid = "6">Treebank annotation, consisting of syntactic structure with words as the terminals, is by its nature more complex and thus more prone to error than other annotation tasks, such as part-of-speech tagging.</S>
			<S sid ="7" ssid = "7">Recent work has therefore focused on the importance of detecting errors in the treebank (Green and Manning, 2010), and methods for finding such errors automatically, e.g.</S>
			<S sid ="8" ssid = "8">(Dickinson and Meurers, 2003b; Boyd et al., 2007; Kato and Matsubara, 2010).</S>
			<S sid ="9" ssid = "9">We present here a new approach to this problem that builds upon Dickinson and Meurers (2003b), by integrating the perspective on treebank consistency checking and search in Kulick and Bies (2010).</S>
			<S sid ="10" ssid = "10">The approach in Dickinson and Meurers (2003b) has certain limitations and complications that are inherent in examining only strings of words.</S>
			<S sid ="11" ssid = "11">To over come these problems, we recast the search as one of searching for inconsistently-used elementary trees in a Tree Adjoining Grammar-based form of the tree- bank.</S>
			<S sid ="12" ssid = "12">This allows consistency checking to be based on structural locality instead of n-grams, resulting in improved precision of finding inconsistent treebank annotation, allowing for the correction of such inconsistencies in future work.</S>
	</SECTION>
	<SECTION title="Background and Motivation. " number = "2">
			<S sid ="13" ssid = "1">2.1 Previous Work - DECCA.</S>
			<S sid ="14" ssid = "2">The basic idea behind the work in (Dickinson and Meurers, 2003a; Dickinson and Meurers, 2003b) is that strings occurring more than once in a corpus may occur with different “labels” (taken to be constituent node labels), and such differences in labels might be the manifestation of an annotation error.</S>
			<S sid ="15" ssid = "3">Adopting their terminology, a “variation nucleus” is the string of words with a difference in the annotation (label), while a “variation n-gram” is a larger string containing the variation nucleus.</S>
			<S sid ="16" ssid = "4">(1) a.</S>
			<S sid ="17" ssid = "5">(NP the (ADJP most important) points) b.</S>
			<S sid ="18" ssid = "6">(NP the most important points) For example, suppose the pair of phrases in (1) are taken from two different sentences in a corpus.</S>
			<S sid ="19" ssid = "7">The “variation nucleus” is the string most important, and the larger surrounding n-gram is the string the most important points.</S>
			<S sid ="20" ssid = "8">This is an example of error in the corpus, since the second annotation is incorrect, and this difference manifests itself by the nucleus having in (a) the label ADJP but in (b) the default label NIL (meaning for their system that the nucleus has no covering node).Dickinson and Meurers (2003b) propose a “non 693 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 693–698, Portland, Oregon, June 1924, 2011.</S>
			<S sid ="21" ssid = "9">Qc 2011 Association for Computational Linguistics fringe heuristic”, which considers two variation nuclei to have a comparable context if they are properly contained within the same variation n-gram - i.e., there is at least one word of the n-gram on both sides of the nucleus.</S>
			<S sid ="22" ssid = "10">For the the pair in (1), the two instances of the variation nucleus satisfy the non- fringe heuristic because they are properly contained within the identical variation n-gram (with the and points on either side).</S>
			<S sid ="23" ssid = "11">See Dickinson and Meurers (2003b) for details.</S>
			<S sid ="24" ssid = "12">This work forms the basis for the DECCA system.1 2.2 Motivation for Our Approach.</S>
			<S sid ="25" ssid = "13">inconsistent structures for the identical word sequences as in (2ab), the DECCA approach would instead focus on the single word Al$yx, which has a NP label in (2a), while it has the default label NIL in (2b).</S>
			<S sid ="26" ssid = "14">However, whether it is reported as a variation depends on the irrelevant fact of whether the word to the right of Al$yx is the same in both instances, thus allowing it to pass the non-fringe heuristic (since it already has the same word, $rm, on the left).</S>
			<S sid ="27" ssid = "15">Consider now the two trees (2bc).</S>
			<S sid ="28" ssid = "16">There is an additional NP level in (2c) because of the adjunct ( mSr ), causing qmp $rm Al$yx to have no (2) a. NP qmp NP summit $rm b. NP qmp summit NP $rm NP Al$yx covering node, and so have the default label NIL, and therefore categorized as a variation compared to (2b).</S>
			<S sid ="29" ssid = "17">However, this is a spurious difference, since the label difference is caused only by the irrelevant presence of an adjunct, and it is clear, without look qmp summit Sharm c. NP Al$yx the Sheikh NP Sharm the Sheikh ing at any further structure, that the annotation of qmp $rm Al$yx is identical in (2bc).</S>
			<S sid ="30" ssid = "18">In this case the “non fringe heuristic” serves to avoid reporting such spurious difference s, since if qmp $rm Al$yx did not have an open parenthesi s on the right in (b), and qmp did not have the same word to its immediate left in both (b) and (c), the two instances $rm Sharm NP Al$yx the Sheikh NP ( mSr ) Egypt would not be surrounded by the same larger variation n-gram, and so would not pass the non-fringe heuristic.</S>
			<S sid ="31" ssid = "19">This reliance on irrelevant material arises from us We motivate our approach by illustrating the limitations of the DECCA approach.</S>
			<S sid ="32" ssid = "20">Consider the trees (2a) and (2b), taken from two instances of the three- word sequence qmp $rm Al$yx in the Arabic Treebank.2 There is no need to look at any surrounding annotation to conclude that there is an inconsistency in the annotation of this sequence.3 However, based on (2ab), the DECCA system would not even identify the three-word sequence qmp $rm Al$yx as a nucleus to compare, because both instances have a NP covering node, and so are considered to have the same label.</S>
			<S sid ="33" ssid = "21">(The same is true for the two-word subsequence $rm Al$yx.)</S>
			<S sid ="34" ssid = "22">Instead of doing the natural comparison of the 1 http://www.decca.osu.edu/.</S>
			<S sid ="35" ssid = "23">2 In Section 4 we give the details of the corpus.</S>
			<S sid ="36" ssid = "24">We use the.</S>
			<S sid ="37" ssid = "25">Buckwalter Arabic transliteration scheme (Buckwalter, 2004).</S>
			<S sid ="38" ssid = "26">3 While the nature of the inconsistency is not the issue here, (b) is the correct annotation.</S>
			<S sid ="39" ssid = "27">ing on a single node label to characterize a structural annotation and the surrounding word context to overcome the resulting complications.</S>
			<S sid ="40" ssid = "28">Our approach instead directly compares the annotations of interest.</S>
	</SECTION>
	<SECTION title="Using Derivation Tree Fragments. " number = "3">
			<S sid ="41" ssid = "1">We utilize ideas from the long line of Tree Adjoining Grammar-based research (Joshi and Schabes, 1997), based on working with small “elementary trees” (abbreviated “etrees” in the rest of this paper) that are the “building blocks” of the full trees of a treebank.</S>
			<S sid ="42" ssid = "2">This decomposition of the full tree into etrees also results in a “derivation tree” that records how the elementary trees relate to each other.</S>
			<S sid ="43" ssid = "3">We illustrate the basics of TAG-based derivation we are using with examples based on the trees in (2).</S>
			<S sid ="44" ssid = "4">Our grammar is a TAG variant with For (2a) For (2b) For (2c) This tree decomposition and resulting derivation #a1 qmp NP NP^ #b1 qmp NP NP^ #c1 qmp NP NP^ tree prov ide us with the tool for com parin g nucl ei with out the inter ferin g effec ts from word s not in the nucl eus.</S>
			<S sid ="45" ssid = "5">We are inter ested not in the deriv ation tree summit #a2 S:1.2 NP $rm Sharm NP^ summit S:1.</S>
			<S sid ="46" ssid = "6">2 #b2 N P Al$ yx The Sheikh summit S:1.</S>
			<S sid ="47" ssid = "7">2 #c2 N P Al$y x The Sheikh for an entire sentence , but rather only that slice of it having etrees with words that are in the nucleus being examine d, which we call the derivatio n tree fragment . That.</S>
			<S sid ="48" ssid = "8">is, for a given nucleus being examined, we partition its instance s based on the covering node in the full tree, and within each set of instance s #a3 S:1.2 #b3 A:1.1,l eft A:1.1,l eft M:1,rig ht we com pare the deri vati on tree frag men ts for each NP Al$yx The Sheikh $rm Sharm #c3 $rm Sharm #c4 NP mSr Egypt instance.</S>
			<S sid ="49" ssid = "9">These derivation tree fragments are the relevant structures to compare for inconsistent annotation, and are computed separately for each instance of each nucleus from the full derivation tree that each instance is part of.5 Figure 1: Etrees and Derivation Trees for (2abc).</S>
			<S sid ="50" ssid = "10">tree-substitution, sister-adjunction, and Chomskyadjunction (Chiang, 2003).</S>
			<S sid ="51" ssid = "11">Sister adjunction at- taches a tree (or single node) as a sister to another node, and Chomskyadjunction forms a recursive structure as well, duplicating a node.</S>
			<S sid ="52" ssid = "12">As typically done, we use head rules to decompose a full tree and extract the etrees.</S>
			<S sid ="53" ssid = "13">The three derivation trees, corresponding to (2abc), are shown in Figure 1.</S>
			<S sid ="54" ssid = "14">Consider first the derivation tree for (2a).</S>
			<S sid ="55" ssid = "15">It has three etrees, numbered a1, a2, a3, which are the nodes in the derivation tree which show how the three etrees connect to each other.</S>
			<S sid ="56" ssid = "16">This derivation tree consists of just tree substitutions.</S>
			<S sid ="57" ssid = "17">The ˆ symbol at node NPˆ in a1 indicates that it is a substitution node, and the S:1.2 above a2 indicates that it substitutes into node at Gorn address 1.2 in tree a1 (i.e., the substitution node), and likewise for a3 substituting into a2.</S>
			<S sid ="58" ssid = "18">The derivation tree for (2b) also has three etrees, although the structure is different.</S>
			<S sid ="59" ssid = "19">Because the lower NP is flat in (2b), the rightmost noun, Al$yx, is taken as the head of the etree b2, with the degenerate tree for $rm sister-adjoining to the left of Al$yx, as indicated by the A:1.1,left.</S>
			<S sid ="60" ssid = "20">The derivation tree for (2c) is identical to that of (2b), except that it has the additional tree c4 for the adjunct mSr, which right Chomsky-adjoins to the root of c2, as indicated by the M:1,right.4 For example, for comparing our three instances of qmp $rm Al$yx, the three derivation tree fragments would be the structures consisting of (a1, a2, a3), (b1, b2, b3) and (c1, c2, c3), along with their connecting Gorn addresses and attachment types.</S>
			<S sid ="61" ssid = "21">This indicates that the instances (2ab) have different internal structures (without the need to look at a surrounding context), while the instances (2bc) have identical internal structures (allowing us to abstract away from the interfering effects of adjunction).</S>
			<S sid ="62" ssid = "22">Space prevents full discussion here, but the etrees and derivation trees as just described require refinement to be truly appropriate for comparing nuclei.</S>
			<S sid ="63" ssid = "23">The reason is that etrees might encode more information than is relevant for many comparisons of nuclei.</S>
			<S sid ="64" ssid = "24">For example, a verb might appear in a corpus with different labels for its objects, such as NP or SBAR, etc., and this would lead to its having different etrees, differing in their node label for the substitution node.</S>
			<S sid ="65" ssid = "25">If the nucleus under comparison includes the verb but not any words from the complement, the inclusion of the different substitution nodes would cause irrelevant differences for that particular nucleus comparison.</S>
			<S sid ="66" ssid = "26">We solve these problems by mapping down the in the derivation tree.</S>
			<S sid ="67" ssid = "27">5 A related approach is taken by Kato and Matsubara (2010), who compare partial parse trees for different instances of the same sequence of words in a corpus, resulting in rules based on a synchronous Tree Substitution Grammar (Eisner, 2003).</S>
			<S sid ="68" ssid = "28">We suspect that there are some major differences between our approaches regarding such issues as the representation of adjuncts, but we leave such a comparison for future work.</S>
			<S sid ="69" ssid = "29">Sy st e m nu cl ei n g r a m s in st an ce s D EC C A 24, 31 9 1,1 58, 34 2 2,9 66, 27 4 U s 54, 49 6 n o t u s e d 6 0 5 , 9 0 6 Table 1: Data examined by the two systems for the ATB S y s t e m nu cle i fo un d non du pli cat e n u cl ei fo u n d t y p e s o f inc on sis ten cy D E C C A 4, 14 0 u n k n o w n u n k n o w n Us int ern al 9, 98 4 4 , 2 7 2 1 , 9 1 1 Table 2: Annotation inconsistencies reported for the ATB representation of the etrees in a derivation tree fragment to form a “reduced” derivation tree fragment.</S>
			<S sid ="70" ssid = "30">These reductions are (automatically) done for each nucleus comparison in a way that is appropriate for that particular nucleus comparison.</S>
			<S sid ="71" ssid = "31">A particular etree may be reduced in one way for one nucleus, and then a different way for a different nucleus.</S>
			<S sid ="72" ssid = "32">This is done for each etree in a derivation tree fragment.</S>
	</SECTION>
	<SECTION title="Results on Test Corpus. " number = "4">
			<S sid ="73" ssid = "1">Green and Manning (2010) discuss annotation consistency in the Penn Arabic Treebank (ATB), and for our test corpus we follow their discussion and use the same data set, the training section of three parts of the ATB (Maamouri et al., 2008a; Maamouri et al., 2009; Maamouri et al., 2008b).</S>
			<S sid ="74" ssid = "2">Their work is ideal for us, since they used the DECCA algorithm for the consistency evaluation.</S>
			<S sid ="75" ssid = "3">They did not use the “non-fringe” heuristic, but instead manually examined a sample of 100 nuclei to determine whether they were annotation errors.</S>
			<S sid ="76" ssid = "4">4.1 Inconsistencies Reported.</S>
			<S sid ="77" ssid = "5">The corpus consists of 598,000 tokens.</S>
			<S sid ="78" ssid = "6">Table 1 compares token manipulation by the two systems.</S>
			<S sid ="79" ssid = "7">The DECCA system6 identified 24,319 distinct variation nuclei, while our system had 54,496.</S>
			<S sid ="80" ssid = "8">DECCA examined 1,158,342 n-grams, consisting of 2,966,274 6 We worked at first with version 0.2 of the software.</S>
			<S sid ="81" ssid = "9">However this software does not implement the non-fringe heuristic and does not make available the actual instances of the nuclei that were found.</S>
			<S sid ="82" ssid = "10">We therefore re-implemented the algorithm to make these features available, being careful to exactly match our output against the released DECCA system as far as the nuclei and n-grams found.</S>
			<S sid ="83" ssid = "11">instances (i.e., different corpus positions of the n- grams), while our system examined 605,906 instances of the 54,496 nuclei.</S>
			<S sid ="84" ssid = "12">For our system, the number of nuclei increases and the variation n- grams are eliminated.</S>
			<S sid ="85" ssid = "13">This is because all nuclei with more than one instance are evaluated, in order to search for constituents that have the same root but different internal structure.</S>
			<S sid ="86" ssid = "14">The number of reported inconsistencies is shown in Table 2.</S>
			<S sid ="87" ssid = "15">DECCA identified 4,140 nuclei as likely errors - i.e., contained in larger n-grams, satisfying the non-fringe heuristic.</S>
			<S sid ="88" ssid = "16">Our system identified 9,984 nuclei as having inconsistent annotation - i.e., with at least two instances with different derivation tree fragments.</S>
			<S sid ="89" ssid = "17">4.2 Eliminating Duplicate Nuclei.</S>
			<S sid ="90" ssid = "18">Some of these 9,984 nuclei are however redundant, due to nuclei contained within larger nuclei, such as $rm Al$yx inside qmp $rm Al$yx in (2abc).</S>
			<S sid ="91" ssid = "19">Eliminating such duplicates is not just a simple matter of string inclusion, since the larger nucleus can sometimes reveal different annotation inconsistencies than just those in the smaller substring nucleus, and also a single nucleus string can be included in different larger nuclei.</S>
			<S sid ="92" ssid = "20">We cannot discuss here the full details of our solution, but it basically consists of two steps.</S>
			<S sid ="93" ssid = "21">First, as a result of the analysis described so far, for each nucleus we have a mapping of each instance of that nucleus to a derivation tree fragment.</S>
			<S sid ="94" ssid = "22">Second, we test for each possible redundancy (meaning string inclusion) whether there is a true structural redundancy by testing for an isomorphism between the mappings for two nuclei.</S>
			<S sid ="95" ssid = "23">For this test corpus, eliminating such duplicates leaves 4,272 nuclei as having inconsistent annotation.</S>
			<S sid ="96" ssid = "24">It is unknown how many of the DECCA nuclei are duplicates, although many certainly are.</S>
			<S sid ="97" ssid = "25">For example, qmp $rm Al$yx and $rm Al$yx are reported as separate results.</S>
			<S sid ="98" ssid = "26">4.3 Grouping Inconsistencies by Structure.</S>
			<S sid ="99" ssid = "27">Across all variation nuclei, there are only a finite number of derivation tree fragments and thus ways in which such fragments indicate an annotation inconsistency.</S>
			<S sid ="100" ssid = "28">We categorize each annotation inconsistency by the inconsistency type, which is simply a set of numbers representing the different derivation tree fragments.</S>
			<S sid ="101" ssid = "29">We can then present the results not by listing each nucleus string, but instead by the inconsistency types, with each type having some number of nuclei associated with it.</S>
			<S sid ="102" ssid = "30">For example, instances of $rm Al$yx might have just the derivation tree fragments (a2, a3) and (b2, b3) in Figure 1, and the numbers representing this pair is the “inconsistency type” for this (nucleus, internal context) inconsistency.</S>
			<S sid ="103" ssid = "31">There are nine other nuclei reported as having an inconsistency based on the exact same derivation tree fragments (abstracting only away from the particular lexical items), and so all these nuclei are grouped together as having the same “inconsistency type”.</S>
			<S sid ="104" ssid = "32">This grouping results in the 4,272 non-duplicate nuclei found being grouped into 1,911 inconsistency types.</S>
			<S sid ="105" ssid = "33">4.4 Precision and Recall.</S>
			<S sid ="106" ssid = "34">The grouping of internal checking results by inconsistency types is a qualitative improvement in consistency reporting, with a high precision.7 By viewing inconsistencies by structural annotation types, we can examine large numbers of nuclei at a time.</S>
			<S sid ="107" ssid = "35">Of the first 10 different types of derivation tree inconsistencies, which include 266 different nuclei, all 10 appear to real cases of annotation inconsistency, and the same seems to hold for each of the nuclei in those 10 types, although we have not checked every single nucleus.</S>
			<S sid ="108" ssid = "36">For comparison, we chose a sample of 100 nuclei output by DECCA on this same data, and by our judgment the DECCA precision is about 74%, including 15 duplicates.</S>
			<S sid ="109" ssid = "37">Measuring recall is tricky, even using the errors identified in Green and Manning (2010) as “gold” errors.</S>
			<S sid ="110" ssid = "38">One factor is that a system might report a variation nucleus, but still not report all the relevant instances of that nucleus.</S>
			<S sid ="111" ssid = "39">For example, while both systems report $rm Al$yx as a sequence with inconsistent annotation, DECCA only reports the two instances that pass the “non-fringe heuristic”, while our system lists 132 instances of $rm Al$yx, partitioning them into the two derivation tree fragments.</S>
			<S sid ="112" ssid = "40">We will be carrying out a careful accounting of the recall evaluation in future work.</S>
			<S sid ="113" ssid = "41">7 “Precision” here means the percentage of reported variations that are actually annotation errors.</S>
	</SECTION>
	<SECTION title="Future Work. " number = "5">
			<S sid ="114" ssid = "1">While we continue the evaluation work, our primary concern now is to use the reported inconsistent derivation tree fragments to correct the annotation inconsistencies in the actual data, and then evaluate the effect of the corpus corrections on parsing.</S>
			<S sid ="115" ssid = "2">Our system groups all instances of a nucleus into different derivation tree fragments, and it would be easy enough for an annotator to specify which is correct (or perhaps instead derive this automatically based on frequencies).</S>
			<S sid ="116" ssid = "3">However, because the derivation trees and etrees are somewhat abstracted from the actual trees in the treebank, it can be challenging to automatically correct the structure in every location to reflect the correct derivation tree fragment.</S>
			<S sid ="117" ssid = "4">This is because of details concerning the surrounding structure and the interaction with annotation style guidelines such as having only one level of recursive modification or differences in constituent bracketing depending on whether a constituent is a “single-word” or not.</S>
			<S sid ="118" ssid = "5">We are focusing on accounting for these issues in current work to allow such automatic correction.</S>
	</SECTION>
	<SECTION title="Acknowledgments">
			<S sid ="119" ssid = "6">We thank the computational linguistics group at the University of Pennsylvania for helpful feedback on a presentation of an earlier version of this work.</S>
			<S sid ="120" ssid = "7">We also thank Spence Green and Chris Manning for supplying the data used in their analysis of the Penn Arabic Treebank.</S>
			<S sid ="121" ssid = "8">This work was supported in part by the Defense Advanced Research Projects Agency, GALE Program Grant No.</S>
			<S sid ="122" ssid = "9">HR001106 10003 (all authors) and by the GALE program, DARPA/CMO Contract No.</S>
			<S sid ="123" ssid = "10">HR001106-C-0022 (first author).</S>
			<S sid ="124" ssid = "11">The content of this paper does not necessarily reflect the position or the policy of the Government, and no official endorsement should be inferred.</S>
	</SECTION>
</PAPER>
