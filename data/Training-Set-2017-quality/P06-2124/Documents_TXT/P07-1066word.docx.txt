Bilingual-LSA Based LM Adaptation for Spoken Language Translation



Yik-Cheung Tam and Ian Lane and Tanja Schultz 
InterACT, Language Technologies Institute Carnegie 
Mellon University
Pittsburgh, PA 15213
{yct,ian.lane,tanja}@cs.cmu.edu








Abstract

We propose a novel approach to crosslingual 
language model (LM) adaptation based on 
bilingual Latent Semantic Analysis (bLSA). 
A bLSA model is introduced which enables 
latent topic distributions to be efficiently 
transferred across languages by enforcing 
a one-to-one topic correspondence during 
training.  Using the proposed bLSA frame- 
work crosslingual LM adaptation can be per- 
formed by, first, inferring the topic poste- 
rior distribution of the source text and then 
applying the inferred distribution to the tar- 
get language N-gram LM via marginal adap- 
tation.  The proposed framework also en- 
ables rapid bootstrapping of LSA models 
for new languages based on a source LSA 
model from another language.  On Chinese 
to English speech and text translation the 
proposed bLSA framework successfully re- 
duced word perplexity of the English LM by 
over 27% for a unigram LM and up to 13.6% 
for a 4-gram LM. Furthermore, the pro- 
posed approach consistently improved ma- 
chine translation quality on both speech and 
text based adaptation.

1   Introduction

Language model adaptation is crucial to numerous 
speech and translation tasks as it enables higher- 
level contextual information to be effectively incor- 
porated into a background LM improving recogni- 
tion or translation performance.   One approach is
520


to employ Latent Semantic Analysis (LSA) to cap- 
ture in-domain word unigram distributions which are  
then  integrated  into  the  background  N-gram LM. 
This approach has been successfully applied in 
automatic speech recognition (ASR) (Tam and 
Schultz, 2006) using the Latent Dirichlet Alloca- 
tion (LDA) (Blei et al., 2003). The LDA model can 
be viewed as a Bayesian topic mixture model with 
the topic mixture weights drawn from a Dirichlet 
distribution.  For LM adaptation, the topic mixture 
weights are estimated based on in-domain adapta- 
tion text (e.g. ASR hypotheses). The adapted mix- 
ture weights are then used to interpolate a topic- 
dependent unigram LM, which is finally integrated 
into the background N-gram LM using marginal 
adaptation (Kneser et al., 1997)

  In this paper, we propose a framework to per- 
form LM adaptation across languages, enabling the 
adaptation of a LM from one language based on the 
adaptation text of another language.  In statistical 
machine translation (SMT), one approach is to ap- 
ply LM adaptation on the target language based on 
an initial translation of input references (Kim and 
Khudanpur, 2003; Paulik et al., 2005). This scheme 
is limited by the coverage of the translation model, 
and overall by the quality of translation. Since this 
approach only allows to apply LM adaptation af- 
ter translation, available knowledge cannot be ap- 
plied to extend the coverage. We propose a bilingual 
LSA model (bLSA) for crosslingual LM adaptation 
that can be applied before translation.  The bLSA 
model consists of two LSA models:  one for each 
side of the language trained on parallel document 
corpora. The key property of the bLSA model is that


Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 520–527, 
Prague, Czech Republic, June 2007. Qc 2007 Association for Computational Linguistics


the latent topic of the source and target LSA mod- 
els can be assumed to be a one-to-one correspon- 
dence and thus share a common latent topic space 
since the training corpora consist of bilingual paral- 
lel data.  For instance, say topic 10 of the Chinese 
LSA model is about politics.  Then topic 10 of the 
English LSA model is set to also correspond to pol- 
itics and so forth.  During LM adaptation, we first 
infer the topic mixture weights from the source text 
using the source LSA model. Then we transfer the 
inferred mixture weights to the target LSA model 
and thus obtain the target LSA marginals. The chal- 
lenge is to enforce the one-to-one topic correspon-
dence. Our proposal is to share common variational









ASR hypo



   Chinese ASR 	Chinese−>English SMT Chinese N−gram LM 	    
English N−gram LM

Adapt 	Adapt

Topic distribution
Chinese LSA 	English LSA



Chinese text 	English text

Chinese−English




Parallel document corpus









MT hypo


Dirichlet posteriors over the topic mixture weights 
of a document pair in the LDA-style model.  The 
beauty of the bLSA framework is that the model 
searches for a common latent topic space in an un- 
supervised fashion, rather than to require manual in- 
teraction. Since the topic space is language indepen- 
dent, our approach supports topic transfer in multi- 
ple language pairs in O(N) where N is the number of 
languages.
  Related work includes the Bilingual Topic Ad- 
mixture Model (BiTAM) for word alignment pro- 
posed by (Zhao and Xing, 2006).  Basically, the 
BiTAM model consists of topic-dependent transla-
tion lexicons modeling P r(c|e, k) where c, e and
k denotes the source Chinese word, target English
word  and  the  topic  index  respectively.    On  the 
other hand, the bLSA framework models P r(c|k) 
and P r(e|k)  which is different from the BiTAM
model. By their different modeling nature, the bLSA 
model usually supports more topics than the BiTAM 
model.   Another work by (Kim and Khudanpur,
2004) employed crosslingual LSA using singular 
value decomposition which concatenates bilingual 
documents into a single input supervector before 
projection.
  We organize the paper as follows: In Section 2, 
we introduce the bLSA framework including La- 
tent Dirichlet-Tree Allocation (LDTA) (Tam and 
Schultz, 2007) as a correlated LSA model, bLSA 
training and crosslingual LM adaptation.  In Sec- 
tion 3, we present the effect of LM adaptation on 
word perplexity, followed by SMT experiments re- 
ported in BLEU on both speech and text input in 
Section 3.3. Section 4 describes conclusions and fu-


Figure 1: Topic transfer in bilingual LSA model.

ture works.

2   Bilingual Latent Semantic Analysis

The goal of a bLSA model is to enforce a one- 
to-one topic correspondence between monolingual 
LSA models, each of which can be modeled using 
an LDA-style model.  The role of the bLSA model 
is to transfer the inferred latent topic distribution 
from the source language to the target language as- 
suming that the topic distributions on both sides are 
identical. The assumption is reasonable for parallel 
document pairs which are faithful translations. Fig- 
ure 1 illustrates the idea of topic transfer between 
monolingual LSA models followed by LM adapta- 
tion. One observation is that the topic transfer can be 
bi-directional meaning that the “flow” of topic can 
be from ASR to SMT or vice versa.  In this paper, 
we only focus on ASR-to-SMT direction.  Our tar- 
get is to minimize the word perplexity on the target 
language through LM adaptation. Before we intro- 
duce the heuristic of enforcing a one-to-one topic 
correspondence, we describe the Latent Dirichlet- 
Tree Allocation (LDTA) for LSA.

2.1   Latent Dirichlet-Tree Allocation
The LDTA model extends the LDA model in which 
correlation among latent topics are captured using a 
Dirichlet-Tree prior. Figure 2 illustrates a depth-two 
Dirichlet-Tree. A tree of depth one simply falls back 
to the LDA model. The LDTA model is a generative 
model with the following generative process:
1. Sample a vector of branch probabilities bj   ∼



j=1
Dir(.)



j=2	j=3


Similar to LDA training, 
we apply the variational 
Bayes approach by 
optimizing the lower bound 
of the marginalized 
document likelihood:

p(wn , 
zn, bJ ; 
Λ)



Dir(.)



Dir(.)



Dir(.)


L(wn ; Λ, Γ) = Eq 
[log  	1     1     1 	]


1	q(zn , bJ ; Γ)
1	1
p(zn|bJ )


= Eq [log p(wn |zn)] + Eq [log


1    1   ]



Latent topics



topic 1 	topic 4



topic K


1    1	q(zn )



Figure 2: Dirichlet-Tree prior of depth two.

Dir(αj ) for each node j = 1...J where αj  de-



+Eq [log


p(bJ ; {αj })
q(bJ ; {γj })


notes the parameter (aka the pseudo-counts of


where q(zn , bJ ; Γ) = Tin q(zi ) · TiJ  q(bj ) is a fac-


1	1	i	j


its outgoing branches) of the Dirichlet distribu-
tion at node j.

2. Compute the topic proportions as:

θk	=	  bδjc (k)
jc


torizable variational posterior distribution over the
latent variables parameterized by Γ which are 
deter- mined in the E-step. Λ is the model 
parameters for
a Dirichlet-Tree {αj } and the topic-dependent uni-
gram LM {βwk }.  The LDTA model has an E-step
similar to the LDA model:
E-Step:



where δjc(k) is an indicator function which sets	n 	K



to unity when the c-th branch of the j-th node


γjc	=	αjc + ) ) qik · δjc(k)	(2)


leads to the leaf node of topic k and zero other-	i 	k


wise. The k-th topic proportion θk is computed 
as the product of branch probabilities from the 
root node to the leaf node of topic k.




where


qik	∝	βw k · eEq [log θk ]


(3)



3. Generate a document using the topic multino- 
mial for each word wi:


Eq [log θk ]	=  ) δjc(k)Eq [log bjc]
jc
(	\



zi	∼  M ult(θ)


=  ) δjc(k)
jc


Ψ(γjc) − Ψ() γjc)
c


wi	∼  M ult(β.zi )



where qik



denotes q(zi



= k) meaning the variational


where β.zi    denotes the  topic-dependent uni- 
gram LM indexed by zi.

The joint distribution of the latent variables (topic


topic posterior of word wi.   Eqn 2 and Eqn 3 are
executed iteratively until convergence is reached.
M-Step:

n


sequence  zn


and  the  
Dirichlet  
nodes  over  
child


βwk 	∝


) qik · δ(wi , 
w) 	(4)


branches bj ) and an observed document wn  can be
written as follows:

n


i

where δ(wi , w) is a Kronecker Delta function. 
The alpha parameters can  be estimated with 
iterative


p(wn, zn , bJ ) 	=  p(bJ |{αj })      βw z


· θz


methods such as Newton-Raphson or simple 
gradi-


1	1	1	1

J


i i	i
i



ent ascent procedure.


where	p(bJ |{αj }) 	=


  Dir(bj ; αj )
j


2.2	Bilingual LSA 
training
For the following 
explanations, we assume 
that our


   αjc −1
∝	jc
jc


source and target languages are 
Chinese and En- glish respectively.  
The bLSA model training is a


two-stage procedure.	At the first stage, we train 
a  Chinese  LSA  model  using  the  Chinese  docu-


LM:



( P rldta(w)  β


ments in parallel corpora.	We applied the varia-
tional EM algorithm (Eqn 2–4) to train a Chinese


P ra(w|h)	∝



P rbg



(w)


· P rbg (w|h) (7)


LSA model.  Then we used the model to compute 
the term eEq [log θk ] needed in Eqn 3 for each Chinese 
document in parallel corpora.  At the second stage, 
we apply the same eEq [log θk ] to bootstrap an English 
LSA model, which is the key to enforce a one-to-one 
topic correspondence. Now the hyper-parameters of 
the variational Dirichlet posteriors of each node in 
the Dirichlet-Tree are shared among the Chinese and 
English model. Precisely, we apply only Eqn 3 with 
fixed eEq [log θk ] in the E-step and Eqn 4 in the M-step
on {βwk } to bootstrap an English LSA model. No-
tice that the E-step is non-iterative resulting in rapid
LSA training.  In short, given a monolingual LSA 
model, we can rapidly bootstrap LSA models of new 
languages using parallel document corpora. Notice 
that the English and Chinese vocabulary sizes do not 
need to be similar.  In our setup, the Chinese vo- 
cabulary comes from the ASR system while the En- 
glish vocabulary comes from the English part of the 
parallel corpora. Since the topic transfer can be bi- 
directional, we can perform the bLSA training in a 
reverse manner, i.e. training an English LSA model 
followed by bootstrapping a Chinese LSA model.

2.3   Crosslingual LM adaptation

Given a source text, we apply the E-step to estimate 
variational Dirichlet posterior of each node in the 
Dirichlet-Tree. We estimate the topic weights on the 
source language using the following equation:

δjc (k)


Likewise,  LM  adaptation  can  take  place  on  the
source language as well due to the bi-directional na- 
ture of the bLSA framework when target-side adap- 
tation text is available.  In this paper, we focus on 
LM adaptation on the target language for SMT.

3   Experimental Setup

We evaluated our bLSA model using the Chinese– 
English parallel document corpora consisting of the 
Xinhua news, Hong Kong news and Sina news. The 
combined corpora contains 67k parallel documents 
with 35M Chinese (CH) words and 43M English 
(EN) words.  Our spoken language translation sys- 
tem translates from Chinese to English. The Chinese 
vocabulary comes from the ASR decoder while the 
English vocabulary is derived from the English por- 
tion of the parallel training corpora. The vocabulary 
sizes for Chinese and English are 108k and 69k re- 
spectively. Our background English LM is a 4-gram 
LM trained with the modified Kneser-Ney smooth- 
ing scheme using the SRILM toolkit on the same 
training text. We explore the bLSA training in both
directions: EN→CH and CH→EN meaning that an
English LSA model is trained first and a Chinese
LSA model is bootstrapped or vice versa.  Exper- 
iments explore which bootstrapping direction yield 
best results measured in terms of English word per- 
plexity. The number of latent topics is set to 200 and 
a balanced binary Dirichlet-Tree prior is used.
With an increasing interest in the ASR-SMT cou-
pling for spoken language translation, we also eval-


ˆ(C H )
k 	∝


(	γjc
jc	c′  γjc′



(5)



uated our approach 
with Chinese ASR 
hypotheses and 
compared with 
Chinese manual 
transcriptions. We 
are interested to 
see the impact due 
to recog-


Then we apply the topic weights into the target LSA
model to obtain an in-domain LSA marginals:

K


nition errors on the ASR hypotheses compared to 
the manual transcriptions. We employed the CMU- 
InterACT ASR system  developed for  the  GALE


P rEN (w) 	=


) β(EN ) · θˆ(C H )


(6)


2006 evaluation.  We 
trained acoustic models 
with


wk 	k
k=1

We integrate the LSA marginal into the target back- 
ground LM using marginal adaptation (Kneser et al.,
1997) which minimizes the Kullback-Leibler diver- 
gence between the adapted LM and the background


over 500 hours of quickly transcribed speech data re- 
leased by the GALE program and the LM with over
800M-word Chinese corpora.  The character error 
rates on the CCTV, RFA and NTDTV shows in the 
RT04 test set are 7.4%, 25.5% and 13.1% respec- 
tively.



Topi
c 
inde
x
T
o
p
 
w
o
r
d
s
“
C
H
-
4
0
”
 
“
E
N
-
4
0
”
fl
y
i
n
g
,
 
s
u
b
m
a
r
i
n
e
,
 
a
i
r
c
r
a
f
t
,
 
a
i
r
,
 
p
i
l
o
t
,
 
l
a
n
d
,
 
m
i
s
s
i
o
n
,
 
b
r
a
n
d
-
n
e
w
 
a
i
r
,
 
s
e
a
,
 
s
u
b
m
a
r
i
n
e
,
 
a
i
r
c
r
a
f
t
,
 
f
l
i
g
h
t
,
 
f
l
y
i
n
g
,
 
s
h
i
p
,
 
t
e
s
t
“
C
H
-
4
1
”
 
“
E
N
-
4
1
”
sat
e
l
l
i
t
e
,
 
h
a
n
-
t
i
a
n
,
 
l
a
u
n
c
h
,
 
s
p
a
c
e
,
 
c
h
i
n
a
,
 
t
e
c
h
n
o
l
o
g
y
,
 
a
s
t
r
o
n
o
m
y
 
s
p
a
c
e
,
 
s
a
t
e
l
l
i
t
e
,
 
c
h
i
n
a
,
 
t
e
c
h
n
o
l
o
g
y
,
 
s
a
t
e
l
l
i
t
e
s
,
 
s
c
i
e
n
c
e
“
C
H
-
4
2
”
 
“
E
N
-
4
2
”
f
i
r
e
,
 
a
i
r
p
o
r
t
,
 
s
e
r
v
i
c
e
s
,
 
m
a
r
i
n
e
,
 
a
c
c
i
d
e
n
t
,
 
a
i
r
f
i
r
e
,
 
a
i
r
p
o
r
t
,
 
s
e
r
v
i
c
e
s
,
 
d
e
p
a
r
t
m
e
n
t
,
 
m
a
r
i
n
e
,
 
a
i
r
,
 
s
e
r
v
i
c
e

Table 1:  Parallel topics extracted by the bLSA 
model. Top words on the Chinese side are translated 
into English for illustration purpose.



-2.7e+08

-2.75e+08

-2.8e+08

-2.85e+08

-2.9e+08

-2.95e+08

-3e+08

-3.05e+08




b
o
o
t
s
t
r
a
p
p
e
d
 
E
N
 
L
S
A
   
	
m
o
n
o
l
i
n
g
u
a
l
 
E
N
 
L
S
A
   
	












2 	4 	6 	8 	10 	12 	14 	16 	18 	20



Table 
2: 
Engli
sh 
word 
perple
xity 
(PPL) 
on the 
RT04 
test 
set 
using 
a 
unigr
am 
LM.


3
.
2
   
L
M
 
a
d
a
p
t
a
t
i
o
n
 
r
e
s
u
l
t
s
We 
traine
d the 
bLSA 
model
s on 
both 
CH→
EN 
and
EN→
CH 
direct
ions 
and 
comp
ared 
their 
LM 
adapt
a-
tion 
perfor
manc
e 
using 
the 
Chine
se 
ASR 
hypot
he-
ses 
(hypo
) and 
the 
manu
al 
transc
riptio
ns 
(ref) 
as in- 
put. 
We 
adapt
ed the 
Engli
sh 
backg
round 
LM 
using 
the 
LSA 
margi
nals 
descri
bed in 
Secti
on 
2.3 
for 
each


# of training iterations

Figure 3: Comparison of training log likelihood of 
English LSA models bootstrapped from a Chinese 
LSA and from a flat monolingual English LSA.


3.1   Analysis of the bLSA model


By examining the top-words of the extracted paral- 
lel topics, we verify the validity of the heuristic de- 
scribed in Section 2.2 which enforces a one-to-one 
topic correspondence in the bLSA model.  Table 1
shows the latent topics extracted by the CH→EN
bLSA model. We can see that the Chinese-English
topic words have strong correlations. Many of them 
are actually translation pairs with similar word rank- 
ings. From this viewpoint, we can interpret bLSA as 
a crosslingual word trigger model. The result indi- 
cates that our heuristic is effective to extract parallel 
latent topics. As a sanity check, we also examine the 
likelihood of the training data when an English LSA 
model is bootstrapped.  We can see from Figure 3 
that the likelihood increases monotonically with the 
number of training iterations. The figure also shows 
that by sharing the variational Dirichlet posteriors 
from the Chinese LSA model, we can bootstrap an 
English LSA model rapidly compared to monolin- 
gual English LSA training with both training proce- 
dures started from the same flat model.


show on the test 
set.
  We first evaluated the English word perplexity 
us- ing the EN unigram LM generated by the 
bLSA model.  Table 2 shows that the bLSA-based 
LM adaptation reduces the word perplexity by over 
27% relative compared to an unadapted EN 
unigram LM. The results indicate that the bLSA 
model success- fully leverages the text from the 
source language and improves the word perplexity 
on the target language. We observe that there is 
almost no performance dif- ference when either the 
ASR hypotheses or the man- ual transcriptions are 
used for adaptation. The result is encouraging 
since the bLSA model may be in- sensitive to 
moderate recognition errors through the projection 
of the input adaptation text into the latent topic 
space.  We also apply an English translation 
reference for adaptation to show an oracle perfor- 
mance. The results using the Chinese hypotheses 
are not too far off from the oracle performance. 
Another
observation is that the CH→EN bLSA model 
seems
to give better performance than the EN→CH 
bLSA
model.  However, their differences are not 
signifi-
cant. The result may imply that the direction of 
the bLSA training is not important since the latent 
topic space captured by either language is similar 
when parallel training corpora are used. Table 3 
shows the word perplexity when the background 
4-gram En- glish LM is adapted with the tuning 
parameter β set



L
M
 
(
4
3
M
, 
β 
= 
0
.
7
)
C
C
T
V
R
F
A
N
T
D
T
V
B
G
 
E
N
 
4
-
g
r
a
m
1
1
8
2
1
2
2
0
3
+
C
H
→
E
N 
(
C
H 
r
e
f)
+
E
N
→
C
H 
(
C
H 
r
e
f)
1
0
2
1
0
2
1
9
1
1
9
8
1
7
9
1
7
9
+
C
H
→
E
N 
(C
H 
hy
po
)
+
E
N
→
C
H 
(C
H 
hy
po
)
1
0
2
1
0
3
1
9
3
1
9
8
1
8
0
1
8
0
+
C
H
→
E
N
 
(
E
N
 
r
e
f)
+
E
N
→
C
H
 
(
E
N
 
r
e
f)
1
0
0
1
0
1
1
8
6
1
9
0
1
7
6
1
7
6

Table 3: English word perplexity (PPL) on the RT04 
test set using a 4-gram LM.

CCTV (CER=7.4%)


rated the proposed approach into our state-of-the-art 
phrase-based SMT system. Translation performance 
was evaluated on the RT04 broadcast news evalua- 
tion set when applied to both the manual transcrip- 
tions and 1-best ASR hypotheses.  During evalua- 
tion two performance metrics, BLEU (Papineni et 
al., 2002) and NIST, were computed. In both cases, a 
single English reference was used during scoring. In 
the transcription case the original English references 
were used. For the ASR case, as utterance segmen- 
tation was performed automatically, the number of 
sentences generated by ASR and SMT differed from


125


120


B
G
 
4
-
g
r
a
m
   
	
+bLSA 
(CH  
reference)
+bLSA (CH 
ASR hypo)   
	
+bLSA 
(EN  
reference
)


the 
nu
mb
er 
of 
Eng
lish 
refe
ren
ces. 
In 
this 
cas
e, 
Lev
- 
ens
htei
n 
alig
nm
ent 
was 
use
d to 
alig
n 
the 
tran
slati
on 
out
put 
to 
the 
Eng
lish 
refe
ren
ces 
bef
ore 
scor
ing.



115




110


3.4	Baseline SMT Setup





105


100






0.1 
	0
.2 
	0
.3 
	0
.4 
	0
.5 
	0
.6 
	0
.7 
	0
.8 
	0
.9 	1
B
e
t
a


The 
bas
elin
e 
SM
T 
syst
em 
con
sist
ed 
of a 
non 
ada
p- 
tive 
syst
em 
trai
ned 
usin
g 
the 
sam
e 
Chi
nes
e-
Eng
lish 
par
alle
l 
doc
um
ent 
cor
por
a 
use
d in 
the 
pre
vio
us 
ex- 
peri
me
nts 
(Se
ctio
ns 
3.1 
and 
3.2)
. 
For 
phr
ase 
extr
ac-


Figure 4: Word perplexity with different β using 
manual reference or ASR hypotheses on CCTV.

to 0.7. Figure 4 shows the change of perplexity with 
different β. We see that the adaptation performance 
using the ASR hypotheses or the manual transcrip- 
tions are almost identical on different β with an op- 
timal value at around 0.7. The results show that the 
proposed approach successfully reduces the perplex- 
ity in the range of 9–13.6% relative compared to an 
unadapted baseline on different shows when ASR 
hypotheses are used.  Moreover, we observe simi- 
lar performance using ASR hypotheses or manual 
Chinese transcriptions which is consistent with the 
results on Table 2. On the other hand, it is interest- 
ing to see that the performance gap from the oracle 
adaptation is somewhat related to the degree of mis- 
match between the test show and the training condi- 
tion. The gap looks wider on the RFA and NTDTV 
shows compared to the CCTV show.

3.3   Incorporating bLSA into Spoken Language
Translation
To investigate the effectiveness of bLSA LM adap- 
tation for spoken language translation, we incorpo-


tion a cleaned subset of these corpora, consisting of
1M Chinese-English sentence pairs, was used. SMT 
decoding  parameters were optimized using  man- 
ual transcriptions and translations of 272 utterances 
from the RT04 development set (LDC2006E10).
  SMT translation was performed in two stages us- 
ing an approach similar to that in (Vogel, 2003). 
First, a translation lattice was constructed by match- 
ing all possible bilingual phrase-pairs, extracted 
from the training corpora, to the input sentence. 
Phrase extraction was performed using the “PESA” 
(Phrase Pair Extraction as Sentence Splitting) ap- 
proach described in (Vogel, 2005).  Next, a search 
was performed to find the best path through the lat- 
tice, i.e. that with maximum translation-score. Dur- 
ing search reordering was allowed on the target lan- 
guage side.   The final translation result was that 
hypothesis with maximum translation-score, which 
is a log-linear combination of 10 scores consist- 
ing of Target LM probability, Distortion Penalty, 
Word-Count Penalty, Phrase-Count and six Phrase- 
Alignment scores.   Weights for each component 
score were optimized to maximize BLEU-score on 
the development set using MER optimization as de- 
scribed in (Venugopal et al., 2005).




S
M
T
 
T
a
r
g
e
t
 
L
M
T
ra
n
sl
at
io
n 
Q
u
al
it
y 
- 
B
L
E
U 
(
N
I
S
T
)

C
C
T
V
R
F
A
N
T
D
T
V
A
L
L

M
a
n
u
a
l
 
T
r
a
n
s
c
r
i
p
t
i
o
n
B
a
s
e
l
i
n
e
 
L
M
:
0.
16
2 
(5.
21
2)
0.
08
7 
(3.
85
4)
0.
14
0 
(4.
85
9)
0.
13
2 
(5.
14
6)
b
L
S
A 
(b
L
S
A-
A
da
pt
ed 
L
M
):
0.
16
4 
(5.
21
2)
0.
08
7 
(3.
89
7)
0.
14
3 
(4.
86
4)
0.
13
4 
(5.
16
2)

1
-
b
e
s
t
 
A
S
R
 
O
u
t
p
u
t
C
E
R
 
(
%
)
7
.
4
2
5
.
5
1
3
.
1
1
4
.
9
B
a
s
e
l
i
n
e
 
L
M
:
0.
1
2
9 
(4
.1
5)
0.
0
5
1 
(2
.7
7)
0.
0
8
6 
(3
.5
0)
0.
0
9
5 
(3
.9
0)
b
L
S
A 
(b
L
S
A-
A
da
pt
ed 
L
M
):
0.
1
3
2 
(4
.1
6)
0.
0
5
0 
(2
.7
9)
0.
0
8
9 
(3
.5
3)
0.
0
9
6 
(3
.9
1)

Table 4: Translation performance of baseline and bLSA-Adapted Chinese-English SMT systems on manual 
transcriptions and 1-best ASR hypotheses



3.5   Performance of Baseline SMT System

First, the baseline system performance was evalu- 
ated by applying the system described above to the 
reference transcriptions and 1-best ASR hypotheses 
generated by our Mandarin speech recognition sys- 
tem. The translation accuracy in terms of BLEU and 
NIST for each individual show (“CCTV ”, “RFA”, 
and “NTDTV ”), and for the complete test-set, are 
shown in Table 4 (Baseline LM). When applied to 
the reference transcriptions an overall BLEU score 
of 0.132 was obtained.  BLEU-scores ranged be- 
tween 0.087 and 0.162 for the “RFA”, “NTDTV ” and 
“CCTV ” shows, respectively.  As the “RFA” show
contained a large segment of conversational speech,





0.16

0.14

0.12

0.1

0.08

0.06

0.04

0.02

0




Baseline-LM	bLSA Adapted LM














CCTV	RFA	NTDTV	All shows


translation quality was considerably lower for this 
show due to genre mismatch with the training cor- 
pora of newspaper text.
  For the 1-best ASR hypotheses, an overall BLEU 
score of 0.095 was achieved.   For the ASR case, 
the relative reduction in BLEU scores for the RFA 
and NTDTV shows is large, due to the significantly 
lower recognition accuracies for these shows. BLEU 
score is also degraded due to poor alignment of ref- 
erences during scoring.

3.6   Incorporation of bLSA Adaptation

Next, the effectiveness of bLSA based LM adapta- 
tion was evaluated.  For each show the target En- 
glish LM was adapted using bLSA-adaptation, as 
described in Section 2.3. SMT was then applied us- 
ing an identical setup to that used in the baseline ex- 
periments.
  The translation accuracy when bLSA adaptation 
was incorporated is shown in Table 4.  When ap-


Figure 5:  BLEU score for those 25% utterances
which resulted in different translations after bLSA
adaptation (manual transcriptions)

plied to the manual transcriptions, bLSA adaptation 
improved the overall BLEU-score by 1.7% relative 
(from 0.132 to 0.134).  For all three shows bLSA 
adaptation gained higher BLEU and NIST metrics. 
A similar trend was also observed when the pro- 
posed approach was applied to the 1-best ASR out- 
put. On the evaluation set a relative improvement in 
BLEU score of 1.0% was gained.
  The semantic interpretation of the majority of ut- 
terances in broadcast news are not affected by topic 
context.  In the experimental evaluation it was ob- 
served that only 25% of utterances produced differ- 
ent translation output when bLSA adaptation was 
performed compared to the topic-independent base- 
line. Although the improvement in translation qual- 
ity (BLEU) was small when evaluated over the en- 
tire test set, the improvement in BLEU score for


these 25% utterances was significant.  The trans- 
lation quality for the baseline and bLSA-adaptive 
system when evaluated only on these utterances is 
shown in Figure 5 for the manual transcription case. 
On this subset of utterances an overall improvement 
in BLEU of 0.007 (5.7% relative) was gained, with 
a gain of 0.012 (10.6% relative) points for the “NT- 
DTV ” show. A similar trend was observed when ap- 
plied to the 1-best ASR output.  In this case a rel- 
ative improvement in BLEU of 12.6% was gained 
for “NTDTV ”, and for “All shows” 0.007 (3.7%) 
was gained.  Current evaluation metrics for trans- 
lation, such as “BLEU”, do not consider the rela- 
tive importance of specific words or phrases during 
translation and thus are unable to highlight the true 
effectiveness of the proposed approach.  In future 
work, we intend to investigate other evaluation met- 
rics which consider the relative informational con- 
tent of words.

4   Conclusions

We  proposed  a  bilingual  latent  semantic  model 
for crosslingual LM adaptation in spoken language 
translation.  The bLSA model consists of a set of 
monolingual LSA models in which a one-to-one 
topic correspondence is enforced between the LSA 
models through the sharing of variational Dirich- 
let posteriors.   Bootstrapping a LSA model for a 
new language can be performed rapidly with topic 
transfer from a well-trained LSA model of another 
language.  We transfer the inferred topic distribu- 
tion from the input source text to the target lan- 
guage effectively to obtain an in-domain target LSA 
marginals for LM adaptation.  Results showed that 
our approach significantly reduces the word per- 
plexity on the target language in both cases using 
ASR hypotheses and manual transcripts.  Interest- 
ingly, the adaptation performance is not much af- 
fected when ASR hypotheses were used.  We eval- 
uated the adapted LM on SMT and found that the 
evaluation metrics are crucial to reflect the actual 
improvement in performance. Future directions in- 
clude the exploration of story-dependent LM adap- 
tation with automatic story segmentation instead of 
show-dependent adaptation due to the possibility of 
multiple stories within a show.  We will investigate 
the incorporation of monolingual documents for po-


tentially better bilingual LSA modeling.

Acknowledgment

This work is partly supported by the Defense Ad- 
vanced Research Projects Agency (DARPA) under 
Contract No.  HR0011-06-2-0001.  Any opinions, 
findings and conclusions or recommendations ex- 
pressed in this material are those of the authors and 
do not necessarily reflect the views of DARPA.


References

D. Blei, A. Ng, and M. Jordan.  2003.  Latent Dirichlet 
Allocation. In Journal of Machine Learning Research, 
pages 1107–1135.

W. Kim and S. Khudanpur. 2003. LM adaptation using
cross-lingual information. In Proc. of Eurospeech.

W. Kim and S. Khudanpur.  2004.  Cross-lingual latent 
semantic analysis for LM. In Proc. of ICASSP.

R. Kneser, J. Peters, and D. Klakow.  1997.  Language 
model adaptation using dynamic marginals.  In Proc. 
of Eurospeech, pages 1971–1974.

K. Papineni, S. Roukos, T. Ward, and W. Zhu.   2002.
BLEU: A method for automatic evaluation of machine 
translation. In Proc. of ACL.

M. Paulik, C. Fu¨ gen, T. Schaaf, T. Schultz, S. Stu¨ ker, and 
A. Waibel.  2005. Document driven machine transla- 
tion enhanced automatic speech recognition. In Proc. 
of Interspeech.

Y. C. Tam and T. Schultz. 2006. Unsupervised language 
model adaptation using latent semantic marginals. In 
Proc. of Interspeech.

Y. C. Tam and T. Schultz. 2007. Correlated latent seman- 
tic model for unsupervised language model adaptation. 
In Proc. of ICASSP.

A. Venugopal, A. Zollmann, and A. Waibel. 2005. Train- 
ing and evaluation error minimization rules for statis- 
tical machine translation. In Proc. of ACL.

S. Vogel. 2003. SMT decoder dissected: Word reorder- 
ing. In Proc. of ICNLPKE.

S. Vogel. 2005. PESA: Phrase pair extraction as sentence 
splitting. In Proc. of the Machine Translation Summit.

B. Zhao and E. P. Xing. 2006. BiTAM: Bilingual topic 
admixture models for word alignment.   In Proc. of 
ACL.

