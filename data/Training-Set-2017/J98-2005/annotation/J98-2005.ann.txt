Citance Number: 1 | Reference Article:  J98-2005.xml | Citing Article:  J01-2004.xml | Citation Marker Offset:  ['72'] | Citation Marker:  1998 | Citation Offset:  ['72'] | Citation Text: <S sid ="72" ssid = "37">Chi and Geman (1998) proved that any PCFG estimated from a treebank with the relative frequency estimator is tight.</S> | Reference Offset:  ['17'] | Reference Text:  <S sid ="17" ssid = "17">We will show that in both cases the estimated probability is tight.</S> | Discourse Facet:  Aim_Citation | Annotator:  Ankur Khanna, NUS |


Citance Number: 2 | Reference Article:  J98-2005.xml | Citing Article:  N03-1027.xml | Citation Marker Offset:  ['56'] | Citation Marker:  1998 | Citation Offset:  ['56'] | Citation Text:  <S sid ="56" ssid = "19">Chi and Geman (1998) proved that this con­dition is met if the rule probabilities are estimated using relative frequency estimation from a corpus.</S> | Reference Offset:  ['45'] | Reference Text:  <S sid ="45" ssid = "9">(8~fl)ea ~(B --~/3) = ~=lf(B --~/3;cai) (3) c~ s.t. H &lt;B-~)e~ ~i=lf(B ---+o4cai) The maximum-likelihood estimator is the natural, &quot;relative frequency,&quot; estimator.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankur Khanna, NUS |


Citance Number: 3 | Reference Article:  J98-2005.xml | Citing Article:  P01-1017.xml | Citation Marker Offset:  ['79'] | Citation Marker:  5 | Citation Offset:  ['79'] | Citation Text: <S sid ="79" ssid = "32">When a PCFG probability distribu­tion is estimated from training data (in our case the Penn tree-bank) PCFGs de.ne a tight (sum­ming to one) probability distribution over strings [5], thus making them appropriate for language models.</S> | Reference Offset:  ['17'] | Reference Text:  <S sid ="17" ssid = "17">We will show that in both cases the estimated probability is tight.</S> | Discourse Facet:  Aim_Citation | Annotator:  Ankur Khanna, NUS |


Citance Number: 6 | Reference Article:  J98-2005.xml | Citing Article:  P13-1102.xml | Citation Marker Offset:  ['23'] | Citation Marker:  1998 | Citation Offset:  ['23'] | Citation Text:  <S sid ="23" ssid = "23">Chi and Geman(1998) studied the question for Maximum Likelihood (ML) estimation, and showed that ML es 1033 timates are always tight for both the supervisedcase (where the input consists of parse trees) andthe unsupervised case (where the input consists ofyields or terminal strings).</S> | Reference Offset:  ['16', '17'] | Reference Text:  <S sid ="16" ssid = "16">If the corpus is unparsed then there is an iterative approach to maximum-likelihood estimation (the EM or Baum-Welsh algorithm--again, see Section 2) and the same question arises: do we get actual probabilities or do the estimated PCFG&apos;s assign some mass to infinite trees?</S><S sid ="17" ssid = "17">We will show that in both cases the estimated probability is tight.</S> | Discourse Facet:  Aim_Citation | Annotator:  Ankur Khanna, NUS |


