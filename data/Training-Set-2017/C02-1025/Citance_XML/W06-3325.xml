<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">In modern biology, digitization of biosystematics publications is an important task.</S>
		<S sid ="2" ssid = "2">Extraction of taxonomic names from such documents is one of its major issues.</S>
		<S sid ="3" ssid = "3">This is because these names identify the various genera and species.</S>
		<S sid ="4" ssid = "4">This article reports on our experiences with learning techniques for this particular task.</S>
		<S sid ="5" ssid = "5">We say why established Named-Entity Recognition techniques are somewhat difficult to use in our context.</S>
		<S sid ="6" ssid = "6">One reason is that we have only very little training data available.</S>
		<S sid ="7" ssid = "7">Our experiments show that a combining approach that relies on regular expressions, heuristics, and word-level language recognition achieves very high precision and recall and allows to cope with those difficulties.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="8" ssid = "8">Digitization of biosystematics publications currently is a major issue.</S>
			<S sid ="9" ssid = "9">They contain the names and descriptions of taxonomic genera and species.</S>
			<S sid ="10" ssid = "10">The names are important because they identify the various genera and species.</S>
			<S sid ="11" ssid = "11">They also position the species in the tree of life, which in turn is useful for a broad variety of biology tasks.</S>
			<S sid ="12" ssid = "12">Hence, recognition of taxonomic names is relevant.</S>
			<S sid ="13" ssid = "13">However, manual extraction of these names is time- consuming and expensive.</S>
			<S sid ="14" ssid = "14">The main problem for the automated recognition of these names is to distinguish them from the surrounding text, including other Named Entities (NE).</S>
			<S sid ="15" ssid = "15">Named Entity Recognition (NER) currently is a big research issue.</S>
			<S sid ="16" ssid = "16">However, conventional NER techniques are not readily applicable here for two reasons: First, the NE categories are rather high-level, e.g., names of organizations or persons (cf.</S>
			<S sid ="17" ssid = "17">common NER benchmarks such as (Carreras 2005)).</S>
			<S sid ="18" ssid = "18">Such a classification is too coarse for our context.</S>
			<S sid ="19" ssid = "19">The structure of taxonomic names varies widely and can be complex.</S>
			<S sid ="20" ssid = "20">Second, those recognizers require large bodies of training data.</S>
			<S sid ="21" ssid = "21">Since digitization of biosystematics documents has started only recently, such data is not yet available in biosystematics.</S>
			<S sid ="22" ssid = "22">On the other hand, it is important to demonstrate right away that text-learning technology is of help to biosystematics as well.</S>
			<S sid ="23" ssid = "23">This paper reports on our experiences with learning techniques for the automated extraction of taxonomic names from documents.</S>
			<S sid ="24" ssid = "24">The various techniques are obviously useful in this context: • Language recognition – taxonomic names are a combination of Latin or Latinized words, with surrounding text written in English, • structure recognition – taxonomic names follow a certain structure, • lexica support – certain words never are/may well be part of taxonomic names.</S>
			<S sid ="25" ssid = "25">On the other hand, an individual technique in isolation is not sufficient for taxonomic name extraction.</S>
			<S sid ="26" ssid = "26">Mikheev (1999) has shown that a combining approach, i.e., one that integrates the results of several different techniques, is superior to the individual techniques for common NER.</S>
			<S sid ="27" ssid = "27">Combining approaches are also promising for taxonomic name extraction.</S>
			<S sid ="28" ssid = "28">Having said this, the article will now proceed as follows: First, we have conducted a thorough inspection of taxonomic names.</S>
			<S sid ="29" ssid = "29">An important observation is that one cannot model taxonomic names both concisely and precisely using regular expressions.</S>
			<S sid ="30" ssid = "30">As is done in bootstrapping, we use two kinds of regular expressions: precision rules, whose instances are taxonomic names with very high probability, and recall rules, whose instances are a superset of all taxonomic names.</S>
			<S sid ="31" ssid = "31">We propose a meaningful definition of precision rules and recall rules for taxonomic names.</S>
			<S sid ="32" ssid = "32">126 Proceedings of the BioNLP Workshop on Linking Natural Language Processing and Biology at HLTNAACL 06, pages 126–133, New York City, June 2006.</S>
			<S sid ="33" ssid = "33">Qc 2006 Association for Computational Linguistics Second, the essence of a combining approach is to arrange the individual specific approaches in the right order.</S>
			<S sid ="34" ssid = "34">We propose such a composition for taxonomic name extraction, and we say why it is superior to other compositions that may appear feasible as well at first sight.</S>
			<S sid ="35" ssid = "35">Finally, to quantify the impact of the various alternatives described so far, we report on experimental results.</S>
			<S sid ="36" ssid = "36">The evaluation is based on a corpus of biosystematics documents marked up by hand.</S>
			<S sid ="37" ssid = "37">The best solution achieves about 99.2% in precision and recall.</S>
			<S sid ="38" ssid = "38">It prompts the user for only 0.2% of the words.</S>
			<S sid ="39" ssid = "39">The remainder of the paper is as follows: Section 2 discusses related approaches.</S>
			<S sid ="40" ssid = "40">Section 3 introduces some preliminaries.</S>
			<S sid ="41" ssid = "41">Section 4 describes one specific combining approach in some detail.</S>
			<S sid ="42" ssid = "42">Section 5 features an evaluation.</S>
			<S sid ="43" ssid = "43">Section 6 concludes.</S>
	</SECTION>
	<SECTION title="Related Work. " number = "2">
			<S sid ="44" ssid = "1">This section reviews solutions to problems related to the extraction of taxonomic names.</S>
			<S sid ="45" ssid = "2">2.1 Named Entity Recognition.</S>
			<S sid ="46" ssid = "3">Taxonomic names are a special case of named entity.</S>
			<S sid ="47" ssid = "4">In the recent past, NER has received much attention, which yielded a variety of methods.</S>
			<S sid ="48" ssid = "5">The most common ones are list lookups, grammars, rules, and statistical methods like SVMs (Bikel 1997).</S>
			<S sid ="49" ssid = "6">All these techniques have been developed for tasks like the one presented by Carreras (2005).</S>
			<S sid ="50" ssid = "7">Thus, their focus is the recognition of somewhat common NE like locations and persons.</S>
			<S sid ="51" ssid = "8">Consequently, they are not feasible for the complex and variable structure of taxonomic names (see Section 3.3).</S>
			<S sid ="52" ssid = "9">Another problem of common NER techniques is that they usually require several hundred thousand words of pre- annotated training data.</S>
			<S sid ="53" ssid = "10">2.2 List-based Techniques.</S>
			<S sid ="54" ssid = "11">List-based NER techniques (Palmer 1997) make use of lists to determine whether a word is a NE of the category sought.</S>
			<S sid ="55" ssid = "12">The sole use of a thesaurus as a positive list is not an option for taxonomic names.</S>
			<S sid ="56" ssid = "13">All existing thesauri are incomplete.</S>
			<S sid ="57" ssid = "14">Nevertheless, such a list allows recognizing known parts of taxonomic names.</S>
			<S sid ="58" ssid = "15">The inverse approach would be list-based exclusion, using a common English dictionary.</S>
			<S sid ="59" ssid = "16">Koning (2005) combines such an approach with structural rules.</S>
			<S sid ="60" ssid = "17">In isolation, however, it is not an option either.</S>
			<S sid ="61" ssid = "18">First, it would not exclude proper names reliably.</S>
			<S sid ="62" ssid = "19">Second, it excludes parts of taxonomic names that are also used in common English.</S>
			<S sid ="63" ssid = "20">However, exclusion of sure negatives, i.e., words that are never part of taxonomic names, simplifies the classification.</S>
			<S sid ="64" ssid = "21">2.3 Rule Based Techniques.</S>
			<S sid ="65" ssid = "22">Rule based techniques do not require pre- annotated training data.</S>
			<S sid ="66" ssid = "23">They extract words or word sequences based on their structure.</S>
			<S sid ="67" ssid = "24">Yoshida (1999) applies regular expressions to extract the names of proteins.</S>
			<S sid ="68" ssid = "25">He makes use of the syntax of protein names like NGmonomethyl-L-arginine, which is very distinctive.</S>
			<S sid ="69" ssid = "26">There are also rules for the syntax of taxonomic names, but they are less restrictive.</S>
			<S sid ="70" ssid = "27">For instance, Prenolepis (Nylanderia) vividula Erin subsp.</S>
			<S sid ="71" ssid = "28">guatemalensis Forel var.</S>
			<S sid ="72" ssid = "29">itinerans Forel is a taxonomic name as well as Dolichoderus decollatus.</S>
			<S sid ="73" ssid = "30">Because of the wide range of optional parts, it is impossible to find a regular expression that matches all taxonomic names and at the same time provides satisfactory precision.</S>
			<S sid ="74" ssid = "31">Koning (2005) presents an approach based on regular expressions and static dictionaries.</S>
			<S sid ="75" ssid = "32">This technique performs satisfactorily compared to common NER approaches, but their conception of what is a positive is restricted.</S>
			<S sid ="76" ssid = "33">For instance, they leave aside taxonomic names that do not specify a genus.</S>
			<S sid ="77" ssid = "34">However, the idea of rule-based filters for the phrases of documents is helpful.</S>
			<S sid ="78" ssid = "35">2.4 Bootstrapping.</S>
			<S sid ="79" ssid = "36">Instead of a large amount of labeled training data, Bootstrapping uses some labeled examples (“seeds”) and an even larger amount of unlabeled data for the training.</S>
			<S sid ="80" ssid = "37">Jones (1999) has shown that this approach performs equal to techniques requiring labeled training data.</S>
			<S sid ="81" ssid = "38">However, Bootstrapping is not readily applicable to our particular problem.</S>
			<S sid ="82" ssid = "39">Niu (2003) used an unlabeled corpus of 88.000.000 words for training a named entity recognizer.</S>
			<S sid ="83" ssid = "40">For our purpose, even unlabeled training data is not available in this order of magnitude, at least right now.</S>
			<S sid ="84" ssid = "41">2.5 Active Learning.</S>
			<S sid ="85" ssid = "42">According to Day (1997), the original idea of Active Learning was to speed up the creation of large labeled training corpora from unlabeled documents.</S>
			<S sid ="86" ssid = "43">The system uses all of its knowledge during all phases of the learning.</S>
			<S sid ="87" ssid = "44">Thus, it labels most of the data items automatically and requires user interaction only in rare cases.</S>
			<S sid ="88" ssid = "45">In order to in word as uncertain and prompt the user.</S>
			<S sid ="89" ssid = "46">This prevents misclassifications, but induces intellectual effort.</S>
			<S sid ="90" ssid = "47">To quantify this effort as well, there are two further measures: U(P) := positives not classified (uncertain) U(N) := negatives not classified (uncertain) Given this, Coverage C is defined as the fraction of all classifications that are not uncertain: crease data quality, we include user-interaction in our taxonomic name extractor as well.</S>
			<S sid ="91" ssid = "48">C := P(P) + P(P) + N(P) + N(P) + U(P) + P(N) + P(N) + N(N) N(N) + U(N) 2.6 Gene and Protein Name Extraction.</S>
			<S sid ="92" ssid = "49">In the recent past, the major focus of biomedical NER has been the recognition of gene and protein To obtain a single measure for overall classification quality, we multiply f-Measure and coverage and define Quality Q as names.</S>
			<S sid ="93" ssid = "50">Tanabe (2002) gives a good overview of Q := fMeasure × C various approaches to this task.</S>
			<S sid ="94" ssid = "51">Frequently used techniques are structural rules, dictionary lookups and Hidden Markov Models.</S>
			<S sid ="95" ssid = "52">Most of the approaches use the output of a part-of-speech tagger as additional evidence.</S>
			<S sid ="96" ssid = "53">Both gene and protein names differ from taxonomic names in that the nomenclature rules for them are by far stricter.</S>
			<S sid ="97" ssid = "54">For instance, they never include the names of the discoverer / author of a given part.</S>
			<S sid ="98" ssid = "55">In addition, there are parts which are easily distinguished from the surrounding text based on their structure, which is not true for taxonomic names.</S>
			<S sid ="99" ssid = "56">Consequently, the techniques for gene or protein name recognition are not feasible for the extraction of taxonomic names.</S>
	</SECTION>
	<SECTION title="Preliminaries. " number = "3">
			<S sid ="100" ssid = "1">This section introduces some preliminaries regarding word-level language recognition.</S>
			<S sid ="101" ssid = "2">We also describe a measure to quantify the user effort induced by interactions.</S>
			<S sid ="102" ssid = "3">3.1 Measure for User Effort.</S>
			<S sid ="103" ssid = "4">In NLP, the f-Measure is popular to quantify the performance of a word classifier: P(P) := positives classified as positive N(P) := positives classified as negative P(N) := negatives classified as positive N(N) := negatives classified as negative 3.2 Word-Level Language Recognition.</S>
			<S sid ="104" ssid = "5">for Taxonomic Name Extraction In earlier work (Sautter 2006), we have presented a technique to classify words as parts of taxonomic names or as common English, respectively.</S>
			<S sid ="105" ssid = "6">It is based on two statistics containing the N- Gram distribution of taxonomic names and of common English.</S>
			<S sid ="106" ssid = "7">Both statistics are built from examples from the respective languages.</S>
			<S sid ="107" ssid = "8">It uses active learning to deal with the lack of training data.</S>
			<S sid ="108" ssid = "9">Precision and recall reach a level of 98%.</S>
			<S sid ="109" ssid = "10">This is satisfactory, compared to common NER components.</S>
			<S sid ="110" ssid = "11">At the same time, the user has to classify about 3% of the words manually.</S>
			<S sid ="111" ssid = "12">In a text of 10.000 words, this would be 300 manual classifications.</S>
			<S sid ="112" ssid = "13">We deem this relatively high.</S>
			<S sid ="113" ssid = "14">3.3 Formal Structure of Taxonomic Names.</S>
			<S sid ="114" ssid = "15">The structure of taxonomic names is defined by the rules of Linnaean nomenclature (Ereshefsky 1997).</S>
			<S sid ="115" ssid = "16">They are not very restrictive and include many optional parts.</S>
			<S sid ="116" ssid = "17">For instance, both Prenole- pis (Nylanderia) vividula Erin subsp.</S>
			<S sid ="117" ssid = "18">guatemalen- sis Forel var.</S>
			<S sid ="118" ssid = "19">itinerans Forel and Dolichoderus decollatus are taxonomic names.</S>
			<S sid ="119" ssid = "20">There are only two mandatory parts in such a name: the genus and the species.</S>
			<S sid ="120" ssid = "21">Table 1 shows the decomposition of the two examples.</S>
			<S sid ="121" ssid = "22">The parts with their names Pr ecision p := P(P) P(P) + P(N) Re call r := 2 × p × r P(P) P(P) + N(P) in brackets are optional.</S>
			<S sid ="122" ssid = "23">More formally, the rules of Linnaean nomenclat ure define the structure of fMeasure := p + r taxonomic names as follows: But components that use active learning have three possible outputs.</S>
			<S sid ="123" ssid = "24">If the decision between positive or negative is narrow, they may classify a • The genus is mandatory.</S>
			<S sid ="124" ssid = "25">It is a capitalized word, often abbreviated by its first one or two letters, followed by a dot.</S>
			<S sid ="125" ssid = "26">• The subgenus is optional.</S>
			<S sid ="126" ssid = "27">It is a capitalized word, often enclosed in brackets.</S>
			<S sid ="127" ssid = "28">• The species is mandatory.</S>
			<S sid ="128" ssid = "29">It is a lower case word.</S>
			<S sid ="129" ssid = "30">It is often followed by the name of the scientist who first described the species.</S>
			<S sid ="130" ssid = "31">• The subspecies is optional.</S>
			<S sid ="131" ssid = "32">It is a lower case word, often preceded by subsp.</S>
			<S sid ="132" ssid = "33">or subspecies as an indicator.</S>
			<S sid ="133" ssid = "34">It is often followed by the name of the scientist who first described it.</S>
			<S sid ="134" ssid = "35">• The variety is optional.</S>
			<S sid ="135" ssid = "36">It is a lower case word, preceded by var.</S>
			<S sid ="136" ssid = "37">or variety as an indicator.</S>
			<S sid ="137" ssid = "38">It is often followed by the name of the scientist who first described it.</S>
			<S sid ="138" ssid = "39">Part Genus Prenolepis Dolichoderus (Subgenus) (Nylanderia) Species vividula decollatus (Discoverer) Erin (Subspecies) subsp.</S>
			<S sid ="139" ssid = "40">guatemalensis (Discoverer) Forel (Variety) var.</S>
			<S sid ="140" ssid = "41">itinerans (Discoverer) Forel Table 1: The parts of taxonomic names</S>
	</SECTION>
	<SECTION title="Combining Techniques. " number = "4">
			<S sid ="141" ssid = "1">for Taxonomic Name Extraction Due to its capability of learning at runtime, the word-level language recognizer needs little training data, but it still does.</S>
			<S sid ="142" ssid = "2">In addition, the manual effort induced by uncertain classifications is high.</S>
			<S sid ="143" ssid = "3">Making use of the typical structure of taxonomic names, we can improve both aspects.</S>
			<S sid ="144" ssid = "4">First, we can use syntax-based rules to harvest training data directly from the documents.</S>
			<S sid ="145" ssid = "5">Second, we can use these rules to reduce the number of words the classifier has to deal with.</S>
			<S sid ="146" ssid = "6">However, it is not possible to find rules that extract taxonomic names with both high precision and recall, as we will show later.</S>
			<S sid ="147" ssid = "7">But we have found rules that fulfill one of these requirements very well.</S>
			<S sid ="148" ssid = "8">In what follows, we refer to these as precision rules and recall rules, respectively.</S>
			<S sid ="149" ssid = "9">4.1 The Classification Process.</S>
			<S sid ="150" ssid = "10">1.</S>
			<S sid ="151" ssid = "11">We apply the precision rules.</S>
			<S sid ="152" ssid = "12">Every word.</S>
			<S sid ="153" ssid = "13">sequence from the document that matches such a rule is a sure positive.</S>
			<S sid ="154" ssid = "14">2.</S>
			<S sid ="155" ssid = "15">We apply the recall rules to the phrases that.</S>
			<S sid ="156" ssid = "16">are not sure positives.</S>
			<S sid ="157" ssid = "17">A phrase not matching one of these rules is a sure negative.</S>
			<S sid ="158" ssid = "18">3.</S>
			<S sid ="159" ssid = "19">We make use of domain-specific vocabulary.</S>
			<S sid ="160" ssid = "20">and filter out word sequences containing at least one known negative word.</S>
			<S sid ="161" ssid = "21">4.</S>
			<S sid ="162" ssid = "22">We collect a set of names from the set of sure.</S>
			<S sid ="163" ssid = "23">positives (see Subsection 4.5).</S>
			<S sid ="164" ssid = "24">We then use these names to both include and exclude further word sequences.</S>
	</SECTION>
	<SECTION title="We train the word-level language recognizer. " number = "5">
			<S sid ="165" ssid = "1">with the surely positive and surely negative words.</S>
			<S sid ="166" ssid = "2">We then apply it to the remaining uncertain word sequences.</S>
			<S sid ="167" ssid = "3">Figure 1 visualizes the classification process.</S>
			<S sid ="168" ssid = "4">At first sight, other orders seem to be possible as well, e.g., the language recognizer classifies each word first, and then we apply the rules.</S>
			<S sid ="169" ssid = "5">But this is not feasible: It would require external training data.</S>
			<S sid ="170" ssid = "6">In addition, the language recognizer would have to classify all the words of the document.</S>
			<S sid ="171" ssid = "7">This would incur more manual classifications.</S>
			<S sid ="172" ssid = "8">Figure 1: The Classification Process This approach is similar to the bootstrapping algorithm proposed by Jones (1999).</S>
			<S sid ="173" ssid = "9">The difference is that this process works solely with the document it actually processes.</S>
			<S sid ="174" ssid = "10">In particular, it does not need any external data or a training phase.</S>
			<S sid ="175" ssid = "11">Average biosystematics documents contain about 15.000 words, which is less than 0.02% of the data used by Niu (2003).</S>
			<S sid ="176" ssid = "12">On the other hand, with the classification process proposed here, the accuracy of the underlying classifier has to be very high from the start.</S>
			<S sid ="177" ssid = "13">4.2 Structural Rules.</S>
			<S sid ="178" ssid = "14">In order to make use of the structure of taxonomic names, we use rules that refer to this structure.</S>
			<S sid ="179" ssid = "15">We use regular expressions for the formal representation of the rules.</S>
			<S sid ="180" ssid = "16">In this section, we develop a regular expression matching any word sequence that conforms to the Linnaean rules of nomenclature (see 3.3).</S>
			<S sid ="181" ssid = "17">Table 2 provides some abbreviations, to increase readability.</S>
			<S sid ="182" ssid = "18">We model taxonomic names as follows: _ one white space character &lt;LcW&gt; [a-z](3,) &lt;CapW&gt; [A-Z][a-z](2,) &lt;CapA&gt; [A-Z]{[a-z]}?.</S>
			<S sid ="183" ssid = "19">&lt;Name&gt; {&lt;CapA&gt;_}(0,2)&lt;CapW&gt; Table 2: Abbreviations • The genus is a capitalized word, often abbreviated.</S>
			<S sid ="184" ssid = "20">We denote it as &lt;genus&gt;, which stands for {&lt;CapW&gt;|&lt;CapA&gt;}.</S>
			<S sid ="185" ssid = "21">• The subgenus is a capitalized word, optionally surrounded by brackets.</S>
			<S sid ="186" ssid = "22">We denote it as &lt;subGenus&gt;, which stands for &lt;CapW&gt;|(&lt;CapW&gt;).</S>
			<S sid ="187" ssid = "23">• The species is a lower case word, optionally followed by a name.</S>
			<S sid ="188" ssid = "24">We denote it as &lt;species&gt;, which stands for &lt;LcW&gt;{_&lt;Name&gt;}?.</S>
			<S sid ="189" ssid = "25">• The subspecies is a lower case word, preceded by the indicator subsp.</S>
			<S sid ="190" ssid = "26">or subspecies, and optionally followed by a name.</S>
			<S sid ="191" ssid = "27">We denote it as &lt;subSpecies&gt;, standing for {subsp.|subspecies}_&lt;LcW&gt;{_&lt;Name&gt;}?.</S>
			<S sid ="192" ssid = "28">• The variety is a lower case word, preceded by the indicator var.</S>
			<S sid ="193" ssid = "29">or variety, and optionally followed by a name.</S>
			<S sid ="194" ssid = "30">We denote it as &lt;variety&gt;, which stands for {var.| variety}_&lt;LcW&gt;{_&lt;Name&gt;}?.</S>
			<S sid ="195" ssid = "31">A taxonomic name is now modeled as follows.</S>
			<S sid ="196" ssid = "32">We refer to the pattern as &lt;taxName&gt;: &lt;genus&gt;{_&lt;subGenus&gt;}?</S>
			<S sid ="197" ssid = "33">_&lt;species&gt;{_&lt;subSpecies&gt;}?</S>
			<S sid ="198" ssid = "34">{_&lt;variety&gt;}?</S>
			<S sid ="199" ssid = "35">4.3 Precision Rules.</S>
			<S sid ="200" ssid = "36">Because &lt;taxName&gt; matches any sequence of words that conforms to the Linnaean rules, it is not very precise.</S>
			<S sid ="201" ssid = "37">The simplest match is a capitalized word followed by one in lower case.</S>
			<S sid ="202" ssid = "38">Any two words at the beginning of a sentence are a match!</S>
			<S sid ="203" ssid = "39">To obtain more precise regular expressions, we rely on the optional parts of taxonomic names.</S>
			<S sid ="204" ssid = "40">In particular, we classify a sequence of words as a sure positive if it contains at least one of the optional parts &lt;subGenus&gt;, &lt;subSpecies&gt; and &lt;variety&gt;.</S>
			<S sid ="205" ssid = "41">Even though these regular expressions may produce false negatives, our evaluation will show that this happens very rarely.</S>
			<S sid ="206" ssid = "42">Our set of precise regular expressions has three elements: • &lt;taxName&gt; with subgenus in brackets, &lt;subspecies&gt; and &lt;variety&gt; optional: &lt;genus&gt;_(&lt;CapW&gt;) _&lt;species&gt;{_&lt;subSpecies&gt;}?</S>
			<S sid ="207" ssid = "43">{_&lt;variety&gt;}?</S>
			<S sid ="208" ssid = "44">• &lt;taxName&gt; with &lt;subspecies&gt; given, &lt;subGenus&gt; and &lt;variety&gt; optional: &lt;genus&gt;{_&lt;subGenus&gt;}?</S>
			<S sid ="209" ssid = "45">_&lt;species&gt;_&lt;subSpecies&gt; {_&lt;variety&gt;}?</S>
			<S sid ="210" ssid = "46">• &lt;taxName&gt; with &lt;variety&gt; mandatory, &lt;subGenus&gt; and &lt;subSpecies&gt; optional: &lt;genus&gt;{_&lt;subGenus&gt;}?</S>
			<S sid ="211" ssid = "47">_&lt;species&gt;{_&lt;subSpecies&gt;}?</S>
			<S sid ="212" ssid = "48">{_&lt;variety&gt;} To classify a word sequence as a sure positive if it matches at least one of these regular expressions, we combine them disjunctively and call the result &lt;preciseTaxName&gt;.</S>
			<S sid ="213" ssid = "49">A notion related to that of a sure positive is the one of a surely positive word.</S>
			<S sid ="214" ssid = "50">A surely positive word is a part of a taxonomic name that is not part of a scientist’s name.</S>
			<S sid ="215" ssid = "51">For instance, the taxonomic name Prenolepis (Nylanderia) vividula Erin subsp.</S>
			<S sid ="216" ssid = "52">guatemalensis Forel var.</S>
			<S sid ="217" ssid = "53">itinerans Forel contains the surely positive words Prenolepis, Nylanderia, vividula, guatemalensis, and itinerans.</S>
			<S sid ="218" ssid = "54">We assume that surely positive words exclusively appear as parts of taxonomic names.</S>
			<S sid ="219" ssid = "55">4.4 Recall Rules.</S>
			<S sid ="220" ssid = "56">&lt;taxName&gt; matches any sequence of words that conforms to the Linnaean rules, but there is a further issue: Enumerations of several species of the same genus tend to contain the genus only once.</S>
			<S sid ="221" ssid = "57">For instance, in Pseudomyrma arborissanctae Emery, latinoda Mayr and tachigalide Forel”we want to extract latinoda Mayr and tachigalide Forel as well.</S>
			<S sid ="222" ssid = "58">To address this, we make use of the surely positive words: We use them to extract parts of taxonomic names that lack the genus.</S>
			<S sid ="223" ssid = "59">Our technique also extracts the names of the scientists from the sure positives and collects them in a name lexicon.</S>
			<S sid ="224" ssid = "60">Based on the structure described in Section 3.3, a capitalized word in a sure positive is a name if it comes after the second position.</S>
			<S sid ="225" ssid = "61">From the sure positive Pseudomyrma (Minimyrma) arborissanctae Emery, the technique extracts Pseudomyrma, Minimyrma and arborissanctae.</S>
			<S sid ="226" ssid = "62">In addition, it would add Emery to the name lexicon.</S>
			<S sid ="227" ssid = "63">We cannot be sure that the list of sure positive words suffices to find all species names in an enumeration.</S>
			<S sid ="228" ssid = "64">Hence, our technique additionally collects all lowercase words followed by a word contained in the name lexicon.</S>
			<S sid ="229" ssid = "65">In the example, we extract latinoda Mayr and tachigalide Forel if Mayr and Forel are in the name lexicon.</S>
			<S sid ="230" ssid = "66">4.5 Data Rules.</S>
			<S sid ="231" ssid = "67">Because we want to achieve close to 100% in recall, the recall rules are very weak.</S>
			<S sid ="232" ssid = "68">In consequence, many word sequences that are not taxonomic names are considered uncertain.</S>
			<S sid ="233" ssid = "69">Before the word-level language recognizer deals with them, we see some more ways to exclude negatives.</S>
			<S sid ="234" ssid = "70">Sure Negatives . As mentioned in Subsection 4.3, &lt;taxName&gt; matches any capitalized word followed by a word in lower case.</S>
			<S sid ="235" ssid = "71">This includes the start of any sentence.</S>
			<S sid ="236" ssid = "72">Making use of the sure negatives, we can recognize these phrases.</S>
			<S sid ="237" ssid = "73">In particular, out technique classifies any word sequence as negative that contains a word which is also in the set of sure negatives.</S>
			<S sid ="238" ssid = "74">For instance, in sentence “Additional evidence results from …”, Additional evidence matches &lt;taxName&gt;.</S>
			<S sid ="239" ssid = "75">Another sentence contains an additional advantage, which does not match &lt;taxName&gt;.</S>
			<S sid ="240" ssid = "76">Thus, the set of sure negatives contains an, additional, and advantage.</S>
			<S sid ="241" ssid = "77">Knowing that additional is a sure negative, we exclude the phrase Additional evidence.</S>
			<S sid ="242" ssid = "78">Names of Scientists.</S>
			<S sid ="243" ssid = "79">Though the names of scientists are valid parts of taxonomic names, they also cause false matches.</S>
			<S sid ="244" ssid = "80">The reason is that they are capitalized.</S>
			<S sid ="245" ssid = "81">A misclassification occurs if they are matched with the genus or subgenus part – &lt;taxName&gt; cannot exclude this.</S>
			<S sid ="246" ssid = "82">In addition, they might appear elsewhere in the text without belonging to a taxonomic name.</S>
			<S sid ="247" ssid = "83">Similarly to sure negatives, we exclude a match of &lt;taxName&gt; if the first or second word is contained in the name lexicon.</S>
			<S sid ="248" ssid = "84">For instance, in “…, and Forel further concludes”, Forel further matches &lt;taxName&gt;.</S>
			<S sid ="249" ssid = "85">If the name lexicon contains Forel, we know that it is not a genus, and thus exclude Forel further.</S>
			<S sid ="250" ssid = "86">4.6 Classification of Remaining Words.</S>
			<S sid ="251" ssid = "87">After applying the rules, some word sequences still remain uncertain.</S>
			<S sid ="252" ssid = "88">To deal with them, we use word-level language recognition.</S>
			<S sid ="253" ssid = "89">We train the classifier with the sure positive and sure negative words.</S>
			<S sid ="254" ssid = "90">We do not classify every word separately, but compute the classification score of all words of a sequence and then classify the sequence as a whole.</S>
			<S sid ="255" ssid = "91">This has several advantages: First, if one word of a sequence is uncertain, this does not automatically incur a feedback request.</S>
			<S sid ="256" ssid = "92">Second, if a word sequence is uncertain as a whole, the user gives feedback for the entire sequence.</S>
			<S sid ="257" ssid = "93">This results in several surely classified uncertain words at the cost of only one feedback request.</S>
			<S sid ="258" ssid = "94">In addition, it is easier to determine the meaning of a word sequence than the one of a single word.</S>
			<S sid ="259" ssid = "95">5 Evaluation.</S>
			<S sid ="260" ssid = "96">A combining approach gives rise to many questions, e.g.: How does a word-level classifier perform with training data automatically generated?</S>
			<S sid ="261" ssid = "97">How does rule-based filtering affect precision, recall, and coverage?</S>
			<S sid ="262" ssid = "98">What is the effect to dynamic lexicons?</S>
			<S sid ="263" ssid = "99">Which kinds of errors remain?</S>
			<S sid ="264" ssid = "100">We run two series of experiments: We first process individual documents.</S>
			<S sid ="265" ssid = "101">We then process the documents incrementally, i.e., we do neither clear the sets of known positives and negatives after each document, nor the statistics of the word-level language recognizer.</S>
			<S sid ="266" ssid = "102">This is to measure the benefit of reusing data obtained from one document in the processing of subsequent ones.</S>
			<S sid ="267" ssid = "103">Finally, we take a closer look at the effects of the individual steps and heuristics from Section 4.</S>
			<S sid ="268" ssid = "104">The platform is implemented in JAVA 1.4.2.</S>
			<S sid ="269" ssid = "105">We use the java.util.regex package to represent the rules.</S>
			<S sid ="270" ssid = "106">All tests are based on 20 issues of the American Museum Novitates, a natural science periodical published by the American Museum of Natural History.</S>
			<S sid ="271" ssid = "107">The documents contain about 260.000 words, including about 2.500 taxonomic names.</S>
			<S sid ="272" ssid = "108">The latter consist of about 8.400 words.</S>
			<S sid ="273" ssid = "109">5.1 Tests with Individual Documents.</S>
			<S sid ="274" ssid = "110">First, we test the combined classifier with individual documents.</S>
			<S sid ="275" ssid = "111">The Docs column in Table 3 contains the results.</S>
			<S sid ="276" ssid = "112">The combination of rules and word-level classification provides very high precision and recall.</S>
			<S sid ="277" ssid = "113">The former is 99.7% on average, the latter 98.2%.</S>
			<S sid ="278" ssid = "114">The manual effort is very low: The average coverage is 99.7%.</S>
			<S sid ="279" ssid = "115">5.2 Tests with Entire Corpus.</S>
			<S sid ="280" ssid = "116">In the first test the classifier did not transfer any experience from one document to later ones.</S>
			<S sid ="281" ssid = "117">We now process the documents one after another.</S>
			<S sid ="282" ssid = "118">The Corp column of Table 3 shows the results.</S>
			<S sid ="283" ssid = "119">As expected, the classifier performs better than with individual documents.</S>
			<S sid ="284" ssid = "120">The average recall is 99.2%, coverage is 99.8% on average.</S>
			<S sid ="285" ssid = "121">Only precision is a little less, 99.1% on average.</S>
			<S sid ="286" ssid = "122">Docs Corp &lt;preciseTaxName&gt; 22,6 &lt;taxName&gt; 414,1 SN excluded 78,5 Names excluded 176,15 Scorings 139,9 User Feedbacks 19,6 10,35 False positives 4,25 1,5 False negatives 0,55 1,5 Precision 0,997 0,991 Recall 0,982 0,992 f-Measure 0,990 0,992 Coverage 0,997 0,998 Quality 0,987 0,990 Table 3: Test results The effect of the incremental learning is obvious.</S>
			<S sid ="287" ssid = "123">The false positives are less than half of those in the first test.</S>
			<S sid ="288" ssid = "124">A comparison of Line False Positives in Table 3 shows this.</S>
			<S sid ="289" ssid = "125">The same is true for the number feedback requests (Line User Feedbacks).</S>
			<S sid ="290" ssid = "126">The slight decrease in precision (Line False Negatives) results from the propagation of misclassifications between documents.</S>
			<S sid ="291" ssid = "127">The reason for the improvement becomes clear for documents where the number of word sequences in &lt;preciseTaxName&gt; is low: experience from previous documents compensates the lack of positive examples.</S>
			<S sid ="292" ssid = "128">This reduces both false positives and manual classifications.</S>
			<S sid ="293" ssid = "129">5.3 The Data Rules.</S>
			<S sid ="294" ssid = "130">The exclusion of word sequences containing a sure negative turns out to be effective to filter the matches of &lt;taxName&gt;.</S>
			<S sid ="295" ssid = "131">Lines &lt;taxName&gt; and SN excluded of Tables 3 show this.</S>
			<S sid ="296" ssid = "132">On average, this step excludes about 20% of the word sequences matching &lt;taxName&gt;.</S>
			<S sid ="297" ssid = "133">Lines &lt;taxName&gt; and Names excluded tell us that the rule based on the names of scientists is even more effective.</S>
			<S sid ="298" ssid = "134">On average, it excludes about 40% of the matches of &lt;taxName&gt;.</S>
			<S sid ="299" ssid = "135">Both data rules decrease the number of words the language recognizer has to deal with and eventually the manual effort.</S>
			<S sid ="300" ssid = "136">This is because they reduce the number of words classified uncertain.</S>
			<S sid ="301" ssid = "137">5.4 Comparison to Word-Level Classifier.</S>
			<S sid ="302" ssid = "138">and TaxonGrab A word-level classifier (WLC) is the core component of the combining technique.</S>
			<S sid ="303" ssid = "139">We compare it in standalone use to the combining technique (Comb) and to the TaxonGrab (T-Grab) approach (Koning 2005).</S>
			<S sid ="304" ssid = "140">See Table 4.</S>
			<S sid ="305" ssid = "141">The combining technique is superior to both TaxonGrab and stand- alone word-level classification.</S>
			<S sid ="306" ssid = "142">The reason for better precision and recall is that it uses more different evidence.</S>
			<S sid ="307" ssid = "143">The better coverage results from the lower number of words that the word-level classifier has to deal with.</S>
			<S sid ="308" ssid = "144">On average, it has to classify only 2.5% of the words in a document.</S>
			<S sid ="309" ssid = "145">This reduces the classification effort, leading to less manual feedback.</S>
			<S sid ="310" ssid = "146">It also decreases the number of potential errors of the word-level classifier.</S>
			<S sid ="311" ssid = "147">All these positive effects result in about 99% f- Measure and 99.7% coverage.</S>
			<S sid ="312" ssid = "148">This means the error is reduced by 75% compared to word-level classification, and by 80% compared to Taxon- Grab.</S>
			<S sid ="313" ssid = "149">The manual effort decreases by 94% compared to the standalone word-level classifier.</S>
			<S sid ="314" ssid = "150">Precision Recall f-Measure Coverage T-Grab 96% 94% 95% WLC 97% 95% 96% 95% Comb 99.1% 99.2% 99% 99.7% Table 4: Comparison to Related Approaches 5.5 Misclassified Words.</S>
			<S sid ="315" ssid = "151">Despite all improvements, there still are word sequences that are misclassified.</S>
			<S sid ="316" ssid = "152">False Negatives.</S>
			<S sid ="317" ssid = "153">The regular expressions in &lt;preciseTaxName&gt; are intended to be 100% precise.</S>
			<S sid ="318" ssid = "154">There are, however, some (rare) exceptions.</S>
			<S sid ="319" ssid = "155">Consider the following phrase: “… In Guadeloup (Mexico) another subspecies killed F. Smith.” Except for the word In, this sentence matches the regular expression from &lt;preciseTaxName&gt; where &lt;subSpecies&gt; is mandatory.</S>
			<S sid ="320" ssid = "156">Similar pathologic cases could occur for the variety part.</S>
			<S sid ="321" ssid = "157">Another class of false negatives contains two word sequences, and the first one is the name of a genus.</S>
			<S sid ="322" ssid = "158">For instance, “Xenomyrmex varies …” falls into this category.</S>
			<S sid ="323" ssid = "159">The classifier (correctly) recognizes the first word as a part of a taxonomic name.</S>
			<S sid ="324" ssid = "160">The second one is not typical enough to change the overall classification of the sequence.</S>
			<S sid ="325" ssid = "161">To recognize these false negatives, one might use POS-tagging.</S>
			<S sid ="326" ssid = "162">We could exclude word sequences containing words whose meaning does not fit into a taxonomic name.</S>
			<S sid ="327" ssid = "163">False Positives.</S>
			<S sid ="328" ssid = "164">Though &lt;taxName&gt; matches any taxonomic name, the subsequent exclusion mechanisms may misclassify a sequence of words.</S>
			<S sid ="329" ssid = "165">In particular, the word-level classifier has problems recognizing taxonomic names containing proper names of persons.</S>
			<S sid ="330" ssid = "166">The problem is that these words consist of N-Grams that are typical for common English.</S>
			<S sid ="331" ssid = "167">“Wheeleria rogersi Smith”, for instance, is a fictitious but valid taxonomic name.</S>
			<S sid ="332" ssid = "168">A solution to this problem might be to use the scientist names for constructing and recognizing the genus and species names derived from them.</S>
	</SECTION>
	<SECTION title="Conclusions. " number = "6">
			<S sid ="333" ssid = "1">This paper has reported on our experiences with the automatic extraction of taxonomic names from English text documents.</S>
			<S sid ="334" ssid = "2">This task is essential for modern biology.</S>
			<S sid ="335" ssid = "3">A peculiarity of taxonomic name extraction is a shortage of training data.</S>
			<S sid ="336" ssid = "4">This is one reason why deployment of established NER techniques has turned out to be infeasible, at least without adaptations.</S>
			<S sid ="337" ssid = "5">A taxonomic-name extractor must circumvent that shortage.</S>
			<S sid ="338" ssid = "6">Our experience has been that designing regular expressions that generate training data directly from the documents is feasible in the context of taxonomic name extraction.</S>
			<S sid ="339" ssid = "7">A combining approach where individual techniques are carefully tuned and assigned in the right order has turned out to be superior to other potential solutions with regard to precision, recall, and number of user interactions.</S>
			<S sid ="340" ssid = "8">– Finally, is seems promising to use document and term frequencies as additional evidence.</S>
			<S sid ="341" ssid = "9">The ides is that both are low for taxonomic names.</S>
	</SECTION>
	<SECTION title="References. " number = "7">
</PAPER>
