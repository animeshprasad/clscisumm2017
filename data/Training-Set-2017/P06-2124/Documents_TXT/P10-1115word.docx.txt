Cross-Lingual Latent Topic Extraction




 Duo Zhang University of 
Illinois at Urbana-Champaign 
dzhang22@cs.uiuc.edu


Qiaozhu Mei University of 
Michigan qmei@umich.edu


ChengXiang Zhai 
University of Illinois at 
Urbana-Champaign 
czhai@cs.uiuc.edu








Abstract

Probabilistic latent topic models have re- 
cently enjoyed much success in extracting 
and analyzing latent topics in text in an un- 
supervised way.  One common deficiency 
of existing topic models, though, is that 
they would not work well for extracting 
cross-lingual latent topics simply because 
words in different languages generally do 
not co-occur with each other. In this paper, 
we propose a way to incorporate a bilin- 
gual dictionary into a probabilistic topic 
model so that we can apply topic models to 
extract shared latent topics in text data of 
different languages. Specifically, we pro- 
pose a new topic model called Probabilis- 
tic Cross-Lingual Latent Semantic Anal- 
ysis (PCLSA) which extends the Proba- 
bilistic Latent Semantic Analysis (PLSA) 
model by regularizing its likelihood func- 
tion with soft constraints defined based on 
a bilingual dictionary. Both qualitative and 
quantitative experimental results show that 
the PCLSA model can effectively extract 
cross-lingual latent topics from multilin- 
gual text data.
1   Introduction

As a robust unsupervised way to perform shallow 
latent semantic analysis of topics in text, prob- 
abilistic topic models (Hofmann, 1999a; Blei et 
al., 2003b) have recently attracted much atten- 
tion. The common idea behind these models is the 
following.  A topic is represented by a multino- 
mial word distribution so that words characteriz- 
ing a topic generally have higher probabilities than 
other words.  We can then hypothesize the exis- 
tence of multiple topics in text and define a gener- 
ative model based on the hypothesized topics. By 
fitting the model to text data, we can obtain an es- 
timate of all the word distributions corresponding


to the latent topics as well as the topic distributions 
in text. Intuitively, the learned word distributions 
capture clusters of words that co-occur with each 
other probabilistically.
  Although many topic models have been pro- 
posed and shown to be useful (see Section 2 for 
more detailed discussion of related work), most 
of them share a common deficiency: they are de- 
signed to work only for mono-lingual text data and 
would not work well for extracting cross-lingual 
latent topics, i.e.   topics shared in text data in 
two different natural languages.  The deficiency 
comes from the fact that all these models rely on 
co-occurrences of words forming a topical cluster, 
but words in different language generally do not 
co-occur with each other.  Thus with the existing 
models, we can only extract topics from text in 
each language, but cannot extract common topics 
shared in multiple languages.
  In this paper, we propose a novel topic model, 
called Probabilistic Cross-Lingual Latent Seman- 
tic Analysis (PCLSA) model, which can be used to 
mine shared latent topics from unaligned text data 
in different languages. PCLSA extends the Proba- 
bilistic Latent Semantic Analysis (PLSA) model 
by regularizing its likelihood function with soft 
constraints defined based on a bilingual dictio- 
nary. The dictionary-based constraints are key to 
bridge the gap of different languages and would 
force the captured co-occurrences of words in 
each language by PCLSA to be “synchronized” 
so that related words in the two languages would 
have similar probabilities.  PCLSA can be esti- 
mated efficiently using the General Expectation- 
Maximization (GEM) algorithm.  As a topic ex- 
traction algorithm, PCLSA would take a pair of 
unaligned document sets in different languages 
and a bilingual dictionary as input, and output a 
set of aligned word distributions in both languages 
that can characterize the shared topics in the two 
languages. In addition, it also outputs a topic cov-




1128

Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1128–1137, 
Uppsala, Sweden, 11-16 July 2010. Qc 2010 Association for Computational Linguistics


erage distribution for each language to indicate the 
relative coverage of different shared topics in each 
language.
  To the best of our knowledge, no previous work 
has attempted to solve this topic extraction prob- 
lem and generate the same output.  The closest 
existing work to ours is the MuTo model pro- 
posed in (Boyd-Graber and Blei, 2009) and the 
JointLDA model published recently in (Jagarala- 
mudi and Daume´ III, 2010). Both used a bilingual 
dictionary to bridge the language gap in a topic 
model. However, the goals of their work are dif- 
ferent from ours in that their models mainly focus 
on mining cross-lingual topics of matching word 
pairs and discovering the correspondence at the 
vocabulary level.  Therefore, the topics extracted 
using their model cannot indicate how a common 
topic is covered differently in the two languages, 
because the words in each word pair share the 
same probability in a common topic. Our work fo- 
cuses on discovering correspondence at the topic 
level. In our model, since we only add a soft con- 
straint on word pairs in the dictionary, their prob- 
abilities in common topics are generally different, 
naturally capturing which shows the different vari- 
ations of a common topic in different languages.
  We use a cross-lingual news data set and a re- 
view data set to evaluate PCLSA. We also propose 
a “cross-collection” likelihood measure to quanti- 
tatively evaluate the quality of mined topics. Ex- 
perimental results show that the PCLSA model 
can effectively extract cross-lingual latent topics 
from multilingual text data, and it outperforms a 
baseline approach using the standard PLSA on text 
data in each language.

2   Related Work

Many topic models have been proposed, and the 
two basic models are the Probabilistic Latent Se- 
mantic Analysis (PLSA) model (Hofmann, 1999a) 
and the Latent Dirichlet Allocation (LDA) model 
(Blei et al., 2003b).  They and their extensions 
have been successfully applied to many prob- 
lems, including hierarchical topic extraction (Hof- 
mann, 1999b; Blei et al., 2003a; Li and McCal- 
lum, 2006), author-topic modeling (Steyvers et al.,
2004), contextual topic analysis (Mei and Zhai,
2006), dynamic and correlated topic models (Blei 
and Lafferty, 2005; Blei and Lafferty, 2006), and 
opinion analysis (Mei et al., 2007; Branavan et al.,
2008). Our work is an extension of PLSA by in-


corporating the knowledge of a bilingual dictio- 
nary as soft constraints. Such an extension is sim- 
ilar to the extension of PLSA for incorporating so- 
cial network analysis (Mei et al., 2008a) but our 
constraint is different.
  Some previous work on multilingual topic mod- 
els assume documents in multiple languages are 
aligned either at the document level, sentence level 
or by time stamps (Mimno et al., 2009; Zhao and 
Xing, 2006; Kim and Khudanpur, 2004; Ni et al.,
2009; Wang et al., 2007). However, in many ap- 
plications, we need to mine topics from unaligned 
text corpus.   For example, mining topics from 
search results in different languages can facilitate 
summarization of multilingual search results.
  Besides all the multilingual topic modeling 
work discussed above, comparable corpora have 
also been studied extensively (e.g.  (Fung, 1995; 
Franz et al., 1998; Masuichi et al., 2000; Sadat 
et al., 2003; Gliozzo and Strapparava, 2006)), but 
most previous work aims at acquiring word trans- 
lation knowledge or cross-lingual text categoriza- 
tion from comparable corpora.  Our work differs 
from this line of previous work in that our goal is 
to discover shared latent topics from multi-lingual 
text data that are weakly comparable (e.g. the data 
does not have to be aligned by time).

3   Problem Formulation

In general, the problem of cross-lingual topic ex- 
traction can be defined as to extract a set of com- 
mon cross-lingual latent topics covered in text col- 
lections in different natural languages.  A cross- 
lingual latent topic will be represented as a multi- 
nomial word distribution over the words in all 
the languages, i.e.   a multilingual word distri- 
bution.   For example, given two collections of 
news articles in English and Chinese, respectively, 
we would like to extract common topics simul- 
taneously from the two collections.  A discov- 
ered common topic, such as the terrorist attack 
on September 11, 2001, would be characterized 
by a word distribution that would assign relatively 
high probabilities to words related to this event in 
both English and Chinese (e.g. “terror”, “attack”, 
“afghanistan”, “taliban”, and their translations in 
Chinese).
  As a computational problem, our input is a 
multi-lingual text corpus, and output is a set of 
cross-lingual latent topics.   We now define this 
problem more formally.



  Definition 1 (Multi-Lingual Corpus) A multi- 
lingual  corpus  C  is  a  set  of  text  collections


4	Probabilistic Cross-Lingual Latent
Semantic Analysis


{C1, C2 , . . . , Cs },  where Ci   = {di , di , . . . , di    }
1 	2 	Mi


is a collection of documents in language Li with


In this section, we present our probabilistic cross-


vocabulary Vi  = {wi , wi , . . . , wi


}. Here, Mi is


lingual latent semantic analysis 
(PCLSA) model


1 	2 	Ni


the total number of documents in Ci , Ni is the to-
tal number of words in Vi , and di is a document in 
collection Ci .
  Following the common assumption of bag-of- 
words representation, we represent document di


and discuss how it can be used to extract cross-
lingual topics from multi-lingual text data.
  The main reason why existing topic models 
can’t be used for cross-lingual topic extraction is 
because they cannot cross the language barrier. 
Intuitively, in order to cross the language barrier


with a bag of words {wi  , wi  , . . . , wi


}, and use


and extract a common topic shared in 
articles in


j1 	j2 	jd


c(wi , di )


to denote 
the count 
of word wi  
in docu-


k 	j 	k
ment di .
  Definition 2 (Cross-Lingual Topic): A cross- 
lingual topic θ is a semantically coherent multi- 
nomial distribution over all the words in the vo-
cabularies of languages L1, ..., Ls. That is, p(w|θ)
would give the probability of a word w which can
be in any of the s languages under consideration. θ 
is semantically coherent if it assigns high probabil- 
ities to words that are semantically related either in 
the same language or across different languages.


different languages, we must rely on some kind
of linguistic knowledge.  Our PCLSA model as- 
sumes the availability of bi-lingual dictionaries for 
at least some language pairs, which are generally 
available for major language pairs.  Specifically, 
for text data in languages L1,  ..., Ls , if we rep- 
resent each language as a node in a graph and 
connect those language pairs for which we have a 
bilingual dictionary, the minimum requirement is 
that the whole graph is connected. Thus, as a min-
imum, we will need s − 1 distinct bilingual dictio-


Clearly, we have ∑s
∈
cross-lingual topic θ.


p(w|θ) = 1 for any


naries. This is so that we can 
potentially cross all the 
language barriers.



  Definition 3 (Cross-Lingual Topic Extrac- 
tion) Given a multi-lingual corpus C, the task of
cross-lingual topic extraction is to model and ex- 
tract k major cross-lingual topics {θ1, θ2, . . . , θk } 
from C, where θi is a cross-lingual topic, and k is
a user specified parameter.
  The extracted cross-lingual topics can be di- 
rectly used as a summary of the common con- 
tent of the multi-lingual data set.  Note that once 
a  cross-lingual topic is  extracted,  we can eas- 
ily obtain its representation in each language Li 
by “splitting” the cross-lingual topic into multi- 
ple word distributions in different languages. For- 
mally,  the  word  distribution of  a  cross-lingual
topic θ in language Li  is given by pi (wi |θ)  =
p(wi |θ)
∑
w∈Vi p(w|θ)
These aligned language-specific word distribu-
tions can directly review the variations of topics 
in different languages.  They can also be used to 
analyze the difference of the coverage of the same 
topic in different languages.  Moreover, they are 
also useful for retrieving relevant articles or pas- 
sages in each language and aligning them to the 
same common topic, thus essentially also allow- 
ing us to integrate and align articles in multiple 
languages.
  

Our key idea is to “synchronize” the extraction 
of monolingual “component topics” of a cross- 
lingual topic from individual languages by forcing 
a cross-lingual topic word distribution to assign 
similar probabilities to words that are potential 
translations according to a Li -Lj  bilingual dictio- 
nary. We achieve this by adding such preferences 
formally to the likelihood function of a probabilis- 
tic topic model as “soft constraints” so that when 
we estimate the model, we would try to not only 
fit the text data well (which is necessary to extract 
coherent component topics from each language), 
but also satisfy our specified preferences (which 
would ensure the extracted component topics in 
different languages are semantically related). Be- 
low we present how we implement this idea in 
more detail.
  A bilingual dictionary for languages Li and Lj 
generally would give us a many-to-many map- 
ping between the vocabularies of the two lan- 
guages.  With such a mapping, we can construct 
a bipartite graph Gij  =  (Vij , Eij ) between the 
two languages where if one word can be poten- 
tially translated into another word, the two words 
would be connected with an edge.  An edge can 
be weighted based on the probability of the cor- 
responding translation.    An example graph for


Chinese-English dictionary is shown in Figure 1.

 

Figure 1: A Dictionary based Word Graph


  With multiple bilingual dictionaries, we can 
merge the graphs to generate a multi-partite graph 
G  = (V, E).   Based on this graph, the PCLSA 
model extends the standard PLSA by adding a 
constraint to the likelihood function to “smooth” 
the word distributions of topics in PLSA on the 
multi-partite graph so that we would encourage the 
words that are connected in the graph (i.e.  pos- 
sible translations of each other) to be given simi- 
lar probabilities by every cross-lingual topic. Thus 
when a cross-lingual topic picks up words that co- 
occur in mono-lingual text, it would prefer pick- 
ing up word pairs whose translations in other lan- 
guages also co-occur with each other, giving us a 
coherent multilingual word distribution that char- 
acterizes well the content of text in different lan- 
guages.
Specifically, let Θ = {θj } (j = 1, ..., k) be a set
of k cross-lingual topic models to be discovered

from a multilingual text data set with s languages 
such that p(w|θi ) is the probability of word w ac-
cording to the topic model θi .
  If we are to use the regular PLSA to model our 
data, we would have the following log-likelihood 
and we usually use a maximum likelihood estima- 
tor to estimate parameters and discover topics.


is the degree of word u, i.e. the sum of the weights 
of all the edges ending with u.
  Intuitively, R(C) measures the difference be- 
tween p(wu|θj ) and p(wv |θj ) for each pair (u, v)
in a bilingual dictionary; the more they differ, the 
larger R(C) would be.  So it can be regarded as
a “loss function” to help us assess how well the 
“component word distributions” in multiple lan- 
guages are correlated semantically.  Clearly, we 
would like the extracted topics to have a small
R(C).  We choose this specific form of loss func-
tion because it would make it convenient to solve
the optimization problem of maximizing the cor- 
responding regularized maximum likelihood (Mei 
et al., 2008b).   The normalization with Deg(u) 
and Deg(v) can be regarded as a way to compen- 
sate for the potential ambiguity of u and v in their 
translations.
Putting  L(C)  and  R(C)  together,  we  would
like to maximize the following objective function
which is a regularized log-likelihood:

O(C, G)    =  (1 − λ)L(C) − λR(C)	(1)

where λ ∈ (0, 1) is a parameter to balance the 
likelihood and the regularizer.  When λ = 0, we 
recover the standard PLSA.
  Specifically, we will search for a set of values 
for all our parameters that can maximize the ob- 
jective function defined above.   Our parameters 
include all the cross-lingual topics and the cov- 
erage distributions of the topics in all documents,
which we denote by Ψ = {p(w|θj ), p(θj |d)}d,w,j
where j = 1, ..., k, w varies over the entire vo-
cabularies of all the languages ,  d  varies over 
all the documents in our collection.  This opti- 
mization problem can be solved using a General- 
ized Expectation-Maximization (GEM) algorithm 
as described in (Mei et al., 2008a).


s 	k


L(C) = ∑ ∑ ∑ c(w, d) log ∑ p(θj |d)p(w|θj )


Specifically, in the E-step of the algorithm, the


i=1 d∈Ci    w


j=1


distribution of 
hidden variables is 
computed using
Eq. 2.


Our main extension is to add to L(C) a cross-
lingual constraint term R(C)  to incorporate the
knowledge of bilingual dictionaries.  R(C) is de-
fined as

k




z(w, d, j)  = 	p(θj |d)p(w|θj )
j′ p(θj′ |d)p(w|θj′ )





(2)


R( ) = 1
2


∑ w(u, v)


∑( p(wu |θj 
)
Deg(u
)


p(wv |θj ) )2
Deg(v)



Then in 
the M-
step, we 
need to 
maximize 
the


⟨u,v⟩∈E


j=1


complete data 
likelihood Q(Ψ; 
Ψn):


where w(u, v) is the weight on the edge between
u and v in the multi-partite graph G  = (V, E), 
which in our experiments is set to 1, and Deg(u)



Q(Ψ; Ψn )   =  (1 − λ)L′ (C) − λR(C)


where
L′ (C) = ∑ ∑ c(w, d) ∑ z(w, d, j) log p(θj |d)p(w|θj ), 	(3)

d	w 	j


a simple segmenter1 to split the data into Chinese 
phrases. Both Chinese and English stopwords are 
removed from our data.
The dictionary file we used for our PCLSA
2


with the constraints that ∑j p(θj |d)   = 1 and
∑w p(w|θj ) = 1.
There is a closed form solution if we only want
to maximize the L′ (C) part:


model is from mandarintools.com . For each Chi-
nese phrase, if it has several English meanings, we 
add an edge between it and each of its English 
translation.  If one English translation is an En- 
glish phrase, we add an edge between the Chinese 
phrase and each English word in the phrase.


∑  c(w, d)z(w, d, j)


p(n+1) (θj |d)    =


 	w 	
∑w ∑j′  c(w, d)z(w, 
d, j′ )


5.2	Baseline 
Method


∑ c(w, d)z(w, d, j)


As a baseline method, we can apply the 
standard


p(n+1) (w|θj )   =


 	d 	(4)
w c(w′ , 
d)z(w′ , d, j)


PLSA (Hofmann, 
1999a) directly to 
the multi- lingual 
corpus.  Since 
PLSA takes 
advantage of


However, there is no closed form solution in the
M-step for the whole objective function.  Fortu- 
nately, according to GEM we do not need to find 
the local maximum of Q(Ψ; Ψn ) in every M-step, 
and we only need to find a new value Ψn+1 to im- 
prove the complete data likelihood, i.e.  to make

sure Q(Ψn+1 ; Ψn ) ≥ Q(Ψn ; Ψn ). So our method 
is to first maximize the L′ (C) part using Eq. 4 and
then use Eq. 5 to gradually increase the R(C) part.


p(t+1) (wu |θj )   =  (1 − α)p(t)(wu|θj )           (5)


the word co-occurrences in the document level to 
find semantic topics, directly using it for a multi- 
lingual corpus will result in finding topics mainly 
reflecting a single language (because words in dif- 
ferent languages would not co-occur in the same 
document in general). That is, the discovered top- 
ics are mostly monolingual.  These monolingual 
topics can then be aligned based on a bilingual dic- 
tionary to suggest a possible cross-lingual topic.

6   Experimental Results

6.1   Qualitative Comparison


+  α    ∑
⟨u,v⟩∈E


 w(u, v)
Deg(v) p


(t)


(wv |θj )



To qualitatively compare 
PCLSA with the baseline 
method, we compare the word 
distributions of top- ics 
extracted by them. The data 
set we used in this


Here, parameter α is the length of each smooth-
ing step.  Obviously, after each smoothing step, 
the sum of the probabilities of all the words in one 
topic is still equal to 1. We smooth the parameters 
until we cannot get a better parameter set Ψn+1 . 
Then, we continue to the next E-step.  If there is
no Ψn+1 s.t.  Q(Ψn+1 ; Ψn) ≥ Q(Ψn; Ψn), then
we consider Ψn to be the local maximum point of
the objective function Eq. 1.

5   Experiment Design

5.1   Data Set

The data set we used in our experiment is collected 
from news articles of Xinhua English and Chi- 
nese newswires. The whole data set is quite big, 
containing around 40,000 articles in Chinese and
35,000 articles in English. For different purpose of 
our experiments, we randomly selected different 
number of documents from the whole corpus, and 
we will describe the concrete statistics in each ex- 
periment. To process the Chinese corpus, we use


experiment is selected from the Xinhua News data 
during the period from Jun. 8th, 2001 to Jun. 15th,
2001. There are totally 1799 English articles and
1485 Chinese articles in the data set.  The num- 
ber of topics to be extracted is set to 10 for both 
methods.
  Table 1 shows the experimental results.   To 
make it easier to understand, we add an English 
translation to each Chinese phrase in our results. 
The first ten rows show sample topics of the mod- 
eling results of traditional PLSA model.  We can 
see that it only contains mono-language topics, 
i.e.  the topics are either in Chinese or in En- 
glish.   The next ten rows are the results from 
our PCLSA model.    Compared with the base- 
line method, PCLSA can not only find coherent 
topics from the cross-lingual corpus, but it can 
also show the content about one topic from both 
two language corpora. For example, in ’Topic 2’

1 http://www.mandarintools.com/segmenter.html
2 http://www.mandarintools.com/cedict.html



Table 2: Synthetic Data Set from Xinhua News

En
glis
h
S
h
r
i
n
e
9
0
O
l
y
m
p
i
c
1
0
1
Ch
am
pio
nsh
ip
7
0
Chi
nes
e
CP
C 
An
niv
ers
ary
9
5
Af
gha
n 
Wa
r
2
0
6
Ch
am
pio
nsh
ip
7
2


which is about ’Israel’ and ’Palestinian’, the Chi- 
nese corpus mentions a lot about ’Arafat’ who is 
the leader of ’Palestinian’, while the English cor- 
pus discusses more on topics such as ’cease fire’


6.3   Quantitative Evaluation
We also quantitatively evaluate how well our 
PCLSA model can discover common topics 
among corpus in different languages.  We pro- 
pose a “cross-collection” likelihood measure for 
this purpose.  The basic idea is:  suppose we got 
k cross-lingual topics from the whole corpus, then 
for each topic, we split the topic into two sepa- 
rate set of topics, English topics and Chinese top- 
ics, using the splitting formula described before,


and ’women’.  Similarly, in ’Topic 9’, the topic


i.e.  pi (wi |θ)  =	p(w  |θ)


.  Then, we use the


is related to Philippine, the Chinese corpus men- 
tions some environmental situation in Philippine, 
while the English corpus mentions a lot about
’Abu Sayyaf’.


6.2   Discovering Common Topics

To demonstrate the ability of PCLSA for finding 
common topics in cross-lingual corpus, we use 
some event names, e.g.  ’Shrine’ and ’Olympic’, 
as queries and randomly select a certain number of 
documents from the whole corpus, which are re- 
lated to the queries. The number of documents for 
each query in the synthetic data set is shown in Ta- 
ble 2. In either the English corpus or the Chinese 
corpus, we select a smaller number of documents 
about topic ’Championship’ combined with the 
other two topics in the same corpus. In this way, 
when we want to extract two topics from either En- 
glish or Chinese corpus, the ’Championship’ topic 
may not be easy to extract, because the other two 
topics have more documents in the corpus. How- 
ever, when we use PCLSA to extract four topics 
from the two corpora together, we expect that the 
topic ’Championship’ will be found, because now 
the sum of English and Chinese documents related 
to ’Championship’ is larger than other topics. The 
experimental result is shown in Table 3. The first 
two columns are the two topics extracted from En- 
gish corpus, the third and the forth columns are 
two topics from Chinese corpus, and the other four 
columns are the results from cross-lingual cor- 
pus.  We can see that in either the Chinese sub- 
collection or the English sub-collection, the topic
’Championship’ is not extracted as a significant 
topic. But, as expected, the topic ’Championship’ 
is extracted from the cross-lingual corpus, while 
the topic ’Olympic’ and topic ’Shrine’ are merged 
together. This demonstrate that PCLSA is capable 
of extracting common topics from a cross-lingual 
corpus.


w∈Vi p(w|θ)
word distribution of the Chinese topics (translating
the words into English) to fit the English Corpus 
and use the word distribution of the English top- 
ics (translating the words into Chinese) to fit the 
Chinese Corpus. If the topics mined are common 
topics in the whole corpus, then such a “cross- 
collection” likelihood should be larger than those 
topics which are not commonly shared by the En- 
glish and the Chinese corpus.  To calculate the 
likelihood of fitness, we use the folding-in method 
proposed in (Hofmann, 2001). To translate topics 
from one language to another, e.g. Chinese to En- 
glish, we look up the bilingual dictionary and do 
word-to-word translation. If one Chinese word has 
several English translations, we simply distribute 
its probability mass equally to each English trans- 
lation.
  For comparison, we use the standard PLSA 
model as the baseline.  Basically, suppose PLSA 
mined k semantic topics in the Chinese corpus and 
k semantic topics in the English corpus. Then, we 
also use the “cross-collection” likelihood measure 
to see how well those k semantic Chinese topics fit 
the English corpus and those k semantic English 
topics fit the Chinese corpus.
  We totally collect three data sets to compare the 
performance.   For the first data set, (English 1, 
Chinese 1), both the Chinese and English corpus 
are chosen from the Xinhua News Data during 
the period from 2001.06.08 to 2001.06.15, which 
has 1799 English articles and 1485 Chinese ar- 
ticles.  For the second data set, (English 2, Chi- 
nese 2), the Chinese corpus Chinese 2 is the same 
as Chinese 1, but the English corpus is chosen 
from 2001.06.14 to 2001.06.19 which has 1547 
documents. For the third data set, (English 3, Chi- 
nese 3), the Chinese corpus is the same as in data 
set one, but the English corpus is chosen from
2001.10.02 to 2001.10.07 which contains 1530 
documents.  In other words, in the first data set,


Table 1: Qualitative Evaluation

T
o
p
i
c
 
0
T
o
p
i
c
 
1
T
o
p
i
c
 
2
T
o
p
i
c
 
3
T
o
pi
c 
4
T
o
p
i
c
 
5
Top
ic 6
T
o
p
i
c
 
7
Topi
c 8
To
pic 
9
 
(
p
a
r
t
y
)
   
(c
o
m
m
un
ist
)
$
\
W
(
r
e
v
o
l
u
t
i
o
n
)
  
(p
art
y 
me
m
be
r)
 
;
!
;
(
c
e
n
t
r
a
l
)
 
 
(
i
s
m
)
-
T
t
r
(
c
a
d
r
e
)
=E   
�f(ch
airma
n  
mao)
  
(chinese 
commu
nist)
f
f
i
-
@
(
l
e
a
d
e
r
)
 
�
(
c
r
i
m
e
)
�   
(a
gr
ic
ul
tu
re
)
J
J
W
(
t
r
a
v
e
l
)
 
�(
hea
the
ndo
m)
0$.:(
public 
securi
ty)
  
(
n
a
m
e
)
�
(
c
a
s
e
)
  
(law 
enforce
ment)
r
n
(
c
i
t
y
)
;
£
t
f
r
J
(
p
e
n
a
l
i
z
e
)
�
:
f
.
(
a
t
h
l
e
t
e
)
J
a    
(
c
h
a
m
p
i
o
n
)
 
t�(ch
ampion
ship)
 
(
b
a
s
e
)
B=E 
(bad
mint
on)
 
l
f
(
s
p
o
r
t
s
)
j
\
:
�
(
f
i
n
a
l
)
  
(
w
o
m
e
n
)
�
J
t
(
c
h
e
s
s
)
�
:
5
t
(
f
i
t
n
e
s
s
)
 
(
p
a
l
e
s
t
i
n
e
)
 l-
w:\:(pal
estine)
�
e
J
'(
is
ra
el
)
 
1f(
cea
se 
fire
)
   
(
U
N
)
 
�
f(
mi
d 
ea
st)
   
(leb
ano
n)
   
(mac
edon)
$
*
(
c
o
n
fl
i
c
t)
 
l
k
(
t
a
l
k
)
 
f(colla
boration
)
_t.�(
shang
hai)
:K
�
(re
lat
io
n)
  
(bilat
eral)
W
&
(
t
r
a
d
e
)
 
�(pr
eside
nt)
 
(
c
o
u
n
t
r
y
)
 
0
(fr
ien
dl
y)
 
f
t
(
m
e
e
t
)
��-
w(rus
sia)
�l
f(e
duc
atio
n)
 
(
b
a
l
l
)
 
�
(
l
e
a
g
u
e
)
  
(
s
o
c
c
e
r
)
::
5
$
(
m
i
n
u
t
e
)
  
(team 
member
)
�
fl
J(
te
a
c
h
e
r)
   
(sc
hoo
l)
  
(
t
e
a
m
)
E
f
(
g
r
a
d
e
 
A
)
i
s
r
a
e
l
p
al
es
ti
ni
a
n 
e
u
p
o
l
i
c
e
 
r
e
p
o
r
t
 
s
e
c
u
r
e
 
k
i
l
l
 
e
u
r
o
p
e
 
e
g
y
p
t
 
t
r
e
a
t
y
b
t
b
e
a
t
 
f
i
n
a
l
 
c
h
a
m
p
i
o
n
s
h
i
p
 
p
l
a
y
c
h
a
m
p
i
o
n
 
w
i
n
 
o
l
y
m
p
i
c
 
g
a
m
e
c
u
p
d
o
l
l
a
r
p
e
r
c
e
n
t 
m
il
li
o
n 
i
n
d
e
x 
s
t
o
c
k 
p
o
i
n
t 
s
h
a
r
e 
c
l
o
s
e
0
 
b
i
l
l
i
o
n
c
h
i
n
a
c
o
o
p
e
r
a
t
e
 
s
h
a
n
g
h
a
i
 
d
e
v
e
l
o
p
 
b
e
i
j
e
 
p
a
r
t
i
c
u
l
a
t
e
 
m
a
t
t
e
r
s
c
o
 
i
n
v
e
s
t
 
p
r
o
j
e
c
t
 
 
(
b
i
l
a
t
e
r
a
l
)
 
f
(c
ol
la
b
or
at
io
n)
 
l
k
(
t
a
l
k
)
 
0
(
f
r
i
e
n
d
l
y
)
 
(
p
a
l
e
s
t
i
n
e
)
c
o
u
n
t
r
y
 
 
 
(
U
N
)
 
f
f
i
-
@
 
(
l
e
a
d
e
r
)
 
b
i
l
a
t
e
r
a
l
s
t
a
t
e
 
�
(
l
e
a
g
u
e
)
  
(
n
a
m
e
)
 
(
b
a
l
l
)
 
 
(
s
h
e
n
h
u
a
)
  
(
h
o
s
t
)
 
A
b
a
l
l
�
   
(
j
i
n
d
e
)
�
*
(
s
e
a
s
o
n
)
  
(
p
l
a
y
e
r
)
i
s
r
a
e
l
�
e
J
'
(
i
s
r
a
e
l
)
b
t
 
p
a
l
e
s
t
i
n
i
a
n
 
c
e
a
s
e
f
i
r
e
 
ii  
�
(a
ra
fa
t)
w
o
m
e
n
 
j
e
r
u
s
a
l
e
m
 
m
i
d
e
a
s
t
 
l
e
b
a
n
o
n
c
o
o
p
e
r
a
t
e
 
s
c
o
 
d
e
v
e
l
o
p
 
c
o
u
n
t
r
y
 
p
r
e
s
i
d
e
n
t
 
a
p
e
c
 
s
h
a
n
g
h
a
i
 
a
f
r
i
c
a
 
m
e
e
t
�   
�(zemi
n jiang)
�
:f
.(
at
h
le
te
)
p
a
r
t
i
c
u
l
a
t
e
 
J
a
 
a
t
h
l
e
t
e
 
c
h
a
m
p
i
o
n
 
i
i
�
J
t
(
c
h
e
s
s
)
 
c
o
m
p
e
t
i
t
i
o
n
 
c
o
n
t
e
s
t
a
n
t
 
1(gy
mnast
ics)
p
a
r
t
y
 
(
p
a
r
t
y
)
 
c
o
m
m
u
n
i
s
t
 
r
e
v
o
l
u
t
i
o
n
  
(-
is
m
) 
J
L
S
(a
nt
i
w
ar
) 
f
P
�
(c
o
m
ra
de
)
$\
W(re
volu
tion)
   
(p
ar
ty
)
i
d
e
o
l
o
g
y
e
u
 
k
h
a
t
a
m
i
 
i
r
e
l
a
n
d
   
(ireland
)
el
ec
t 
vo
te 
pr
esi
de
nti
al 
cp
c
ira
n 
ref
er
en
du
m
i
n
v
e
s
t
  
(in
ve
st
m
en
t)
 
J
t
(
b
i
l
l
i
o
n
)
�
l
f
(
e
d
u
c
a
ti
o
n
)
  
(enviro
n. 
protect.)
 
�
(
m
o
n
e
y
)
   
(
s
c
h
o
o
l
)
m
a
r
k
e
t
�
f
l
J
(
t
e
a
c
h
e
r
)
b
u
s
i
n
e
s
s
0 
d
o
ll
a
r 
p
e
r
c
e
n
t 
i
n
d
e
x 
m
il
li
o
n 
s
t
o
c
k 
b
il
li
o
n 
p
o
i
n
t
i-  
(billion)
s
h
a
r
e
IJ,
A(
abs
orb
)
l
     
(abu)
l
  
(pa
rtic
le) 
phi
lip
pin
e 
abu
 
(
b
a
s
e
)
 
I
I
I
 
t
f
o
(
o
b
j
e
c
t
)

Table 3: Effectiveness of Extracting Common Topics

Engli
sh 1
En
glis
h 2
C
h
i
n
e
s
e
 
1
C
hi
ne
se 
2
C
r
o
s
s
 
1
C
r
o
s
s 
2
C
r
o
s
s
 
3
C
r
o
s
s
 
4
japa
n 
shri
ne 
visit 
koiz
umi 
yas
uku
ni 
war 
aug
ust 
asia 
cri
min
al ii
o
l
y
m
p
i
c
 
i
o
c
 
b
e
i
j
e
 
g
a
m
e
 
j
u
l
y
b
i
d
 
s
w
i
m
 
v
o
t
e
cha
mpi
onsh
ip 
com
mitt
ee
   
(
C
P
C
)
 
(
c
h
a
m
p
i
o
n
s
h
i
p
)
i
t
!
(
w
o
r
l
d
)
'
i
§
�
(
t
h
o
u
g
h
t
)
 
 
(
t
h
e
o
r
y
)
 
5
'
i
§
(
m
a
r
x
)
W
J
c
(
s
w
i
m
)
 
t�
(cha
mpio
nship
)
 
(
p
a
r
t
y
)
}
!
  
(
f
o
u
n
d
 
p
a
r
t
y
)
 
'i'tf
(afgh
an)
 
(
t
a
l
i
b
a
n
)
;f
Jj}
(ta
lib
an
)
  
(mi
litar
y)
 
1(
atta
ck)
�    
(US 
army
)
f
t
(
l
a
d
e
n
)
t
r  
(
a
r
m
y
)
�
�(
bo
mb)
$    
(ka
bul)
k
o
i
z
u
m
i
 
y
a
s
u
k
u
n
i
 
i
o
c
j
a
p
a
n
 
o
l
y
m
p
i
c
 
b
e
i
j
e
 
s
h
r
i
n
e
 
v
i
s
i
t
   
(ol
y
m
pi
c)
 
;\%\/l
5(ol
ympi
c)
;fJ
j}(t
ali
ban
)
  
(mil
itary
)
c
i
t
y
 
r
e
f
u
g
e
e
 
s
i
d
e
�    
(US 
army
)
�
�
(b
o
m
b)
$    
(kab
ul)
  
(at
ta
ck
)
1<
�(r
efu
gee)
s
w
i
m
 
(
c
h
a
m
p
i
o
n
s
h
i
p
)
§
E
i
3
J
c
(
f
r
e
e
 
s
t
y
l
e
)
l
f
;
J
<
(
d
i
v
i
n
g
)
 
t�
(cha
mpio
nship
)
�
j
\
:
�
(
s
e
m
i 
fi
n
a
l)
c
o
m
p
e
t
i
t
i
o
n
W
J
c
(
s
w
i
m
)
�
      
(
r
e
c
o
r
d
)
�
�
�(
xu
eju
an 
luo
)
I
 
(
w
o
r
k
e
r
)
p
a
r
t
y
�
1
'
-
(
t
h
r
e
e
)
 
5
'
i
§
(
m
a
r
x
) 
c
o
m
m
u
n
i
s
t 
m
a
r
x
t
h
e
o
r
y
}!  
(foun
d 
party
)
   
(
C
P
C
)
r
e
v
o
l
u
t
i
o
n



the English corpus and Chinese corpus are com- 
parable with each other, because they cover simi- 
lar events during the same period.  In the second 
data set, the English and Chinese corpora share 
some common topics during the overlap period. 
The third data is the most tough one since the two 
corpora are from different periods. The purpose of 
using these three different data sets for evaluation 
is to test how well PCLSA can mine common top- 
ics from either a data set where the English corpus 
and the Chinese corpus are comparable or a data 
set where the English corpus and the Chinese cor- 
pus rarely share common topics.

  The experimental results are shown in Table 4. 
Each row shows the “cross-collection” likelihood 
of using the “cross-collection” topics to fit the data 
set named in the first column.  For example, in 
the first row, the values are the “cross-collection” 
likelihood of using Chinese topics found by differ- 
ent methods from the first data set to fit English 1. 
The last collum shows how much improvement we 
got from PCLSA compared with PLSA. From the 
results, we can see that in all the data sets, our 
PCLSA has higher “cross-collection” likelihood 
value, which means it can find better common top- 
ics compared to the baseline method. Notice that 
the Chinese corpora are the same in all three data 
sets. The results show that both PCLSA and PLSA 
get lower “cross-collection” likelihood for fitting 
the Chinese corpora when the data set becomes 
“tougher”, i.e. less topic overlapping, but the im-



Table  4:   Quantitative  Evaluation  of  Common
Topic Finding (“cross-collection” log-likelihood)


P
C
L
S
A
P
L
S
A
Rel. 
Imp
rv.
En
glis
h 1
-
2.8
629
4E
+06
-
3.0
317
6E
+06
5
.
6
%
Chi
nes
e 1
-
4.6
998
9E
+06
-
4.8
536
9E
+06
3
.
2
%
En
glis
h 2
-
2.4
817
4E
+06
-
2.6
080
5E
+06
4
.
8
%
Chi
nes
e 2
-
4.7
321
8E
+06
-
4.8
890
6E
+06
3
.
2
%
En
glis
h 3
-
2.4
471
4E
+06
-
2.6
054
0E
+06
6
.
1
%
Chi
nes
e 3
-
4.7
963
9E
+06
-
4.9
427
3E
+06
3
.
0
%

provement of PCLSA over PLSA does not drop 
much.   On the other hand, the improvement of 
PCLSA over PLSA on the three English corpora 
does not show any correlation with the difficulty 
of the data set.

6.4   Extracting from Multi-Language Corpus

In the previous experiments, we have shown the 
capability and effectiveness of the PCLSA model 
in latent topic extraction from two language cor- 
pora.  In fact, the proposed model is general and 
capable of extracting latent topics from multi- 
language corpus.   For example, if we have dic- 
tionaries among multiple languages, we can con- 
struct a multi-partite graph based on the corre- 
spondence between those vocabularies, and then 
smooth the PCLSA model with this graph.
  To show the effectiveness of PCLSA in min- 
ing multiple language corpus, we first construct a 
simulated data set based on 1115 reviews of three 
brands of laptops, namely IBM (303), Apple(468) 
and DELL(344). To simulate a three language cor-


Table 5: Effectiveness of Latent Topic Extraction from Multi-Language Corpus

To
pic 
0
T
o
pi
c 
1
To
pic 
2
T
o
pi
c 
3
T
o
p
i
c 
4
To
pi
c 
5
To
pi
c 
6
To
pic 
7
cd(ap
ple) 
port(
apple
) 
drive
(appl
e) 
airpo
rt(ap
ple) 
firew
ire(a
pple) 
dvd(
apple
) 
usb(a
pple) 
rw(a
pple) 
card(
apple
) 
mous
e(app
le)
b
at
te
ry
(d
el
l)
d
r
i
v
e
(
d
e
l
l
)
82
00
(d
ell
) 
in
sp
ir
on
(d
ell
) 
sy
st
e
m
(d
ell
) 
ho
ur
(d
ell
) 
so
un
d(
de
ll) 
de
ll(
de
ll) 
se
rv
ic
e(
de
ll) 
lif
e(
de
ll)
mous
e(dell
) 
butto
n(dell
) 
touch
pad(d
ell) 
pad(d
ell) 
keybo
ard(d
ell) 
point(
dell) 
stick(
dell) 
rest(d
ell) 
touch
(dell) 
erase(
dell)
prin
t(ap
ple) 
reso
luti
on(
dell
) 
burn
(app
le) 
nor
mal
(del
l) 
ima
ge(d
ell) 
digi
tal(a
pple
) 
orga
nize
(app
le) 
cds(
appl
e) 
latc
h(ap
ple) 
adv
ertis
e(de
ll)
po
rt(
ib
m) 
ca
rd
(ib
m) 
m
od
e
m(
ib
m) 
di
sp
la
y(i
b
m) 
bu
ilt
(ib
m) 
sw
ap
(ib
m) 
ea
sy
(ib
m) 
co
nn
ec
tor
(ib
m) 
fe
at
ur
e(i
b
m) 
cd
(ib
m)
lapt
op(i
bm) 
t20(
ibm
) 
thin
kpa
d(ib
m) 
batt
ery(
ibm
) 
note
boo
k(ib
m) 
ibm
(ib
m)
3
(
i
b
m
)
 
f
e
e
l
(
i
b
m
)
 
h
o
u
r
(
i
b
m
)
 
h
i
g
h
(
i
b
m
)
o
s
(
a
p
p
l
e
)
r
u
n
(
a
p
p
l
e
)
1(a
ppl
e) 
ra
m(
app
le) 
ma
c(a
ppl
e) 
batt
ery
(ap
ple
) 
hou
r(a
ppl
e)
12(
app
le) 
ope
rate
(ap
ple) 
wor
d(a
ppl
e)
p
or
t(
d
el
l)
2
(
d
e
l
l
)
u
s
b
(
d
e
ll
)
1
(
d
e
l
l
)
0(del
l) 
slot(d
ell) 
firewi
re(de
ll) 
displ
ay(de
ll) 
stand
ard(d
ell) 
fast(d
ell)
osx(a
pple) 
memo
ry(del
l) 
specia
l(dell) 
crucia
l(dell) 
memo
ry(ap
ple) 
memo
ry(ib
m) 
netsca
pe(ap
ple) 
resell
er(app
le)
1
0
(
d
e
l
l
)
speci
al(ap
ple)
apple
work(
apple) 
file(ap
ple) 
bounc
e(appl
e) 
quit(a
pple) 
word(
apple) 
file(ib
m) 
file(de
ll)
micr
osoft
(appl
e) 
ms(a
pple) 
excel
(appl
e)
port(d
ell) 
port(a
pple) 
port(i
bm) 
firewi
re(app
le) 
imac(
apple) 
firewi
re(del
l) 
firewi
re(ib
m) 
jack(a
pple) 
playb
ack(d
ell) 
jack(d
ell)
bat
ter
y(
del
l) 
bat
ter
y(i
b
m) 
bat
ter
y(
ap
ple
) 
ge
for
ce
4(
del
l)
100
mhz
(app
le)
4
4
0
(
d
e
l
l
)
b
u
s
(
a
p
p
l
e
)
8
2
0
0
(
d
e
l
l
)
8
1
0
0
(
d
e
l
l
)
c
hi
ps
et
(d
el
l)
l
i
g
h
t
e
s
t
(
i
b
m
)
 
q
u
a
l
i
t
y
(
d
e
l
l
)
 
y
e
a
r
(
i
b
m
)
 
h
a
s
s
l
e
(
i
b
m
)
 
b
a
n
i
a
(
d
e
l
l
)
800m
hz(ap
ple) 
trackp
ad(ap
ple) 
cover(
ibm) 
work
mans
hip(de
ll) 
sectio
n(appl
e)
uxga(
dell) 
ultras
harp(
dell) 
displa
y(dell
) 
organi
ze(ap
ple) 
learn(
apple) 
logo(a
pple) 
postsc
ript(a
pple) 
ll(app
le) 
sxga(
dell) 
warm
(apple
)
light
(ibm
) 
ultra
bay(i
bm) 
conn
ector
(ibm
) 
dvd(
ibm) 
nice(
ibm) 
mod
em(i
bm) 
conn
ector
(dell
) 
light
(appl
e) 
light
(dell
) 
flopp
y(ib
m)
batter
y(appl
e) 
point(
dell) 
touch
pad(d
ell) 
button
(dell) 
hour(
apple) 
batter
y(ibm
) 
batter
y(dell
) 
fan(de
ll) 
erase(
dell) 
point(
apple)
2
0
0
0(
ib
m
)
wind
ow(i
bm)
20
00(
app
le)
2000(
dell) 
wind
ow(a
pple) 
wind
ow(d
ell) 
porte
ge(ib
m) 
optio
n(ib
m) 
hassl
e(ibm
) 
devic
e(ibm
)
ra
m
(a
p
pl
e) 
ra
m
(i
b
m
) 
ra
m
(d
el
l) 
sc
re
en
(a
p
pl
e)
1
(
a
p
p
l
e
)
 
s
c
r
e
e
n
(
i
b
m
)
 
s
c
r
e
e
n
(
d
e
l
l
)
1
(
i
b
m
)
1
(
d
e
l
l
)
m
ac
o(
a
p
pl
e)
po
rt(
de
ll) 
po
rt(
ap
pl
e) 
po
rt(
ib
m
)
2
(
d
e
l
l
)
2
(
a
p
p
l
e
)
2(ib
m) 
spea
k(de
ll) 
tosh
iba(
dell
) 
spea
k(ib
m) 
tosh
iba(
ibm
)
itune(
apple) 
apple
work(
apple) 
imovi
e(appl
e) 
impor
t(appl
e) 
batter
y(appl
e) 
iphoto
(apple
) 
batter
y(ibm
) 
batter
y(dell
) 
hour(
apple) 
hour(i
bm)
ux
ga
(d
ell
) 
sc
re
en
(d
ell
) 
sc
re
en
(ib
m) 
sc
re
en
(a
pp
le) 
ult
ra
sh
ar
p(
de
ll)
160
0x1
200
(del
l) 
dis
pla
y(d
ell) 
dis
pla
y(a
ppl
e) 
dis
pla
y(ib
m) 
vie
w(d
ell)
port
(app
le) 
port
(ib
m) 
port
(del
l) 
usb(
appl
e) 
plug
(app
le) 
cord
(app
le) 
usb(
ibm
) 
usb(
dell
) 
fire
wire
(app
le) 
plug
(ib
m)
pentiu
m(del
l) 
proce
ssor(d
ell) 
p4(del
l) 
power
(dell) 
pentiu
m(app
le) 
pentiu
m(ib
m) 
keybo
ard(de
ll) 
proce
ssor(i
bm) 
proce
ssor(a
pple) 
power
(apple
)
driv
e(ib
m) 
driv
e(d
ell) 
driv
e(a
ppl
e) 
har
d(i
bm
) 
osx
(ap
ple) 
har
d(d
ell) 
har
d(a
ppl
e) 
car
d(i
bm
) 
dvd
(ib
m) 
car
d(d
ell)



pus, we use an ’IBM’ word, an ’Apple’ word, and 
a ’Dell’ word to replace an English word in their 
corpus. For example, we use ’IBM10’, ’Apple10’,
’Dell10’ to replace the word ’CD’ whenever it ap- 
pears in an IBM’s, Apple’s, or Dell’s review. Af- 
ter the replacement, the reviews about IBM, Ap- 
ple, and Dell will not share vocabularies with each 
other.  On the other hand, for any three created 
words which represent the same English word, we 
add three edges among them, and therefore we 
get a simulated dictionary graph for our PCLSA 
model.




  The experimental result is shown in Table 5, in 
which we try to extract 8 topics from the cross- 
lingual corpus.  The first ten rows show the re- 
sult of our PCLSA model, in which we set a very 
small value to the weight parameter λ for the reg- 
ularizer part.  This can be used as an approxima- 
tion of the result from the traditional PLSA model 
on this three language corpus.  We can see that 
the extracted topics are mainly written in mono- 
language.  As we set the value of parameter λ 
larger, the extracted topics become multi-lingual, 
which is shown in the next ten rows.  From this 
result, we can see the difference between the re- 
views of different brands about the similar topic. 
In addition, if we set the λ even larger, we will 
get topics that are mostly made of the same words 
from the three different brands, which means the 
extracted topics are very smooth on the dictionary 
graph now.


7   Conclusion

In this paper, we study the problem of cross- 
lingual latent topic extraction where the task is to 
extract a set of common latent topics from multi- 
lingual text data. We propose a novel probabilistic 
topic model (i.e.  the Probabilistic Cross-Lingual 
Latent Semantic Analysis (PCLSA) model) that 
can incorporate translation knowledge in bilingual 
dictionaries as a regularizer to constrain the pa- 
rameter estimation so that the learned topic models 
would be synchronized in multiple languages. We 
evaluated the model using several data sets.  The 
experimental results show that PCLSA is effec- 
tive in extracting common latent topics from mul- 
tilingual text data, and it outperforms the baseline 
method which uses the standard PLSA to fit each 
monolingual text data set.
  Our work opens up some interesting future re- 
search  directions to  further  explore.    First,  in 
this paper, we have only experimented with uni- 
form weighting of edge in the bilingual graph. 
It should be very interesting to explore how to 
assign weights to the edges and study whether 
weighted graphs can further improve performance. 
Second, it would also be interesting to further 
extend PCLSA to accommodate discovering top- 
ics in each language that aren’t well-aligned with 
other languages.

8   Acknowledgments

We sincerely thank the anonymous reviewers for 
their comprehensive and constructive comments. 
The work was supported in part by NASA grant


NNX08AC35A, by the National Science Foun- 
dation under Grant Numbers IIS-0713581, IIS-
0713571, and CNS-0834709, and by a Sloan Re- 
search Fellowship.


References

David Blei and John Lafferty. 2005.  Correlated topic 
models. In NIPS ’05: Advances in Neural Informa- 
tion Processing Systems 18.

David M. Blei and John D. Lafferty.  2006.  Dynamic 
topic models.  In Proceedings of the 23rd interna- 
tional conference on Machine learning, pages 113–
120.

D. Blei, T. Griffiths, M. Jordan, and J. Tenenbaum.
2003a.   Hierarchical topic models and the nested 
chinese restaurant process.  In Neural Information 
Processing Systems (NIPS) 16.

D. Blei, A. Ng, and M. Jordan. 2003b. Latent Dirichlet 
allocation. Journal of Machine Learning Research,
3:993–1022.

J. Boyd-Graber and D. Blei. 2009. Multilingual topic 
models for unaligned text. In Uncertainty in Artifi- 
cial Intelligence.

S. R. K. Branavan, Harr Chen, Jacob Eisenstein, and 
Regina Barzilay.   2008.   Learning document-level 
semantic properties from free-text annotations.  In 
Proceedings of ACL 2008.

Martin Franz, J. Scott McCarley, and Salim Roukos.
1998. Ad hoc and multilingual information retrieval 
at IBM.  In Text REtrieval Conference, pages 104–
115.

Pascale Fung.    1995.    A pattern matching method 
for finding noun and proper noun translations from 
noisy parallel corpora. In Proceedings of ACL 1995, 
pages 236–243.

Alfio Gliozzo and Carlo Strapparava.  2006.  Exploit- 
ing comparable corpora and bilingual dictionaries 
for cross-language text categorization.  In ACL-44: 
Proceedings of the 21st International Conference 
on Computational Linguistics and the 44th annual 
meeting of the Association for Computational Lin- 
guistics, pages 553–560, Morristown, NJ, USA. As- 
sociation for Computational Linguistics.

T. Hofmann. 1999a. Probabilistic latent semantic anal- 
ysis. In Proceedings of UAI 1999, pages 289–296.

Thomas Hofmann.   1999b.   The cluster-abstraction 
model:  Unsupervised learning of topic hierarchies 
from text data. In IJCAI’ 99, pages 682–687.

Thomas Hofmann.  2001.  Unsupervised learning by 
probabilistic latent semantic analysis. Mach. Learn.,
42(1-2):177–196.


Jagadeesh Jagaralamudi and Hal Daume´ III. 2010. Ex- 
tracting multilingual topics from unaligned corpora. 
In Proceedings of the European Conference on In- 
formation Retrieval (ECIR), Milton Keynes, United 
Kingdom.

Woosung Kim and Sanjeev Khudanpur.  2004.  Lex- 
ical triggers and latent semantic analysis for cross- 
lingual language model adaptation.   ACM Trans- 
actions on Asian Language Information Processing 
(TALIP), 3(2):94–112.

Wei Li and Andrew McCallum. 2006. Pachinko allo- 
cation: Dag-structured mixture models of topic cor- 
relations. In ICML ’06: Proceedings of the 23rd in- 
ternational conference on Machine learning, pages
577–584.

H. Masuichi, R. Flournoy, S. Kaufmann, and S. Peters.
2000. A bootstrapping method for extracting bilin- 
gual text pairs. In Proc. 18th COLINC, pages 1066–
1070.

Qiaozhu Mei and ChengXiang Zhai. 2006. A mixture 
model for contextual text mining. In Proceedings of 
KDD ’06, pages 649–655.

Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su, 
and ChengXiang Zhai. 2007. Topic sentiment mix- 
ture: Modeling facets and opinions in weblogs.  In 
Proceedings of WWW ’07.

Qiaozhu Mei, Deng Cai, Duo Zhang, and ChengXiang 
Zhai. 2008a. Topic modeling with network regular- 
ization. In WWW, pages 101–110.

Qiaozhu  Mei,  Duo  Zhang,  and  ChengXiang  Zhai.
2008b.    A general optimization framework for 
smoothing language models on graph structures. In 
SIGIR ’08: Proceedings of the 31st annual interna- 
tional ACM SIGIR conference on Research and de- 
velopment in information retrieval, pages 611–618, 
New York, NY, USA. ACM.

David Mimno, Hanna M. Wallach, Jason Naradowsky, 
David A. Smith, and Andrew Mccallum.   2009. 
Polylingual topic models.   In Proceedings of the
2009 Conference on Empirical Methods in Natural 
Language Processing, pages 880–889, Singapore, 
August. Association for Computational Linguistics.

Xiaochuan Ni, Jian-Tao Sun, Jian Hu, and Zheng Chen.
2009.  Mining multilingual topics from wikipedia. 
In WWW ’09: Proceedings of the 18th international 
conference on World wide web, pages 1155–1156, 
New York, NY, USA. ACM.

F. Sadat, M. Yoshikawa, and S. Uemura. 2003. Bilin- 
gual terminology acquisition from comparable cor- 
pora and phrasal translation to cross-language infor- 
mation retrieval.  In ACL ’03:  Proceedings of the
41st Annual Meeting on Association for Computa- 
tional Linguistics, pages 141–144.


Mark Steyvers, Padhraic Smyth, Michal Rosen-Zvi, 
and Thomas Griffiths.  2004.  Probabilistic author- 
topic models for information discovery. In Proceed- 
ings of KDD’04, pages 306–315.

Xuanhui Wang, ChengXiang Zhai, Xiao Hu, and 
Richard Sproat.   2007.   Mining correlated bursty 
topic patterns from coordinated text streams.   In 
KDD ’07: Proceedings of the 13th ACM SIGKDD 
international conference on Knowledge discovery 
and data mining, pages 784–793, New York, NY, 
USA. ACM.

Bing Zhao and Eric P. Xing.  2006.  Bitam: Bilingual 
topic admixture models for word alignment.  In In 
Proceedings of the 44th Annual Meeting of the As- 
sociation for Computational Linguistics.

