<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">We introduce bilingual word embeddings: semantic embeddings associated across two languages in the context of neural language models.</S>
		<S sid ="2" ssid = "2">We propose a method to learn bilingual embeddings from a large unlabeled corpus, while utilizing MT word alignments to constrain translational equivalence.</S>
		<S sid ="3" ssid = "3">The new em- beddings significantly outperform baselines in word semantic similarity.</S>
		<S sid ="4" ssid = "4">A single semantic similarity feature induced with bilingual em- beddings adds near half a BLEU point to the results of NIST08 ChineseEnglish machine translation task.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="5" ssid = "5">It is difficult to recognize and quantify semantic similarities across languages.</S>
			<S sid ="6" ssid = "6">The FrEn phrase-pair {‘un cas de force majeure’, ‘case of absolute necessity’}, ZhEn phrase pair {‘依然故我’,‘persist in a stubborn manner’} are similar in semantics.</S>
			<S sid ="7" ssid = "7">If co- occurrences of exact word combinations are rare in the training parallel text, it can be difficult for classical statistical MT methods to identify this similarity, or produce a reasonable translation given the source phrase.</S>
			<S sid ="8" ssid = "8">We introduce an unsupervised neural model to learn bilingual semantic embedding for words across two languages.</S>
			<S sid ="9" ssid = "9">As an extension to their monolingual counterpart (Turian et al., 2010; Huang et al., 2012; Bengio et al., 2003), bilingual embeddings capture not only semantic information of monolingual words, but also semantic relationships across different languages.</S>
			<S sid ="10" ssid = "10">This prop erty allows them to define semantic similarity metrics across phrase-pairs, making them perfect features for machine translation.</S>
			<S sid ="11" ssid = "11">To learn bilingual embeddings, we use a new objective function which embodies both monolingual semantics and bilingual translation equivalence.</S>
			<S sid ="12" ssid = "12">The latter utilizes word alignments, a natural sub-task in the machine translation pipeline.</S>
			<S sid ="13" ssid = "13">Through large- scale curriculum training (Bengio et al., 2009), we obtain bilingual distributed representations which lie in the same feature space.</S>
			<S sid ="14" ssid = "14">Embeddings of direct translations overlap, and semantic relationships across bilingual embeddings were further improved through unsupervised learning on a large unlabeled corpus.</S>
			<S sid ="15" ssid = "15">Consequently, we produce for the research community a first set of Mandarin Chinese word embed- dings with 100,000 words trained on the Chinese Gigaword corpus.</S>
			<S sid ="16" ssid = "16">We evaluate these embedding on Chinese word semantic similarity from SemEval 2012 (Jin and Wu, 2012).</S>
			<S sid ="17" ssid = "17">The embeddings significantly outperform prior work and pruned tfidf baselines.</S>
			<S sid ="18" ssid = "18">In addition, the learned embeddings give rise to 0.11 F1 improvement in Named Entity Recognition on the OntoNotes dataset (Hovy et al., 2006) with a neural network model.</S>
			<S sid ="19" ssid = "19">We apply the bilingual embeddings in an end-to- end phrase-based MT system by computing semantic similarities between phrase pairs.</S>
			<S sid ="20" ssid = "20">On NIST08 ChineseEnglish translation task, we obtain an improvement of 0.48 BLEU from a competitive baseline (30.01 BLEU to 30.49 BLEU) with the Stanford Phrasal MT system.</S>
			<S sid ="21" ssid = "21">1393 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1393–1398, Seattle, Washington, USA, 1821 October 2013.</S>
			<S sid ="22" ssid = "22">Qc 2013 Association for Computational Linguistics</S>
	</SECTION>
	<SECTION title="Review of prior work. " number = "2">
			<S sid ="23" ssid = "1">Distributed word representations are useful in NLP applications such as information retrieval (Pas¸ca et al., 2006; Manning et al., 2008), search query expansions (Jones et al., 2006), or representing semantics of words (Reisinger et al., 2010).</S>
			<S sid ="24" ssid = "2">A number of methods have been explored to train and apply word embeddings using continuous models for language.</S>
			<S sid ="25" ssid = "3">Collobert et al.</S>
			<S sid ="26" ssid = "4">(2008) learn embed- dings in an unsupervised manner through a con- trastive estimation technique.</S>
			<S sid ="27" ssid = "5">Mnih and Hinton ( 2008), Morin and Bengio ( 2005) proposed efficient hierarchical continuous-space models.</S>
			<S sid ="28" ssid = "6">To systematically compare embeddings, Turian et al.</S>
			<S sid ="29" ssid = "7">(2010) evaluated improvements they bring to state-of-the- art NLP benchmarks.</S>
			<S sid ="30" ssid = "8">Huang et al.</S>
			<S sid ="31" ssid = "9">(2012) introduced global document context and multiple word prototypes.</S>
			<S sid ="32" ssid = "10">Recently, morphology is explored to learn better word representations through Recursive Neural Networks (Luong et al., 2013).Bilingual word representations have been explored with hand-designed vector space mod Here f is a function defined by a neural network.</S>
			<S sid ="33" ssid = "11">wr is a word chosen in a random subset VR of the vocabulary, and cwr is the context window containing word wr . This unsupervised objective function contrasts the score between when the correct word is placed in context with when a random word is placed in the same context.</S>
			<S sid ="34" ssid = "12">We incorporate the global context information as in Huang et al.</S>
			<S sid ="35" ssid = "13">(2012), shown to improve performance of word embed- dings.</S>
			<SUBSECTION>3.2 Bilingual initialization and training.</SUBSECTION>
			<S sid ="36" ssid = "14">In the joint semantic space of words across two languages, the Chinese word ‘政府’ is expected to be close to its English translation ‘government’.</S>
			<S sid ="37" ssid = "15">At the same time, when two words are not direct transla tions, e.g. ‘lake’ and the Chinese word ‘潭’ (deep pond), their semantic proximity could be correctly quantified.</S>
			<S sid ="38" ssid = "16">We describe in the next subsections the methods to intialize and train bilingual embeddings.</S>
			<S sid ="39" ssid = "17">These methods ensure that bilingual embeddings retain els (Peirsman and Pado´ , 2010; Sumita, 2000), their translational equivalence while their distribu and with unsupervised algorithms such as LDA and LSA (BoydGraber and Resnik, 2010; Tam et al., 2007; Zhao and Xing, 2006).</S>
			<S sid ="40" ssid = "18">Only recently have continuous space models been applied to machine translation (Le et al., 2012).</S>
			<S sid ="41" ssid = "19">Despite growing interest in these models, little work has been done along the same lines to train bilingual distributioned word represenations to improve machine translation.</S>
			<S sid ="42" ssid = "20">In this paper, we learn bilingual word embeddings which achieve competitive performance on semantic word similarity, and apply them in a practical tional semantics are improved during online training with a monolingual corpus.</S>
			<SUBSECTION>3.2.1 Initialization by MT alignments First, we use MT Alignment counts as weighting to initialize Chinese word embeddings.</SUBSECTION>
			<S sid ="43" ssid = "21">In our experiments, we use MT word alignments extracted with the Berkeley Aligner (Liang et al., 2006) 1 . Specifically, we use the following equation to compute starting word embeddings: phrase-based MT system.</S>
	</SECTION>
	<SECTION title="Algorithm and methods. " number = "3">
			<S sid ="44" ssid = "1">S Wtinit = ) s=1 Cts + 1 Ct + S Ws (2) 3.1 Unsupervised training with global context.</S>
			<S sid ="45" ssid = "2">Our method starts with embedding learning formulations in Collobert et al.</S>
			<S sid ="46" ssid = "3">(2008).</S>
			<S sid ="47" ssid = "4">Given a context window c in a document d, the optimization minimizes the following Context Objective for a word w in the vocabulary: In this equation, S is the number of possible target language words that are aligned with the source word.</S>
			<S sid ="48" ssid = "5">Cts denotes the number of times when word t in the target and word s in the source are aligned in the training parallel text; Ct denotes the total number of counts of word t that appeared in the target language.</S>
			<S sid ="49" ssid = "6">Finally, Laplace smoothing is applied to this weighting function.</S>
			<S sid ="50" ssid = "7">J (c,d) wr ∈VR max(0, 1 − f (cw , d) + f (cw , d)) (1) 1 On NIST08 Zh-.</S>
			<S sid ="51" ssid = "8">En training data and data from GALE MT evaluation in the past 5 years Single-prototype English embeddings by Huang et al.</S>
			<S sid ="52" ssid = "9">(2012) are used to initialize Chinese em- beddings.</S>
			<S sid ="53" ssid = "10">The initialization readily provides a set (Align-Init) of benchmark embeddings in experiments (Section 4), and ensures translation equivalence in the embeddings at start of training.</S>
			<S sid ="54" ssid = "11">3.2.2 Bilingual training Using the alignment counts, we form alignment matrices Aen→zh and Azh→en.</S>
			<S sid ="55" ssid = "12">For Aen→zh, each row corresponds to a Chinese word, and each column an English word.</S>
			<S sid ="56" ssid = "13">An element aij is first assigned the counts of when the ith Chinese word is aligned with the jth English word in parallel text.</S>
			<S sid ="57" ssid = "14">After assignments, each row is normalized such that it sums to one.</S>
			<S sid ="58" ssid = "15">The matrix Azh→en is defined similarly.</S>
			<S sid ="59" ssid = "16">Denote the set of Chinese word embeddings as Vzh, with each row a word embedding, and the set of English word embeddings as Ven.</S>
			<S sid ="60" ssid = "17">With the two alignment matrices, we define the Translation Equivalence Objective: 3.3 Curriculum training.</S>
			<S sid ="61" ssid = "18">We train 100k-vocabulary word embeddings using curriculum training (Turian et al., 2010) with Equation 5.</S>
			<S sid ="62" ssid = "19">For each curriculum, we sort the vocabulary by frequency and segment the vocabulary by a band-size taken from {5k, 10k, 25k, 50k}.</S>
			<S sid ="63" ssid = "20">Separate bands of the vocabulary are trained in parallel using minibatch L-BFGS on the Chinese Gigaword corpus 3 . We train 100,000 iterations for each curriculum, and the entire 100k vocabulary is trained for 500,000 iterations.</S>
			<S sid ="64" ssid = "21">The process takes approximately 19 days on a eight-core machine.</S>
			<S sid ="65" ssid = "22">We show visualization of learned embeddings overlaid with English in Figure 1.</S>
			<S sid ="66" ssid = "23">The two-dimensional vectors for this visualization is obtained with t-SNE (van der Maaten and Hinton, 2008).</S>
			<S sid ="67" ssid = "24">To make the figure comprehensible, subsets of Chinese words are provided with reference translations in boxes with green borders.</S>
			<S sid ="68" ssid = "25">Words across the two languages are positioned by the semantic relationships implied by their embed- dings.</S>
			<S sid ="69" ssid = "26">JT EOen zh = Vzh − Aen zhVen 2 JT EOzh en = Ven − Azh enVzh 2 (3) (4) We optimize for a combined objective during training.</S>
			<S sid ="70" ssid = "27">For the Chinese embeddings we optimize for: JC O-zh + λJT EOen→zh (5) For the English embeddings we optimize for: JC O-en + λJT EOzh→en (6) During bilingual training, we chose the value of λ such that convergence is achieved for both JC O and JT EO . A small validation set of word similarities from (Jin and Wu, 2012) is used to ensure the em- beddings have reasonable semantics.</S>
			<S sid ="71" ssid = "28">2 In the next sections, ‘bilingual trained’ embed- dings refer to those initialized with MT alignments and trained with the objective defined by Equation 5.</S>
			<S sid ="72" ssid = "29">‘Monolingual trained’ embeddings refer to those intialized by alignment but trained without JT EOen→zh.</S>
			<S sid ="73" ssid = "30">2 In our experiments, λ = 50..</S>
			<S sid ="74" ssid = "31">Figure 1: Overlaid bilingual embeddings: English words are plotted in yellow boxes, and Chinese words in green; reference translations to English are provided in boxes with green borders directly below the original word.</S>
	</SECTION>
	<SECTION title="Experiments. " number = "4">
			<S sid ="75" ssid = "1">4.1 Semantic Similarity.</S>
			<S sid ="76" ssid = "2">We evaluate the Mandarin Chinese embeddings with the semantic similarity test-set provided by the or 3 Fifth Edition.</S>
			<S sid ="77" ssid = "3">LDC catelog number LDC2011T13.</S>
			<S sid ="78" ssid = "4">We only exclude cna cmn, the Traditional Chinese segment of the corpus.</S>
			<S sid ="79" ssid = "5">Table 1: Results on Chinese Semantic Similarity Method Sp.</S>
			<S sid ="80" ssid = "6">Corr.</S>
			<S sid ="81" ssid = "7">K. Tau (×100) (×100) Prior work (Jin and Wu, 2012) 5.0 Tfidf Naive tfidf 41.5 28.7 Pruned tfidf 46.7 32.3 Word Embeddings Align-Init 52.9 37.6 Mono-trained 59.3 42.1 Biling-trained 60.8 43.3 Table 2: Results on Named Entity Recognition Embeddings Prec.</S>
			<S sid ="82" ssid = "8">Rec.</S>
			<S sid ="83" ssid = "9">F1 Improve Align-Init 0.34 0.52 0.41 Mono-trained 0.54 0.62 0.58 0.17 Biling-trained 0.48 0.55 0.52 0.11 Table 3: Vector Matching Alignment AER (lower is better) Embeddings Prec.</S>
			<S sid ="84" ssid = "10">Rec.</S>
			<S sid ="85" ssid = "11">AER Mono-trained 0.27 0.32 0.71 Biling-trained 0.37 0.45 0.59 ganizers of SemEval2012 Task 4.</S>
			<S sid ="86" ssid = "12">This test-set contains 297 Chinese word pairs with similarity scores estimated by humans.</S>
			<S sid ="87" ssid = "13">The results for semantic similarity are shown in Table 1.</S>
			<S sid ="88" ssid = "14">We show two evaluation metrics: Spear- man Correlation and Kendall’s Tau.</S>
			<S sid ="89" ssid = "15">For both, bilingual embeddings trained with the combined objective defined by Equation 5 perform best.</S>
			<S sid ="90" ssid = "16">For pruned tfidf, we follow Reisinger et al.</S>
			<S sid ="91" ssid = "17">(2010; Huang et al.</S>
			<S sid ="92" ssid = "18">(2012) and count word co-occurrences in a 10- word window.</S>
			<S sid ="93" ssid = "19">We use the best results from a range of pruning and feature thresholds to compare against our method.</S>
			<S sid ="94" ssid = "20">The bilingual and monolingual trained embeddings4 outperform pruned tfidf by14.1 and 12.6 Spearman Correlation (×100), respec tively.</S>
			<S sid ="95" ssid = "21">Further, they outperform embeddings initialized from alignment by 7.9 and 6.4.</S>
			<S sid ="96" ssid = "22">Both our tfidf implementation and the word embeddings have significantly higher Kendall’s Tau value compared to Prior work (Jin and Wu, 2012).</S>
			<S sid ="97" ssid = "23">We verified Tau calculations with original submissions provided by the authors.</S>
			<S sid ="98" ssid = "24">4.2 Named Entity Recognition.</S>
			<S sid ="99" ssid = "25">We perform NER experiments on OntoNotes (v4.0) (Hovy et al., 2006) to validate the quality of the Chinese word embeddings.</S>
			<S sid ="100" ssid = "26">Our experimental setup is the same as Wang et al.</S>
			<S sid ="101" ssid = "27">(2013).</S>
			<S sid ="102" ssid = "28">With em- beddings, we build a naive feed-forward neural network (Collobert et al., 2008) with 2000 hidden neurons and a sliding window of five words.</S>
			<S sid ="103" ssid = "29">This naive setting, without sequence modeling or sophisticated join optimization, is not competitive with state-of- the-art (Wang et al., 2013).</S>
			<S sid ="104" ssid = "30">Table 2 shows that the bilingual embeddings obtains 0.11 F1 improvement, lagging monolingual, but significantly better than Align-Init (as in Section3.2.1) on the NER task.</S>
			<S sid ="105" ssid = "31">4.3 Vector matching alignment.</S>
			<S sid ="106" ssid = "32">Translation equivalence of the bilingual embeddings is evaluated by naive word alignment to match word embeddings by cosine distance.5 The Alignment Error Rates (AER) reported in Table 3 suggest that bilingual training using Equation 5 produces embed- dings with better translation equivalence compared to those produced by monolingual training.</S>
			<S sid ="107" ssid = "33">4.4 Phrase-based machine translation.</S>
			<S sid ="108" ssid = "34">Our experiments are performed using the Stanford Phrasal phrase-based machine translation system (Cer et al., 2010).</S>
			<S sid ="109" ssid = "35">In addition to NIST08 training data, we perform phrase extraction, filtering and phrase table learning with additional data from GALE MT evaluations in the past 5 years.</S>
			<S sid ="110" ssid = "36">In turn, our baseline is established at 30.01 BLEU and reasonably competitive relative to NIST08 results.</S>
			<S sid ="111" ssid = "37">We use Minimum Error Rate Training (MERT) (Och, 2003) to tune the decoder.</S>
			<S sid ="112" ssid = "38">In the phrase-based MT system, we add one feature to bilingual phrase-pairs.</S>
			<S sid ="113" ssid = "39">For each phrase, the word embeddings are averaged to obtain a feature vector.</S>
			<S sid ="114" ssid = "40">If a word is not found in the vocabulary, we disregard and assume it is not in the phrase; if no word is found in a phrase, a zero vector is assigned 4 Due to variations caused by online minibatch L-BFGS, we.</S>
			<S sid ="115" ssid = "41">take embeddings from five random points out of last 105 mini- batch iterations, and average their semantic similarity results.</S>
	</SECTION>
	<SECTION title="This  is evaluated  on 10,000  randomly  selected  sentence. " number = "5">
			<S sid ="116" ssid = "1">pairs from the MT training set.</S>
			<S sid ="117" ssid = "2">Table 4: NIST08 ChineseEnglish translation BLEU Method BLEU Our baseline 30.01 Embeddings Random-Init Mono-trained 30.09 Align-Init 30.31 Mono-trained 30.40 Biling-trained 30.49 to it.</S>
			<S sid ="118" ssid = "3">We then compute the cosine distance between the feature vectors of a phrase pair to form a semantic similarity feature for the decoder.</S>
			<S sid ="119" ssid = "4">Results on NIST08 ChineseEnglish translation task are reported in Table 46 . An increase of 0.48 BLEU is obtained with semantic similarity.</S>
			<S sid ="120" ssid = "5">with bilingual embeddings.</S>
			<S sid ="121" ssid = "6">The increase is modest, just surpassing a reference standard deviation 0.29BLEU Cer et al.</S>
			<S sid ="122" ssid = "7">(2010)7 evaluated on a similar sys tem.</S>
			<S sid ="123" ssid = "8">We intend to publish further analysis on statistical significance of this result as an appendix.</S>
			<S sid ="124" ssid = "9">From these suggestive evidence in the MT results, random initialized monolingual trained embeddings add little gains to the baseline.</S>
			<S sid ="125" ssid = "10">Bilingual initialization and training seem to be offering relatively more consistent gains by introducing translational equivalence.</S>
			<S sid ="126" ssid = "11">5 Conclusion.</S>
			<S sid ="127" ssid = "12">In this paper, we introduce bilingual word embed- dings through initialization and optimization constraint using MT alignments The embeddings are learned through curriculum training on the Chinese Gigaword corpus.</S>
			<S sid ="128" ssid = "13">We show good performance on Chinese semantic similarity with bilingual trained embeddings.</S>
			<S sid ="129" ssid = "14">When used to compute semantic similarity of phrase pairs, bilingual embeddings improve NIST08 end-to-end machine translation results by just below half a BLEU point.</S>
			<S sid ="130" ssid = "15">This implies that semantic embeddings are useful features for improving MT systems.</S>
			<S sid ="131" ssid = "16">Further, our results offer suggestive evidence that bilingual word embeddings act as high-quality semantic features and embody bilingual translation equivalence across languages.</S>
	</SECTION>
	<SECTION title="We report case-insensitive BLEU. " number = "6">
			<S sid ="132" ssid = "1">We gratefully acknowledge the support of the Defense Advanced Research Projects Agency (DARPA) Broad Operational Language Translation (BOLT) program through IBM.</S>
			<S sid ="133" ssid = "2">Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the view of the DARPA, or the US government.</S>
			<S sid ="134" ssid = "3">We thank John Bauer and Thang Luong for helpful discussions.</S>
	</SECTION>
</PAPER>
