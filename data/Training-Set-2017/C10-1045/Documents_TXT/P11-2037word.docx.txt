Language-Independent Parsing with Empty Elements




Shu Cai and David Chiang
USC Information Sciences Institute
4676 Admiralty Way, Suite 1001
Marina del Rey, CA 90292
{shucai,chiang}@isi.edu


Yoav Goldberg
Ben Gurion University of the Negev 
Department of Computer Science 
POB 653 Be’er Sheva, 84105, Israel 
yoavg@cs.bgu.ac.il








Abstract

We present a simple, language-independent 
method for integrating recovery of empty ele- 
ments into syntactic parsing. This method out- 
performs the best published method we are 
aware of on English and a recently published 
method on Chinese.


1	Introduction




NP

-NONE-

*pro*


IP


ADVP AD 暂时
zànshí
for now




VP



VV

终止 zhōngzhǐ suspend



VP NP

-NONE-

*PRO*





IP VV

实施
shíshī









VP

NP

NN 	NN



Empty elements in the syntactic analysis of a sen- 
tence are markers that show where a word or phrase 
might otherwise be expected to appear, but does not.


implement  法律
fǎlǜ
law


条文
tiáowén clause


They play an important role in understanding the 
grammatical relations in the sentence. For example, 
in the tree of Figure 2a, the ﬁrst empty element (*) 
marks where John would be if believed were in the 
active voice (someone believed. . .), and the second 
empty element (*T*) marks where the man would be 
if who were not fronted (John was believed to admire 
who?).
  Empty elements exist in many languages and serve 
different purposes. In languages such as Chinese and 
Korean, where subjects and objects can be dropped 
to avoid duplication, empty elements are particularly 
important, as they indicate the position of dropped 
arguments. Figure 1 gives an example of a Chinese 
parse tree with empty elements. The ﬁrst empty el- 
ement (*pro*) marks the subject of the whole sen- 
tence, a pronoun inferable from context. The second 
empty element (*PRO*) marks the subject of the de- 
pendent VP (shíshī fǎlǜ tiáowén).
  The Penn Treebanks  (Marcus  et al., 1993;  Xue 
et al., 2005) contain detailed annotations of empty 
elements. Yet most parsing work based on these 
resources  has ignored  empty elements,  with some
212


Figure 1: Chinese parse tree with empty elements marked.
The meaning of the sentence is, “Implementation of the 
law is temporarily suspended.”



notable exceptions. Johnson (2002) studied empty- 
element recovery in English, followed by several 
others (Dienes and Dubey, 2003; Campbell, 2004; 
Gabbard et al., 2006); the best results we are aware of 
are due to Schmid (2006). Recently, empty-element 
recovery for Chinese has begun to receive attention: 
Yang and Xue (2010) treat it as classiﬁcation prob- 
lem, while Chung and Gildea (2010) pursue several 
approaches for both Korean and Chinese, and ex- 
plore applications to machine translation.
  Our intuition motivating this work is that empty 
elements are an integral part of syntactic structure, 
and should be constructed jointly with it, not added 
in afterwards. Moreover, we expect empty-element 
recovery to improve as the parsing quality improves. 
Our method makes use of a strong syntactic model, 
the PCFGs with latent annotation of Petrov et al. 
(2006),  which  we  extend  to  predict  empty  cate-




Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 212–216, 
Portland, Oregon, June 19-24, 2011. Qc 2011 Association for Computational Linguistics


gories  by the  use  of lattice  parsing.  The  method 
is language-independent  and performs very well on 
both languages we tested it on: for English, it out- 
performs the best published method we are aware of 
(Schmid, 2006), and for Chinese, it outperforms the 
method of Yang and Xue (2010).1

2   Method
Our method is fairly simple. We take a state-of-the- 
art parsing model, the Berkeley parser (Petrov et al.,
2006), train it on data with explicit empty elements, 
and test it on word lattices that can nondeterminis- 
tically insert empty elements anywhere. The idea is 
that the state-splitting of the parsing model will en- 
able it to learn where to expect empty elements to be 
inserted into the test sentences.

Tree transformations    Prior to training,  we alter 
the annotation of empty elements so that the termi- 
nal label is a consistent symbol (ϵ), the preterminal 
label is the type of the empty element, and -NONE- 
is deleted  (see Figure 2b). This simpliﬁes  the lat- 
tices because there is only one empty symbol, and 
helps the parsing model to learn dependencies be- 
tween nonterminal labels and empty-category types 
because there is no intervening -NONE-.
  Then, following Schmid (2006), if a constituent 
contains an empty element that is linked to another 
node with label X, then we append /X  to its label. 
If there is more than one empty element,  we pro- 
cess them bottom-up (see Figure 2b). This helps the 
parser learn to expect where to ﬁnd empty elements. 
In our experiments, we did this only for elements of 
type *T*. Finally, we train the Berkeley parser on the 
preprocessed training data.

Lattice parsing    Unlike the training data, the test 
data does not mark any empty elements. We allow 
the parser to produce empty elements by means of 
lattice-parsing  (Chappelier et al., 1999), a general-


processing  community  (Hall,  2005;  Chappelier  et 
al.,  1999),  and  was  recently  applied  to  the  task 
of joint clitic-segmentation  and syntactic-parsing in 
Hebrew  (Goldberg  and  Tsarfaty,  2008;  Goldberg 
and Elhadad,  2011)  and Arabic  (Green  and Man- 
ning, 2010). Here, we use lattice parsing for empty- 
element recovery.
  We use a modiﬁed version of the Berkeley parser 
which allows handling lattices as input.2 The modiﬁ- 
cation is fairly straightforward: Each lattice arc cor- 
respond to a lexical item. Lexical items are now in- 
dexed  by their start and end states rather than by
their sentence position, and the initialization proce- 
dure of the CKY chart is changed to allow lexical 
items of spans greater than 1. We then make the nec- 
essary adjustments to the parsing algorithm to sup- 
port this change: trying rules involving preterminals 
even when the span is greater than 1, and not relying 
on span size for identifying lexical items.
  At test time, we ﬁrst construct a lattice for each 
test sentence that allows 0, 1, or 2 empty symbols 
(ϵ) between each pair of words or at the start/end of 
the sentence. Then we feed these lattices through our 
lattice parser to produce trees with empty elements. 
Finally, we reverse the transformations that had been 
applied to the training data.

3   Evaluation Measures
Evaluation metrics for empty-element  recovery are 
not well established, and previous studies use a vari- 
ety of metrics. We review several of these here and 
additionally propose a uniﬁed evaluation of parsing 
and empty-element recovery.3

  If A and B are multisets, let A(x) be the number 
of occurrences  of  x in A, let |A|  =  ∑x A(x), and
let A ∩ B be the multiset  such that (A ∩ B)(x)  = 
min(A(x), B(x)). If T is the multiset of “items” in the 
trees being tested and G is the multiset of “items” in 
the gold-standard trees, then


ization of CKY parsing allowing it to parse a word- 
lattice instead of a predetermined  list of terminals.
Lattice parsing adds a layer of ﬂexibility  to exist-


precision = |G ∩ T |
|T |


recall = |G ∩ T |
|G|
2


ing parsing  technology,  and allows  parsing  in sit-


F1 =



 	1 	



   1 	



uations  where  the  yield  of  the  tree  is  not  known	 	


precision + recall


in advance. Lattice parsing originated in the speech

  1 Unfortunately, not enough information was available to 
carry out comparison with the method of Chung and Gildea 
(2010).


2 The modiﬁed parser is available at http://www.cs.bgu.
ac.il/~yoavg/software/blatt/
    3 We provide a scoring script which supports all of these eval- 
uation metrics. The code is available at http://www.isi.edu/
~chiang/software/eevalb.py .


SBARQ


SBARQ



WHNP 	SQ



WHNP



SQ/WHNP



WP 	VBZ   NP 	VP



WP 	VBZ   NP



VP/WHNP/NP



who



is     NNP



VBN 
	
S



who



is     NNP



VBN



S/WHNP/NP



John  believed 	NP 	VP



John  believed  NP



VP/WHNP



-NONE-   TO 	VP

* 	to 	VB 	NP



*     TO

ϵ	to



VP/WHNP

VB 	NP/WHNP



admire  -NONE-

*T*
(a) 	(b)



admire



*T*

ϵ



Figure 2: English parse tree with empty elements marked. (a) As annotated in the Penn Treebank. (b) With empty 
elements reconﬁgured and slash categories added.




where “items” are deﬁned differently for each met- 
ric,  as  follows.  Deﬁne  a  nonterminal   node,  for 
present purposes, to be a node which is neither a ter- 
minal nor preterminal node.
The  standard  PARSEVAL  metric  (Black  et  al.,
1991) counts labeled nonempty brackets: items are 
(X, i, j) for each nonempty nonterminal node, where 
X is its label and i, j are the start and end positions 
of its span.
  Yang  and  Xue  (2010)  simply  count  unlabeled 
empty elements: items are (i, i) for each empty ele- 
ment, where i is its position. If multiple empty ele- 
ments occur at the same position, they only count the 
last one.
  The metric originally proposed by Johnson (2002) 
counts labeled empty brackets: items are (X/t, i, i) for 
each empty nonterminal  node, where X is its label 
and t is the type of the empty element it dominates, 
but also (t, i, i) for each empty element  not domi- 
nated by an empty nonterminal node.4 The following 
structure has an empty nonterminal dominating two 
empty elements:
SBAR


(SBAR-S/*T*, i, i).5   We  tried  to  follow  Schmid 
in a generic way: we collapse any vertical chain of 
empty nonterminals into a single nonterminal.
  In order to avoid problems associated with cases 
like this, we suggest a pair of simpler metrics. The 
ﬁrst is to count labeled empty elements, i.e., items 
are (t, i, i) for each empty element, and the second, 
similar in spirit to SParseval (Roark et al., 2006), is 
to count all labeled brackets, i.e., items are (X, i, j) 
for each nonterminal node (whether nonempty or 
empty). These two metrics, together with part-of- 
speech accuracy, cover all possible nodes in the tree.

4   Experiments and Results

English   As is standard, we trained the parser on 
sections 02–21 of the Penn Treebank Wall Street 
Journal corpus, used section 00 for development, and 
section 23 for testing. We ran 6 cycles of training; 
then, because we were unable to complete the 7th 
split-merge  cycle with the default setting of merg- 
ing 50% of splits, we tried increasing merges to 75% 
and ran 7 cycles of training. Table 1 presents our 
results. We chose the parser settings that gave the


-NONE-

0


S

-NONE-

*T*


best labeled empty 
elements F1  on the dev 
set, and used these 
settings for the test set. We 
outperform the state of 
the art at recovering 
empty elements, as well 
as achieving state of the 
art accuracy at 
recovering


Johnson   counts   this   as  (SBAR, i, i), (S/*T*, i, i);
Schmid 	(2006) 	counts 	it 	as 	a 	single

  4 This happens in the Penn Treebank for types *U* and 0, but 
never in the Penn Chinese Treebank except by mistake.


phrase structure.

  5 This difference is not small; scores using Schmid’s metric 
are lower by roughly 1%. There are other minor differences in 
Schmid’s metric which we do not detail here.





Se
cti
on	System
L
a
b
e
l
e
d
E
m
p
t
y
 
B
r
a
c
k
e
t
s
P
	R	F1
L
a
b
e
l
e
d
E
m
p
t
y
 
E
l
e
m
e
n
t
s
P
	R	F1
A
l
l
 
L
a
b
e
l
e
d
B
r
a
c
k
e
t
s
P
	R	F1
0
0
	Schmid (2006)
s
p
l
i
t
 
5
×
 
m
e
r
g
e
 
5
0
%
 
s
p
l
i
t
 
6
×
 
m
e
r
g
e
 
5
0
%
 
s
p
l
i
t
 
6
×
 
m
e
r
g
e
 
7
5
%
 
s
p
l
i
t
 
7
×
 
m
e
r
g
e
 
7
5
%
88.
3	82.9	85.5
91.
0	79.8	85.0
91.
9	81.1	86.1
92.
7	80.7	86.3
91.
0	80.4	85.4
89.
4	83.8	86.5
93.
1	81.8	87.1
93.
6	82.4	87.6
94.
6	82.0	87.9
93.
2	82.1	87.3
87.
1	85.6	86.3
90.
4	88.7	89.5
90.
4	89.1	89.7
90.
3	88.5	89.3
90.
5	88.9	89.7
2
3
	Schmid (2006)
s
p
l
i
t
 
6
×
 
m
e
r
g
e
 
7
5
%
86.
1	81.7	83.8
90.
1	79.5	84.5
87.
9	83.0	85.4
92.
3	80.9	86.2
86.
8	85.9	86.4
90.
1	88.5	89.3

Table 1: Results on Penn (English) Treebank, Wall Street Journal, sentences with 100 words or fewer.



Ta
sk	System
U
n
l
a
b
e
l
e
d
E
m
p
t
y
 
E
l
e
m
e
n
t
s
P
	R	F1
L
a
b
e
l
e
d
E
m
p
t
y
 
E
l
e
m
e
n
t
s
P
	R	F1
A
l
l
 
L
a
b
e
l
e
d
B
r
a
c
k
e
t
s
P
	R	F1
De
v	split 5× merge 50%
s
p
l
i
t
 
6
×
 
m
e
r
g
e
 
5
0
%
s
p
l
i
t
 
7
×
 
m
e
r
g
e
 
5
0
%
82.
5	58.0	68.1
76.
4	60.5	67.5
74.
9	58.7	65.8
72.
6	51.8	60.5
68.
2	55.1	60.9
65.
9	52.5	58.5
84.
6	80.7	82.6
83.
2	81.3	82.2
82.
7	81.1	81.9
Te
st	Yang and Xue (2010)
s
p
l
i
t
 
6
×
 
m
e
r
g
e
 
5
0
%
80.
3	57.9	63.2
74.
0	61.3	67.0

66.
0	54.5	58.6

82.
7	80.8	81.7

Table 2: Results on Penn (Chinese) Treebank.




Chinese    We  also  experimented  on  a  subset  of 
the  Penn  Chinese  Treebank  6.0.  For  comparabil- 
ity  with  previous  work  (Yang  and  Xue,  2010), 
we trained the parser on sections 0081–0900, used 
sections 0041–0080  for development,  and sections
0001–0040 and 0901–0931 for testing. The results 
are shown in Table 2. We selected the 6th split-merge 
cycle based on the labeled empty elements F1 mea- 
sure. The unlabeled empty elements column shows 
that our system outperforms the baseline system of 
Yang and Xue (2010). We also analyzed the empty- 
element recall by type (Table 3). Our system outper- 
formed that of Yang and Xue (2010) especially on
*pro*, used for dropped arguments, and *T*,  used 
for relative clauses and topicalization.

5   Discussion and Future Work

The empty-element recovery method we have 
presented is simple, highly effective, and fully 
integrated  with  state  of the  art  parsing.  We  hope 
to exploit cross-lingual information about empty 
elements    in   machine    translation.    Chung    and 
Gildea (2010) have shown that such information 
indeed helps translation, and we plan to extend this 
work  by  handling  more  empty  categories  (rather




T
yp
e
To
tal
Go
ld
C
o
r
r
e
c
t
Y
X	Ours
R
e
c
a
l
l
Y
X	Ours
*
pr
o
*
*P
R
O*
*
T
*
*R
N
R*
*
O
P
*
*
2
9
0
2
9
9
5
7
8
3
2
1
3
4
1
9
12
5	159
19
6	199
33
8	388
20	15
20	65
5	3
43.
1	54.8
65.
6	66.6
58.
5	67.1
62.
5	46.9
14.
9	48.5
26.
3	15.8

Table 3: Recall on different types of empty categories. 
YX = (Yang and Xue, 2010), Ours = split 6×.


than just *pro* and *PRO*), and to incorporate them 
into a syntax-based translation model instead of a 
phrase-based model.
  We also plan to extend our work here to recover 
coindexation information (links between a moved el- 
ement and the trace which marks the position it was 
moved from). As a step towards shallow semantic 
analysis, this may further beneﬁt other natural lan- 
guage processing tasks such as machine translation 
and summary generation.

Acknowledgements

We would like to thank Slav Petrov for his help in 
running the Berkeley parser, and Yaqin Yang, Bert


Xue, Tagyoung Chung, and Dan Gildea for their an- 
swering  our  many  questions.  We  would  also  like 
to thank our colleagues in the Natural Language 
Group at ISI for meaningful discussions and the 
anonymous reviewers for their thoughtful sugges- 
tions. This work was supported in part by DARPA 
under contracts HR0011-06-C-0022  (subcontract to 
BBN  Technologies)  and DOI-NBC  N10AP20031, 
and by NSF under contract IIS-0908532.


References

E. Black, S. Abney, D. Flickinger, C. Gdaniec, R. Gr- 
ishman, P. Harrison, D. Hindle, R. Ingria, F. Jelinek, 
J.  Klavans,  M.  Liberman,  M.  Marcus,  S.  Roukos, 
B. Santorini, and T. Strzalkowski. 1991. A procedure 
for quantitatively comparing the syntactic coverage of 
English grammars. In Proc. DARPA Speech and Natu- 
ral Language Workshop.
Richard Campbell.  2004.  Using linguistic principles to 
recover empty categories. In Proc. ACL.
J.-C. Chappelier, M. Rajman, R. Arag¨ues, and A. Rozen- 
knop.  1999.  Lattice parsing for speech recognition. 
In Proc. Traitement Automatique du Langage Naturel 
(TALN).
Tagyoung Chung and Daniel Gildea.    2010.    Effects 
of empty categories on machine translation.  In Proc. 
EMNLP.
P´eter Dienes and Amit Dubey. 2003. Antecedent recov- 
ery: Experiments with a trace tagger. In Proc. EMNLP. 
Ryan Gabbard, Seth Kulick, and Mitchell Marcus. 2006. 
Fully parsing the Penn Treebank.   In Proc. NAACL
HLT.
Yoav Goldberg and Michael Elhadad.  2011.  Joint He- 
brew segmentation and parsing using a PCFG-LA lat- 
tice parser. In Proc. of ACL.
Yoav Goldberg and Reut Tsarfaty. 2008. A single gener- 
ative model for joint morphological segmentation and 
syntactic parsing. In Proc. of ACL.
Spence Green and Christopher D. Manning. 2010. Better 
Arabic parsing: Baselines, evaluations, and analysis. In 
Proc of COLING-2010.
Keith B. Hall.   2005.   Best-ﬁrst word-lattice parsing: 
techniques for integrated syntactic language modeling. 
Ph.D. thesis, Brown University, Providence, RI, USA. 
Mark Johnson.   2002.   A simple pattern-matching al- 
gorithm  for  recovering empty  nodes  and  their  an-
tecedents. In Proc. ACL.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann 
Marcinkiewicz. 1993. Building a large annotated cor- 
pus of English: the Penn Treebank.   Computational 
Linguistics, 19:313–330.


Slav Petrov, Leon Barrett, Romain Thibaux, and Dan 
Klein.  2006.  Learning accurate, compact, and inter- 
pretable tree annotation. In Proc. COLING-ACL.
Brian Roark, Mary Harper, Eugene Charniak, Bonnie 
Dorr, Mark Johnson, Jeremy G. Kahn, Yang Liu, Mari 
Ostendorf, John Hale, Anna Krasnyanskaya, Matthew 
Lease, Izhak Shafran, Matthew Snover, Robin Stewart, 
and Lisa Yung.  2006.  SParseval: Evaluation metrics 
for parsing speech. In Proc. LREC.
Helmut Schmid.  2006.  Trace prediction and recovery 
with unlexicalized PCFGs and slash features. In Proc. 
COLING-ACL.
Nianwen Xue, Fei Xia, Fu-dong Chiou, and Martha 
Palmer.  2005.  The Penn Chinese TreeBank: Phrase 
structure annotation of a large corpus.  Natural Lan- 
guage Engineering, 11(2):207–238.
Yaqin Yang and Nianwen Xue. 2010. Chasing the ghost: 
recovering empty categories in the Chinese Treebank. 
In Proc. COLING.

