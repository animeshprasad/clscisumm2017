Determining Compositionality of Word Expressions Using
Various Word Space Models and Measures



Lubom´ır Krcˇma´ rˇ1,2
1University of West Bohemia, 
Faculty of Applied  Sciences, 
NTIS – New Technologies
for the Information Society, 
Pilsen, Czech Republic

lkrcmar@kiv.zcu.cz


Karel Jezˇek2
2University of West Bohemia, 
Faculty of Applied  Sciences, 
Department of Computer 
Science and Engineering, 
Pilsen, Czech Republic

jezek ka@kiv.zcu.cz


Pavel Pecina3
3Charles University in Prague, 
Faculty of Mathematics and 
Physics, Institute of Formal 
and Applied Linguistics, 
Prague, Czech Republic

pecina@ufal.mff.cuni.cz







Abstract

This paper presents a comparative study 
of 5 different types of Word Space Mod- 
els (WSMs) combined  with 4 different 
compositionality measures applied to the 
task of automatically determining seman- 
tic compositionality of word expressions. 
Many combinations of WSMs and mea- 
sures have never been applied  to the task 
before.
The study follows Biemann and Gies- 
brecht (2011) who attempted to find a list 
of expressions for which the composition- 
ality assumption – the meaning of an ex- 
pression is determined by the meaning of 
its constituents and their combination – 
does not hold. Our results are very promis- 
ing and can be appreciated by those inter- 
ested in WSMs, compositionality,  and/or 
relevant evaluation methods.

1   Introduction

Our understanding of WSM is in agreement with 
Sahlgren (2006): “The word space  model is a 
computational model of word meaning that uti- 
lizes the distributional  patterns of words collected 
over large text data to represent semantic similar- 
ity between words in terms of spatial proximity”. 
There are many types of WSMs built by different 
algorithms.  WSMs  are based on the Harris distri- 
butional hypothesis (Harris, 1954), which assumes 
that words are similar to the extent to which they 
share similar linguistic contexts. WSM can be 
viewed  as a set of words associated with vectors 
representing contexts in which the words occur. 
Then, similar vectors imply (semantic) similarity 
of the words and vice versa. Consequently, WSMs


provide  a means to find words semantically simi- 
lar to a given  word. This capability of WSMs is 
exploited by many Natural Language Processing 
(NLP) applications  as listed e.g. by Turney 
and Pantel (2010).
  This study follows Biemann  and Giesbrecht 
(2011), who attempted  to find a  list  of  non- 
compositional  expressions whose meaning is not 
fully  determined  by the meaning of  its 
con- stituents and their combination.  The task 
turned out to be frustratingly hard (Johannsen  
et al.,
2011). Biemann’s idea and motivation is that non- 
compositional  expressions could be treated as sin- 
gle units in many NLP applications   such as In- 
formation Retrieval (Acosta et al., 2011) or Ma- 
chine Translation (Carpuat and Diab, 2010). We 
extend this motivation by stating that WSMs could 
also benefit from a set of non-compositional ex- 
pressions. Specifically, WSMs could treat se- 
mantically  non-compositional  expressions as sin- 
gle units.   As an example,  consider  “kick  the 
bucket”, “hot dog”, or “zebra crossing”. Treat- 
ing such expressions  as single units might  improve 
the quality of WSMs since the neighboring 
words of these expressions should not be related 
to their constituents (“kick”, “bucket”, “dog” or 
“zebra”), but instead to the whole expressions.
  Recent  works, including that of Lin (1999), 
Baldwin et al. (2003), Biemann and Giesbrecht 
(2011), Johannsen  et al. (2011), Reddy et al. 
(2011a), Krcˇma´ˇr et al. (2012), and Krcˇma´ˇr et al. 
(2013), show the applicability  of WSMs in deter- 
mining the compositionality of word expressions. 
The proposed methods exploit  various  types of 
WSMs combined with various  measures for 
de- termining the compositionality  applied to 
various datasets.  First, this leads to non-directly 
compa- rable results and second, many 
combinations  of




64

Proceedings of the Workshop on Continuous  Vector Space Models and their Compositionality, pages 64–73, 
Sofia, Bulgaria, August 9 2013. Qc 2013 Association for Computational Linguistics



WSMs  and measures have never before been ap- 
plied to the task. The main contribution  and nov- 
elty of our study lies in systematic  research of 
several basic and also advanced WSMs combined 
with all the so far, to the best of our knowledge, 
proposed WSM-based  measures for determining 
the semantic compositionality.
  The explored WSMs, described in more detail 
in Section 2, include the Vector Space  Model,


noted as  log)  or √cij   (denoted  as sqrt).   The
purpose of local weighting is to lower the im- 
portance of highly occurring words in the docu- 
ment. The global function weights every value 
in row i of C by the same value calculated  for 
row i.    Typically:  none (denoted   as N o), In- 
verse Document  Frequency  (denoted  as I df ) or 
a  function referred  to as  Entropy (Ent).    I df 
is calculated  as 1 + log(ndocs/df (i))  and Ent
 


Latent Semantic Analysis, Hyperspace Analogue


as 1 + {


j p(i, j) log p(i, j)}/ log ndocs, where


to Language, Correlated Occurrence Analogue to
Lexical Semantics,  and Random  Indexing. The 
measures, including substitutability, endocentric- 
ity, compositionality,  and neighbors-in-common- 
based, are described  in detail in Section 3. Sec- 
tion 4 describes our experiments performed  on 
the manually  annotated datasets – Distributional 
Semantics and Compositionality  dataset (DISCO) 
and the dataset built by Reddy et al. (2011a). Sec- 
tion 5 summarizes the results and Section 6 con- 
cludes the paper.

2   Word Space Models

The simplest and oldest types of WSMs1 are the 
Vector Space Model  (VSM) and Hyperspace Ana- 
logue to Language (HAL). More recent and ad- 
vanced models  include Latent Semantic Analy- 
sis (LSA), which is based on VSM, and Corre- 
lated Occurrence Analogue to Lexical Semantics 
(COALS), which originates from HAL. Random 
Indexing (RI) is WSM joining the principles of 
LSA and HAL. Many other WSMs have been pro- 
posed too. Their description is outside the scope 
of this paper and can be found e.g. in Turney and 
Pantel (2010) or Jurgens and Stevens (2010).

VSM   is based on the assumption that similar (re- 
lated) words tend to occur in the same documents.2
VSM stores occurrence counts of all word types 
in documents  a given corpus in a co-occurrence 
matrix C.  The row vectors of the matrix corre- 
spond to the word types and the columns to the 
documents in the corpus.  The numbers of occur- 
rences cij  in C are usually weighted by the prod- 
uct of the local and global weighting functions 
(Nakov et al., 2001). The local function weights 
cij  by the same mathematical function;  typically 
none (further denoted  as no), log(cij  + 1) (de-

1 WSMs are also referred  to as distributional  models of


ndocs is the number of documents in the corpora,
df (i) is the number of documents containing word 
type i, and p(i, j) is the probability of occurrence 
of word type i in document j.

LSA   builds on VSM and was  introduced  by 
Landauer and Dumais (1997).  The LSA algo- 
rithm works with the same co-occurrence matrix 
C which can be weighted in the same manner as 
in VSM. The matrix is than transformed by Sin- 
gular Value Decomposition (SVD) (Deerwester et 
al., 1990) into C.   The purpose of SVD is to 
project the row vectors and column  vectors of C 
into a lower-dimensional  space and thus bring the 
vectors of word types and vectors of documents, 
respectively, with similar meanings near to each 
other.3 The output number of dimensions is a pa- 
rameter of SVD and typically ranges from 200 to
1000 (Landauer and Dumais, 1997; Rohde et al.,
2005).

HAL   was first explored by Lund and Burgess 
(1996). It differs from VSM and LSA in that it 
only exploits  neighboring  words  as contexts for 
word types. HAL processes the corpus by moving 
a sliding double-sided window with a size rang- 
ing from 1 to 5 around the word type in focus 
and accumulating the weighted co-occurrences of 
the preceding and following words into a matrix. 
Typically, the linear weighting function is used 
to ensure  that the occurrences  of words which 
are  closer to the word type in focus are  more 
significant. The dimensions of the resulting co-
occurrence matrix are of size |V | and  2|V |, where
V  denotes  the vocabulary  consisting of all the
word types occurring in the processed corpora. Fi- 
nally, the HAL co-occurrence matrix can be re- 
duced by retaining the most informative  columns 
only. The columns with the highest values of en-
tropy (−    j pj log pj , where pj  denotes the prob-


semantics, vector space models, or semantic spaces.	 	


     2 VSM was originally developed for the SMART informa- 
tion retrieval system (Salton, 1971).
  

3 In this way, LSA is able to capture higher-order  co- 
occurrences.


ability of a word in the investigated column j) can 
be considered as the most informative.   The alter- 
natives and their description  can be found e.g. in


The mathematical formulas are presented below.

cos(a, b) =  	i=1 aibi 	


Song et al. (2004).


i=1(ai)2
1


i=1(bi)2



COALS	was introduced by Rohde et al. (2005).


euc(a, b) =
1 +


i=1 (ai − bi)2


Compared to HAL, COALS also processes a cor- 
pus by using a sliding window and linear weight-



cor(a, b) =    	n


n
i=1


(ai − a¯)(bi − ¯b)
2	n 	¯ 2


ing, but differs in several aspects: the window  size


i=1(ai − a¯)
n


i=1(bi − b)
n


of COALS is 4 and this value is fixed; COALS



where


a¯ =    i=1 ai ,   ¯b =     i=1 bi


does not distinguish  between the preceding and	n 	n
following words and treats them equally; applying
COALS supposes that all but the most frequent m


columns reflecting the most common open-class 
words are discarded; COALS transforms weighted 
counts in the co-occurrence matrix in a special 
way (all the word pair correlations are calculated, 
negative values are set to 0, and non-negative ones 
are square rooted – corr); and optionally,  Singu- 
lar Value Decomposition (Deerwester et al., 1990) 
can be applied to the COALS co-occurrence ma- 
trix.


RI   is described in Sahlgren (2005)  and can be 
viewed  as a mixture  of HAL and LSA. First, RI 
assigns random vectors to each word type in the 
corpus. The random vectors, referred to as index 
vectors,  are very sparse, typically with a length 
of thousands,  and contain only several  (e.g. 7)


SU   The substitutability-based  Measure is based
on  the  fact  that  the  replacement of   non- 
compositional expressions’ constituents by the 
words similar to them leads to anti-collocations 
(Pearce, 2002). The compositionality of expres- 
sions is calculated  as the ratio between the num- 
ber of occurrences of the expression in a corpora 
and the sum of occurrences of its alternatives – 
possibly anti-collocations.   In a similar way, we 
can compare pointwise mutual information  scores 
(Lin, 1999). As an example, consider the possible 
occurrences of “hot dog” and “warm dog” in the 
corpora.
  Formally, adopted from Krcˇma´ˇr et al. (2012), 
we calculate the compositionality  score csu for an 
examined expression as follows:


non-zero values from the {-1,1} set.  Second, RI


H    W (ah, m) ∗	M


W (h, am)



processes the corpus by exploiting  a sliding win- 
dow like HAL and COALS. However, RI does not


csu =


i=1


i		j=1	j	, W (h, m)


accumulate the weighted co-occurrence counts of 
neighboring words to the vector of the word type 
in focus. Instead, RI accumulates the index vec- 
tors of the co-occurring words. For accounting the 
word order, the permutation variant of RI was also 
developed (Sahlgren et al., 2008). This variant 
permutes the index vectors of neighboring words 
of the word type in focus according to the word 
order.


3   Compositionality Measures

We  experimented  with four basically different 
compositionality measures (further  referred to as 
Measures) (Krcˇma´ˇr  et al., 2013). Each Measure 
employs a function to measure similarity of WSM 
vectors.  We  experimented  with the following 
ones: cosine (cos), Euclidian  (inverse to Euclid- 
ian distance) (euc), and Pearson correlation  (cor).


where (h, m) denotes the number of corpora oc-
currences of the examined expression consisting
of a head and a modifying word, ah and am denote
i	j
i-th and j-th most similar word4 in a certain WSM
to the head and modifying word of the expression, 
respectively.  W stands for a weighting  function; 
following Krcˇma´ˇr et al. (2012), we experimented 
with no (no) and logarithm  (log) weighting. The
∗ symbol  stands for one of the two operators: ad-
dition (plus) and multiplication (mult).

EN   The endocentricity-based Measure, also re- 
ferred to as component  or constituent-based,  com- 
pares the WSM vectors of the examined expres- 
sions and their constituents. The vectors expected 
to be different from each other are e.g. the vector 
representing the expression “hot dog” and the vec- 
tor representing the word “dog”.  Formally, the

  4 When exploiting POS tags, we constrained the similar 
words to be of the same POS category in our experiments.


compositionality  score cen  can be calculated   as 
follows:
cen = f (xh, xm)  ,

where xh  and xm  denote the similarity (sim) or 
inverse rank distance (–dist) between the exam- 
ined expression and its head and modifying  con- 
stituent, respectively,  with regards  to a certain 
WSM. Function f stands for a combination  of its 
parameters:  0.5xh + 0.5xm  (avg), 0xh  + 1xm 
(mOnly), 1xh + 0xm (hOnly), min(xh, xm) (min), 
and max(xh, xm) (max).

CO   The compositionality-based  Measure com- 
pares the true co-occurrence vector of the exam- 
ined expression and the vector obtained from the 
vectors corresponding to the constituents of the 
expression using some compositionality  function 
(Reddy et al., 2011a). Commonly  used compo-
sitionality functions  are vector addition  (⊕) and
pointwise vector multiplication (⊗) (Mitchell and
Lapata, 2008). The vectors expected to be dif-
ferent from each  other are  e.g. “hot dog” and
“hot”⊕“dog”. Formally,
cco = s(ve, vh ∗ vm)  ,

where ve, vh, and vm  stand for vectors of an ex- 
amined expression, its head and modifying con-
stituents, respectively.  ∗ stands for a vector opera-
tion.

NE   The neighbors-in-common-based  Measure 
is based on overlap of the most similar words to 
the examined  expression and to its constituents 
(McCarthy et al., 2003). As an example, consider 
that “hot dog” is similar to “food” or “chips” and 
“dog” is similar to “cat” or “bark”. On the other 
hand, the list of neighbors of a semantically  com- 
positional  expression such as “black dog” is sup- 
posed to overlap with at least one of the lists of 
neighbors of both the expression constituents. For-


Datasets We  experimented  with  the DISCO 
(Biemann and Giesbrecht, 2011) and Reddy 
(Reddy et al., 2011a) human annotated datasets, 
built for the task of automatic determining of se- 
mantic compositionality.   The DISCO and Reddy 
datasets consist  of manually  scored expressions 
of adjective-noun (AN), verb-object (VO), and 
subject-verb (SV) types and the noun-noun (NN) 
type, respectively.   The DISCO dataset consists 
of 349 expressions divided into training, valida- 
tion, and test data (TestD);  the Reddy dataset con- 
sists of one set containing  90 expressions. Since 
the DISCO validation  data are of low size (35), 
we concatenated them with the training  data (Tr- 
ValD). To TrValD and TestD we added the Reddy 
dataset, which we had divided stratifically  ahead 
of time. Numbers of expressions of all the differ- 
ent types are summarized in Table 1.

da
ta
se
t
A
N-
V
O-
S
V
A
N
V
O
S
V
N
N
Tr
Va
lD
17
5
68
68
39
45
Te
st
D
17
4
77
62
35
45

Table 1: Numbers of expressions of all the differ- 
ent types from the DISCO and Reddy datasets.


WSM   construction Since the  DISCO  and 
Reddy data were extracted from the ukWaC cor- 
pus (Baroni et al., 2009), we also build our WSMs 
from the same corpus. We use our own modifica- 
tion of the S-Space package (Jurgens and Stevens,
2010). The modification lies in treating multiword 
expressions and handling stopwords. Specifically, 
we extended the package with the capability of 
building WSM vectors for the examined expres- 
sions in such a way that the WSM vectors previ- 
ously built for words are preserved. This differen- 
tiates our approach e.g. from Baldwin  et al. (2003), 
who label the expressions in the corpus ahead of
5


mally,


time 
and 
treat 
them as 
single 
words.


As for 
treat-


cne = oh


+ om  ,


ing stopwords, we map 
trigrams containing deter-
miners  as the middle 
word into bigrams 
without


where oh


and om 
stand for 
the number 
of same


the 
determiner
s.  The 
intuition is 
to extract 
better


words occurring in the list of the most similar 
words to the examined expression and to its head 
and modifying  constituent, respectively.

4   Experiments

We evaluated the ability of various combinations 
of WSMs  and Measures to rank expressions as the 
human annotators had done ahead of time.


co-occurrence statistics for VO expressions often 
containing an intervening  determiner.  As an ex- 
ample, compare the occurrences of “reinvent (de-

  5 Since many single word occurrences  disappear,  the 
WSM vectors for words change.  The more expressions are 
treated  as single words, the more WSM changes. Conse- 
quently, we believe that this approach cannot be used for 
building a list of all expressions occurring  in an examined 
corpus ordered by their compositionality score.


terminer) wheel” and “reinvent wheel” in ukWaC
being 623 and 27, respectively.
  We experimented with lemmas (noT ) or with 
lemmas  concatenated with their part of speech 
(POS) tags (yesT ).  We  labeled the following 
strings in ukWaC as  stopwords: low-frequency 
words (lemmas with frequency < 50), strings con- 
taining two adjacent non-letter  characters (thus 
omitting sequences  of  various symbols), and 
closed-class words.
  For our experiments, we built WSMs using var- 
ious parameters examined in previous works (see 
Section 2) and parameters which are implied  from 
our own experience with WSMs. Figure 1 sum- 
marizes all the parameters we used for building 
WSMs.

Measure settings  We examined various Mea- 
sure settings (see Section  3), summarized in Ta- 
ble 2. For all the vector comparisons, we used the 
cos similarity. Only for HAL we also examined 
euc and for COALS cor, since these are the rec- 
ommended similarity functions for these particu- 
lar WSMs (Lund and Burgess, 1996; Rohde et al.,
2005).

M
et.
pa
r.
po
ssi
bl
e 
va
lu
es
all
si
m.
co
s, 
eu
c 
if 
H
A
L, 
co
r if 
C
O
A
L
S
S
U
H
0,
1,.
..,
20
,3
0,.
..,
10
0
S
U
M
0,
1,.
..,
20
,3
0,.
..,
10
0
S
U
W
no
, 
lo
g
S
U
E
N
∗
x
pl
us
, 
m
ult
si
m, 
–
di
st
E
N
f
av
g, 
m
O
nly
, 
h
O
nly
, 
mi
n, 
m
ax
C
O
N
E
∗
N
⊕, 
⊗
10
,2
0,.
..,
50
,1
00
,2
00
,...
,5
00
,1
00
0

Table 2: All the parameters of Measures for de- 
termining semantic compositionality  described in 
Section 3 used in our experiments.


Experimental  setup  Following Biemann and 
Giesbrecht (2011), Reddy et al. (2011a), Krcˇma´ˇr 
et al. (2012),  and Krcˇma´ˇr  et al. (2013), we use 
the Spearman correlation  (ρ) for the evaluation of 
all the combinations of WSMs and Measures (Se- 
tups). Since the distribution  of scores assigned to 
Reddy’s NN dataset might not have corresponded 
to the distribution of DISCO  scores, we decided 
not to map them to the same scale. Thus, we do not 
create a single  list consisting of all the examined 
expressions. Instead, we order our Setups accord-


ing to the weighted  average of Spearman 
corre- lations calculated across all the 
expression types. The weights  are directly 
proportional to the fre- quencies of the 
particular expression types. Thus, the Setup 
score (wAvg) is calculated  as follows:

wAvg = |AN |ρAN  + |V O|ρV O  + |SV |ρSV  + |N N |ρN N 
.
|AN | + |V O| + |SV | + |N N |


  Having  the evaluation testbed, we tried to 
find the optimal parameter settings for all WSMs 
com- bined with all Measures with the help of 
TrValD. Then, we applied the found Setups to 
TestD.

Notes  Because several expressions or their 
con- stituents concatenated with their POS tags 
did not
occur sufficiently often (for expressions:   ≥ 
0,
for constituents:  ≥ 50) in ukWaC, we 
removed
them from the experiments; we removed 
“number
crunching”, “pecking order”, and “sacred 
cow” from TrValD and “leading  edge”, “broken  
link”, “spinning jenny”, and “sitting duck” from 
TestD.

5   
Results

The Setups achieving the highest wAvg when 
ap- plied to TrValD are depicted in Table 3. The 
same Setups and their results when applied to 
TestD are depicted in Table 4. The values of 
Spearman cor- relations in TestD confirm many 
of the observa- tions from TrValD6:
  Almost all the combinations  of WSMs 
and Measures achieve correlation  values which 
are sta- tistically significant. This is best 
illustrated by the
ρ(AN − V O − SV ) column in Table 4, where  
a
lot of correlation values are statistically  (p < 
0.05)
or highly statistically (p < 0.001) significant, 
with regards to the number of expressions (172).
  The results  suggest that for every 
expression type, the task of determining 
compositionality is of varying difficulty. While 
determining the com- positionality of the NN 
expression type seems to be the simplest (the 
highest correlations observed), determining the 
compositionality of the SV ex- pression type 
seems to be hard since the majority of values in 
the ρSV column  are not statistically significant; 
taking into account the number of SV 
expressions in TestD – 35, the statistically 
signifi- cant value of ρ at the p < 0.05 level is 
0.34.
  The correlation values differ with regards to 
the expression type. Certain WSMs combined 
with

6 A test of statistical difference between two values of the
Spearman correlation is adopted from Papoulis 
(1990).


 

Figure 1: All the parameters of WSMs described in Section 2 used in all our experiments. Semicolon 
denotes OR. All the examined combinations of parameters are implied  from reading the diagram from 
left to right.




certain Measures, although achieving high corre- 
lations upon certain expression types, fail to cor- 
relate with the rest of the expression types. Com- 
pare e.g. the correlation  values of VSM and LSA 
combined with the SU Measure upon the AN and 
SV types with the correlation values upon the VO 
and NN types.
  The results, as expected, illustrate  that employ- 
ing more advanced alternatives of basic WSMs is 
more appropriate. Specifically, LSA outperforms 
VSM and COALS outperforms HAL in 21 and 23 
correlation  values out of 24, respectively. Con- 
cerning RI, the values of correlations  seem to be 
close to the values of VSM and HAL.
  An interesting observation showing the appro- 
priateness of using wAvg(of ρ) as a good  evalu- 
ation score is supported by a comparison  of the
wAvg(of ρ) and ρ(AN −V O−SV ) columns. The
columns suggest that some Setups might only be
able to order the expressions of the same type and 
might not be able to order the expressions of dif- 
ferent types among each other. As an example, 
compare the value of ρ = 0.42 in wAvg(of ρ)
with ρ = 0.28 in ρ(AN−V O−SV ) in the row cor-
responding to COALS combined with SU. Con-

sider also that all the values of correlations  are 
higher or equal to the value in ρ(AN −V O−SV ).
  

As for the parameters learned  from applying 
all the combinations of differently set WSM algo- 
rithms and Measures to TrValD, their diversity is 
well illustrated in Tables 5 and 6. Due to this diver- 
sity, we cannot recommend any particular settings 
except for one. All our SU Measures benefit from 
weighting numbers of expression occurrences by 
logarithm.
  The correlation  values in TestD are  slightly 
lower – probably due to overfitting – than the 
ones observed in TrValD. HAL combined with the 
Measures using euc similarity  was not as success- 
ful as when combined with cos.7
  For comparison,  the results  of Reddy et al. 
(2011b) and Chakraborty  et al. (2011) as  the 
results of the best performing   Setups based on 
WSMs and association measures, respectively,  ap- 
plied to the DISCO  data, are presented (Biemann 
and Giesbrecht, 2011). The correlation values of 
our Setups based on LSA and COALS, respec- 
tively, are mostly higher. However, the improve- 
ments are not statistically  significant.  Also, the re- 
cent results achieved by Krcˇma´ˇr et al. (2012) em- 
ploying COALS and Krcˇma´ˇr et al. (2013) employ-

  7 However, using HAL combined with euc, we observed 
significant  negative correlations  which deserve further explo- 
ration.


ing LSA are depicted.

Discussion    As described  above,  we observed 
different values of correlations for different ex- 
pression types. This motivates  us to think about 
other classes of expressions different  from types; 
Measures could be e.g. varyingly  successful with 
regards to different  occurrence frequency classes 
of expressions (Evert, 2005). However, with such 
small datasets, as shown  e.g. by the fact that the 
majority of our results are statistically   indistin- 
guishable,  we cannot  carry out any deeper  in- 
vestigations. A large dataset  would provide a 
more reliable comparison. Ideally, this would 
consist of all the candidate expressions occurring 
in some smaller  corpus.  Also, we would pre- 
fer the annotated dataset not to be biased towards 
non-compositional  expressions and to be provided 
with an inner-annotator agreement (Pecina, 2008); 
which is unfortunately not the case of the DISCO 
dataset.

6   Conclusion

Our study suggests that different WSMs combined 
with different  Measures perform reasonably well 
in the task of determining the semantic composi- 
tionality of word expressions of different types. 
Especially, LSA and COALS perform well in 
our experiments since their results are better than 
those of their basic variants (VSM and HAL, re- 
spectively) and, although not statistically signifi- 
cantly, they outperform the best results of the pre- 
viously  proposed approaches (Table 4).
  Importantly, our results demonstrate (Section 5) 
that the datasets used for the experiments are small 
for: first, a statistical learning of optimal parame- 
ters of both WSM algorithms and Measures; sec- 
ond, a thorough (different  types) and reliable (sta- 
tistically significant)  comparison of our and the 
previously proposed approaches.
  Therefore, we plan to build a larger manually- 
annotated  dataset. Finally, we plan to extract 
a list of semantically non-compositional expres- 
sions from a given corpus and experiment with us- 
ing it in NLP applications.

Acknowledgments

We  thank to V´ıt  Suchomel  for  providing the 
ukWaC corpus and the anonymous  reviewers 
for  their  helpful  comments and suggestions. 
This  work  was   supported by  the  European


Regional Development  Fund (ERDF), project 
NTIS  –  New Technologies  for  the Informa- 
tion Society, European  Centre of  Excellence, 
CZ.1.05/1.1.00/02.0090;  by Advanced Comput- 
ing  and Information Systems  (grant no. SGS-
2013-029); and by the Czech Science  Foun- 
dation (grant no. P103/12/G084).   Also,  the 
access  to  the CERIT-SC computing facilities 
provided under the programme  Center CERIT 
Scientific Cloud, part of the Operational  Pro- 
gram Research and Development  for Innovations, 
reg. no. CZ.1.05/3.2.00/08.0144 is highly appreci- 
ated.


References

Otavio Costa Acosta, Aline Villavicencio, and Vi- 
viane P. Moreira.  2011. Identification  and treatment 
of multiword expressions applied to information re- 
trieval. In Proceedings of the Workshop on Multi- 
word Expressions: from Parsing and Generation to 
the Real World, MWE ’11, pages 101–109, Strouds- 
burg, PA, USA.

Timothy  Baldwin, Colin Bannard, Takaaki Tanaka, and 
Dominic Widdows. 2003. An empirical model of 
multiword expression  decomposability. Proceed- 
ings of the ACL 2003 workshop on Multiword ex- 
pressions analysis acquisition  and treatment, pages
89–96.

Marco Baroni, Silvia Bernardini,  Adriano Ferraresi, 
and Eros Zanchetta.  2009. The WaCky wide web: 
a  collection of very large linguistically processed 
web-crawled  corpora.  Journal of Language  Re- 
sources And Evaluation, 43(3):209–226.

Chris Biemann and Eugenie Giesbrecht.   2011. Dis- 
tributional semantics  and compositionality  2011: 
shared task description  and results.  In Proceedings 
of the Workshop on Distributional Semantics and 
Compositionality, DiSCo ’11, pages 21–28.

Marine Carpuat and Mona Diab.  2010. Task-based 
evaluation of multiword expressions:   a pilot study 
in statistical machine translation. In Human Lan- 
guage Technologies:  The 2010 Annual Conference 
of the North American Chapter of the Association 
for Computational Linguistics, HLT ’10, pages 242–
245, Stroudsburg, PA, USA.

Tanmoy Chakraborty, Santanu Pal, Tapabrata Mondal, 
Tanik Saikh, and Sivaju Bandyopadhyay. 2011. 
Shared task system description:  Measuring the com- 
positionality of bigrams using statistical methodolo- 
gies. In Proceedings of the Workshop on Distribu- 
tional Semantics and Compositionality,  pages 38–
42, Portland, Oregon, USA.

Scott C. Deerwester,  Susan T. Dumais,  Thomas K. Lan- 
dauer, George W. Furnas, and Richard A. Harshman.



W
S
M
M
ea
su
re
w
Av
g(
of 
ρ)
ρ
A
N-
V
O
-
S
V
ρ
A
N
ρ
V
O
ρ
S
V
ρ
N
N
V
S
M
1
V
S
M
2
V
S
M
3
V
S
M
1
S
U
1
E
N
1
C
O
1
N
E
1
0
.
3
1
0
.
3
6
0
.
4
0
0
.
3
4
0
.
1
1
0
.
3
2
0
.
3
4
0
.
2
6
-
0.
03
0.
4
1
0.
4
0
0.
2
0
0.
3
6
0.
3
0
0.
2
6
0.
4
8
0.
3
1
0.
1
0
0.
3
9
0.
0
7
0.
7
5
0.
6
1
0.
6
4
0.
6
0
L
S
A
1
L
S
A
2
L
S
A
3
L
S
A
2
S
U
2
E
N
2
C
O
1
N
E
2
0
.
3
4
0
.
5
6
0
.
5
5
0
.
5
0
0
.
1
9
0
.
5
3
0
.
5
3
0
.
4
5
-
0.
05
0.
5
4
0.
4
9
0.
4
6
0.
4
6
0.
5
1
0.
5
6
0.
3
7
0.
4
2
0.
5
9
0.
6
3
0.
6
4
0.
7
1
0.
6
5
0.
5
8
0.
6
2
H
A
L
1
H
A
L
2
H
A
L
3
H
A
L
4
S
U
3
E
N
3
C
O
1
N
E
3
0
.
4
5
0
.
3
6
0
.
2
3
0
.
2
7
0
.
3
6
0
.
3
5
0
.
1
5
0
.
2
5
0.
2
8
0.
4
7
0.
2
8
0.
3
1
0.
5
0
0.
2
8
0.
1
2
0.
2
1
0.
4
0
0.
2
7
-
0.
01
0.
1
7
0.
6
7
0.
3
8
0.
5
4
0.
3
9
C
O
A
L
S1
C
O
A
L
S2
C
O
A
L
S2
C
O
A
L
S2
S
U
4
E
N
2
C
O
1
N
E
4
0
.
4
8
0
.
5
8
0
.
5
9
0
.
5
8
0
.
4
1
0
.
5
4
0
.
5
4
0
.
5
6
0.
2
8
0
.
6
0
.
6
0.
6
1
0.
5
6
0.
6
3
0.
6
4
0.
5
8
0.
4
9
0.
3
7
0.
3
7
0.
4
6
0.
6
8
0.
6
8
0.
7
0
0.
6
7
R
I
1
R
I
2
R
I
3
R
I
2
S
U
5
E
N
3
C
O
1
N
E
5
0
.
5
2
0
.
4
5
0
.
2
1
0
.
4
3
0
.
4
4
0
.
4
4
0
.
1
3
0
.
4
3
0.
4
5
0.
4
1
0.
1
3
0.
4
3
0.
5
1
0.
5
7
0.
1
6
0.
5
3
0.
5
2
0.
3
3
0.
1
1
0.
2
1
0.
6
8
0.
4
5
0.
5
4
0.
4
9

Table 3: The Spearman correlations ρ of the best performing  (wAvg) combinations of particular WSMs 
and Measures from all the tested Setups applied to TrValD.  The highest correlation values in the particular 
columns and the correlation values which are not statistically  different from them (p < 0.05) are in bold 
(yet we do not know how to calculate the stat. significance for the wAvg(of ρ) column). The parameters 
of WSMs and Measures corresponding to the indexes are depicted in Tables 5 and 6, respectively.




1990. Indexing by latent semantic analysis. Jour- 
nal of the American Society of Information Science,
41(6):391–407.

Stefan Evert. 2005. The statistics of word cooccur- 
rences :  word pairs and collocations. Ph.D. the- 
sis, Universita¨t  Stuttgart, Holzgartenstr. 16, 70174
Stuttgart.

Zellig Harris. 1954. Distributional structure. Word,
10(23):146–162.

Anders Johannsen, Hector Martinez Alonso, Christian 
Rishøj, and Anders Søgaard. 2011. Shared task sys- 
tem description: frustratingly hard compositionality 
prediction. In Proceedings of the Workshop on Dis- 
tributional Semantics and Compositionality, DiSCo
’11, pages 29–32, Stroudsburg, PA, USA.

David Jurgens  and Keith Stevens.     2010.   The s- 
space package:   an open source package for word 
space models.  In Proceedings of the ACL 2010 Sys- 
tem Demonstrations, ACLDemos  ’10, pages 30–35, 
Stroudsburg, PA, USA.

Lubom´ır Krcˇma´ˇr, Karel Jezˇek, and Massimo  Poesio.
2012. Detection of semantic compositionality  using 
semantic spaces.  Lecture  Notes in Computer Sci- 
ence, 7499 LNAI:353–361.


Lubom´ır  Krcˇma´ˇr,  Karel Jezˇek, and Pavel Pecina. 2013.
Determining compositionality of word expressions 
using word space models.  In Proceedings of the 9th 
Workshop on Multiword Expressions,  pages 42–50, 
Atlanta, Georgia, USA.

Thomas K. Landauer and Susan T. Dumais.	1997.
A solution to Plato’s problem:  The latent semantic 
analysis theory of acquisition,  induction,  and rep- 
resentation of knowledge. Psychological Review,
104(2):211–240.

Dekang Lin.     1999.    Automatic identification of 
non-compositional  phrases.  In Proceedings of the
37th annual meeting of the Association for Compu- 
tational Linguistics on Computational Linguistics, 
ACL ’99, pages 317–324, Stroudsburg, PA, USA.

Kevin  Lund and Curt Burgess.      1996.    Produc- 
ing high-dimensional   semantic  spaces from lexi- 
cal co-occurrence. Behavior Research Methods,
28(2):203–208.

Diana McCarthy,  Bill   Keller,  and John Carroll.
2003. Detecting  a continuum  of compositionality 
in phrasal verbs. In Proceedings of the ACL 2003 
workshop on Multiword expressions analysis acqui- 
sition and treatment, volume 18 of MWE ’03, pages
73–80.



W
S
M
M
ea
su
re
w
Av
g(
of 
ρ)
ρ
A
N-
V
O
-
S
V
ρ
A
N
ρ
V
O
ρ
S
V
ρ
N
N
V
S
M
1
V
S
M
2
V
S
M
3
V
S
M
1
S
U
1
E
N
1
C
O
1
N
E
1
0
.
2
8
0
.
2
6
0
.
3
2
0
.
3
2
0
.
0
3
0
.
1
9
0
.
2
6
0
.
1
9
0.
0
1
0.
0
8
0.
2
4
0.
3
6
0.
5
1
0.
2
9
0.
2
3
0.
2
5
0.
0
4
0.
0
4
0.
2
5
-
0.
13
0.
6
2
0.
6
9
0.
6
5
0.
7
3
L
S
A
1
L
S
A
2
L
S
A
3
L
S
A
2
S
U
2
E
N
2
C
O
1
N
E
2
0
.
3
1
0
.
5
0
0
.
4
8
0
.
4
4
0
.
0
6
0
.
4
0
0
.
3
6
0
.
3
3
0.
0
5
0.
3
9
0.
2
9
0.
3
4
0.
5
0
0.
5
5
0.
6
0
0.
4
0
0.
2
0
0.
3
2
0.
4
2
0.
4
4
0.
5
9
0.
7
8
0.
6
9
0.
6
7
H
A
L
1
H
A
L
2
H
A
L
3
H
A
L
4
S
U
3
E
N
3
C
O
1
N
E
3
0
.
2
9
0
.
3
6
0
.
2
4
0
.
2
1
0
.
1
6
0
.
2
8
0
.
2
2
0
.
1
4
0.
0
9
0.
3
3
0.
2
5
0.
0
2
0.
3
2
0.
3
5
0.
1
6
0.
3
3
0.
3
4
0.
2
6
0.
1
5
0.
0
6
0.
5
6
0.
5
3
0.
4
2
0.
4
7
C
O
A
L
S1
C
O
A
L
S2
C
O
A
L
S2
C
O
A
L
S2
S
U
4
E
N
2
C
O
1
N
E
4
0
.
4
2
0
.
4
9
0
.
4
7
0
.
5
2
0
.
2
8
0
.
4
4
0
.
4
0
0
.
4
8
0.
2
8
0.
5
2
0.
4
7
0.
5
5
0.
5
4
0.
5
1
0.
5
1
0.
5
0
0.
3
0
0.
0
7
0.
0
7
0.
2
1
0.
5
9
0.
7
2
0.
7
4
0.
7
4
R
I
1
R
I
2
R
I
3
R
I
2
S
U
5
E
N
3
C
O
1
N
E
5
0
.
3
0
0
.
4
4
0
.
2
3
0
.
3
1
0
.
1
4
0
.
3
4
0
.
2
3
0
.
2
6
0.
1
4
0.
3
7
0.
2
9
0.
2
6
0.
2
9
0.
5
4
0.
1
7
0.
4
2
0.
1
2
0.
2
0
0.
1
7
0.
0
4
0.
7
2
0.
6
3
0.
2
6
0.
4
4
R
e
d
d
y
-
W
S
M
 
S
t
a
t
M
i
x
K
r
c
m
a
r
-
C
O
A
L
S
 
K
r
c
m
a
r
-
L
S
A
-
-
-
-
0
.
3
5
0
.
3
3
0
.
4
2
0
.
5
0
-
-
0.
4
2
0.
5
0
-
-
0.
6
9
0.
5
6
-
-
0
.
2
4
0
.
4
1
-
-
-
-

Table 4: The Spearman correlations ρ of the best performing  (wAvg) combinations of particular WSMs 
and Measures trained in TranValD applied to TestD. The highest correlation  values in the particular 
columns and the correlation values which are not statistically  different from them (p < 0.05) are in bold 
(yet we do not know how to calculate the stat. significance for the wAvg(of ρ) column). Reddy-WSM and 
StatMix stand for the best performing  system based on WSMs  and association measures, respectively, 
applied to the DISCO task (Biemann and Giesbrecht, 2011). Krcmar-COALS and Krcmar-LSA stand for 
the best published  results achieved upon the dataset presented in Krcˇma´ˇr et al. (2012) and Krcˇma´ˇr et al. 
(2013), respectively.  The parameters of WSMs and Measures corresponding to the indexes are depicted 
in Tables 5 and 6, respectively.




Jeff Mitchell and Mirella Lapata.  2008. Vector-based 
models of semantic composition.  In Proceedings of 
ACL-08: HLT, pages 236–244, Columbus,  Ohio.

Preslav  Nakov, Antonia Popova,  and Plamen Ma- 
teev.   2001.  Weight functions impact on lsa per- 
formance. In Proceedings of the EuroConference 
Recent Advances in Natural Language Processing 
(RANLP’01), pages 187–193.

Athanasios Papoulis.   1990. Probability & statistics.
Prentice Hall.

Darren Pearce. 2002. A Comparative Evaluation of 
Collocation Extraction Techniques. In Proceedings 
of the Third International  Conference on Language 
Resources and Evaluation, LREC.

Pavel Pecina. 2008. Reference data for Czech collo-


cation extraction. In Proceedings of the LREC 2008
Workshop Towards a Shared Task for Multiword Ex- 
pressions, pages 11–14, Marrakech, Morocco. Euro- 
pean Language Resources Association.

Siva Reddy, Diana McCarthy, and Suresh Manand- 
har.  2011a. An empirical study on composition- 
ality in compound nouns. In Proceedings of 5th In- 
ternational Joint Conference on Natural Language 
Processing, pages 210–218, Chiang Mai, Thailand, 
November. Asian Federation of Natural Language 
Processing.

Siva Reddy, Diana McCarthy,  Suresh Manandhar, and 
Spandana Gella.  2011b. Exemplar-based word- 
space model for compositionality  detection: Shared 
task system description.  In Proceedings of the Work- 
shop on Distributional Semantics and Composition- 
ality, pages 54–60, Portland, Oregon, USA.



M
ea
su
re 	parameters
S
U	sim.	∗	W 	H 	M
S
U1	cos	plus	log	30	3
S
U2	cos	plus	log	100	5
S
U3	cos	mult	log	12	2
S
U4	cos	mult	log	80	4
S
U5	cos	mult	log	4	3
E
N	sim.	func.	x
E
N1	cos	min	sim
E
N2	cos	avg	sim
E
N3	cos	min	–dist
C
O	sim.	∗
C
O
1	cos	⊕
N
E	sim.	O
N
E1	cos	1000
N
E2	cos	500
N
E3	cos	50
N
E4	cor	500
N
E5	cos	20






Table 5: Parameters of WSMs (Section 2) which, 
combined with particular Measures, achieved the 
highest average correlation  in TrValD.


Douglas L. Rohde, Laura M. Gonnerman, and David C.
Plaut. 2005. An improved model of semantic sim- 
ilarity based on lexical co-occurrence. Unpublished 
manuscript.

Magnus Sahlgren, Anders Holst, and Pentti Kanerva.
2008. Permutations  as a means to encode order in 
word space. In V. Sloutsky, B. Love, and K. Mcrae, 
editors, Proceedings of the 30th Annual Conference 
of the Cognitive  Science Society, pages 1300–1305. 
Cognitive Science Society, Austin, TX.

Magnus Sahlgren.  2005. An introduction to random 
indexing. In Methods and Applications of Semantic 
Indexing Workshop at the 7th International  Confer- 
ence on Terminology and Knowledge Engineering, 
Leipzig, Germany.

Magnus Sahlgren. 2006. The Word-Space Model: Us- 
ing distributional  analysis to represent syntagmatic 
and paradigmatic relations between words in high- 
dimensional vector spaces. Ph.D. thesis, Stockholm 
University.

Gerard Salton.  1971.  The SMART Retrieval Sys- 
tem; Experiments in Automatic Document Process- 
ing.  Prentice-Hall, Inc., Upper Saddle River, NJ, 
USA.

Dawei Song, Peter Bruza,  and Richard  Cole.  2004.
Concept learning and information  inferencing on a


Table 6:   Parameters  of Measures  (Section 3) 
which, combined with particular WSMs, achieved 
the highest average correlation  in TrValD.


highdimensional  semantic space.   In ACM SIGIR
2004 Workshop on Mathematical/Formal  Methods 
in Information Retrieval.

Peter D. Turney and Patrick Pantel.  2010. From fre- 
quency to meaning:  vector space models of seman- 
tics. J. Artif. Int. Res., 37(1):141–188.

