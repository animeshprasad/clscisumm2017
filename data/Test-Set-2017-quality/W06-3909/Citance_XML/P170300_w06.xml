<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">Linguistic relations in oral conversations present how opinions are constructed and developed in a restricted time.</S>
		<S sid ="2" ssid = "2">The relations bond ideas, arguments, thoughts, and feelings, re- shape them during a speech, and finally build knowledge out of all information provided in the conversation.</S>
		<S sid ="3" ssid = "3">Speakers share a common interest to discuss.</S>
		<S sid ="4" ssid = "4">It is expected that each speakers reply includes duplicated forms of words from previous speakers.</S>
		<S sid ="5" ssid = "5">However, linguistic adaptation is observed and evolves in a more complex path than just transferring slightly modified versions of common concepts.</S>
		<S sid ="6" ssid = "6">A conversation aiming a benefit at the end shows an emergent cooperation inducing the adaptation.</S>
		<S sid ="7" ssid = "7">Not only cooperation, but also competition drives the adaptation or an opposite scenario and one can capture the dynamic process by tracking how the concepts are linguistically linked.</S>
		<S sid ="8" ssid = "8">To uncover salient complex dynamic events in verbal communications, we attempt to discover self-organized linguistic relations hidden in a conversation with explicitly stated winners and losers.</S>
		<S sid ="9" ssid = "9">We examine open access data of the United States Supreme Court.</S>
		<S sid ="10" ssid = "10">Our understanding is crucial in big data research to guide how transition states in opinion mining and decision-making should be modeled and how this required knowledge to guide the model should be pinpointed, by filtering large amount of data.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="11" ssid = "11">Traditionally, in computational linguistics, it is essential to integrate models and algorithms with fundamental laws of language.</S>
			<S sid ="12" ssid = "12">Widely applied hierarchical dependency trees and parsing in natural language processing (NLP) follow existing grammatical relations.</S>
			<S sid ="13" ssid = "13">Nowadays, while algorithms and models reach higher levels and available data becomes bigger, not enough linguistic laws are uncovered and can have a chance to meet with developed techniques.</S>
			<S sid ="14" ssid = "14">Language processing in data science mainly considers evaluated data as single source in terms of language.</S>
			<S sid ="15" ssid = "15">There are approaches such as cross-media topic analysis, retrieving information referring various data platforms including websites, blogs, and mobile phones, and multimodal analysis (Poria et al. 2016; Poria et al. 2017a; Poria et al. 2017b), combining text data with images, videos, and audio, however, they only gather all available channels and do not address the richness of language.</S>
			<S sid ="16" ssid = "16">On the other hand, language itself has many dimensions, language of a text written by a single author is different than language used in a dialogue or that of a group speech, e.g., trialogue discussions.</S>
			<S sid ="17" ssid = "17">Therefore, it is emergent that current conventional NLP should meet with the revolutionary philosophy of linguistics (Chomsky 1975) and establish new hidden laws applicable in data science: the human mind easily knows and applies by birth, but hardly formulates to understand the underlying structure.</S>
			<S sid ="18" ssid = "18">One of the remarkable perspectives to dig into natural linguistic laws is provided by social and behavior sciences, adaptation in language during communication as a result of changes in opinions and decisions.</S>
			<S sid ="19" ssid = "19">Opinions and decisions are personal in individual level, however, they are flexible while facing public opinions and decisions.</S>
			<S sid ="20" ssid = "20">Linguistic adaptation is twofold.</S>
			<S sid ="21" ssid = "21">In one part, collective voice unifies opinions and decisions in a complex process, ideas are biased, and consequently people start acting similarly, talking similarly, and so writing similarly.</S>
			<S sid ="22" ssid = "22">Twitter conversations (DanescuNiculescu-Mizil, Gamon, and Dumais 2011; Purohit et al. 2013) and popular memes (Myers and Leskovec 2012; Coscia 2013) prove this similarity in social media.</S>
			<S sid ="23" ssid = "23">In the other part, when people have a well-defined goal at the end, they tend to reshape their arguments.</S>
			<S sid ="24" ssid = "24">In the presence of distinct winning and losing sides and social hierarchy, people at lower status show both cooperation through that at the higher status and competition among each other.</S>
			<S sid ="25" ssid = "25">Therefore, a verbal discussion in such explicitly opposing groups host linguistic adaptation, investigated in social exchange theory (Willer 1999; Thye, Willer, and Markovsky 2006).</S>
			<S sid ="26" ssid = "26">While information and emotions are the fundamental elements of human knowledge, commonsense knowledge is the fundamental element for gluing society (Cambria et al. 2009; Cambria et al. 2016).</S>
			<S sid ="27" ssid = "27">Commonsense is implicit semantic and affective information humans continuously tap on for decision-making, communication, and reasoning in general (Cambria and Hussain 2015; Rajagopal et al. 2013; Poria et al. 2013; Tran, Cambria, and Hussain 2016).</S>
			<S sid ="28" ssid = "28">Effective speeches and public talks use commonsense efficiently to drive opinions and change decisions in large scales (Drath and Palus 1994).</S>
			<S sid ="29" ssid = "29">The resultant unified collective motion is extremely interesting in social groups (BorgeHolthoefer et al. 2011; GonzalezBailon et al. 2011).</S>
			<S sid ="30" ssid = "30">Opinions and decisions are personal in individual level.</S>
			<S sid ="31" ssid = "31">However, as observed, they are quite flexible facing with a collective decision.</S>
			<S sid ="32" ssid = "32">Complex knowledge extraction process in micro state suddenly becomes less valuable and group decision gains (Conover et al. 2011).</S>
			<S sid ="33" ssid = "33">We can argue that our opinions are biased when our decisions mostly rely on our previous knowledge, e.g., commonsense, and so richness of opinions kept in each individual is relatively unimportant.</S>
			<S sid ="34" ssid = "34">We can further argue that commonsense drives an adaptation in extracting knowledge.</S>
			<S sid ="35" ssid = "35">To measure commonsense for a particular situation is hard, however, adaptations can be easily captured in Twitter conversations (DanescuNiculescu- Mizil, Gamon, and Dumais 2011; Purohit et al. 2013), in memes (Myers and Leskovec 2012; Coscia 2013), and face- to-face discussions (DanescuNiculescu-Mizil et al. 2012).</S>
			<S sid ="36" ssid = "36">In this paper, our main concerns are firstly to construct discussion groups including agents having different social powers and serving opposite aims.</S>
			<S sid ="37" ssid = "37">Secondly, we investigate how we can track the progress of opinions together with their influences on decisions in oral conversations.</S>
			<S sid ="38" ssid = "38">We claim that linguistic relations (Poria et al. 2015) preserve all rich phenomena, shortly discussed above, including collective voice, reshaping arguments, and so adaptation.</S>
			<S sid ="39" ssid = "39">To analyze adaptation induced by both cooperation and competition, we consider court conversations: they are held in clearly stated winner and loser groups with distinct hierarchy in decision- making due to the presence of Justices and lawyers.</S>
			<S sid ="40" ssid = "40">To this end, we evaluate the open access data of the United States Supreme Court (Hawes, Lin, and Resnik 2009; Hawes 2009; DanescuNiculescu-Mizil et al. 2012), prepare conversation groups with different adaptation levels, implement a suitable algorithm to extract linguistic relations in these group conversations, and finally provide a comparison between the groups and the discovered linguistic relations.</S>
			<S sid ="41" ssid = "41">The rest of the paper is organized as follows: the first section presents the dataset we consider and designed conversation groups out of the data; the second section describes our algorithm in detail; the following section explains how we implement pointwise mutual information for the conversation groups and then link with linguistic relations; finally, we provide experimental results and conclude the paper.</S>
			<S sid ="42" ssid = "42">Supreme Court Data We borrow the textual data of the conversations in the United States Supreme Court pre-processed by (Hawes, Lin, and Resnik 2009; Hawes 2009) and enriched by (DanescuNiculescu-Mizil et al. 2012) including the final votes of Justices.</S>
			<S sid ="43" ssid = "43">Both the original data and the most updated version used here are publicly available (DanescuNiculescu- Mizil et al. 2012).</S>
			<S sid ="44" ssid = "44">The data gathers oral speeches before the Supreme Court and hosts 50,389 conversational exchanges among Justices and lawyers.</S>
			<S sid ="45" ssid = "45">Distinct hierarchy between Justices (high power) and lawyers (low power) impose lawyers to tune their arguments under the perspective and understandings of Justices, and as a result, speech adaptation and linguistic coordination leaves their traces in a sudden occurrence of sharing the same adverbs, conjunctions, and pronouns.</S>
			<S sid ="46" ssid = "46">Tracking initial utterances, the sides present a unique and personal speaking, but after a while in the communication, word selections, their forms, and frequencies mirror each other’s language preference.</S>
			<S sid ="47" ssid = "47">The linguistic coordination is systematically quantified by (DanescuNiculescu-Mizil et al. 2012) and the arguments follow the principles of exchange theory examining behavior dynamics in low and high power groups (Willer 1999; Thye, Willer, and Markovsky 2006): Lawyers tend to cooperate more to Justices than conversely and demonstrate strong linguistic coordination in their speech.</S>
			<S sid ="48" ssid = "48">Moreover, lawyers show even more cooperation to unfavorable Justices than favorable ones.</S>
			<S sid ="49" ssid = "49">Here, we enrich the comparison including the identity of winners and losers in lawsuits.</S>
			<S sid ="50" ssid = "50">The data provides whether the petitioner or the respondent is the winner at the end of each lawsuit.</S>
			<S sid ="51" ssid = "51">In addition, the speaker of each utterance is labeled as their position, e.g., Justice or lawyer.</S>
			<S sid ="52" ssid = "52">Furthermore, Justice’s votes and the side of lawyers are tagged with the utterances.</S>
			<S sid ="53" ssid = "53">Table 1 identifies all roles carried by Justices and lawyers.</S>
			<S sid ="54" ssid = "54">For Justices, both the vote (middle) and whom to speak (last) are given.</S>
			<S sid ="55" ssid = "55">Lawyers are allowed to speak only when Justices address their side.</S>
			<S sid ="56" ssid = "56">ID Roles of Justices (J ) and Lawyers (l) 1 J - Vote Petitioner - Speak to Petitioner’s l</S>
	</SECTION>
	<SECTION title="J - Vote Petitioner - Speak to Respondent’s l" number = "2">
			<S sid ="57" ssid = "1">4 J - Vote Respondent - Speak to Respondent’s l 5 l - Petitioner Side 6 l - Respondent Side Table 1: The segregation schema of the roles in conversations: Support sides of Justices and sides of lawyers.</S>
			<S sid ="58" ssid = "2">16 summarize all potential roles present in the data.</S>
			<S sid ="59" ssid = "3">In 14, who supported by the Justice is given in the middle.</S>
			<S sid ="60" ssid = "4">Furthermore, the last indicates the side of lawyer the Justice speaks to.</S>
			<S sid ="61" ssid = "5">Referring exchange theory (Willer 1999; Thye, Willer, and Markovsky 2006) and the measured coordination (DanescuNiculescu-Mizil et al. 2012), one can order the relative power of each Justice and lawyer pair P (Ju , l) &gt; P (Js , l), (1) where J and l represent Justices and lawyers, respectively (note that for comparing individually following the social exchange theory, P (J ) &gt; P (l) for both supportive and unsupported Justices).</S>
			<S sid ="62" ssid = "6">The subscript u indicates that Justice doesn’t support the side of lawyer and the supportive version is described by s. For instance, in Table 1, in the communications of 1 and 5; 4 and 6, Justices show supports and play as Js , whereas that of 3 and 5; 2 and 6, lawyers are unsupported by Ju . The scenarios and pairs guide to construct groups with different cooperation level induced by P as illustrated in Table 2.</S>
			<S sid ="63" ssid = "7">We further add another dimension in the relative power: Winners and Losers, haven’t been investigated in the previous study (DanescuNiculescu-Mizil et al. 2012).</S>
			<S sid ="64" ssid = "8">To this end, Eq. 1 is reformulated P (Ju , l)win &gt; P (Js , l)win , (2) P (Ju , l)lose &gt; P (Js , l)lose .</S>
			<S sid ="65" ssid = "9">(3) Group ID Cooperation Pool of J and l I.i supportive, P (Js , l) 1 and 5 I.ii unsupported, P (Ju , l) 3 and 5 II.i unsupported, P (Ju , l) 2 and 6 II.ii supportive, P (Js , l) 4 and 6 Table 2: Grouping communications with respect to level of cooperation, based on the relative power of the partners in the conversations.</S>
			<S sid ="66" ssid = "10">16 and the power pairs P (Js , l) and P (Ju , l) as defined previously.</S>
			<S sid ="67" ssid = "11">Here, win and lose subscripts highlight that the concerned Justice and lawyer pairs are the partners in a won or lost lawsuit.</S>
			<S sid ="68" ssid = "12">As an illustration, P (Js , l)win occurs in the group I.i when petitioners are the winner and also in II.ii while respondents are the winners of the lawsuits.</S>
			<S sid ="69" ssid = "13">On the other hand, P (Js , l)lose is the Justices-lawyers of I.i in respondent won lawsuits as well as of II.ii in petitioner won lawsuits.</S>
			<S sid ="70" ssid = "14">The situations are generated for the unsupported Justice-lawyer groups and all are listed in Table 3.</S>
			<S sid ="71" ssid = "15">κ Cooperation Gathering Group ID A supportive, win: P (Js , l)win I.i of Pe + II.ii of Re B supportive, lose: P (Js , l)lose I.i of Re + II.ii of Pe C unsupported, win: P (Ju , l)win I.ii of Pe + II.i of Re D unsupported, lose: P (Ju , l)lose I.ii of Re + II.i of Pe Table 3: Designed conversation groups κ based on different expectations for the level of linguistic coordination, induced by distinct P . The groups κ are presented in A, B, C , and D, whether they preserve supportive or unsupported conversations as well as a winner or loser status stated by the Supreme Court.</S>
			<S sid ="72" ssid = "16">Pe and Re represent the particular lawsuits where Petitioner and Respondent as the winner, respectively.</S>
			<S sid ="73" ssid = "17">Gathered conversations of the cases I.i, I.ii, II.i, and II.ii and the relative powers P are as introduced earlier.</S>
			<S sid ="74" ssid = "18">Calculating utterances in κ, we have 21,105 for A, 15,116 for B, 15,489 for C , and 24,461 for D, gathered by different combinations of 195 lawsuits.</S>
			<S sid ="75" ssid = "19">The large number of each pool convinces that we have enough examples to perform statistics and our measurement won’t be biased by the size effect.</S>
			<S sid ="76" ssid = "20">On the other hand, noting the total number of 50,389 utterances, almost the half of the data presents P (Ju , l)lose type social relations, e.g., case D. Eqs.</S>
			<S sid ="77" ssid = "21">(2) and (3) do not include the comparison of {P (Ju , l)win ; P (Js , l)lose } and {P (Ju , l)lose ; P (Js , l)win } on purpose since it is unknown whether P (Ju , l) &gt; P (Js , l) is still valid in the presence of win and lose, bringing interesting perspective while coupling the power hypothesis with the cooperation and not considered in social exchange theory.</S>
			<S sid ="78" ssid = "22">We aim to understand this full picture by correlating determined linguistic relations with the separated relative power groups.</S>
			<S sid ="79" ssid = "23">Linguistic Relation Extraction The Supreme Court hosts lawsuits of rich subjects.</S>
			<S sid ="80" ssid = "24">To design specific linguistic relations in each distinct lawsuit is challenging and not required.</S>
			<S sid ="81" ssid = "25">Our aim is to suggest relations suit able for any discussion concept.</S>
			<S sid ="82" ssid = "26">To generalize the task, we first determine noun phrases in the data following the definition in (Pennacchiotti and Pantel 2006).</S>
			<S sid ="83" ssid = "27">The phrases are combinations of adjectives and nouns.</S>
			<S sid ="84" ssid = "28">The technical steps include standard part-of-speech tagging including grammar based chunk parser.</S>
			<S sid ="85" ssid = "29">We then restrict our attention to address the relations linking only determined noun phrases within one sentence.</S>
			<S sid ="86" ssid = "30">The data shows utterances of grammatically correct and well-organized sentences.</S>
			<S sid ="87" ssid = "31">To this end, we apply rule-based relation extraction.</S>
			<S sid ="88" ssid = "32">While Fig.</S>
			<S sid ="89" ssid = "33">1 shows each step of the developed algorithm, steps (A-C) indicate the discussed concept recognition of noun phrases.</S>
			<S sid ="90" ssid = "34">The rule-based schema starts with first restricting linguistic relations and then constructing static surface patterns (regular expressions) for them.</S>
			<S sid ="91" ssid = "35">The assigned patterns run as an iterative process searching the exact match of the real patterns between any concept pair, which is any noun phrase pair here.</S>
			<S sid ="92" ssid = "36">Within a sentence, multiple relations can be addressed based on the comparison in the iteration, to capture both different relations or the same relation but with the different patterns.</S>
			<S sid ="93" ssid = "37">To balance the relations without over- weighting extreme cases, we first apply classical IsA (Hearst 1992) and PartOf (Girju, Badulescu, and Moldovan 2003) relations.</S>
			<S sid ="94" ssid = "38">The patterns of the relations follow both lexico- syntactic formalisms (Klaussner and Zhekova 2011) and manual investigations of the data.</S>
			<S sid ="95" ssid = "39">We then recommend further relations as UsedBy, Used- For, UsedIn, UsedOver, and UsedWith to cover the rest of the data.</S>
			<S sid ="96" ssid = "40">The Used relations do not accumulate for certain lawsuits and nicely distribute over entire data, which provides us reliable analysis.</S>
			<S sid ="97" ssid = "41">Fig.</S>
			<S sid ="98" ssid = "42">1(D and E) highlight the iteration process to detect all potential relations.</S>
			<S sid ="99" ssid = "43">To illustrate the outcome of our algorithm, we provide examples for each relation.</S>
			<S sid ="100" ssid = "44">They are given with the detected noun phrases in Table 4.</S>
			<S sid ="101" ssid = "45">The identity of the sentences, a-g, are to guide the following concerned examples, where the linked noun phrases are highlighted in bold: (a) That was so because her claim is that J. Howard intended to give her a catchall trust.</S>
			<S sid ="102" ssid = "46">(b) And when you look at the core value of the two clauses, they do not clash.</S>
			<S sid ="103" ssid = "47">(c) And what I’m trying to do here for the Court is to draw upon your own authority, the word you’ve spoken, as opposed to the test proposed by the Criminal Justice Foundation and by the United States.</S>
			<S sid ="104" ssid = "48">(d) One, the manufacturing process allows there to be a safe use for one of the components in marijuana.</S>
			<S sid ="105" ssid = "49">(e) The phrase Justice Harlan used in the Davis case.</S>
			<S sid ="106" ssid = "50">(f) For 124 years, as state power over alcohol has ebbed and flowed.</S>
			<S sid ="107" ssid = "51">(g) The haulers are required today to comply with the program.</S>
			<S sid ="108" ssid = "52">The validation of the discovered linguistic relations and their suggested patterns are systematically satisfied by the following protocol.</S>
			<S sid ="109" ssid = "53">From each conversation group κ in Table 3, 1000 utterances are randomly selected.</S>
			<S sid ="110" ssid = "54">Utterances present averages sentences of 24, the minimum is for the group C , P (Ju , l)win , and the maximum for group D, P (Ju , l)lose .</S>
			<S sid ="111" ssid = "55">(A) (B) (C) (D) (E) i n p u t s e n t e n c e p a r t o f s p e e c h n o u n p h r a s e s ( n p ) : g r a m m a r + p a r s i n g ( a d j e c t i v e s &amp; n o u n s ) r e g u l a r e x p r e s s i o n s : e.g.: ( n p ) : : i s t h a t : : ( n p ) ( n p ) : : u s e d i n : : ( n p ) . . .</S>
			<S sid ="112" ssid = "56">a s s i g n i n g r e l a t i o n s : in Fig.</S>
			<S sid ="113" ssid = "57">1(D F).</S>
			<S sid ="114" ssid = "58">The over all aver age scor es, com parin g the relati ons gene rated by our algo rith m with the grou nd truth , are obtai ned as 59.9 2% for Rec all, 67.2 % for Prec ision , and 63.3 5% for the resul tant F1.</S>
			<S sid ="115" ssid = "59">The scor es are relati vely high er than that of the rule base d relat ion extr actio n algo rith ms for more gene ral purp oses appli ed in large data sets (Pa n- tel, Ravi chan dran, and Hov y 2004 ).</S>
			<S sid ="116" ssid = "60">Our man ual effor ts, the gra mma ticall y corr ect sent ence s, and relat ively sma ll and well orga nize d data are the reas ons behi nd the good perf or- man ce.</S>
			<S sid ="117" ssid = "61">How ever, we obse rve that the fore most reas on is the ling uisti c coor dinat ion extra cting man y relati ons from the sam e static patt erns . In the rest of the pape r, we will dem onstr ate how we in- terpr et thes e lingu istic relati ons in the Supr eme Cour t con- vers ation grou ps of diffe rent relati ve pow ers.</S>
			<S sid ="118" ssid = "62">P o i n t w i s e M u t u a l I n f o r m a t i o n Poin twis e mut ual infor mati on (PM I) is a metri c to mea sure (F) no relati on e.g.: (n p) ::I s A :: (n p) (np) ::Use dIn:: (np) . . .</S>
			<S sid ="119" ssid = "63">coin cide nce of two discr ete rand om even ts.</S>
			<S sid ="120" ssid = "64">It com bines in divi dual prob abilit ies of even ts and their join ed pro babi lity to dete rmin e how ofte n the two even ts occu r at the sam e occasi on.</S>
			<S sid ="121" ssid = "65">We qua ntify to what exte nd lingu istic relati ons R are addr esse d by conv ersat ion grou ps κ and whet her we obse rve any varia tion in the sele ctio ns.</S>
			<S sid ="122" ssid = "66">validation manual annotation To this end, PMI between R and κ is introduced (Pantel, Ravichandran, and Hovy 2004)Figure 1: Flow diagram of the rule-based relation extrac f (R,κ) M I (R, κ) = log N .</S>
			<S sid ="123" ssid = "67">(4) tion algorithm.</S>
			<S sid ="124" ssid = "68">The important steps are summarized from (A) to (F): (A-C) present suggesting concepts based on noun phrases of combined adjectives and nouns.</S>
			<S sid ="125" ssid = "69">(D-E) de all R 2: f (Ri ,κ) Ri N × all κ 2: f (R,κj ) κj N scribe the iteration of applying designed static surface patterns (regular expressions) together with supervising for the 6 relations, namely, IsA, PartOf, UsedBy, UsedFor, UsedIn, UsedOver, and UsedWith.</S>
			<S sid ="126" ssid = "70">(F) indicates the final step of validation compared with the manual annotation set and formulating again regular expressions in (D) to increase the performance.</S>
			<S sid ="127" ssid = "71">Re lati on L i n k e d N o u n P h r a s e s Se nt.</S>
			<S sid ="128" ssid = "72">ID Is A c l a i m : : c a t c h a l l t r u s t ( a ) Pa rt Of c o r e v a l u e : : c l a u s e s ( b ) Us ed By tes t :: Cri mi na l Ju sti ce Fo un da tio n, ( c ) U n i t e d S t a t e s Us ed Fo r s a f e u s e : : c o m p o n e n t s , ( d ) m a r i j u a n a Us ed In phr as e Ju sti ce Ha rla n :: Da vis cas e ( e ) Us ed Ov er s t a t e p o w e r : : a l c o h o l ( f ) Us ed Wi th h a u l e r s : : p r o g r a m ( g ) Table 4: Extracted relations with our algorithms and the corresponded (linked) noun phrases.</S>
			<S sid ="129" ssid = "73">Sent.</S>
			<S sid ="130" ssid = "74">ID refers the labeled example sentences above in the main text.</S>
			<S sid ="131" ssid = "75">Then, manual annotations are provided for each pool, which works as the ground truth, and the patterns are readjusted if necessary based on the performance, as shown Here, f (R, κ) represents the frequency of occurrence for certain R in particular κ and N is the total number of all R in all κ.</S>
			<S sid ="132" ssid = "76">So, while the numerator describes the probabilistic occurrence of R in κ, the denominator provides individual probability of R and that of κ in the pool.</S>
			<S sid ="133" ssid = "77">We expect high M I (R, κ) while R appears in a specific κ and that is an indicator of its rare presence in the other conversation groups.</S>
			<S sid ="134" ssid = "78">Unlike the previous study (DanescuNiculescu-Mizil et al. 2012), entirely tracking back and forth utterances and proving the adaptation, e.g., linguistic coordination, by identifying the frequency of selected keywords, we directly utilize their overall conclusion and claim that linguistic relations already preserve the adaptation and any other complex collective linguistic process induced by both cooperation and competition in different power groups.</S>
			<S sid ="135" ssid = "79">We expect that the variation in M I (R, κ) of gathered utterances of each relative power group, independent of the utterance order, suggests which relations can distinguish the difference in the groups and the magnitude of M I (R, κ) of that difference highlights which relative power groups drastically influence the applied language.</S>
			<S sid ="136" ssid = "80">We will analyze M I (R, κ) following this discussed understanding in coming Section.</S>
			<S sid ="137" ssid = "81">Results We perform M I (R, κ) for each group κ separated by different coordination level and linguistic dynamics, expected due to the distinct relative powers as introduced in Table 3, and each relation R described in Section Linguistic Relation Extraction.</S>
			<S sid ="138" ssid = "82">The results are presented in Fig.</S>
			<S sid ="139" ssid = "83">2 and suggests rich behavior.</S>
			<S sid ="140" ssid = "84">First, M I for the relations IsA, PartOf, and UsedBy is almost indistinguishable overall κ.</S>
			<S sid ="141" ssid = "85">We understand that these relations cannot uncover the linguistic variations in different power groups.</S>
			<S sid ="142" ssid = "86">This is an obvious outcome of NLP and examining sentences by lexico-syntactic patterns: Any sentence can consider them with no complex linguistic process such as coordination and competition.</S>
			<S sid ="143" ssid = "87">On the other hand, we observe quite remarkable separation starting with UsedFor.</S>
			<S sid ="144" ssid = "88">Successfully, the results of UsedIn, Use- dOver, and UsedWith show that their appearances in κ are not arbitrary.</S>
			<S sid ="145" ssid = "89">A states impose observable deviations and none group resembles each other, oppositely, each presents very unique behavior.</S>
			<S sid ="146" ssid = "90">In a simplified picture, M I (R, κ) for C always indicates significantly positive values.</S>
			<S sid ="147" ssid = "91">This proves that the utterances in C consider all type of relations, can be the reason behind the success of the “win” state in spite of the presence of unsupported Justices.</S>
			<S sid ="148" ssid = "92">Conclusion We investigated the linguistic dynamics in terms of a restricted set of linguistic relations in oral conversations while the actors have different powers such as Justices (high power) and lawyers (low power) in the United States Supreme Court.</S>
			<S sid ="149" ssid = "93">Initially, defined cooperation of lawyers to Justices and the resultant linguistic coordination are only based on the relative power.</S>
			<S sid ="150" ssid = "94">This is a microscopic picture underestimating the dynamics of emergent competition 0.4 0.2 0.0 0.2 0.4 B C D IsA Part Of UsedBy UsedFor UsedIn UsedOverUs edWith R e l a t i o n s ( R ) arises in a losing state (lost lawsuits ), which can change the nature of the linguist ic coordin ation and make the linguistic relation s richer.</S>
			<S sid ="151" ssid = "95">Our argume nt is proven by measuring M I (R, κ) always positive for the group C , P (Ju , l)win . Novelt y of our approac h is that it evaluate s supporti ve and unsupp orted situatio ns in more realistic ally.</S>
			<S sid ="152" ssid = "96">The principl e of exchang e theory suggest s P (Ju , l) &gt; P (Js , l) and one should expect high coordin ation in the former.</S>
			<S sid ="153" ssid = "97">How ever, this can be always true if there is no explicitly stated decision at the end of the commu nication : Winner or loser lawyer.</S>
			<S sid ="154" ssid = "98">We can observe P (Js , l)lose c:: P (Ju , l)lose and so the linguist ic coordin ation (dynami cs) for both can be compara ble, as we trace in our result, e.g., very similar trend of M I (R, κ) for groups B and D. Therefo re, both social exchan ge theory and their impacts on the linguistic behavio r need to be reinterp reted under exogen ous Figure 2: PMI between relations R and conversation groups κ: M I (R, κ).</S>
			<S sid ="155" ssid = "99">The overall values indicate that, unlike IsA, PartOf, and UsedBy relations, the occurrences of UsedFor, UsedIn, UsedOver, and UsedWith are driven by the relative power and the resultant linguistic coordination and further complex process.</S>
			<S sid ="156" ssid = "100">The marker representations are as follows: Circles (blue) for A, squares (red) for B, left triangles (green) for C , and right triangles (yellow) for D. Evaluating the results in more detail, let us remind Table 3.</S>
			<S sid ="157" ssid = "101">A is expected to have the least relative power, P (Js , l)win , and consequently, no significant variation is observed.</S>
			<S sid ="158" ssid = "102">However, the situations are much more challenging for B, C , and D: They face with many conceptual challenges while defending their sides and competing with the opposite arguments, C and D, and to experiment different communications in a losing state, B and D. Each difficulty is a potential origin of the competition, some can build sufficient cooperation and make the lawyer winner, C , some cannot help to overcome the situation, keep the coordination limited, and so we experience lost lawsuits, B and D. To remind, B for P (Js , l)lose , C for P (Ju , l)win , and D for P (Ju , l)lose . If we just call social exchange theory, for any measurable linguistic quantity, we would need to have A ≡ B and C ≡ D. However, we show that the win and lose factors such as win-lose situations.</S>
			<S sid ="159" ssid = "103">Furthermore, we experience that the rule-based relation extraction is well-applicable for speech data, in this grammatically correct form with minor noise, because of the presence of the linguistic adaptation, providing a better performance than its usage for other type of textual data such as internet data.</S>
			<S sid ="160" ssid = "104">Furthermore, M I (R, κ) brings another perspective to uncover complex linguistic dynamics, including cooperation and competition, and discover the correlations between the linguistic relations and the relative powers.</S>
			<S sid ="161" ssid = "105">We establish the preliminary setup to examine the linguistic dynamics of trialogue discussions hosting in social groups with distinct hierarchy.</S>
			<S sid ="162" ssid = "106">Our main conclusion is that win and lose states impose further complexity and change the conventional application of social exchange theory in language and communication.</S>
			<S sid ="163" ssid = "107">In our future study, we attempt to analyze back and forth utterances in detail regarding semantics bonding by the linguistic relations by applying advanced tools.</S>
	</SECTION>
	<SECTION title="Acknowledgments">
			<S sid ="164" ssid = "108">This work was conducted within the Rolls-Royce@NTU Corporate Lab with support from the National Research Foundation (NRF) Singapore under the Corp Lab@University Scheme.</S>
			<S sid ="165" ssid = "109">We thank San Linn for his useful comments on the rule based relation extraction approach.</S>
	</SECTION>
</PAPER>
