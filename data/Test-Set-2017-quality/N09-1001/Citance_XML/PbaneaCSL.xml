<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">Recent research on English word sense subjectivity has shown that the subjective aspect of an entity is a characteristic that is better delineated at the sense level, instead of the traditional word level.</S>
		<S sid ="2" ssid = "2">In this paper, we seek to explore whether senses aligned across languages exhibit this trait consistently, and if this is the case, we investigate how this property can be leveraged in an automatic fashion.</S>
		<S sid ="3" ssid = "3">We first conduct a manual annotation study to gauge whether the subjectivity trait of a sense can be robustly transferred across language boundaries.</S>
		<S sid ="4" ssid = "4">An automatic framework is then introduced that is able to predict subjectivity labeling for unseen senses using either cross-lingual or multilingual training enhanced with bootstrapping.</S>
		<S sid ="5" ssid = "5">We show that the multilingual model consistently outperforms the cross-lingual one, with an accuracy of over 73% across all iterations.</S>
		<S sid ="6" ssid = "6">© 2013 Elsevier Ltd. All rights reserved.</S>
		<S sid ="7" ssid = "7">Keywords: Sentiment and text classification; Multilingual subjectivity analysis; Sense level subjectivity</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="8" ssid = "8">Sentiment and subjectivity analysis seeks to automatically identify opinions, beliefs, speculations, emotions, sentiments and other private states in natural text (Wiebe et al., 2005).</S>
			<S sid ="9" ssid = "9">Quirk et al.</S>
			<S sid ="10" ssid = "10">(1985) define a private state as a state that does not lend itself to an objective external validation, or in other words “a person may be observed to assert that God exists, but not to believe that God exists.</S>
			<S sid ="11" ssid = "11">Belief is in this sense private.” (p. 1181).</S>
			<S sid ="12" ssid = "12">In the field of natural language processing, researchers have used the term subjectivity analysis to denote identifying private states in text, namely separating objective from subjective instances, while sentiment or polarity analysis further refines the subjective text into positive, negative or neutral.</S>
			<S sid ="13" ssid = "13">Sentiment and subjectivity analysis has stemmed into a prolific area of research, mainly due to the fact that numerous text processing applications stand to gain from incorporating sentiment dimensions into their models, including automatic expressive text-to-speech synthesis (Alm et al., 1990), tracking sentiment timelines in online forums and news (Balog et al., 2006; Lloyd et al., 2005), and mining opinions from product reviews (Hu and Liu, 2004).</S>
			<S sid ="14" ssid = "14">In many natural language processing tasks, subjectivity and sentiment classification has been used as a first phase filtering to generate more viable data.</S>
			<S sid ="15" ssid = "15">Research that benefited from this additional layering ranges from question � This paper has been recommended for acceptance by Prof. R.K. Moore.</S>
			<S sid ="16" ssid = "16">∗ Corresponding author.</S>
			<S sid ="17" ssid = "17">Tel.: +1 940 369 7630.</S>
			<S sid ="18" ssid = "18">Email addresses: carmen.banea@gmail.com (C. Banea), rada@cs.unt.edu (R. Mihalcea), wiebe@cs.pitt.edu (J. Wiebe).</S>
			<S sid ="19" ssid = "19">08852308/$ – see front matter © 2013 Elsevier Ltd. All rights reserved.</S>
			<S sid ="20" ssid = "20">http://dx.doi.org/10.1016/j.csl.2013.03.002 answering (Yu and Hatzivassiloglou, 2003), to conversation summarization (Carenini et al., 2008), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006) and lexical substitution (Su and Markert, 2010).</S>
			<S sid ="21" ssid = "21">In experiments carried out on English, Wiebe and Mihalcea (2006) have shown that the most robust subjectivity delineation occurs at sense and not at word level.</S>
			<S sid ="22" ssid = "22">Following this more fine-grained perspective, Esuli and Sebastiani (2006) and Andreevskaia and Bergler (2006) have proposed methods to embed sense-level automatic sentiment annotations (objective/neutral, negative and positive) over the English WordNet structure (Miller, 1995), using its relationships (synonymy, antonymy, meronymy, etc.).</S>
			<S sid ="23" ssid = "23">On the other hand, noticing the scarcity of hand crafted sense-level subjectivity/polarity lexica, Markert and Su (2008) have explored ways to infer them from data annotated at either the word or sentence level.</S>
			<S sid ="24" ssid = "24">Sense-level subjectivity and cross-lingual subjectivity and sentiment analysis have received considerable attentions in recent years, yet our paper explores the area that lies at the intersection of these two topics.</S>
			<S sid ="25" ssid = "25">To our knowledge, this area has not been formally investigated, and while the techniques may be similar to those applied in sentiment and subjectivity analysis at the sentence or the review level, our work explores the more difficult task of sense-level subjectivity, which also involves deep semantic aspects of the language.</S>
			<S sid ="26" ssid = "26">The manual annotation study we performed for this task (cross-lingual sense-level subjectivity annotations), as well as the methods we proposed (cross-lingual and multilingual learning using dictionaries in multiple languages) are novel to our knowledge.</S>
			<S sid ="27" ssid = "27">This work seeks to answer the following questions.</S>
			<S sid ="28" ssid = "28">First, for word senses aligned across languages, is their subjectivity content consistent, or in other words, does a subjective sense in language A map to a subjective sense in language B (and similarly for an objective sense)?</S>
			<S sid ="29" ssid = "29">Second, can we employ a multilingual framework that can automatically discover new subjective/objective senses starting with a limited amount of annotated data?</S>
			<S sid ="30" ssid = "30">We seek to answer the first question by conducting a manual annotation study in Section 2.</S>
			<S sid ="31" ssid = "31">For the second question, we propose two models (see Section 3), one cross-lingual and one multilingual, which are able to simultaneously use information extracted from several languages when making subjectivity sense-level predictions.</S>
	</SECTION>
	<SECTION title="Sense level subjectivity consistency across languages: annotation study. " number = "2">
			<S sid ="32" ssid = "1">To answer the first question, we conduct a case study in subjectivity sense transfer across languages, focusing on English and Romanian.</S>
			<S sid ="33" ssid = "2">We consider a sense-level aligned multilingual resource such as WordNet.</S>
			<S sid ="34" ssid = "3">WordNet (Miller, 1995) was first developed for English, and is a lexical resource that maintains semantic relationships between basic units of meaning, or synsets.</S>
			<S sid ="35" ssid = "4">A synset groups together senses of different words that share a very similar meaning.</S>
			<S sid ="36" ssid = "5">Due to its particular usefulness for NLP tasks, numerous independent noncommercial projects1 have replicated its structure in over 50 languages, while maintaining alignment with the original WordNet and allowing for sense-level mapping across languages.</S>
			<S sid ="37" ssid = "6">In our experiments we use the English (Miller, 1995) and the Romanian (Tufis et al., 2006) versions of WordNet, which contain 117,6592 and 58,7253 synsets, respectively.</S>
			<S sid ="38" ssid = "7">Many of these are aligned at the synset level.</S>
			<S sid ="39" ssid = "8">In order to infuse subjectivity information into the model, we use sense-level manually annotated subjectivity data from (Wiebe and Mihalcea, 2006) and (Akkaya et al., 2009), as well as a list of 48 additional words, for a total of 128 words accounting for 580 English senses (with an average polysemy of 4.6).</S>
			<S sid ="40" ssid = "9">Their equivalent into Romanian is also obtained by traversing the WordNet structure.</S>
			<S sid ="41" ssid = "10">A native speaker of Romanian (who participated in previous subjectivity annotations studies) was asked to annotate the Romanian data, by being presented with the gloss (definition) and the synset of each given sense from the Romanian WordNet.</S>
			<S sid ="42" ssid = "11">The annotator agreement between the English and the Romanian subjectivity labels ranged from 84% (for the Akkaya et al.</S>
			<S sid ="43" ssid = "12">(2009) dataset) to 90% (for the Wiebe and Mihalcea (2006) dataset).</S>
			<S sid ="44" ssid = "13">When excluding senses that had both subjective and objective uses in either of the languages, the annotator agreement becomes 87%, with Cohen’s κ = 0.74 for the first dataset, and 94.7% with κ = 0.88 for the second one, indicating good to very good agreement.</S>
			<S sid ="45" ssid = "14">These findings support the hypothesis that the subjectivity of a sense maintains itself across language boundaries.</S>
			<S sid ="46" ssid = "15">Furthermore, they indicate that senses aligned across languages 1 http://www.globalwordnet.org/gwa/wordnet table.htm.</S>
			<S sid ="47" ssid = "16">2 http://wordnet.princeton.edu/wordnet/man/wnstats.7WN.html.</S>
			<S sid ="48" ssid = "17">3 http://www.racai.ro/wnbrowser/Help.aspx.</S>
			<S sid ="49" ssid = "18">Table 1 Sources of conﬂict in cross-lingual subjectivity transfer.</S>
			<S sid ="50" ssid = "19">Definitions and synonyms of the fourth sense of the noun argument, the fourth sense of verb decide, and the first sense of adjective free as provided by the English and Romanian WordNets; for Romanian we also provide the manual translation into English.</S>
			<S sid ="51" ssid = "20">Differences between languages argument Gloss En: a summary of the subject or plot of a literary work or play or movie “the editor added the argument to the poem” Ro:redareprezentare pe scurtscrisa˘ sau orala˘- a ideilor unei lucra˘ri- ale unei expuneri etc.</S>
			<S sid ="52" ssid = "21">(translation) short summary, oral or in writing, of the ideas presented in a literary work Synset En: argument, literary argument Ro: rezumat (translation) summary decide Gloss En: influence or determine “The vote in New Hampshire often decides the outcome of the Presidential election” Ro: a exercita o influen¸ta˘ – a determina (translation) to exercise influence – to determine Synset En: decide Ro: influen¸ta; decide; hota˘rî (translation) influence; decide; determine WordNet granularity free Gloss En: able to act at will; not hampered; not under compulsion or restraint; “free enterprise”; “a free port”; “a free country”; “I have an hour free”; “free will”; “free of racism”; “feel free to stay as long as you wish”; “a free choice” Ro: (Despre oameni) Care are posibilitatea de a ac¸tiona dupa˘ voin¸ta sa– dea face sau dea nu face ceva; (translation) (About people) Someone who can act according to his will – who can do or not do something Synset En: free Ro: liber (translation) free may represent vessels of subjectivity transfer into other languages, thus providing an anchor to generating subjectivity annotated lexica in a target language.</S>
			<S sid ="53" ssid = "22">Since not all senses have the same subjectivity label across languages, we describe below in more detail the various scenarios we encountered.</S>
			<S sid ="54" ssid = "23">In the remainder of this article, English is abbreviated as En and Romanian as Ro.</S>
			<S sid ="55" ssid = "24">2.1.</S>
			<S sid ="56" ssid = "25">Differences between languages.</S>
			<S sid ="57" ssid = "26">There were several examples where the subjectivity label changed between languages.</S>
			<S sid ="58" ssid = "27">For instance, the fourth sense of the noun argument, as listed in Table 1, is marked in the English data as subjective, since it represents an essay where “you take a position on a debatable topic and attempt to change readers’ minds about it.</S>
			<S sid ="59" ssid = "28">The more persuasive your argumentative essay, the more likely readers will be to concede your points and grant your conclusion.”4 Instead, the Romanian gloss and synset for this word denote a “direct summary,” which by definition disallows the expression of any subjective perspective.</S>
			<S sid ="60" ssid = "29">Therefore, in Romanian this sense is objective.</S>
			<S sid ="61" ssid = "30">A similar scenario is posed by the fourth sense of the verb decide (also listed in Table 1).</S>
			<S sid ="62" ssid = "31">While the English sense is labeled as objective, as its meaning denotes causality, the Romanian sense directly implies a subjective decision, and therefore acquires a subjective label.</S>
			<S sid ="63" ssid = "32">2.2.</S>
			<S sid ="64" ssid = "33">WordNet granularity.</S>
			<S sid ="65" ssid = "34">In several cases, the same sense in WordNet may have both subjective and objective meanings.</S>
			<S sid ="66" ssid = "35">To exemplify, let us consider the first sense of the adjective free, as shown in Table 1.</S>
			<S sid ="67" ssid = "36">While the English sense can have both subjective and objective uses, the Romanian sense is subjective, as it further enforces the constraint that the context of the word should refer to people.</S>
			<S sid ="68" ssid = "37">From these examples, we notice that a perfect sense to sense mapping among languages is impossible, as a particular sense may denote additional meanings and uses in one language compared to another.</S>
			<S sid ="69" ssid = "38">However, in our annotation study about 90% of the senses maintained their subjective meaning across languages, implying that this information can be leveraged in an automatic fashion to provide additional clues for the subjectivity labeling of unseen senses.</S>
			<S sid ="70" ssid = "39">4 Writing literary arguments –http://academic.cengage.com/resource uploads/downloads/1413022812 59427.pdf..</S>
	</SECTION>
	<SECTION title="Multilingual subjectivity sense learning. " number = "3">
			<S sid ="71" ssid = "1">In our previous work exploring the ability of multilingual models to better capture subjectivity at the sentence level (Banea et al., 2010), which was conducted on six languages, namely English, Arabic, German, Romanian, Spanish and French, we noticed that simultaneously considering features originating from multiple languages results in error rate reductions ranging from 5% for English to 15% for Arabic, as compared to the monolingual model baselines.</S>
			<S sid ="72" ssid = "2">The experiments also showed that the maximum improvement is achieved when the multilingual model is built over the expanded feature space comprising the vocabulary of all six languages.</S>
			<S sid ="73" ssid = "3">This observation became the catalyst for the work presented here, as it seeks to explore whether the task of sense level subjectivity classification can also benefit from being modeled with a multilingual perspective in mind, and compare it to a monolingual baseline.</S>
			<S sid ="74" ssid = "4">Thus, in this section we explore ways to use a multilingual learning mechanism to automatically predict the subjectivity of a word sense.</S>
			<S sid ="75" ssid = "5">We experiment with two methods.</S>
			<S sid ="76" ssid = "6">The first one is based on cross-lingual training using monolingual feature spaces.</S>
			<S sid ="77" ssid = "7">This method uses the output of individually trained monolingual classifiers paired with a set of constraints to reach an overall decision.</S>
			<S sid ="78" ssid = "8">The second method introduces a learner that is trained on a multilingual feature space, and whose decision is automatically inferred.</S>
			<S sid ="79" ssid = "9">Ultimately, we seek to understand whether, under this scenario, a classifier is able to make a better decision by having access to the entire feature set.</S>
			<S sid ="80" ssid = "10">We start by considering the intersection of the Romanian and English WordNets, so that we can have equivalent senses (including their definitions and synsets) in both languages.</S>
			<S sid ="81" ssid = "11">We were thus able to obtain 19,124 unique synsets.</S>
			<S sid ="82" ssid = "12">We then generate vectorial representations for two monolingual models (one in English and one in Romanian), and one multilingual model (comprising both Romanian and English features).</S>
			<S sid ="83" ssid = "13">These are composed of uni-grams extracted from a synset and its gloss, appended with a binary weight.</S>
			<S sid ="84" ssid = "14">The synset is stripped of any sense identifying features5 in order not to favor the classifier.</S>
			<S sid ="85" ssid = "15">To exemplify, we provide below the sparse vector representation of the fourth sense of the noun argument (see Table 1 for its original gloss and synset in English and Romanian): English vector: &lt;aen 1, summary 1, of 1, the 1, subject 1, or 1, plot 1, literary 1, work 1, play 1, movie 1, editor 1, added 1, argument 1, to 1, poem 1&gt; Romanian vector: &lt;redare 1, prezentare 1, pe 1, scurt 1, scrisa 1, orala 1, aro 1, ideilor 1, unei 1, lucrari 1, ale 1, expuneri 1, etc 1, rezumat 1&gt; Multilingual vector: &lt;aen 1, summary 1, of 1, the 1, subject 1, or 1, plot 1, literary 1, work 1, play 1, movie 1, editor 1, added 1, argument 1, to 1, poem 1, redare 1, prezentare 1, pe 1, scurt 1, scrisa 1, orala 1, aro 1, ideilor 1, unei 1, lucrari 1, ale 1, expuneri 1, etc 1, rezumat 1&gt; Traditionally, the subjectivity content of an entity, be it word, sentence, or document, is regarded as a binary decision (either subjective or objective).</S>
			<S sid ="86" ssid = "16">In this paper, we mimic its occurrence in natural language, and we represent it on a continuum, where 0 is at one end of the spectrum and represents full objectivity, while 1 is at the other end, and denotes full subjectivity.</S>
			<S sid ="87" ssid = "17">We establish a zone of 0.4 from the left and right of our spectrum, and we consider the synsets whose scores fall in these ranges as objective (if below 0.4) or subjective (if above 0.6).</S>
			<S sid ="88" ssid = "18">This allows us to have a buffer zone of 0.2 (above 0.4 and below 0.6), which contains samples that may be considered too vague to be clearly labeled for subjectivity.</S>
			<S sid ="89" ssid = "19">Because a typical classification approach does not lend itself to being employed under a gradient subjectivity content paradigm (unless mapping the numeric scores to nominal buckets), in order to run the experiments we use a linear regression algorithm,6 which extrapolates from the data and infers a subjectivity score for every synset.</S>
			<S sid ="90" ssid = "20">3.1.</S>
			<S sid ="91" ssid = "21">Cross-lingual learning.</S>
			<S sid ="92" ssid = "22">The first method focuses on cross-lingual learning (CL).</S>
			<S sid ="93" ssid = "23">Based on the co-training algorithm proposed by Wan (2008), we consider the manually annotated training data in each of the languages individually, and we learn two monolingual regression algorithms (see Fig.</S>
			<S sid ="94" ssid = "24">1, (1)7 ).</S>
			<S sid ="95" ssid = "25">For every sample in the unlabeled data (2), we allow the machine learners to individually predict a score (3), and at every iteration maintain two sets with the top n most confident 5 We only keep the lemma for the words in the synset when we add them to the vectorial representation of a given sense; we do not include any information on the part-of-speech or sense number.</S>
			<S sid ="96" ssid = "26">6 Included with the Weka machine learning distribution (Hall et al., 2009)..</S>
			<S sid ="97" ssid = "27">7 The numbers or symbols between parentheses refer to the indices included in the figures..</S>
			<S sid ="98" ssid = "28">Fig.</S>
			<S sid ="99" ssid = "29">1.</S>
			<S sid ="100" ssid = "30">Cross-lingual bootstrapping.</S>
			<S sid ="101" ssid = "31">objective and subjective examples, respectively.</S>
			<S sid ="102" ssid = "32">These sets are ordered based on the average of the predictions coming from the English and Romanian learners, which must also fall within the same range (i.e. both below 0.4 or both above 0.6), thus signaling that both learners agree.</S>
			<S sid ="103" ssid = "33">As long as the sets are not empty (4), at the next iteration the monolingual English vectors and the aligned Romanian vectors are added to their respective training set (+) appended with their adjusted subjectivity score, and removed from their respective test set (−); otherwise the bootstrapping terminates.</S>
			<S sid ="104" ssid = "34">Although the method differs from the original co-training mechanism proposed by Blum and Mitchell (1998), since it enforces that both predictions fall in the same range before adding the samples to the next train set, we believe this was a necessary modification given the extremely short contexts available, and the low accuracy attained by the English and Romanian classifiers by themselves (67.66% and 70.28%, respectively).</S>
			<S sid ="105" ssid = "35">Through this additional agreement constraint, we ensure that only samples that have a high probability of being labeled correctly are added, therefore reducing noise propagation across iterations.</S>
			<S sid ="106" ssid = "36">At the same time, we are able to learn new information from the features co-occurring with those that participated in the previous classification step.</S>
			<S sid ="107" ssid = "37">3.2.</S>
			<S sid ="108" ssid = "38">Multilingual learning.</S>
			<S sid ="109" ssid = "39">The second method employs multilingual learning (ML) (see Fig.</S>
			<S sid ="110" ssid = "40">2).</S>
			<S sid ="111" ssid = "41">We create a multilingual feature space based on the model proposed in Banea et al.</S>
			<S sid ="112" ssid = "42">(2010).</S>
			<S sid ="113" ssid = "43">As mentioned earlier, in that work, instead of using the monolingual feature vectors to represent the sentences, we used a multilingual space combinining features drawn from up to six languages.</S>
			<S sid ="114" ssid = "44">Similarly, here, instead of using the monolingual vectors described above, we enrich the feature space by merging together two aligned vector space representations (see the multilingual vector example above), thus allowing the system to simultaneously use both Romanian and English features in order to decide the subjectivity of a given Fig.</S>
			<S sid ="115" ssid = "45">2.</S>
			<S sid ="116" ssid = "46">Multilingual bootstrapping.</S>
			<S sid ="117" ssid = "47">sense.</S>
			<S sid ="118" ssid = "48">We train the multilingual learner (1) and for every sample in the testing set (2), we predict a subjectivity score (3).</S>
			<S sid ="119" ssid = "49">As we did for the cross-lingual learning setup, at every iteration we select the most confident n objective and n subjective samples (4), and add them to the training set (+), while discarding them from the test set for the next iteration (−).</S>
			<S sid ="120" ssid = "50">For both methods, the score of the new samples that are added to the train set during each iteration is mapped to either 0 (objective) or 1 (subjective), the determination being made based on the range in which the original score fell (i.e. if an instance initially received a score of 0.3, since it falls in the objective range its adjusted score will be 0, and the instance will be added to the next iteration training set with this score).</S>
			<S sid ="121" ssid = "51">This allows all the training samples to equally participate in the decision process at every iteration, instead of their novel features being penalized due to being absent from the initial training step.</S>
			<S sid ="122" ssid = "52">For our experiments, we conducted 20 iterations for both methods and added 50 subjective and 50 objective samples at each iteration.</S>
			<S sid ="123" ssid = "53">Additional iterations would have been possible, but we decided to stop given the drop in performance of the Romanian learner embedded in the cross-lingual model.</S>
			<S sid ="124" ssid = "54">3.3.</S>
			<S sid ="125" ssid = "55">Datasets.</S>
			<S sid ="126" ssid = "56">We use the manually annotated data described in Section 2, from which we remove 20 examples that were labeled as both objective and subjective in either English or Romanian, since they could confuse the classifiers and prevent them from making strong predictions.8 We then split the labeled data into three subsets to enable threefold cross validation.</S>
			<S sid ="127" ssid = "57">As these subsets are biased towards the objective class in a ratio of 2:1, we randomly discard about half of the objective samples to be included in the fold for each training set in order to obtain balanced training folds, thus allowing our experiments to not be skewed towards any of the classes.</S>
			<S sid ="128" ssid = "58">Note that we did not balance the test sets.</S>
			<S sid ="129" ssid = "59">Also, throughout every iteration the class balance is maintained as an equal number of subjective and objective samples are added to the next train set.</S>
			<S sid ="130" ssid = "60">Each fold comprises an initial train set of 328 samples and a test set of 164 samples, on which the evaluations for the respective fold are carried out.</S>
			<S sid ="131" ssid = "61">In order to generate a running test set for each fold, we append the remaining unlabeled WordNet senses to each test fold (see Figs.</S>
			<S sid ="132" ssid = "62">1 and 2, (2)).</S>
			<S sid ="133" ssid = "63">These running test sets are used to provide the learners with novel samples (and features) throughout the bootstrapping process.</S>
			<S sid ="134" ssid = "64">We only used 328 training examples because there is a very limited amount of subjectivity data manually annotated at the sense level in English, which moreover, needs to be mirrored in the Romanian WordNet, which has far less coverage (and thus 8 We did not remove those synsets that had conflicting labels across languages..</S>
			<S sid ="135" ssid = "65">0.8 E n C L o v e r a l l R o C L o v e r a l l 0.7 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Number of iterations Fig.</S>
			<S sid ="136" ssid = "66">3.</S>
			<S sid ="137" ssid = "67">Macro-accuracy for cross-lingual bootstrapping.</S>
			<S sid ="138" ssid = "68">lower overlap) vis-à-vis the English WordNet.</S>
			<S sid ="139" ssid = "69">A similar issue will be encountered by most (if not all) of the WordNets developed for languages other than English.</S>
			<S sid ="140" ssid = "70">From the 580 manually annotated English senses, approximately 500 had an equivalent in the Romanian WordNet.</S>
			<S sid ="141" ssid = "71">For this reason, in our experiments we used all the training examples we could have for both our methods as well as the baseline, that would also allow for the existence of a small test set so that we can evaluate our results.</S>
			<S sid ="142" ssid = "72">3.4.</S>
			<S sid ="143" ssid = "73">Results and discussion.</S>
			<S sid ="144" ssid = "74">For the subsequent evaluations, the accuracy and F-measure are calculated based on the score predicted by the linear regression algorithm for every test sample.</S>
			<S sid ="145" ssid = "75">If the score is higher than 0.5, the sample is considered to belong to the subjective class, otherwise it belongs to the objective class (thus we predict a label for each instance of the test data).</S>
			<S sid ="146" ssid = "76">The subjectivity continuum described in Section 3 is only used internally by the cross-lingual / multilingual bootstrapping methods, since its principal aim is to reduce noise propagation across iterations.</S>
			<S sid ="147" ssid = "77">Fig.</S>
			<S sid ="148" ssid = "78">3 presents the results obtained using the cross-lingual learning algorithm over 20 iterations.</S>
			<S sid ="149" ssid = "79">The accuracies obtained at position 0 represent the baseline for a simple monolingual classifier with no co-training.</S>
			<S sid ="150" ssid = "80">As we notice from both trendlines, the accuracy for the first 17 iterations is always higher or within 0.56% of the baseline.</S>
			<S sid ="151" ssid = "81">After the 17th iteration, The Romanian learner drops fast in accuracy, loosing 3.72% over the last three iterations; however, the English learner maintains its robustness and in the last iteration is still 2.43% over the baseline.</S>
			<S sid ="152" ssid = "82">This implies that learners in each of the languages are able to build upon one another and strengthen their prediction, compared to the monolingual scenario; furthermore, they are able to lessen the effect of noise generated at each run, being able to label 1700 additional test samples (representing more than five times the original training set) with over 69% accuracy in both languages.</S>
			<S sid ="153" ssid = "83">It is interesting to note that the Romanian learner outperforms the English one throughout all but the last three iterations; a similar trend was noticed when carrying machine learning subjectivity experiments at the sentence level in English and Romanian (Banea et al., 2008a), which was hypothesized to be caused by overt markers of formality and politeness, inflections due to verb mood, and noun and adjective number, gender, and case available in Romanian.</S>
			<S sid ="154" ssid = "84">Our results seem to further support the hypothesis that subjectivity analysis is an easier task in Romanian proposed by Banea et al.</S>
			<S sid ="155" ssid = "85">(2008a).</S>
			<S sid ="156" ssid = "86">The highest joint accuracy is obtained during the 4th iteration, and it represents a 3.54% improvement over the baseline.</S>
			<S sid ="157" ssid = "87">When we analyze the class behavior (see Fig.</S>
			<S sid ="158" ssid = "88">4), we notice that the objective samples are more correctly predicted by both learners (an F-measure range from 72% to 78%), when compared to the subjective ones (falling in the 59% to 69% range) irrespective of the underlying language.</S>
			<S sid ="159" ssid = "89">This is probably the case because glosses and synsets are generally short, and as objectivity is defined through the absence of subjectivity, shorter contexts have a lower probability of containing the manifestation of a private state in comparison to longer ones.</S>
			<S sid ="160" ssid = "90">In order to understand whether a multilingual vectorial feature space allows for better automatic classification decisions when compared to those taken as a result of heuristics or rules (such as cross-lingual training), we conduct a similar experiment, this time on multilingual vectors, and allow the linear regression algorithm to provide a score.</S>
			<S sid ="161" ssid = "91">0.8 E n C L o b j E n C L s u b j R o C L o b j R o C L s u b j 0.7 0.6 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Number of iterations Fig.</S>
			<S sid ="162" ssid = "92">4.</S>
			<S sid ="163" ssid = "93">F-measure for the objective and subjective classes for cross-lingual bootstrapping.</S>
			<S sid ="164" ssid = "94">As seen in Fig.</S>
			<S sid ="165" ssid = "95">5, the multilingual based learner surpasses the cross-lingual based algorithm in all 20 iterations for both languages.</S>
			<S sid ="166" ssid = "96">Instead of having access to only a fragmented view (as the cross-lingual individual learners use only a monolingual space to make a decision), the multilingual learner has access to the entire feature space, which it uses more proficiently to model subjectivity and thus makes better predictions.</S>
			<S sid ="167" ssid = "97">Thus, if the baseline for subjectivity classification was 67.66% for English and 70.28% for Romanian, upon having access to the merged feature space, the accuracy for both of them increases to 73.98% (before any iteration takes place), which represents an improvement of 6.32% for English and 3.7% for Romanian.</S>
			<S sid ="168" ssid = "98">Upon allowing the cumulative effect of this modeling to echo through the iterations, the best results are noticed in iterations 3 and 4, at over 77% accuracy for both languages.</S>
			<S sid ="169" ssid = "99">We also look at the class behavior under the multilingual settings (see Fig.</S>
			<S sid ="170" ssid = "100">6).</S>
			<S sid ="171" ssid = "101">Both the subjective and the objective F-measures are higher than their corresponding F-measures obtained for either English or Romanian.</S>
			<S sid ="172" ssid = "102">Furthermore, the subjective F-measure increases to over 70% across all the iterations, while the objective one is always higher than 75.6%.</S>
			<S sid ="173" ssid = "103">In iterations 3 and 4, the objective F-measure is 80%, while the subjective one is 72.7%.</S>
			<S sid ="174" ssid = "104">We should also note that while improvement is experienced for both the objective and subjective classes, a major gain is observed for the latter.</S>
			<S sid ="175" ssid = "105">We are not aware of any other work that considered the task of word sense subjectivity labeling in a cross-lingual setting, and thus no direct comparison with previous work can be performed.</S>
			<S sid ="176" ssid = "106">The work closest to ours is the subjectivity word sense disambiguation method proposed in Akkaya et al.</S>
			<S sid ="177" ssid = "107">(2009), where on a set of 83 English words, an accuracy of 88% was observed; and the method proposed in Su and Markert (2009), where an accuracy of 84% was obtained on another dataset of 298 words.</S>
			<S sid ="178" ssid = "108">These results are however not directly comparable to ours, as they are applied on different datasets, with different levels of difficulty.</S>
			<S sid ="179" ssid = "109">0.8 EnRo-ML-overall E n C L o v e r a l l R o C L o v e r a l l 0.7 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Number of iterations Fig.</S>
			<S sid ="180" ssid = "110">5.</S>
			<S sid ="181" ssid = "111">Macro-accuracy for multilingual bootstrapping (versus cross-lingual framework).</S>
			<S sid ="182" ssid = "112">0.9 0.8 E n R o M L o b j E n R o M L s u b j E n C L o b j E n C L s u b j R o C L o b j R o C L s u b j 0.7 0.6 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Number of iterations Fig.</S>
			<S sid ="183" ssid = "113">6.</S>
			<S sid ="184" ssid = "114">F-measure for the objective and subjective classes for multilingual bootstrapping (versus cross-lingual framework).</S>
			<S sid ="185" ssid = "115">We further conduct a qualitative study by applying feature selection based on information gain,9 and keeping the top 100 features (the study was conducted on the training set generated after the tenth iteration carried out on the third fold).</S>
			<S sid ="186" ssid = "116">The subjective entries are listed in Table 2 in order of appearance and they show several interesting trends.</S>
			<S sid ="187" ssid = "117">First, among the monolingual attributes, the Romanian feature space allows for a more robust selection of subjective words, when compared to the fewer subjective entries in the English set.</S>
			<S sid ="188" ssid = "118">This is particularly surprising because Romanian is a highly inflected language, and a larger unlemmatized corpus would be needed to extract similar co- occurrence patterns when compared to English.</S>
			<S sid ="189" ssid = "119">However, this particularity was previously signaled computationally in Fig.</S>
			<S sid ="190" ssid = "120">6, where the subjective F-measure for Romanian is always higher than the subjective F-measure for English.</S>
			<S sid ="191" ssid = "121">Second, when looking at the multilingual attributes we notice that approximately 33% of them are translations of each other (marked in italics in Table 2).</S>
			<S sid ="192" ssid = "122">This shows that the multilingual feature space is able to rely on double co-occurrence metrics learned from equivalent sense definitions, thus allowing a stronger and more accurate prediction to form.</S>
			<S sid ="193" ssid = "123">This fact is also noticed in Fig.</S>
			<S sid ="194" ssid = "124">6, where the multilingual regression model surpasses the monolingual one by 6.4 subjective F-measure percentage points on average for English, and 3.8 for Romanian, respectively (the average is computed across all folds and iterations).</S>
			<S sid ="195" ssid = "125">Third, more than half of the top 100 features obtained as a result of filtering the monolingual and multilingual models using information gain are not subjective from a human annotator’s point of view.</S>
			<S sid ="196" ssid = "126">This shows that the regression algorithm relies on objective markers, thus explaining the improved performance in correctly identifying the objective class, as noticed in Fig.</S>
			<S sid ="197" ssid = "127">6.</S>
			<S sid ="198" ssid = "128">It is interesting to note that using a multilingual space mainly helps the subjective class, as the objective class average F-measure improves by an average of 3.3% with respect to both monolingual models (the average is computed across all folds and iterations).</S>
			<S sid ="199" ssid = "129">Fourth, both the monolingual Romanian space and the multilingual English–Romanian space contain the subjunctive mood particle sa˘ that is unique to Romanian.</S>
			<S sid ="200" ssid = "130">Subjunctive is a grammatical verbal mood used to mark ideas that are subjective or uncertain, such as emotions, doubts, opinions, judgements, etc., and it provides a unique marker for subjectivity.</S>
			<S sid ="201" ssid = "131">It typically appears in subbordinate sentences.</S>
			<S sid ="202" ssid = "132">In English, the form of a verb in subjunctive does not carry any particular markers that allows for an easy recognition of this mood: I suggest 1 / that Jenny exercise several times a week.2 / In this example, exercise is a verb in the subjunctive mood.</S>
			<S sid ="203" ssid = "133">It is not the indicative form, since Jenny is not actually exercising, but rather encodes a hypothetical wish enounciated by the speaker with regards to Jenny.</S>
			<S sid ="204" ssid = "134">The indicative form would have required that the proper agreeement between the subject she and the verb be marked through the suffix -s.</S>
			<S sid ="205" ssid = "135">While English does not entail observable morphological changes in the form of the verb, in Romanian verbs in subjunctive are marked through the particle sa˘ that preceeds the verb.</S>
			<S sid ="206" ssid = "136">This particle occurs uniquely in front of a verb in subjective mood.</S>
			<S sid ="207" ssid = "137">The example above becomes in Romanian: 9 Implementation included in the Weka machine learning distribution (Hall et al., 2009)..</S>
			<S sid ="208" ssid = "138">Table 2 Sample of subjective features appearing in the top 100 discriminant attributes selected with Information Gain on the 3rd fold training data at iteration 10.</S>
			<S sid ="209" ssid = "139">The words in italics in the multilingual features represent equivalent translations in English and Romanian..</S>
			<S sid ="210" ssid = "140">Monolingual features Multilingual features Engl ish R o m a n i a n E n g l i s h &amp; R o m a n i a n feeli ng s e n t i m e n t ( E n : f e e l i n g ) f e e l i n g state s t a r e ( E n : s t a t e ) s e n t i m e n t quali ty l i p s a ˘ ( E n : l a c k ) m a i ( E n : m o r e ) ment al a t i t u d i n e ( E n : a t t i t u d e ) l i p s a ˘ ( E n : l a c k ) feel s u f e r i n ¸ t a ˘ ( E n : s u f f e r i n g ) s t a t e emot ion b o a l a ˘ ( E n : d i s e a s e ) n o t emot ional s i m ¸ t i ( E n : f e e l ) s a ˘ ( s u b j u n c t i v e m o o d p a r t i c l e ) pain i d e e ( E n : i d e a ) a t i t u d i n e ( E n : a t t i t u d e ) no a n u m i t ( E n , a d j . : c e r t a i n ) s t a r e ( E n : s t a t e ) hit s u f l e t e a s c a ˘ ( E n , a . , f e m . : p e r t a i n i n g t o t h e s o u l ) g o o d good i n t e r e s ( E n : i n t e r e s t ) q u a l i t y mind î n ¸ t e l e g e ( E n : u n d e r s t a n d ) n o great p a ˘ r e r e ( E n : o p i n i o n ) m e n t a l self m o r a l a ˘ ( E n : m o r a l ) d i f e r i t e ( E n : d i f f e r e n t ) regar d s a t i s f a c ¸ t i e ( E n : s a t i s f a c t i o n ) f e e l impo rtant m u l ¸ t u m i r e ( E n : c o n t e n t m e n t ) s i m ¸ t i ( E n : f e e l ) judg ment i m p o r t a n t a ˘ ( E n : i m p o r t a n t ) l a c k lack b u n a ˘ ( E n , a . , f e m . : g o o d ) t r u e true p a ˘ r a ˘ s i ( E n : a b a n d o n ) s u f l e t e a s c a ˘ ( E n , a . , f e m . : p e r t a i n i n g t o t h e s o u l ) suffe ring p r o v o c a t a ˘ ( E n , a . , f e m . : p r o v o k e d ) p a i n lacki ng n e l i n i s ¸ t e ( E n : t u r m o i l ) r e g a r d opini on p r o b l e m e ( E n , n . , p l . : p r o b l e m s ) s u f e r i n ¸ t a ˘ ( E n : p a i n ) state ment s t i m a ˘ ( E n : e s t e e m ) s e l f trait a f e c ¸ t i u n e ( E n : a f f e c t i o n ) î n c r e d e r e ( E n : t r u s t ) disp ositi on i z b i ( E n : s m a s h ) î n ¸ t e l e g e ( E n , v . , 3 r d p e r s o n , s g . : u n d e r s t a n d ) conc ern b r u s c ( E n : s u d d e n l y ) t r a i t extre me d i s p o z i ¸ t i e ( E n : m o o d ) i m p o r t a n t felt s t a r e a ( E n , d e t e r m i n e d : s t a t e ) d o r i n ¸ t a ˘ ( E n : d e s i r e ) distr ess s a ˘ ( s u b j u n c t i v e m o o d p a r t i c l e ) l a c k i n g socia l c a l i t a t e ( E n : q u a l i t y ) pleas ure î n ¸ t e l e g e r e ( E n , n o u n : u n d e r s t a n d i n g ) inten se t u l b u r a r e ( E n : p e r t u r b a t i o n ) belie f s i m t ( E n , v . , 1 s t p e r s o n , s g . : f e e l ) dang er a c o r d ( E n : a g r e e m e n t ) feeli ngs d u r e r e ( E n : p a i n ) argu ment v a l o a r e ( E n : v a l u e ) pers onal e m o ¸ t i e ( E n : e m o t i o n ) attitu de a g i t a ¸ t i e ( E n : a g i t a t i o n ) r e s p e c t ( E n : r e s p e c t ) î n c r e d e r e ( E n : t r u s t ) n e c a z ( E n : m i s f o r t u n e ) s p i r i t ( E n : m i n d ) î n s u s ¸ i r e ( E n : t r a i t ) Sugerez1 / ca Jenny s. ˘a. faca˘ mis¸care de câteva ori pe sa˘pta˘mâna˘.</S>
			<S sid ="211" ssid = "141">2 / where the dotted line marks the particle sa˘ . The particle appears in the ranked Romanian attribute selection list in position 75, yet upon learning from the multilingual space it becomes a highly distinguishing feature, earning the position 29.</S>
			<S sid ="212" ssid = "142">This represents one unique example of a way in which a language provides valuable input to accurately classifying subjectivity in another language.</S>
			<S sid ="213" ssid = "143">Our case study provides evidence that a multilingual feature space representation of subjectivity at the sense level allows for a more robust modeling than when considering each language individually.</S>
			<S sid ="214" ssid = "144">Subjectivity clues seem to be able to permeate from each language and simultaneously participate in joint decisions, thus making stronger and more accurate predictions.</S>
			<S sid ="215" ssid = "145">As private states tend to remain the same across languages (see our manual annotation study in Section 2), this Research strengthens the hypothesis that subjectivity is a language independent phenomenon, and as such, it can only gain a stronger contour when considering its emergence from across a number of languages.</S>
			<S sid ="216" ssid = "146">While we were not able to conduct a study on the difference in performance when using different language pairs for sense subjectivity annotations, mainly because we did not have the required sense resources in other languages, however our previous work on subjectivity at sentence level (Banea et al., 2010) seems to indicate that a more robust learning occurs when the languages are further apart.</S>
			<S sid ="217" ssid = "147">In that paper we learned subjectivity from up to 6 languages (English, German, Arabic, Spanish, French and Romanian) at a time, and it was interesting to note that in all combinations of six languages taken 2 through 4, English did not participate in the top performing combination (as it did in the monolingual model).</S>
			<S sid ="218" ssid = "148">Instead, it got replaced by the space generated by German and Spanish, which offered a better model for subjectivity.</S>
	</SECTION>
	<SECTION title="Related work. " number = "4">
			<S sid ="219" ssid = "1">Recently, resources and tools for sentiment analysis developed for English have been used as a starting point to build resources in other languages, via cross-lingual projections or monolingual and multilingual bootstrapping.</S>
			<S sid ="220" ssid = "2">Several directions were followed, focused on leveraging annotation schemes, lexicons, corpora and automated annotation systems.</S>
			<S sid ="221" ssid = "3">English annotation schemes developed for opinionated text lays the groundwork for research carried out by Esuli et al.</S>
			<S sid ="222" ssid = "4">(2008) when annotating expressions of private state in Italian or by Maks and Vossen (2010) in Dutch.</S>
			<S sid ="223" ssid = "5">Sentiment and subjectivity lexicons such as the one included with the OpinionFinder distribution (Wiebe and Riloff, 2005), the General Inquirer (Stone et al., 1966), or the SentiWordNet (Esuli and Sebastiani, 2006) were transferred into Chinese (Ku et al., 2006; Wu, 2008), Romanian (Mihalcea et al., 2007), and Italian (Esuli and Sebastiani, 2011).</S>
			<S sid ="224" ssid = "6">English corpora manually annotated for subjectivity or sentiment such as MPQA (Wiebe et al., 2005), or the multi- domain sentiment classification corpus (Blitzer et al., 2007) were subjected to experiments in Spanish, Romanian, or Chinese upon automatic translation by Banea et al.</S>
			<S sid ="225" ssid = "7">(2008b), Wan (2008).</S>
			<S sid ="226" ssid = "8">Furthermore, tools developed for English were used to determine sentiment or subjectivity labeling for a given target language by transferring the text to English and applying an English classifier on the resulting data.</S>
			<S sid ="227" ssid = "9">The labels were then transferred back into the target language (Bautin et al., 2008; Banea et al., 2008b).</S>
			<S sid ="228" ssid = "10">These experiments are carried out in Arabic, Chinese, French, German, Japanese, Spanish and Romanian.</S>
			<S sid ="229" ssid = "11">Esuli and Sebastiani (2011) did consider transferring automatically inferred polarity annotations at the sense level from the English SentiWordNet to Italian using MultiWordNet (Pianta et al., 2002)10 for the purpose of opinion extraction.</S>
			<S sid ="230" ssid = "12">Since their task was to annotate expressions of opinion, such as the opinion itself, the holder (the person expressing an opinion) and the target (the entity the opinion is about), they flattened the sense-level annotations by devising a cumulative word-level score representing the summation over all the senses of the positive and negative scores.</S>
			<S sid ="231" ssid = "13">In contrast, our work explores the ability of senses to maintain their subjectivity across languages, as well as allowing finer grained subjectivity lexical resources to be developed and enriched in other languages.</S>
			<S sid ="232" ssid = "14">This work is related to Banea and Mihalcea (2011) where we addressed the concept of subjectivity expressed at the sense level in multilingual settings, yet the results we obtained were mainly negative, and were unable to surpass the individual monolingual models using classification techniques.</S>
			<S sid ="233" ssid = "15">The present work differs as it envisions the task of subjectivity detection as a regression problem by allowing senses to be represented on a subjectivity continuum instead of a traditional binary decision.</S>
			<S sid ="234" ssid = "16">Furthermore, we show that we are able to surpass the results obtained on the original sets by implementing a bootstrapping approach.</S>
			<S sid ="235" ssid = "17">In terms of methodology, the work closest to ours is the one proposed by Wan (2008), who constructs a polarity co-training system by using the multilingual versions obtained through the automatic translation of product reviews into Chinese and English.</S>
			<S sid ="236" ssid = "18">Unlike Wan (2008), we do not use any machine translation, and the labels employed are directly assigned by the annotators and not inferred based on stars.</S>
			<S sid ="237" ssid = "19">Furthermore, we focus on subjectivity classification, and not on polarity.</S>
			<S sid ="238" ssid = "20">In Banea et al.</S>
			<S sid ="239" ssid = "21">(2008a) we present a method to learn sentence level subjectivity by training classifiers on multilingual feature spaces and show that when considering features from multiple languages, the classification accuracy improves, even above that of the source language.</S>
			<S sid ="240" ssid = "22">We 10 MultiWordNet is a lexical resource that is part of the multilingual WordNet family, and thus follows the WordNet structure and alignment and.</S>
			<S sid ="241" ssid = "23">is developed for Italian.</S>
			<S sid ="242" ssid = "24">expand this method to allow for bootstrapping and to be employed at the sense level, thus enabling additional samples to be classified.</S>
	</SECTION>
	<SECTION title="Conclusion. " number = "5">
			<S sid ="243" ssid = "1">We conducted a case study seeking to assess subjectivity transfer across languages following sense aligned resources.</S>
			<S sid ="244" ssid = "2">In our annotation experiments the subjectivity content of a sense carried across language boundaries in about 90% of the cases, implying that this information is robust enough to be learned automatically.</S>
			<S sid ="245" ssid = "3">We then proposed and applied a framework that is able to jointly exploit the subjectivity information originating from multiple languages.</S>
			<S sid ="246" ssid = "4">We demonstrated that learning from a multilingual feature space is able to capture more information and outperforms cross-lingual learning based on monolingual vectorial models, while also allowing for even better results to be obtained upon bootstrapping.</S>
			<S sid ="247" ssid = "5">The data we developed for this work as well as the code will be made publicly available.</S>
	</SECTION>
	<SECTION title="Acknowledgments">
			<S sid ="248" ssid = "6">This material is based in part upon work supported by National Science Foundation awards #0917170 and #0916046.</S>
			<S sid ="249" ssid = "7">Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.</S>
	</SECTION>
</PAPER>
