2008 Workshop on Knowledge Discovery and Data Mining





Grasping Related Words of Unknown Word for Automatic Extension of
Lexical Dictionary





Myunggwon Hwang 
Intelligent Computing Lab. 
Gwangju, Korea 
mghwang@chosun.ac.kr

Sunkyoung Baek Intelligent 
Computing Lab. Gwangju, 
Korea 
Zamilla100@chosun.ac.kr

Junho Choi Intelligent 
Computing Lab. Gwangju, 
Korea spica@chosun.ac.kr


Jongan 
Park
Dept. of Information & 
Communication Gwangju, Korea 
japark@chosun.ac.kr

Pankoo 
Kim
Dept. of Computer 
Engineering Gwangju, 
Korea pkkim@chosun.ac.kr








Abstract

   An aim of this research is to grasp related words of 
unknown word. Currently, several lexical dictionaries 
have been developed for semantic retrieval such as 
WordNet  and  FrameNet.  However,  more  new  words 
are created in every day because of new trends, new 
paradigm, new technology, etc. And, it is impossible to 
contain all of these new words. The existing methods, 
which grasp the meaning of unknown word, have a 
limitation that is not exact. To solve this limitation, we 
have studied the way how to make relations between 
known words and unknown word. As a result, we found 
a noble method using co-occurrence, WordNet and 
Bayesian  probability.  The  method  could  find  what 
words are related with unknown word and how much 
weight other words relate with unknown word.

1. Introduction

   This paper deals with a research for real semantic 
information  retrieval with understanding  all of words 
in the document. Many lexical dictionaries have been 
developed   to   overcome   the   limitation   of   current 
retrieval  methods  which  use  a  simple  keyword 
matching  using  probability,  but  it  is  impossible  to


contain words generated everyday by new trends, new 
items and new technologies. So, to guess the meaning of  
these  unknown  words,  which  are  not  defined  in lexical  
dictionaries,  many  researchers  have  studied using 
several ways such as co-occurrence, TF-iDF or learning   
methods.   These   researches   for   unknown words   show   
much   advanced   result   but,   have   a limitation that 
could not find related words with unknown word.
   This  paper   addresses   research   to  grasp   related 
words of unknown word for automatic extension of lexical 
dictionary with getting over the limitation. Known words 
occurring in a document may have only one meaning, but, 
generally have many meanings and relations  between  
other words. Unknown  words also can have many 
meanings and relations with known words  which  are  
defined  in  lexical  dictionary. However, existing 
researches have concentrated on methods to define a 
meaning of unknown word or to find  a  base  class  
(super-class)   of  unknown  word, which is considered as 
instance. So, in this paper, we have  studied  what  words  
are  related  with  unknown word   and   how   much   
weight   is   related   between unknown word and known 
word. To do this, we have used the Word-Net that is 
lexical dictionary, co- occurrence and Bayesian 
probability. We implemented






0-7695-3090-7/08 $25.00 © 2008 IEEE	31
DOI 10.1109/WKDD.2008.151



a  system  depending   on  this  research.  The  results 
showed that this research is very valuable and noble.
This   paper   organized    as   follows:   Section   2



Step 	Contents

- Creating a group of related nouns


introduces   our   main   discourse.   Section   3   shows 
experimental    result   and   evaluation.    Finally,    we
summarize this study in Section 4.


Making a Related
Noun Group


- Calculating Bayesian probability of the group




2. Proposed Method

   When  we  are  reading,  we  meet  UWs  (unknown 
word)  often.  We  can  guess  the  meaning  or  related 
words easily without referring to a dictionary. Because 
the explanation or the definition of UW occurs in the 
same sentence using related words. In other words, 
meaning of UW can be found generally through co- 
occurrence  words  [5].  Especially,  a  noun  word  has 
much meaning than other part of speeches, so, plays 
core role in understanding document [3]. In this way, 
we can guess UWs using co-occurred noun words. 
However, a computer has many limitations to grasp the 
meaning of UW exactly. So, we focused on finding 
related words with UW before grasping the meaning of 
UW, which is an obstacle in NLP research area.
We   define   an  UW   as  word   not  contained   in
WordNet  v2.0 as English lexical dictionary.  And we 
have researched based on following assumptions.
Assumptions:
• The semantically nearest words from UW occur


Normalization 	- Normalizing the Bayesian 
probability of group

2.1. Pre-Processing

   To extract noun words from sentences, first we need 
PoS tagging. We employed the PoSTagger [1] that is 
possible to tag PoS quite exactly. It just tags the PoS of 
each word, so, we need to grasp compound noun, which 
occurs   using   sequential   nouns   in  a  sentence.   For 
example, if a noun ‘football’ and a noun ‘player’ occur 
sequentially,   we   generate   ‘football’,   ‘player’,   and,
‘football_player’   to  match   those  into  WordNet.   If
WordNet contains a compound noun ‘football_player’ 
then, ‘football’ and ‘player’ will exclude in a part to 
measure a weight. Chapter 2.4 deals with this problem. 
After these steps, a stemming, which is a process to find 
an original form of inflected word, is added. Table 2 
shows the result of this pre-processing. The sentence in 
table  2 is  a part  of  a document  about  soccer  player
‘Zidane’ from WIKIPEDIA [2].

Table  2. The result of pre-processing
Zinedine Yazid Zidane, popularly nicknamed


in the same sentence.
• UW can have many meanings and many relations 
with   known   words   those   are   defined   in   a
dictionary.

   In this chapter, we present our proposed method 
through several steps. Table 1 shows each step and 
summary. And, the following sub-chapters explain the 
detail contents about table 1.

Table  1. Overall steps of proposed method

Step 	Contents

- PoS Tagging


Sentence





PoS Tagging




Extracted
Nouns


Zizou, is a French football player of Algerian
descent,  famous  for  leading  France  to winning the 1998 
World Cup.
Zinedine/NNP Yazid/NNP Zidane/NNP, popularly/RB 
nicknamed/VBN Zizou,/NNP is/VBZ  a/DT  French/JJ  
football/NN player/NN   of/IN   Algerian/NNP descent,/NNP 
famous/JJ for/IN leading/VBG France/NNP   to/TO   
winning/VBG   the/DT
1998/CD World/NNP Cup/NNP
Zinedine, Yazid,   Zidane, Zinedine_Yazid, Yazid_Zidane, 
Zizou, football, player, football_player, Algerian, descent, 
Algerian_descent,     France,    World,    Cup,


Pre-processing


- Extract Nouns 
from Sentence
- Stemming


World_Cup


UW Extraction 	- If word which is not contained in
WordNet occurs then that is UW.



2.2. UW Extraction



Creation of Noun
Set

Weight  Measure 
of Co-occurrence 
Word


- Make a noun set 
using noun words 
occurring  with  UW  
in  same sentence

- To give weight to 
co-occurrence word 
using Bayesian 
probability.



   Noun words 
extracted in the 
pre-processing 
step are mapped  
into  a  noun  part  
of  WordNet  to  
make  a decision 
which word is 
UW. If there is no 
agreement word in 
the WordNet, this 
word is 
considered as 
UW. Table 3 is 
pseudo-code to 
extract UW. UW 
is a set of UW 
that will get 
growing  by 
processing  many 
sentences. The 
UWs extracted 
from a sentence in 
Table
2 are presented 
below of table 3.








Pseudo
Code



Tabl
e  3. 
Pseu
do-
code 
to 
extr
act 
UW

Ni  : 
i-th 
noun 
extrac
ted 
from 
docu
ment;
UW  
: 
Unkn
own 
Word 
Set;
WN : 
Noun 
part 
of 
Word
Net;
if ( N i  
∉ WN 
)
{





3 	FIFA



attenti
on,   
Brazil,   
countr
y,   
Cup, 
Europ
e,  
fame,  
goal,  
play-
maker, 
	14
World, 
World_C
up,  
Player, 
Year,
April, 
football







Extracted
UW


UW = UW + 
N i ;
}



Zinedine,   
Yazid,   
Zidane,   
Zinedine_Y
azid, 
Yazid_Zidan
e, Zizou, 
Algerian_de
scent


2.4. 
Weight-
Measure 
of Co-
occurrin
g Words

   This  
step  
measures   
the  
weight  
of  co-
occurring 
words 
with UW 
using 
Bayesian 
probabilit
y because 
frequency 
is 
important 
factor to 
grasp 
related 
degree 
between   
UW   and   
known   
words.   
In  the   
case   of 
compoun
d noun, it 
has 2 
more 
nouns and 
we 
generated 
both each 
single 
noun and 
compoun
d noun in 
chapter
2.1. In 
here, if 
the 
WordNet  
contains  
the 
compound


2.3. Creation of Noun Set

   In this step, we make a noun set occurring with UW 
in the same sentence because co-occurring words have 
a possibility to relate with UW. Table 4 is pseudo-code 
to create a noun set.

Table  4. Pseudo-code to extract UW
UW = {UWi  | 1 ≤ i ≤ m} : Unknown word(UWi ) set;


noun, all of single noun words contained in compound 
noun should be excluded from weight-measure.
   For example, if the WordNet contains a compound 
noun  ‘World  Cup’  and  ‘World  Cup’  occurs  twice, 
single noun ‘World’ occurs once then, these are 
calculated  ‘World’  3  times  occurrence,  ‘Cup’  twice 
and  ‘World  Cup’  twice  in  the  previous  step.  These 
make an affection of duplication to occurring count of


m : Total count of unknown word(


UWi );


noun words because only single 
word ‘World’ occurs
once  independently.  Therefore,  
if  a compound  noun


K i  = {kij  | 1 ≤  j ≤ ni } : Collection of noun( kij ) set occurring


which is consisted of more than 2 words sequentially is


with


UWi ;


detect
ed, 
we 
find a 
pure 
value 
of 
Bayes
ian 
proba
bility


ni   : Total count of noun occurring with UWi   (total count of


of single nouns by extracting Bayesian probability of


noun set of


UWi );


compound   
noun.  
Table  6  
presents   
the  process  
to
measure the 
weight of 
co-
occurrence 
words. And, 
table
7 shows the 
weight of 
each co-
occurrence  
word with


Many UWs are extracted and each UW has many
co-occurring noun words through processing the whole 
document using previous steps. Table 5 shows the just
3 results of processing the document about ‘Zidane’.


Table  5. Extracted UW and noun set


UWs in table 5.

Table  6. Weight-measure of co-occurring words

Bayesian = P(B | A)P( A)
P(B)
oc(UWi ) : Frequency of UWi , oc(kij ) : Frequency of kij


i	UWi


Co-occurred 
Noun Set 	ni


P(oc(UW ) | 
oc(k  ))P(oc(k  
))


Bayesian =


i 	ij 	ij





1 	Zidane


Algerian,  
Cup,  
descent,  
football, 
France,    
June,    
player,    
World,
World_Cup, 
	
attention, 
	
Brazil, 
	
19 country,    
Europe,    
fame,    goal,
playmaker, 	Year, 	April,


P
(
o
c
(
U
W
i
 
)
)

If, kij  = {ki ( j −q 
) | 1 ≤ q ≤ r} is 
compound 
noun,
r : 
count of 
single 
nouns 
compose
d in 
compou
nd noun


football_player


P(oc(k


) | oc(UW )) = P(oc(k


) | oc(UW )) − P(oc(k  ) | oc(UW ))



club,    Madrid,    Real,    attention,


iq ' 	i


iq 	i


ij 	i


Brazil,    country,    Cup,    Europe,


q' : independent occurrence of single noun


2 	Juventus


fame,   goal,   
playmaker,   
World, 	19
championship,  
Euro,  Italy,  
level,


P(oc(kiq'


) | oc(UWi )


Spain, victory, World_Cup


P(oc(UW ) | oc(k  ))P(oc(k  ))    P(oc(UW ) | oc(k  
))P(oc(k  ))
=	i 	iq 	iq       −	i 	ij 	ij


P(oc(UWi ))


P(oc(UWi ))



Table  7. Weight of co-occurring words



Table  8. Related noun group and sum of Bayesian



UWi



Noun(    
) 	Noun(    )
i
j
 
	
i
j

Alger
ian 	0.2 	April 	0.2



UWi



G
ro
u
p 
of 
R
el
at
e
d 
N
o
u
ns 
	Sum

099514
69(footb
all_play
er)-
102838
58(play
er)


football 	0.2 	football_player    0.2

June 	0.2 	player 	0.2



Zidane


10283858(player)-
10284756(playmaker)
08802093(France)-09142657(Europe)


0.6




Zidane


World_C
up   0.6           
attention              
0.2 
country          
0.2           
Europe                 
0.2 goal               
0.2           
playmak
er            
0.2
descent          
0.2           
Brazil                   
0.2


0
8
8
0
2
0
9
3
(
F
r
a
n
c
e
)
-
0
8
0
6
0
6
7
4
(
E
u
r
o
p
e
)
	
0
.
4

Juventus 	08895440(Madrid)-08894294(Spain) 	1.0



France 	0.2 	fame 	0.2
World 	0.2 	Year 	0.2 
club	0.6667 	Madrid 	0.6667


FIFA 	10284756(playmaker)-
10283858(Player)

2.6. Normalization


0.4







Juventus



attention        
0.3333     
Brazil                   
0.3333 
victory           
0.3333     
Europe                 
0.3333 
goal               
0.3333     
playmaker            
0.3333
World_Cu
p   0.3333     
champions
hip      
0.3333

Italy               
0.3333     
level                     
0.3333

Real               
0.6667     
Spain                   
0.3333 
country          
0.3333     
Euro                     
0.3333 
fame              
0.3333
attentio
n 	0.2 	Brazil 	0.2 football 	0.2 	Europe 	0.2
goal               
0.2           
playma
ker            
0.2
   

An 
aim of 
this 
paper is 
to find 
related 
words 
of UW. 
To do 
this, we 
measure
d 
Bayesia
n 
probabil
ity of 
each co-
occurrin
g   word   
and  
made   
related   
noun   
groups 
through 
previous 
steps. 
Howeve
r, that is 
not 
probabil
ity of 
relation 
between 
UW and 
group. 
Moreov
er, to 
reflect 
both 
probabil
ity and 
relation, 
it needs 
normali
zation. 
Table 9 
and 
table 10 
show 
way to 
normali
ze and 
results.


T
a
b
l
e
  
9
.
 
N
o
r
m
a
l
i
z
a
t
i
o
n
 
o
f
 
g
r
o
u
p
Gi  = 
{Gil  | 1 
≤ l ≤ 
s} :  
Relate  
Related  
Group  
of UWi
(This 
group is 
consisted 
of co-
occurren
ce words 
with 
UWi
through 
matching 
into 
WordNe
t.)
s : 
count of 
groups 
related 
with 
UWi



FIFA



World_
Cup   
0.6           
Player                  
0.2 
country          
0.2           
Year                     
0.2 
fame              
0.2           
April                    
0.2
W
o
r
l
d
            
0
.
2


Gil


:
 
R
e
l
a
t
e
d
 
w
o
r
d
s
 
i
n
 
t
h
e
 
c
o
-
o
c
c
u
r
r
e
n
c
e
 
s
e
t
 
k
i
s
∑
 
B
a
y
e
s
i
a
n
 
(
G
i
l
   
|
 
U
W
i
 
)
N
o
r
m
a
l
i
z
a
t
 
i
o
n
 
=
 
 
 
l
 
=
1
 
	
n
i
∑
 
B
a
y
e
s
i
a
n
 
(
k
 
i
j
  
|
 
U
W
i
 
)
j
 
=
1



W : Weight of Co-occurring Word

Table  10. Result of normalization



2.5. Making a Related Noun Group

   The words occurring  with UW can have relations 
with each other. These related words can be grasped by 
matching into WordNet. If some words are related, we 
make a group using these related words because UW 
has much more related probability with the group of co- 
occurring words [4, 6]. The step in this chapter makes a 
group through co-occurring words, and measures the 
related probability between UW and the groups using 
sum  of  Bayesian  probability  of  each  word.  Table  8 
shows the result of group that is consisted of related 
nouns and Bayesian probability of group.


i










1,8


For  example,  if  all  of  evaluators  ( e = 10 )  judge  the


values of every

g


R _ UWijk


( g = 10


) to be 1 then the value


of   ∑ R _ UWijk
k =1


is   10.   So,   the   relevancy   of   this


experiment is 100(%).  Through this experiment and 
evaluation, we found that this research is very 
meaningful and excellent as 95.88(%).













N :Normalization


   In  Table  X,  the UWZidande    has  many  groups  and 
especially   two   groups   (‘football_player’,    ‘player’,
‘playmaker’),  (‘World_Cup’)  show  the  most  related
value as 0.167. And, the second is the group of ‘France’


4. Conclusions

   An ultimate aim of this research is to extend lexical 
dictionary through addition of unknown words 
automatically. To accomplish this aim, the meaning, 
related words and relation such as hyponym, hypernym, 
synonym, antonym, etc of unknown word have to be 
grasped.  In  this  paper,  to  grasp  related  words  of 
unknown word, we applied co-occurrence, Bayesian 
probability  and  WordNet  as  lexical  dictionary. 
Through experiment and evaluation,  we got semantic 
and excellent result. Based on this research, grasping 
the meaning of unknown words and relation is future 
works for auto-extension of lexical dictionary.


and  ‘Europe’.  In  case  of


UWJuventus  ,  the  group  of


Acknowledgment


‘Madrid’ and ‘Spain’ is the most related. This result is
obtained from a short document that is just consisted of
301 words. Though, the result is very meaningful. 
Through many experiments, we obtained that the longer 
document is, the better we get result.


3. Experimental Result

   We  collected  documents  which  are  consisted  of 
more than 1000 words from Wikipedia and gather 10 
( e ) evaluators  for this experiment.  And, we showed 
the  extracted  unknown  word  to  evaluators  and  the 
related  10 ( g ) noun  groups  depending  on the 
normalization   value  and,  we  asked  them  to  judge 
whether each word has relation with UW or not. The 
amount of UW is 100( u ). And then, the relevancy of 
this result is calculated by (1).

e      u      g



This study was supported by Ministry of Culture & 
Tourism and Culture & Content Agency in Republic of 
Korea.

Reference

[1] http://nlp.stanford.edu/software/tagger.shtml
[2] http://en.wikipedia.org/wiki/Zidane
[3] Hyo-Jung Oh, Sung-Hyoun Myaeng, "A Hypertext 
Categorization Method using Incrementally Computable 
Class Link Information", Korean Institute of Information 
Scientists and Engineering, no. 07, vol. 29, pp.498-509, 
August, 2002.
[4] Hyunjang Kong, Myunggwon Hwang, PanKoo Kim: The 
Method 	for     the     Unknown     Word     Classification, 
PKAW2006, pp.207-215, August, 2006.
[5]  A.  Jobbins  and  L.  Evett,  "text  Segmentation   Using
Reiteration    and    Collocation,"    Proceedings    of    the
COLING-ACL'98, pp. 614-618, August 1998.


∑∑∑ R _ UWijk
Re levancy(%) =  i =1   j =1  k =1 	× 100
e × u × g



(1)


[6] Hyunjang Kong, Myunggwon Hwang, 
Gwangsu Hwang, Jaehong Shim, Pankoo 
Kim, “Topic Selection of Web documents 
	using      Specific      Domain      
Ontology”, MICAI2006  : Advances in 
Artificial  Intelligence,  LNAI


Where,


R _ UWijk


has a value 
1 or 0 
depending  
on


4293, pp. 
1047-1056, 
November 
2006.


being relation between UW and related noun groups.

