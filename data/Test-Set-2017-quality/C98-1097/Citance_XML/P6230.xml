<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">When we express some idea or story, it is inevitable to use words that are semantically related to each other.</S>
		<S sid ="2" ssid = "2">When this phenomena is exploited from the aspect of words in the language, it is possible to infer the level of semantic relationship between words by observing their distribution and use in discourse.</S>
		<S sid ="3" ssid = "3">From the aspect of discourse it is possible to model the structure of the document by observing the changes in the lexical cohesion in order to attack high level natural language processing tasks.</S>
		<S sid ="4" ssid = "4">In this research lexical cohesion is investigated from both of these aspects by first building methods for measuring semantic relatedness of word pairs and then using these methods in the tasks of topic segmentation, summarization and keyphrase extraction.</S>
		<S sid ="5" ssid = "5">Measuring semantic relatedness of words requires prior knowledge about the words.</S>
		<S sid ="6" ssid = "6">Two different knowledge-bases are investigated in this research.</S>
		<S sid ="7" ssid = "7">The first knowledge base is a manually built network of semantic relationships, while the second relies on the distributional patterns in raw text corpora.</S>
		<S sid ="8" ssid = "8">In order to discover which method is effective in lexical cohesion analysis, a comprehensive comparison of state-of-the art methods in semantic relatedness is made.</S>
	</ABSTRACT>
	<SECTION title="lexical cohesion" number = "1">
			<S sid ="9" ssid = "9">are present in the literature.</S>
			<S sid ="10" ssid = "10">While some of these confine the relationships only to word repetition or strong semantic relationships like synonymy, no other work uses the semantic relatedness measures that can be calculated for any two word pairs in the vocabulary.</S>
			<S sid ="11" ssid = "11">Our experiments suggest that topic segmentation performance improves methods using both classical relationships and word repetition.</S>
			<S sid ="12" ssid = "12">Furthermore, the experiments compare the performance of different semantic re- latedness methods in a high level task.</S>
			<S sid ="13" ssid = "13">The detected topic segments are used in v summarization, and achieves better results compared to a lexical chains based method that uses WordNet.</S>
			<S sid ="14" ssid = "14">Finally, the use of lexical cohesion analysis in keyphrase extraction is investigated.</S>
			<S sid ="15" ssid = "15">Previous research shows that keyphrases are useful tools in document retrieval and navigation.</S>
			<S sid ="16" ssid = "16">While these point to a relation between keyphrases and document retrieval performance, no other work uses this relationship to identify keyphrases of a given document.</S>
			<S sid ="17" ssid = "17">We aim to establish a link between the problems of query performance prediction (QPP) and keyphrase extraction.</S>
			<S sid ="18" ssid = "18">To this end, features used in QPP are evaluated in keyphrase extraction using a Naive Bayes classifier.</S>
			<S sid ="19" ssid = "19">Our experiments indicate that these features improve the effectiveness of keyphrase extraction in documents of different length.</S>
			<S sid ="20" ssid = "20">More importantly, commonly used features of frequency and first position in text perform poorly on shorter documents, whereas QPP features are more robust and achieve better results.</S>
			<S sid ="21" ssid = "21">Keywords: Lexical Cohesion, Semantic Relatedness, Topic Segmentation, Sum- marization, Keyphrase Extraction.</S>
	</SECTION>
	<SECTION title="Acknowledgement">
			<S sid ="22" ssid = "22">I would like to thank Prof. I˙lyas C¸ i¸cekli who has supervised and supported me since the day I started my graduate studies.</S>
			<S sid ="23" ssid = "23">I am indebted to Prof. Fazlı Can for all the encouragement and guidance he has provided me. Their support, expertise and invaluable recommendations were crucial in this long academic journey.</S>
			<S sid ="24" ssid = "24">I would like to thank all my committee members for spending their time and effort to read and comment on my dissertation.</S>
			<S sid ="25" ssid = "25">Many thanks to the former and current members of the Computer Engineering Department.</S>
			<S sid ="26" ssid = "26">It was both a pleasure and honour to get to know and work with you all.</S>
			<S sid ="27" ssid = "27">I would like to express my deepest gratitude to my family, Nurhayat-Sadık Ercan and I˙lkay-G¨orkem Ercan and Berrin G¨ozen for their patience and support throughout this long journey.</S>
			<S sid ="28" ssid = "28">Finally I thank and dedicate this dissertation to my wife Pınar who has given me both strength and courage to take on this challenge.</S>
			<S sid ="29" ssid = "29">Contents 1 Introduction 1.</S>
			<S sid ="30" ssid = "30">1.1 Goals and Contributions . . .</S>
			<S sid ="31" ssid = "31">9.</S>
			<S sid ="32" ssid = "32">1.2 Outline . . .</S>
			<S sid ="33" ssid = "33">11.</S>
	</SECTION>
	<SECTION title="Related Work 	13. " number = "2">
			<S sid ="34" ssid = "1">2.1 Related Linguistic Theories . . .</S>
			<S sid ="35" ssid = "2">13.</S>
			<S sid ="36" ssid = "3">2.1.1 Semiotics and Meaning . . .</S>
			<S sid ="37" ssid = "4">14 2.1.2 Analytic View . . .</S>
			<S sid ="38" ssid = "5">15 2.1.3 Generative Grammar and Meaning . . .</S>
			<S sid ="39" ssid = "6">15 2.2 Linguistic Background . . .</S>
			<S sid ="40" ssid = "7">16.</S>
			<S sid ="41" ssid = "8">2.2.1 Morphology . . .</S>
			<S sid ="42" ssid = "9">17 2.2.2 Syntax . . .</S>
			<S sid ="43" ssid = "10">22 2.2.3 Coherence . . .</S>
			<S sid ="44" ssid = "11">23 2.2.4 Cohesion . . .</S>
			<S sid ="45" ssid = "12">24 2.2.5 Lexical Cohesion . . .</S>
			<S sid ="46" ssid = "13">25 2.3 Literature Survey . . .</S>
			<S sid ="47" ssid = "14">26.</S>
			<S sid ="48" ssid = "15">CONTENTS x 2.3 .1 S e m an tic R el at ed ne ss . . .</S>
			<S sid ="49" ssid = "16">2 7 2.3 .2 T o pi c S e g m en ta tio n . . .</S>
			<S sid ="50" ssid = "17">3 1 2.3 .3 S u m m ar iz ati o n . . .</S>
			<S sid ="51" ssid = "18">3 6 2.3 .4 K ey ph ra se E xt ra cti o n . . .</S>
			<S sid ="52" ssid = "19">4 1</S>
	</SECTION>
	<SECTION title="Semantic Relatedness	44. " number = "3">
			<S sid ="53" ssid = "1">3.1 Semantic Relatedness Methods . . .</S>
			<S sid ="54" ssid = "2">45.</S>
			<S sid ="55" ssid = "3">3.1.1 WordNet Based Semantic Relatedness Measures . . .</S>
			<S sid ="56" ssid = "4">46 3.1.2 WordNet based Semantic Relatedness Functions . . .</S>
			<S sid ="57" ssid = "5">51 3.1.3 Corpora Based Semantic Relatedness Measures . . .</S>
			<S sid ="58" ssid = "6">58 3.1.4 Building the Vocabulary . . .</S>
			<S sid ="59" ssid = "7">59 3.1.5 Building the Co-occurrence Matrix . . .</S>
			<S sid ="60" ssid = "8">61 3.1.6 Dimension Reduction . . .</S>
			<S sid ="61" ssid = "9">64 3.1.7 Similarity of Term Vectors . . .</S>
			<S sid ="62" ssid = "10">67 3.1.8 Raw Text Corpora . . .</S>
			<S sid ="63" ssid = "11">67 3.2 Intrinsic Evaluation of Semantic Relatedness Measures . . .</S>
			<S sid ="64" ssid = "12">70.</S>
			<S sid ="65" ssid = "13">3.2.1 Word Pair Judgements . . .</S>
			<S sid ="66" ssid = "14">70 3.2.2 Semantic Space Neighbors to WordNet Mapping . . .</S>
			<S sid ="67" ssid = "15">72 3.2.3 Near Synonymy Questions . . .</S>
			<S sid ="68" ssid = "16">74 3.3 Results and Model Selection . . .</S>
			<S sid ="69" ssid = "17">75.</S>
			<S sid ="70" ssid = "18">3.3.1 Effect of Pruning the Vocabulary . . .</S>
			<S sid ="71" ssid = "19">76 3.3.2 Effect of Dimension Reduction and Weighting Function . . 78 CONTENTS xi 3.3.3 Effect of Co-occurrence Window Size . . .</S>
			<S sid ="72" ssid = "20">80 3.3.4 Effect of the Number of Dimensions Retained . . .</S>
			<S sid ="73" ssid = "21">82 3.3.5 Comparison of Semantic Space and WordNet based Measures 84 3.3.6 Comparison to the State-of-the-art Methods . . .</S>
			<S sid ="74" ssid = "22">86 3.3.7 Semantic Spaces and Classical Relationship Types . . .</S>
			<S sid ="75" ssid = "23">86 3.4 Discussion of the Results . . .</S>
			<S sid ="76" ssid = "24">88.</S>
	</SECTION>
	<SECTION title="Topic Segmentation 	91. " number = "4">
			<S sid ="77" ssid = "1">4.1 Semantic Relatedness Based Topic Segmentation Algorithm . . .</S>
			<S sid ="78" ssid = "2">92.</S>
			<S sid ="79" ssid = "3">4.1.1 Number of Topics is Known . . .</S>
			<S sid ="80" ssid = "4">92 4.1.2 Number of Topics is Unknown . . .</S>
			<S sid ="81" ssid = "5">96 4.2 Dataset and Evaluation . . .</S>
			<S sid ="82" ssid = "6">99.</S>
			<S sid ="83" ssid = "7">4.3 Results . . .</S>
			<S sid ="84" ssid = "8">100.</S>
			<S sid ="85" ssid = "9">4.3 .1 Ef fe ct of S e m an tic S pa ce P ar a m et er s . . .</S>
			<S sid ="86" ssid = "10">10 0 4.3 .2 C o m p ar is o n wi th W or d N et b a s e d S e m a nt ic R el at e d n e ss F u n cti o n s . . .</S>
			<S sid ="87" ssid = "11">10 3 4.3 .3 E ff e ct iv e n e s s o f S e m a nt ic R el at e d n e s s b a s e d T o pi c S e g m e n - t a ti o n A lg o ri t h m s . . .</S>
			<S sid ="88" ssid = "12">10 5</S>
	</SECTION>
	<SECTION title="Automated  Text Summarization 	109. " number = "5">
			<S sid ="89" ssid = "1">5.1 Segment Salience and Sentence Extraction . . .</S>
			<S sid ="90" ssid = "2">110.</S>
			<S sid ="91" ssid = "3">5.2 Corpus and Evaluation . . .</S>
			<S sid ="92" ssid = "4">111.</S>
			<S sid ="93" ssid = "5">5.3 Results . . .</S>
			<S sid ="94" ssid = "6">113.</S>
			<S sid ="95" ssid = "7">CONTENTS xii</S>
	</SECTION>
	<SECTION title="Keyphrase Extraction 	115. " number = "6">
			<S sid ="96" ssid = "1">6.1 Keyphrase Extraction using QPP Features . . .</S>
			<S sid ="97" ssid = "2">116.</S>
			<S sid ="98" ssid = "3">6.1.1 Candidate Phrase List Creation . . .</S>
			<S sid ="99" ssid = "4">118 6.1.2 Information Retrieval from Wikipedia . . .</S>
			<S sid ="100" ssid = "5">119 6.1.3 QPP Measures . . .</S>
			<S sid ="101" ssid = "6">121 6.1.4 Learning to Classify Keyphrases . . .</S>
			<S sid ="102" ssid = "7">127 6.2 Corpus and Evaluation Metrics . . .</S>
			<S sid ="103" ssid = "8">128.</S>
			<S sid ="104" ssid = "9">6.3 Results . . .</S>
			<S sid ="105" ssid = "10">130.</S>
	</SECTION>
	<SECTION title="Conclusion	134. " number = "7">
</PAPER>
