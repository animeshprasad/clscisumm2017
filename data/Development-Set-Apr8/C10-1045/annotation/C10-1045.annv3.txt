Citance Number: 1 | Reference Article:  C10-1045.txt | Citing Article:  D12-1046.txt | Citation Marker Offset:  ['39'] | Citation Marker:  Green and Manning, 2010 | Citation Offset:  ['39'] | Citation Text:  <S sid ="39" ssid = "13">Joint segmentation and parsing was also investigated for Arabic (Green and Manning, 2010).</S> | Reference Offset:  ['270'] | Reference Text:  <S sid ="270" ssid = "63">6 Joint Segmentation and Parsing.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 2 | Reference Article:  C10-1045.txt | Citing Article:  J13-1007.txt | Citation Marker Offset:  ['72'] | Citation Marker:  Green and Manning 2010 | Citation Offset:  ['72'] | Citation Text:  <S sid ="72" ssid = "72">Indeed, we have used it to solve the problem of parsing while recovering null elements in both English and Chinese (Cai, Chiang, and Goldberg 2011), and others have used it for the joint segmentation and parsing of Arabic (Green and Manning 2010).</S> | Reference Offset:  ['270'] | Reference Text:  <S sid ="270" ssid = "63">6 Joint Segmentation and Parsing.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 3 | Reference Article:  C10-1045.txt | Citing Article:  J13-1007.txt | Citation Marker Offset:  ['148'] | Citation Marker:  Green and Manning 2010 | Citation Offset:  ['148','149'] | Citation Text:  <S sid ="148" ssid = "74">One possible solution to the unobserved word-sequence problem is a pipeline system in which an initial model is in charge of token-segmentation, and the output of the initial model is fed as the input to a second stage parser.</S><S sid ="149" ssid = "75">This is a popular approach in parsing systems for Arabic and Chinese (Jiang, Huang, and Liu 2009; Green and Manning 2010).</S> | Reference Offset:  ['275'] | Reference Text: <S sid ="275" ssid = "68">But gold segmentation is not available in application settings, so a segmenter and parser are arranged in a pipeline.</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 4 | Reference Article:  C10-1045.txt | Citing Article:  J13-1007.txt | Citation Marker Offset:  ['479'] | Citation Marker:  Green and Manning 2010 | Citation Offset:  ['479','480'] | Citation Text:  <S sid ="479" ssid = "16">This is by now a fairly standard representation for multiple morphological segmentations of Hebrew utterances (Adler 2001; Bar-Haim, Simaâ€™an, and Winter 2005; Adler 2007; Cohen and Smith 2007; Goldberg, Adler, and Elhadad 2008; Goldberg and Tsarfaty 2008; Goldberg and Elhadad 2011).</S><S sid ="480" ssid = "17">It is also used for Arabic (Green and Manning 2010)</S> | Reference Offset:  ['270'] | Reference Text:  <S sid ="270" ssid = "63">6 Joint Segmentation and Parsing.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 5 | Reference Article:  C10-1045.txt | Citing Article:  J13-1007.txt | Citation Marker Offset:  ['511'] | Citation Marker:  2010 | Citation Offset:  ['510','511'] | Citation Text:  <S sid ="510" ssid = "47">Lattice parsing was explored in the context of parsing of speech signals by Chappelier et al.</S><S sid ="511" ssid = "48">(1999), Simaâ€™an (1999), and Hall (2005), and in the context of joint word-segmentation and syntactic disambiguation in Cohen and Smith (2007), Goldberg and Tsarfaty (2008), and Green and Manning (2010).</S> | Reference Offset:  ['6'] | Reference Text:  <S sid ="6" ssid = "6">Finally, we show that in application settings, the absence of gold segmentation lowers parsing performance by 2â€“5% F1.</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 6 | Reference Article:  C10-1045.txt | Citing Article:  J13-1007.txt | Citation Marker Offset:  ['670'] | Citation Marker:  2010 | Citation Offset:  ['670'] | Citation Text:  <S sid ="670" ssid = "13">Recently, Green and Manning (2010) report on an extensive set of experiments with several kinds of tree annotations and refinements, and report parsing accuracies of 79% F1 using the Stanford-parser and 82% F1 using the PCFG-LA BerkeleyParser, both when assuming gold word segmentation.</S> | Reference Offset:  ['24'] | Reference Text:  <S sid ="24" ssid = "24">Finally, we provide a realistic eval uation in which segmentation is performed both in a pipeline and jointly with parsing (Â§6).</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 7 | Reference Article:  C10-1045.txt | Citing Article:  J13-1007.txt | Citation Marker Offset:  ['672'] | Citation Marker:  Green and Manning 2010 | Citation Offset:  ['672'] | Citation Text:  <S sid ="672" ssid = "15">The best reported results for parsing Arabic when the gold word segmentation is not known, however, are obtained using a pipeline model in which a tagger and word-segmenter is applied prior to a manually state-split constituency parser, resulting in an F-score of 79% F1 (for sentences of up to 70 words) (Green and Manning 2010).</S> | Reference Offset:  ['24','289','308'] | Reference Text: <S sid ="24" ssid = "24">Finally, we provide a realistic eval uation in which segmentation is performed both in a pipeline and jointly with parsing (§6).</S><S sid ="289" ssid = "82">Parent Head Modif er Dir # gold F1 Label # gold F1 NP NP TAG R 946 0.54 ADJP 1216 59.45 S S S R 708 0.57 SBAR 2918 69.81 NP NP ADJ P R 803 0.64 FRAG 254 72.87 NP NP N P R 2907 0.66 VP 5507 78.83 NP NP SBA R R 1035 0.67 S 6579 78.91 NP NP P P R 2713 0.67 PP 7516 80.93 VP TAG P P R 3230 0.80 NP 34025 84.95 NP NP TAG L 805 0.85 ADVP 1093 90.64 VP TAG SBA R R 772 0.86 WHN P 787 96.00 S VP N P L 961 0.87 (a) Major phrasal categories (b) Major POS categories (c) Ten lowest scoring (Collins, 2003)-style dependencies occurring more than 700 times Table 8: Per category performance of the Berkeley parser on sentence lengths ≤ 70 (dev set, gold segmentation).</S><S sid ="308" ssid = "101">Table 9: Dev set results for sentences of length ≤ 70.</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 8 | Reference Article:  C10-1045.txt | Citing Article:  J13-1008.txt | Citation Marker Offset:  ['195'] | Citation Marker:  Green and Manning 2010 | Citation Offset:  ['195'] | Citation Text:  <S sid ="195" ssid = "12">As for work on Arabic (MSA), results have been reported on the PATB (Kulick, Gabbard, and Marcus 2006; Diab 2007; Green and Manning 2010)</S> | Reference Offset:  ['11'] | Reference Text: <S sid ="11" ssid = "11">To investigate the influence of these factors, we analyze Modern Standard Arabic (henceforth MSA, or simply “Arabic”) because of the unusual opportunity it presents for comparison to English parsing results.</S> | Discourse Facet:  Aim_Citation | Annotator:  Ankita Patel |


Citance Number: 9 | Reference Article:  C10-1045.txt | Citing Article:  J13-1008.txt | Citation Marker Offset:  ['196'] | Citation Marker:  2010 | Citation Offset:  ['196'] | Citation Text:  <S sid ="196" ssid = "13">Recently, Green and Manning (2010) analyzed the PATB for annotation consistency, and introduced an enhanced split-state constituency grammar, including labels for short idafa constructions and verbal or equational clauses.</S> | Reference Offset:  ['21','22','53','141'] | Reference Text: <S sid ="21" ssid = "21">Next we show that the ATB is similar to other tree- banks in gross statistical terms, but that annotation consistency remains low relative to English (§3).</S><S sid ="22" ssid = "22">We then use linguistic and annotation insights to develop a manually annotated grammar for Arabic (§4).</S><S sid ="53" ssid = "27">When the maSdar lacks a determiner, the constituent as a whole resem bles the ubiquitous annexation construct � ?f iDafa.</S><S sid ="141" ssid = "8">mark- ContainsVerb is especially effective for distinguishing root S nodes of equational sentences.</S> | Discourse Facet:  ['Results_Citation','Method_Citation'] | Annotator:  Ankita Patel |


Citance Number: 10 | Reference Article:  C10-1045.txt | Citing Article:  J13-1008.txt | Citation Marker Offset:  ['665'] | Citation Marker:  2010 | Citation Offset:  ['665'] | Citation Text:  <S sid ="665" ssid = "131">For better comparison with work of others, we adopt the suggestion made by Green and Manning (2010) to evaluate the parsing quality on sentences up to 70 tokens long.</S> | Reference Offset:  ['64'] | Reference Text: <S sid ="64" ssid = "38">We propose a limit of 70 words for Arabic parsing evaluations.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 11 | Reference Article:  C10-1045.txt | Citing Article:  J13-1009.txt | Citation Marker Offset:  ['190'] | Citation Marker:  2010 | Citation Offset:  ['190'] | Citation Text:  <S sid ="190" ssid = "29">The Arabic grammar features come from Green and Manning (2010), which contains an ablation study similar to Table 2.</S> | Reference Offset:  ['116','117'] | Reference Text:  <S sid ="116" ssid = "4">In our grammar, features are realized as annotations to basic category labels.</S><S sid ="117" ssid = "5">We start with noun features since written Arabic contains a very high proportion of NPs.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 12 | Reference Article:  C10-1045.txt | Citing Article:  J13-1009.txt | Citation Marker Offset:  ['193'] | Citation Marker:  2010 | Citation Offset:  ['193'] | Citation Text:  <S sid ="193" ssid = "32">For Arabic, we use the head-finding rules from Green and Manning (2010).</S> | Reference Offset:  ['128'] | Reference Text: <S sid ="128" ssid = "16">8 We use head-finding rules specified by a native speaker.</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 13 | Reference Article:  C10-1045.txt | Citing Article:  J13-1009.txt | Citation Marker Offset:  ['316'] | Citation Marker:  Green and Manning 2010 | Citation Offset:  ['316'] | Citation Text:  <S sid ="316" ssid = "36">We previously showed that the â€œKulickâ€ tag set is very effective for basic Arabic parsing (Green and Manning 2010).</S> | Reference Offset:  ['312'] | Reference Text: <S sid ="312" ssid = "1">By establishing significantly higher parsing baselines, we have shown that Arabic parsing performance is not as poor as previously thought, but remains much lower than English.</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 14 | Reference Article:  C10-1045.txt | Citing Article:  J13-1009.txt | Citation Marker Offset:  ['397'] | Citation Marker:  Green and Manning 2010 | Citation Offset:  ['397'] | Citation Text:  <S sid ="397" ssid = "13">We previously showed that segmentation errors decrease Arabic parsing accuracy by about 2.0% F1 (Green and Manning 2010).</S> | Reference Offset:  ['301'] | Reference Text: <S sid ="301" ssid = "94">Table 9 shows that MADA produces a high quality segmentation, and that the effect of cascading segmentation errors on parsing is only 1.92% F1.</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 15 | Reference Article:  C10-1045.txt | Citing Article:  J13-1009.txt | Citation Marker Offset:  ['406'] | Citation Marker:  Green and Manning 2010 | Citation Offset:  ['406'] | Citation Text:  <S sid ="406" ssid = "22">We previously showed optimal Berkeley parser (Petrov et al. 2006) pa- rameterizations for both the Arabic (Green and Manning 2010) and French (Green et al. 2011) data sets</S> | Reference Offset:  ['11'] | Reference Text: <S sid ="11" ssid = "11">To investigate the influence of these factors, we analyze Modern Standard Arabic (henceforth MSA, or simply “Arabic”) because of the unusual opportunity it presents for comparison to English parsing results.</S> | Discourse Facet:  Aim_Citation | Annotator:  Ankita Patel |


Citance Number: 16 | Reference Article:  C10-1045.txt | Citing Article:  P11-1159.txt | Citation Marker Offset:  ['108'] | Citation Marker:  reen and Manning, 2010 | Citation Offset:  ['108'] | Citation Text:  <S sid ="108" ssid = "35">As for work on Arabic, results have been reported on PATB (Kulick et al., 2006; Diab, 2007; Green and Manning, 2010)</S> | Reference Offset:  ['11'] | Reference Text: <S sid ="11" ssid = "11">To investigate the influence of these factors, we analyze Modern Standard Arabic (henceforth MSA, or simply “Arabic”) because of the unusual opportunity it presents for comparison to English parsing results.</S> | Discourse Facet:  Aim_Citation | Annotator:  Ankita Patel |


Citance Number: 17 | Reference Article:  C10-1045.txt | Citing Article:  P11-1159.txt | Citation Marker Offset:  ['109'] | Citation Marker:  2010 | Citation Offset:  ['109'] | Citation Text:  <S sid ="109" ssid = "36">Recently, Green and Manning (2010) analyzed the PATB for annotation consistency</S> | Reference Offset:  ['11'] | Reference Text: <S sid ="11" ssid = "11">To investigate the influence of these factors, we analyze Modern Standard Arabic (henceforth MSA, or simply “Arabic”) because of the unusual opportunity it presents for comparison to English parsing results.</S> | Discourse Facet:  Aim_Citation | Annotator:  Ankita Patel |


Citance Number: 18 | Reference Article:  C10-1045.txt | Citing Article:  P11-2037.txt | Citation Marker Offset:  ['34'] | Citation Marker:  Green and Manning, 2010 | Citation Offset:  ['34'] | Citation Text:  <S sid ="34" ssid = "12">We allow the parser to produce empty elements by means of lattice-parsing (Chappelier et al., 1999), a general processing community (Hall, 2005; Chappelier et al., 1999), and was recently applied to the task of joint clitic-segmentation and syntactic-parsing in Hebrew (Goldberg and Tsarfaty, 2008; Goldberg and Elhadad, 2011) and Arabic (Green and Manning, 2010).</S> | Reference Offset:  ['11'] | Reference Text: <S sid ="11" ssid = "11">To investigate the influence of these factors, we analyze Modern Standard Arabic (henceforth MSA, or simply “Arabic”) because of the unusual opportunity it presents for comparison to English parsing results.</S> | Discourse Facet:  Aim_Citation | Annotator:  Ankita Patel |


Citance Number: 19 | Reference Article:  C10-1045.txt | Citing Article:  P11-2122.txt | Citation Marker Offset:  ['7'] | Citation Marker:  Green and Manning, 2010 | Citation Offset:  ['7'] | Citation Text:  <S sid ="7" ssid = "7">Recent work has therefore focused on the importance of detecting errors in the treebank (Green and Manning, 2010)</S> | Reference Offset:  ['72'] | Reference Text: <S sid ="72" ssid = "46">We show that noun-noun vs. discourse-level coordination ambiguity in Arabic is a significant source of parsing errors (Table 8c).</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 20 | Reference Article:  C10-1045.txt | Citing Article:  P11-2122.txt | Citation Marker Offset:  ['73'] | Citation Marker:  2010 | Citation Offset:  ['73'] | Citation Text:  <S sid ="73" ssid = "1">Green and Manning (2010) discuss annotation consistency in the Penn Arabic Treebank (ATB)</S> | Reference Offset:  ['21'] | Reference Text:  <S sid ="21" ssid = "21">Next we show that the ATB is similar to other tree- banks in gross statistical terms, but that annotation consistency</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 21 | Reference Article:  C10-1045.txt | Citing Article:  P11-2122.txt | Citation Marker Offset:  ['109'] | Citation Marker:  2010 | Citation Offset:  ['109'] | Citation Text:  <S sid ="109" ssid = "37">Measuring recall is tricky, even using the errors identified in Green and Manning (2010) as â€œgoldâ€ errors.</S> | Reference Offset:  ['72'] | Reference Text: <S sid ="72" ssid = "46">We show that noun-noun vs. discourse-level coordination ambiguity in Arabic is a significant source of parsing errors (Table 8c).</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 22 | Reference Article:  C10-1045.txt | Citing Article:  P11-2124.txt | Citation Marker Offset:  ['18'] | Citation Marker:  2010 | Citation Offset:  ['18'] | Citation Text:  <S sid ="18" ssid = "18">Recently, Green and Manning (2010) demonstrated the effectiveness of lattice-parsing for parsing Arabic.</S> | Reference Offset:  ['277','279'] | Reference Text: <S sid ="277" ssid = "70">Lattice parsing (Chappelier et al., 1999) is an alternative to a pipeline that prevents cascading errors by placing all segmentation options into the parse chart.</S><S sid ="279" ssid = "72">We extend the Stanford parser to accept pre-generated lattices, where each word is represented as a finite state automaton.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 23 | Reference Article:  C10-1045.txt | Citing Article:  P12-1016.txt | Citation Marker Offset:  ['196'] | Citation Marker:  Green and Manning, 2010 | Citation Offset:  ['196'] | Citation Text:  <S sid ="196" ssid = "23">The data was pre-processed with packages from the Stanford Arabic parser (Green and Manning, 2010).</S> | Reference Offset:  ['0'] | Reference Text: <S sid ="0">Better Arabic Parsing: Baselines, Evaluations, and Analysis</S> | Discourse Facet:  Aim_Citation | Annotator:  Ankita Patel |


Citance Number: 24 | Reference Article:  C10-1045.txt | Citing Article:  P12-2002.txt | Citation Marker Offset:  ['12'] | Citation Marker:  Green and Manning, 2010 | Citation Offset:  ['12'] | Citation Text:  <S sid ="12" ssid = "12">One can either select a segmentation path prior to parsing, or, as has been recently argued, one can let the parser pick a segmentation jointly with decoding (Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008; Green and Manning, 2010).</S> | Reference Offset:  ['24'] | Reference Text: <S sid ="24" ssid = "24">Finally, we provide a realistic eval uation in which segmentation is performed both in a pipeline and jointly with parsing (§6).</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 25 | Reference Article:  C10-1045.txt | Citing Article:  P12-2002.txt | Citation Marker Offset:  ['34'] | Citation Marker:  2010 | Citation Offset:  ['34','35'] | Citation Text:  <S sid ="34" ssid = "12">2 The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008).</S><S sid ="35" ssid = "13">Examples for similar phenomena in Arabic may be found in Green and Manning (2010).</S> | Reference Offset:  ['0'] | Reference Text: <S sid ="0">Better Arabic Parsing: Baselines, Evaluations, and Analysis</S> | Discourse Facet:  Aim_Citation | Annotator:  Ankita Patel |


Citance Number: 26 | Reference Article:  C10-1045.txt | Citing Article:  P12-2002.txt | Citation Marker Offset:  [39'] | Citation Marker:  Green and Manning, 2010 | Citation Offset:  ['38','39'] | Citation Text:  <S sid ="38" ssid = "16">In practice, a statistical component is required to decide on the correct morphological segmentation, that is, to pick out the correct path through the lattice.</S><S sid ="39" ssid = "17">This may be done based on linear local context (Adler and Elhadad, 2006; Shacham and Wintner, 2007; Bar-haim et al., 2008; Habash and Rambow, 2005), or jointly with parsing (Tsarfaty, 2006; Goldberg and Tsarfaty, 2008; Green and Manning, 2010).</S> | Reference Offset:  ['277','279'] | Reference Text: <S sid ="277" ssid = "70">Lattice parsing (Chappelier et al., 1999) is an alternative to a pipeline that prevents cascading errors by placing all segmentation options into the parse chart.</S><S sid ="279" ssid = "72">We extend the Stanford parser to accept pre-generated lattices, where each word is represented as a finite state automaton.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 27 | Reference Article:  C10-1045.txt | Citing Article:  W13-4904.txt | Citation Marker Offset:  ['115'] | Citation Marker:  2010 | Citation Offset:  ['115'] | Citation Text:  <S sid ="115" ssid = "46">Following Green and Manning (2010) and others, sentences headed by X nodes are deleted</S> | Reference Offset:  ['153'] | Reference Text: <S sid ="153" ssid = "20">Preprocessing the raw trees improves parsing performance considerably.9 We first discard all trees dominated by X, which indicates errors and non-linguistic text.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 28 | Reference Article:  C10-1045.txt | Citing Article:  W13-4904.txt | Citation Marker Offset:  ['234'] | Citation Marker: 2010 | Citation Offset:  ['234'] | Citation Text:   <S sid ="234" ssid = "86">Green and Manning (2010) obtain the opposite result in their Arabic parsing experiments, with the lattice parser underperforming the pipeline system by over 3 points (76.01 F1 vs 79.17 F1).</S> | Reference Offset:  ['301'] | Reference Text:  <S sid ="301" ssid = "94">Table 9 shows that MADA produces a high quality segmentation, and that the effect of cascading segmentation errors on parsing is only 1.92% F1.</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 29 | Reference Article:  C10-1045.txt | Citing Article:  W13-4904.txt | Citation Marker Offset:  ['244'] | Citation Marker:  2010 | Citation Offset:  ['244'] | Citation Text:  <S sid ="244" ssid = "96">Green and Manning (2010) find that using automatic tokenization provided by MADA (Habash et al., 2009) instead of gold tokenization results in a 1.92% F score drop in their constituent parsing work.</S> | Reference Offset:  ['301'] | Reference Text:  <S sid ="301" ssid = "94">Table 9 shows that MADA produces a high quality segmentation, and that the effect of cascading segmentation errors on parsing is only 1.92% F1.</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 30 | Reference Article:  C10-1045.txt | Citing Article:  W13-4916.txt | Citation Marker Offset:  ['293'] | Citation Marker:  Green and Manning, 2010 | Citation Offset:  ['293'] | Citation Text:  <S sid ="293" ssid = "18">We also express our gratitude to the treebank providers for each language: Arabic (Maamouri et al., 2004; Habash and Roth, 2009; Habash et al., 2009; Green and Manning, 2010)</S> |  Reference Offset:  ['11'] | Reference Text: <S sid ="11" ssid = "11">To investigate the influence of these factors, we analyze Modern Standard Arabic (henceforth MSA, or simply “Arabic”) because of the unusual opportunity it presents for comparison to English parsing results.</S> | Discourse Facet:  Aim_Citation | Annotator:  Ankita Patel |


Citance Number: 31 | Reference Article:  C10-1045.txt | Citing Article:  W13-4917.txt | Citation Marker Offset:  ['260'] | Citation Marker:  2010 | Citation Offset:  ['260'] | Citation Text:  <S sid ="260" ssid = "60">The Stanford Arabic Phrase Structure Treebank In order to stay compatible with the state of the art, we provide the constituency data set with most of the pre-processing steps of Green and Manning (2010)</S> | Reference Offset:  ['166','167'] | Reference Text:  <S sid ="166" ssid = "33">The intuition here is that the role of a discourse marker can usually be de 9 Both the corpus split and pre-processing code are avail-.</S><S sid ="167" ssid = "34">able at http://nlp.stanford.edu/projects/arabic.shtml.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 32 | Reference Article:  C10-1045.txt | Citing Article:  W13-4917.txt | Citation Marker Offset:  ['262'] | Citation Marker:  2010 | Citation Offset:  ['262'] | Citation Text:  <S sid ="262" ssid = "62">We finally remove all traces, but, unlike Green and Manning (2010), we keep all function tags.</S> | Reference Offset:  ['154'] | Reference Text:  <S sid ="154" ssid = "21">At the phrasal level, we remove all function tags and traces.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 33 | Reference Article:  C10-1045.txt | Citing Article:  W13-4917.txt | Citation Marker Offset:  ['218'] | Citation Marker:  Green and Manning, 2010 | Citation Offset:  ['218'] | Citation Text:  <S sid ="218" ssid = "18">Data Sets The Arabic data set contains two tree- banks derived from the LDC Penn Arabic Treebanks (PATB) (Maamouri et al., 2004b):11 the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009), a dependency treebank, and the Stanford version of the PATB (Green and Manning, 2010)</S> | Reference Offset:  ['12'] | Reference Text: <S sid ="12" ssid = "12">The Penn Arabic Treebank (ATB) syntactic guidelines (Maamouri et al., 2004) were purposefully borrowed without major modification from English (Marcus et al., 1993).</S> |  Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |
