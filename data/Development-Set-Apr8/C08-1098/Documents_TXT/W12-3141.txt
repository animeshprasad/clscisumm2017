Proceedings of the 7th Workshop on Statistical Machine Translation, pages 330?337,
Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational Linguistics
LIMSI @ WMT?12
Hai-Son Le1,2, Thomas Lavergne2, Alexandre Allauzen1,2,
Marianna Apidianaki2, Li Gong1,2, Aure?lien Max1,2,
Artem Sokolov2, Guillaume Wisniewski1,2, Franc?ois Yvon1,2
Univ. Paris-Sud1 and LIMSI-CNRS2
rue John von Neumann, 91403 Orsay cedex, France
{firstname.lastname}@limsi.fr
Abstract
This paper describes LIMSI?s submissions to
the shared translation task. We report results
for French-English and German-English in
both directions. Our submissions use n-code,
an open source system based on bilingual
n-grams. In this approach, both the transla-
tion and target language models are estimated
as conventional smoothed n-gram models; an
approach we extend here by estimating the
translation probabilities in a continuous space
using neural networks. Experimental results
show a significant and consistent BLEU im-
provement of approximately 1 point for all
conditions. We also report preliminary experi-
ments using an ?on-the-fly? translation model.
1 Introduction
This paper describes LIMSI?s submissions to the
shared translation task of the Seventh Workshop
on Statistical Machine Translation. LIMSI partic-
ipated in the French-English and German-English
tasks in both directions. For this evaluation, we
used n-code, an open source in-house Statistical
Machine Translation (SMT) system based on bilin-
gual n-grams1. The main novelty of this year?s
participation is the use, in a large scale system, of
the continuous space translation models described
in (Hai-Son et al, 2012). These models estimate the
n-gram probabilities of bilingual translation units
using neural networks. We also investigate an alter-
native approach where the translation probabilities
of a phrase based system are estimated ?on-the-fly?
1http://ncode.limsi.fr/
by sampling relevant examples, instead of consider-
ing the entire training set. Finally we also describe
the use in a rescoring step of several additional fea-
tures based on IBM1 models and word sense disam-
biguation information.
The rest of this paper is organized as follows. Sec-
tion 2 provides an overview of the baseline systems
built with n-code, including the standard transla-
tion model (TM). The continuous space translation
models are then described in Section 3. As in our
previous participations, several steps of data pre-
processing, cleaning and filtering are applied, and
their improvement took a non-negligible part of our
work. These steps are summarized in Section 5.
The last two sections report experimental results ob-
tained with the ?on-the-fly? system in Section 6 and
with n-code in Section 7.
2 System overview
n-code implements the bilingual n-gram approach
to SMT (Casacuberta and Vidal, 2004; Marin?o et al,
2006; Crego and Marin?o, 2006). In this framework,
translation is divided in two steps: a source reorder-
ing step and a (monotonic) translation step. Source
reordering is based on a set of learned rewrite rules
that non-deterministically reorder the input words.
Applying these rules result in a finite-state graph of
possible source reorderings, which is then searched
for the best possible candidate translation.
2.1 Features
Given a source sentence s of I words, the best trans-
lation hypothesis t? is defined as the sequence of J
words that maximizes a linear combination of fea-
330
ture functions:
t? = argmax
t,a
{
M?
m=1
?mhm(a, s, t)
}
(1)
where ?m is the weight associated with feature func-
tion hm and a denotes an alignment between source
and target phrases. Among the feature functions, the
peculiar form of the translation model constitute one
of the main difference between the n-gram approach
and standard phrase-based systems. This will be fur-
ther detailled in section 2.2 and 3.
In addition to the translation model, fourteen
feature functions are combined: a target-language
model (Section 5.3); four lexicon models; six lexi-
calized reordering models (Tillmann, 2004; Crego
et al, 2011) aiming at predicting the orientation of
the next translation unit; a ?weak? distance-based
distortion model; and finally a word-bonus model
and a tuple-bonus model which compensate for the
system preference for short translations. The four
lexicon models are similar to the ones used in stan-
dard phrase-based systems: two scores correspond
to the relative frequencies of the tuples and two lexi-
cal weights are estimated from the automatic word
alignments. The weights vector ? is learned us-
ing a discriminative training framework (Och, 2003)
(Minimum Error Rate Training (MERT)) using the
newstest2009 as development set and BLEU (Pap-
ineni et al, 2002) as the optimization criteria.
2.2 Standard n-gram translation models
n-gram translation models rely on a specific de-
composition of the joint probability of a sentence
pair P (s, t): a sentence pair is assumed to be
decomposed into a sequence of L bilingual units
called tuples defining a joint segmentation: (s, t) =
u1, ..., uL2. In the approach of (Marin?o et al, 2006),
this segmentation is a by-product of source reorder-
ing obtained by ?unfolding? initial word alignments.
In this framework, the basic translation units are
tuples, which are the analogous of phrase pairs and
represent a matching u = (s, t) between a source
s and a target t phrase (see Figure 1). Using the
n-gram assumption, the joint probability of a seg-
2From now on, (s, t) thus denotes an aligned sentence pair,
and we omit the alignment variable a in further developments.
mented sentence pair decomposes as:
P (s, t) =
L?
i=1
P (ui|ui?1, ..., ui?n+1) (2)
During the training phase (Marin?o et al, 2006), tu-
ples are extracted from a word-aligned corpus (us-
ing MGIZA++3 with default settings) in such a
way that a unique segmentation of the bilingual
corpus is achieved. A baseline n-gram translation
model is then estimated over a training corpus com-
posed of tuple sequences using modified Knesser-
Ney Smoothing (Chen and Goodman, 1998).
2.3 Inference
During decoding, source sentences are represented
in the form of word lattices containing the most
promising reordering hypotheses, so as to reproduce
the word order modifications introduced during the
tuple extraction process. Hence, only those reorder-
ing hypotheses are translated and they are intro-
duced using a set of reordering rules automatically
learned from the word alignments.
In the example in Figure 1, the rule [prix no-
bel de la paix ; nobel de la paix prix] repro-
duces the invertion of the French words that is ob-
served when translating from French into English.
Typically, part-of-speech (POS) information is used
to increase the generalization power of these rules.
Hence, rewrite rules are built using POS rather than
surface word forms (Crego and Marin?o, 2006).
3 SOUL translation models
A first issue with the model described by equa-
tion (2) is that the elementary units are bilingual
pairs. As a consequence, the underlying vocabulary,
hence the number of parameters, can be quite large,
even for small translation tasks. Due to data sparsity
issues, such model are bound to face severe estima-
tion problems. Another problem with (2) is that the
source and target sides play symmetric roles: yet,
in decoding, the source side is known and only the
target side must be predicted.
3.1 A word factored translation model
To overcome these issues, the n-gram probability in
equation (2) can be factored by decomposing tuples
3http://www.kyloo.net/software/doku.php
331
 s?
8
: ? 
 t
?
8
: to 
 s?
9
: recevoir 
 t
?
9
: receive 
 s?
10
: le 
 t
?
10
: the 
 s?
11
: nobel de la paix 
 t
?
11
: nobel peace 
 s?
12
: prix 
 t
?
12
: prize 
 u
8
  u
9
  u
10
  u
11
  u
12
 
S :   .... 
T :   .... 
? recevoir le prix nobel de la paixorg :   ....
....
....
Figure 1: Extract of a French-English sentence pair segmented into bilingual units. The original (org) French sentence
appears at the top of the figure, just above the reordered source s and target t. The pair (s, t) decomposes into a
sequence of L bilingual units (tuples) u1, ..., uL. Each tuple ui contains a source and a target phrase: si and ti.
in two parts (source and target), and by taking words
as the basic units of the n-gram TM. This may seem
to be a regression with respect to current state-of-
the-art SMT systems, as the shift from the word-
based model of (Brown et al, 1993) to the phrase-
based models of (Zens et al, 2002) is usually con-
sidered as a major breakthrough of the recent years.
Indeed, one important motivation for considering
phrases was to capture local context in translation
and reordering. It should however be emphasized
that the decomposition of phrases into words is only
re-introduced here as a way to mitigate the param-
eter estimation problems. Translation units are still
pairs of phrases, derived from a bilingual segmen-
tation in tuples synchronizing the source and target
n-gram streams. In fact, the estimation policy de-
scribed in section 4 will actually allow us to take into
account larger contexts than is possible with conven-
tional n-gram models.
Let ski denote the k
th word of source tuple si.
Considering the example of Figure 1, s111 denotes
the source word nobel, s411 the source word paix.
We finally denote hn?1(tki ) the sequence made of
the n? 1 words preceding tki in the target sentence:
in Figure 1, h3(t211) thus refers to the three words
context receive the nobel associated with t211 peace.
Using these notations, equation (2) is rewritten as:
P (a, s, t) =
L?
i=1
[ |ti|?
k=1
P
(
tki |h
n?1(tki ), h
n?1(s1i+1)
)
?
|si|?
k=1
P
(
ski |h
n?1(t1i ), h
n?1(ski )
)] (3)
This decomposition relies on the n-gram assump-
tion, this time at the word level. Therefore, this
model estimates the joint probability of a sentence
pair using two sliding windows of length n, one for
each language; however, the moves of these win-
dows remain synchronized by the tuple segmenta-
tion. Moreover, the context is not limited to the cur-
rent phrase, and continues to include words from ad-
jacent phrases. Using the example of Figure 1, the
contribution of the target phrase t11 = nobel, peace
to P (s, t) using a 3- gram model is:
P
(
nobel|[receive, the], [la, paix]
)
?P
(
peace|[the, nobel], [la, paix]
)
.
A benefit of this new formulation is that the vo-
cabularies involved only contain words, and are thus
much smaller that tuple vocabularies. These models
are thus less at risk to be plagued by data sparsity is-
sues. Moreover, the decomposition (3) now involves
two models: the first term represents a TM, the sec-
ond term is best viewed as a reordering model. In
this formulation, the TM only predicts the target
phrase, given its source and target contexts.
P (s, t) =
L?
i=1
[ |si|?
k=1
P
(
ski |h
n?1(ski ), h
n?1(t1i+1)
)
?
|ti|?
k=1
P
(
tki |h
n?1(s1i ), h
n?1(tki )
)] (4)
4 The principles of SOUL
In section 3.1, we defined a n-gram translation
model based on equations (3) and (4). A major diffi-
culty with such models is to reliably estimate their
parameters, the numbers of which grow exponen-
tially with the order of the model. This problem
is aggravated in natural language processing due to
332
the well-known data sparsity issue. In this work,
we take advantage of the recent proposal of (Le et
al., 2011). Using a specific neural network architec-
ture (the Structured OUtput Layer or SOUL model),
it becomes possible to handle large vocabulary lan-
guage modeling tasks. This approach was experi-
mented last year for target language models only and
is now extended to translation models. More details
about the SOUL architecture can be found in (Le et
al., 2011), while its extension to translation models
is more precisely described in (Hai-Son et al, 2012).
The integration of SOUL models for large SMT
tasks is carried out using a two-pass approach: the
first pass uses conventional back-off n-gram trans-
lation and language models to produce a k-best list
(the k most likely translations); in the second pass,
the probability of a m-gram SOUL model is com-
puted for each hypothesis and the k-best list is ac-
cordingly reordered. In all the following experi-
ments, we used a context size for SOUL of m = 10,
and used k = 300. The two decompositions of equa-
tions (3) and (4) are used by introducing 4 scores
during the rescoring step.
5 Corpora and data pre-processing
Concerning data pre-processing, we started from our
submissions from last year (Allauzen et al, 2011)
and mainly upgraded the corpora and the associated
language-dependent pre-processing routines.
5.1 Pre-processing
We used in-house text processing tools for the to-
kenization and detokenization steps (De?chelotte et
al., 2008). Previous experiments have demonstrated
that better normalization tools provide better BLEU
scores: all systems are thus built in ?true-case?.
Compared to last year, the pre-processing of utf-8
characters was significantly improved.
As German is morphologically more complex
than English, the default policy which consists in
treating each word form independently is plagued
with data sparsity, which severely impacts both
training (alignment) and decoding (due to unknown
forms). When translating from German into En-
glish, the German side is thus normalized using a
specific pre-processing scheme (described in (Al-
lauzen et al, 2010; Durgar El-Kahlout and Yvon,
2010)), which aims at reducing the lexical redun-
dancy by (i) normalizing the orthography, (ii) neu-
tralizing most inflections and (iii) splitting complex
compounds. All parallel corpora were POS-tagged
with the TreeTagger (Schmid, 1994); in addition, for
German, fine-grained POS labels were also needed
for pre-processing and were obtained using the RF-
Tagger (Schmid and Laws, 2008).
5.2 Bilingual corpora
As for last year?s evaluation, we used all the avail-
able parallel data for the German-English language
pair, while only a subpart of the French-English par-
allel data was selected. Word alignment models
were trained using all the data, whereas the transla-
tion models were estimated on a subpart of the par-
allel data: the UN corpus was discarded for this step
and about half of the French-English Giga corpus
was filtered based on a perplexity criterion as in (Al-
lauzen et al, 2011)).
For French-English, we mainly upgraded the
training material from last year by extracting the
new parts from the common data. The word
alignment models trained last year were then up-
dated by running a forced alignment 4 of the new
data. These new word-aligned data was added to
last year?s parallel corpus and constitute the train-
ing material for the translation models and feature
functions described in Section 2. Given the large
amount of available data, three different bilingual
n-gram models are estimated, one for each source of
data: News-Commentary, Europarl, and the French-
English Giga corpus. These models are then added
to the weighted mixture defined by equation (1). For
German-English, we simply used all the available
parallel data to train one single translation models.
5.3 Monolingual corpora and language models
For the monolingual training data, we also used the
same setup as last year. For German, all the train-
ing data allowed in the constrained task were di-
vided into several sets based on dates or genres:
News-Commentary, the news crawled from the Web
grouped by year, and Europarl. For each subset,
a standard 4-gram LM was estimated using inter-
polated Kneser-Ney smoothing (Kneser and Ney,
4The forced alignment step consists in an additional EM it-
eration.
333
1995; Chen and Goodman, 1998). The resulting
LMs are then linearly combined using interpolation
coefficients chosen so as to minimize the perplexity
of the development set. The German vocabulary is
created using all the words contained in the parallel
data and expanded to reach a total of 500k words by
including the most frequent words observed in the
monolingual News data for 2011.
For French and English, the same monolingual
corpora as last year were used5. We did not observe
any perplexity decrease in our attempts to include
the new data specifically provided for this year?s
evaluation. We therefore used the same language
models as in (Allauzen et al, 2011).
6 ?On-the-fly? system
We also developped an alternative approach imple-
menting ?on-the-fly? estimation of the parameter of
a standard phase-based model, using Moses (Koehn
et al, 2007) as the decoder. Implementing on-the-
fly estimation for n-code, while possible in the-
ory, is less appealing due to the computational cost
of estimating a smoothed language model. Given
an input source file, it is possible to compute only
those statistics which are required to translate the
phrases it contains. As in previous works on on-
the-fly model estimation for SMT (Callison-Burch
et al, 2005; Lopez, 2008), we compute a suffix
array for the source corpus. This further enables
to consider only a subset of translation examples,
which we select by deterministic random sampling,
meaning that the sample is chosen randomly with
respect to the full corpus but that the same sample
is always returned for a given value of sample size,
hereafter denoted N . In our experiments, we used
N = 1, 000 and computed from the sample and the
word alignments (we used the same tokenization and
word alignments as in all other submitted systems)
the same translation6 and lexical reordering models
as the standard training scripts of the Moses system.
Experiments were run on the data sets used for
WMT English-French machine translation evalua-
tion tasks, using the same corpora and optimization
5The fifth edition of the English Gigaword (LDC2011T07)
was not used.
6An approximation is used for p(f |e), and coherent transla-
tion estimation is used; see (Lopez, 2008).
procedure as in our other experiments. The only no-
table difference is our use of the Moses decoder in-
stead of the n-gram-based system. As shown in Ta-
ble 1, our on-the-fly system achieves a result (31.7
BLEU point) that is slightly worst than the n-code
baseline (32.0) and slightly better than the equiva-
lent Moses baseline (31.5), but does it much faster.
Model estimation for the test file is reduced to 2
hours and 50 minutes, with an additional overhead
for loading and writing files of one and a half hours,
compared to roughly 210 hours for our baseline sys-
tems under comparable hardware conditions.
7 Experimental results
7.1 n-code with SOUL
Table 1 summarizes the experimental results sub-
mitted to the shared translation for French-English
and German-English in both directions. The perfor-
mances are measured in terms of BLEU on new-
stest2011, last year?s test set, and this year?s test
set newstest2012. For the former, BLEU scores are
computed with the NIST script mteva-v13.pl, while
we provide for newstest2012 the results computed
by the organizers 7. The Baseline results are ob-
tained with standard n-gram models estimated with
back-off, both for the bilingual and monolingual tar-
get models. With standard n-gram estimates, the or-
der is limited to n = 4. For instance, the n-code
French-English baseline achieves a 0.5 BLEU point
improvement over a Moses system trained with the
same data setup in both directions.
From Table 1, it can be observed that adding
the SOUL models (translation models and target
language model) consistently improves the base-
line, with an increase of 1 BLEU point. Con-
trastive experiments show that the SOUL target LM
does not bring significant gain when added to the
SOUL translation models. For instance, a gain of
0.3 BLEU point is observed when translating from
French to English with the addition of the SOUL tar-
get LM. In the other translation directions, the differ-
ences are negligible.
7All results come from the official website: http://
matrix.statmt.org/matrix/.
334
Direction System BLEU
test2011 test2012?
en2fr Baseline 32.0 28.9
+ SOUL TM 33.4 29.9
on-the-fly 31.7 28.6
fr2en Baseline 30.2 30.4
+ SOUL TM 31.1 31.5
en2de Baseline 15.4 16.0
+ SOUL TM 16.6 17.0
de2en Baseline 21.8 22.9
+ SOUL TM 22.8 23.9
Table 1: Experimental results in terms of BLEU scores
measured on the newstest2011 and newstest2012. For
newstest2012, the scores are provided by the organizers.
7.2 Experiments with additional features
For this year?s evaluation, we also investigated sev-
eral additional features based on IBM1 models and
word sense disambiguation (WSD) information in
rescoring. As for the SOUL models, these features
are added after the n-best list generation step.
In previous work (Och et al, 2004; Hasan, 2011),
the IBM1 features (Brown et al, 1993) are found
helpful. As the IBM1 model is asymmetric, two
models are estimated, one in both directions. Con-
trary to the reported results, these additional features
do not yield significant improvements over the base-
line system. We assume that the difficulty is to add
information to an already extensively optimized sys-
tem. Moreover, the IBM1 models are estimated on
the same training corpora as the translation system,
a fact that may explain the redundancy of these ad-
ditional features.
In a separate series of experiments, we also add
WSD features calculated according to a variation of
the method proposed in (Apidianaki, 2009). For
each word of a subset of the input (source lan-
guage) vocabulary, a simple WSD classifier pro-
duces a probability distribution over a set of trans-
lations8. During reranking, each translation hypoth-
esis is scanned and the word translations that match
one of the proposed variant are rewarded using an
additional score. While this method had given some
8The difference with the method described in (Apidianaki,
2009) is that no sense clustering is performed, and each transla-
tion is represented by a separate weighted source feature vector
which is used for disambiguation
small gains on a smaller dataset (IWSLT?11), we did
not observe here any improvement over the base-
line system. Additional analysis hints that (i) most
of the proposed variants are already covered by the
translation model with high probabilities and (ii) that
these variants are seldom found in the reference sen-
tences. This means that, in the situation in which
only one reference is provided, the hypotheses with
a high score for the WSD feature are not adequately
rewarded with the actual references.
8 Conclusion
In this paper, we described our submissions to
WMT?12 in the French-English and German-
English shared translation tasks, in both directions.
As for our last year?s participation, our main sys-
tems are built with n-code, the open source Statis-
tical Machine Translation system based on bilingual
n-grams. Our contributions are threefold. First, we
have experimented a new kind of translation mod-
els, where the bilingual n-gram distribution are es-
timated in a continuous space with neural networks.
As shown in past evaluations with target language
model, there is a significant reward for using this
kind of models in a rescoring step. We observed that,
in general, the continuous space translation model
yields a slightly larger improvement than the target
translation model. However, their combination does
not result in an additional gain.
We also reported preliminary results with a sys-
tem ?on-the-fly?, where the training data are sam-
pled according to the data to be translated in order
to train contextually adapted system. While this sys-
tem achieves comparable performance to our base-
line system, it is worth noticing that its total train-
ing time is much smaller than a comparable Moses
system. Finally, we investigated several additional
features based on IBM1 models and word sense dis-
ambiguation information in rescoring. While these
methods have sometimes been reported to help im-
prove the results, we did not observe any improve-
ment here over the baseline system.
Acknowledgment
This work was partially funded by the French State
agency for innovation (OSEO) in the Quaero Pro-
gramme.
335
References
Alexandre Allauzen, Josep M. Crego, I?lknur Durgar El-
Kahlout, and Franc?ois Yvon. 2010. LIMSI?s statis-
tical translation systems for WMT?10. In Proc. of the
Joint Workshop on Statistical Machine Translation and
MetricsMATR, pages 54?59, Uppsala, Sweden.
Alexandre Allauzen, Gilles Adda, He?le`ne Bonneau-
Maynard, Josep M. Crego, Hai-Son Le, Aure?lien Max,
Adrien Lardilleux, Thomas Lavergne, Artem Sokolov,
Guillaume Wisniewski, and Franc?ois Yvon. 2011.
LIMSI @ WMT11. In Proceedings of the Sixth Work-
shop on Statistical Machine Translation, pages 309?
315, Edinburgh, Scotland, July. Association for Com-
putational Linguistics.
Marianna Apidianaki. 2009. Data-driven semantic anal-
ysis for multilingual WSD and lexical selection in
translation. In Proceedings of the 12th Conference of
the European Chapter of the ACL (EACL 2009), pages
77?85, Athens, Greece, March. Association for Com-
putational Linguistics.
Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della
Pietra, and Robert L. Mercer. 1993. The mathemat-
ics of statistical machine translation: parameter esti-
mation. Comput. Linguist., 19(2):263?311.
Chris Callison-Burch, Colin Bannard, and Josh
Schroeder. 2005. Scaling phrase-based statisti-
cal machine translation to larger corpora and longer
phrases. In Proceedings of the 43rd Annual Meeting
of the Association for Computational Linguistics
(ACL?05), pages 255?262, Ann Arbor, Michigan,
June. Association for Computational Linguistics.
Francesco Casacuberta and Enrique Vidal. 2004. Ma-
chine translation with inferred stochastic finite-state
transducers. Computational Linguistics, 30(3):205?
225.
Stanley F. Chen and Joshua T. Goodman. 1998. An
empirical study of smoothing techniques for language
modeling. Technical Report TR-10-98, Computer Sci-
ence Group, Harvard Un iversity.
Josep M. Crego and Jose? B. Marin?o. 2006. Improving
statistical MT by coupling reordering and decoding.
Machine Translation, 20(3):199?215.
Josep M. Crego, Franc?ois Yvon, and Jose? B. Marin?o.
2011. N-code: an open-source Bilingual N-gram SMT
Toolkit. Prague Bulletin of Mathematical Linguistics,
96:49?58.
Ilknur Durgar El-Kahlout and Franc?ois Yvon. 2010. The
pay-offs of preprocessing for German-English Statis-
tical Machine Translation. In Marcello Federico, Ian
Lane, Michael Paul, and Franc?ois Yvon, editors, Pro-
ceedings of the seventh International Workshop on
Spoken Language Translation (IWSLT), pages 251?
258.
Daniel De?chelotte, Gilles Adda, Alexandre Allauzen,
Olivier Galibert, Jean-Luc Gauvain, He?le`ne May-
nard, and Franc?ois Yvon. 2008. LIMSI?s statisti-
cal translation systems for WMT?08. In Proc. of the
NAACL-HTL Statistical Machine Translation Work-
shop, Columbus, Ohio.
Hai-Son, Alexandre Allauzen, and Franc?ois Yvon. 2012.
Continuous space translation models with neural net-
works. In NAACL ?12: Proceedings of the 2012 Con-
ference of the North American Chapter of the Associ-
ation for Computational Linguistics on Human Lan-
guage Technology.
Sas?a Hasan. 2011. Triplet Lexicon Models for Statisti-
cal Machine Translation. Ph.D. thesis, RWTH Aachen
University.
Reinhard Kneser and Herman Ney. 1995. Improved
backing-off for m-gram language modeling. In Pro-
ceedings of the International Conference on Acoustics,
Speech, and Signal Processing, ICASSP?95, pages
181?184, Detroit, MI.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open source
toolkit for statistical machine translation. In Proceed-
ings of the 45th Annual Meeting of the Association for
Computational Linguistics Companion Volume Pro-
ceedings of the Demo and Poster Sessions, pages 177?
180, Prague, Czech Republic, June. Association for
Computational Linguistics.
Hai-Son Le, Ilya Oparin, Alexandre Allauzen, Jean-Luc
Gauvain, and Franc?ois Yvon. 2011. Structured output
layer neural network language model. In Proceedings
of ICASSP?11, pages 5524?5527.
Adam Lopez. 2008. Tera-scale translation models via
pattern matching. In Proceedings of the 22nd Interna-
tional Conference on Computational Linguistics (Col-
ing 2008), pages 505?512, Manchester, UK, August.
Coling 2008 Organizing Committee.
Jose? B. Marin?o, Rafael E. Banchs, Josep M. Crego, Adria`
de Gispert, Patrick Lambert, Jose? A.R. Fonollosa, and
Marta R. Costa-Jussa`. 2006. N-gram-based machine
translation. Computational Linguistics, 32(4):527?
549.
Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur,
Anoop Sarkar, Kenji Yamada, Alex Fraser, Shankar
Kumar, Libin Shen, David Smith, Katherine Eng,
Viren Jain, Zhen Jin, and Dragomir Radev. 2004. A
smorgasbord of features for statistical machine trans-
lation. In Daniel Marcu Susan Dumais and Salim
Roukos, editors, HLT-NAACL 2004: Main Proceed-
ings, pages 161?168, Boston, Massachusetts, USA,
336
May 2 - May 7. Association for Computational Lin-
guistics.
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In ACL ?03: Proc. of
the 41st Annual Meeting on Association for Computa-
tional Linguistics, pages 160?167.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic eval-
uation of machine translation. In ACL ?02: Proc. of
the 40th Annual Meeting on Association for Compu-
tational Linguistics, pages 311?318. Association for
Computational Linguistics.
Helmut Schmid and Florian Laws. 2008. Estimation
of conditional probabilities with decision trees and an
application to fine-grained POS tagging. In Proceed-
ings of the 22nd International Conference on Com-
putational Linguistics (Coling 2008), pages 777?784,
Manchester, UK, August.
Helmut Schmid. 1994. Probabilistic part-of-speech tag-
ging using decision trees. In Proc. of International
Conference on New Methods in Language Processing,
pages 44?49, Manchester, UK.
Christoph Tillmann. 2004. A unigram orientation model
for statistical machine translation. In Proceedings of
HLT-NAACL 2004, pages 101?104. Association for
Computational Linguistics.
Richard Zens, Franz Josef Och, and Hermann Ney. 2002.
Phrase-based statistical machine translation. In KI
?02: Proceedings of the 25th Annual German Con-
ference on AI, pages 18?32, London, UK. Springer-
Verlag.
337
